{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random \n",
    "from torchvision.datasets import ImageFolder\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "########## Mean and std are calculated from the train dataset\n",
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(90),\n",
    "    # random brightness and random contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "118\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "batchsize=4\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset = CovidCTDataset(root_dir='/home/wangchenxu/covid/Images-processed',\n",
    "                                   txt_COVID='/home/wangchenxu/covid/Data-split/COVID/trainCT_COVID.txt',\n",
    "                                   txt_NonCOVID='/home/wangchenxu/covid/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                                   transform=train_transformer)\n",
    "    valset = CovidCTDataset(root_dir='/home/wangchenxu/covid/Images-processed',\n",
    "                                 txt_COVID='/home/wangchenxu/covid/Data-split/COVID/valCT_COVID.txt',\n",
    "                                 txt_NonCOVID='/home/wangchenxu/covid/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                                 transform=val_transformer)\n",
    "    testset = CovidCTDataset(root_dir='/home/wangchenxu/covid/Images-processed',\n",
    "                                 txt_COVID='/home/wangchenxu/covid/Data-split/COVID/testCT_COVID.txt',\n",
    "                                 txt_NonCOVID='/home/wangchenxu/covid/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                                 transform=val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a559b5e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_index, batch_samples in enumerate(train_loader):      \n",
    "        data, target = batch_samples['img'], batch_samples['label']\n",
    "skimage.io.imshow(data[0,1,:,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process is defined here \n",
    "\n",
    "alpha = None\n",
    "## alpha is None if mixup is not used\n",
    "alpha_name = f'{alpha}'\n",
    "device = 'cuda'\n",
    "\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        \n",
    "        ## adjust data to meet the input dimension of model\n",
    "#         data = data[:, 0, :, :]\n",
    "#         data = data[:, None, :, :]    \n",
    "        \n",
    "        #mixup\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target, alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "        \n",
    "        #mixup loss\n",
    "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    \n",
    "#     print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "#         100.0 * train_correct / len(train_loader.dataset)))\n",
    "#     f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "#     f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "#         100.0 * train_correct / len(train_loader.dataset)))\n",
    "#     f.write('\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val process is defined here\n",
    "\n",
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            \n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist\n",
    "    \n",
    "    # Write to tensorboard\n",
    "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test process is defined here \n",
    "\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "# #             # FN    predict 0 label 1\n",
    "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "# #             # FP    predict 1 label 0\n",
    "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "    return targetlist, scorelist, predlist\n",
    "    \n",
    "    # Write to tensorboard\n",
    "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dense169\n",
    "import torchvision.models as models\n",
    "model = models.densenet169(pretrained=True).cuda()\n",
    "# modelname = 'Dense169'\n",
    "\n",
    "\"\"\"load MoCo pretrained model\"\"\"\n",
    "checkpoint = torch.load('save_model_dense/checkpoint_luna_covid.tar')\n",
    "# # # print(checkpoint.keys())\n",
    "# # # print(checkpoint['arch'])\n",
    "\n",
    "state_dict = checkpoint['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    if 'module.encoder_q' in key:\n",
    "#         print(key[17:])\n",
    "        new_key = key[17:]\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "    del state_dict[key]\n",
    "for key in list(state_dict.keys()):\n",
    "    if  key == 'classifier.0.weight':\n",
    "        new_key = 'classifier.weight'\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "    if  key == 'classifier.0.bias':\n",
    "        new_key = 'classifier.bias'\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "    if  key == 'classifier.2.weight' or key == 'classifier.2.bias':\n",
    "        del state_dict[key]\n",
    "state_dict['classifier.weight'] = state_dict['classifier.weight'][:1000,:]\n",
    "state_dict['classifier.bias'] = state_dict['classifier.bias'][:1000]\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# # # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Change names and locations to the Self-Trans.pt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load Self-Trans model\"\"\"\n",
    "\"\"\"Change names and locations to the Self-Trans.pt\"\"\"\n",
    "\n",
    "\n",
    "# model = models.densenet169(pretrained=True).cuda()\n",
    "# pretrained_net = torch.load('Self-Trans.pt')\n",
    "\n",
    "# model.load_state_dict(pretrained_net)\n",
    "\n",
    "# modelname = 'Dense169_ssl_luna_moco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/107 (0%)]\tTrain Loss: 1.789013\n",
      "Train Epoch: 1 [4/107 (4%)]\tTrain Loss: 1.305024\n",
      "Train Epoch: 1 [8/107 (7%)]\tTrain Loss: 0.552971\n",
      "Train Epoch: 1 [12/107 (11%)]\tTrain Loss: 0.188670\n",
      "Train Epoch: 1 [16/107 (15%)]\tTrain Loss: 0.195091\n",
      "Train Epoch: 1 [20/107 (19%)]\tTrain Loss: 0.148177\n",
      "Train Epoch: 1 [24/107 (22%)]\tTrain Loss: 0.154550\n",
      "Train Epoch: 1 [28/107 (26%)]\tTrain Loss: 0.195373\n",
      "Train Epoch: 1 [32/107 (30%)]\tTrain Loss: 0.136773\n",
      "Train Epoch: 1 [36/107 (34%)]\tTrain Loss: 0.453245\n",
      "Train Epoch: 1 [40/107 (37%)]\tTrain Loss: 0.068195\n",
      "Train Epoch: 1 [44/107 (41%)]\tTrain Loss: 0.152751\n",
      "Train Epoch: 1 [48/107 (45%)]\tTrain Loss: 0.194741\n",
      "Train Epoch: 1 [52/107 (49%)]\tTrain Loss: 0.326931\n",
      "Train Epoch: 1 [56/107 (52%)]\tTrain Loss: 0.276739\n",
      "Train Epoch: 1 [60/107 (56%)]\tTrain Loss: 0.140563\n",
      "Train Epoch: 1 [64/107 (60%)]\tTrain Loss: 0.175018\n",
      "Train Epoch: 1 [68/107 (64%)]\tTrain Loss: 0.126016\n",
      "Train Epoch: 1 [72/107 (67%)]\tTrain Loss: 0.133005\n",
      "Train Epoch: 1 [76/107 (71%)]\tTrain Loss: 0.114113\n",
      "Train Epoch: 1 [80/107 (75%)]\tTrain Loss: 0.206758\n",
      "Train Epoch: 1 [84/107 (79%)]\tTrain Loss: 0.171383\n",
      "Train Epoch: 1 [88/107 (82%)]\tTrain Loss: 0.044376\n",
      "Train Epoch: 1 [92/107 (86%)]\tTrain Loss: 0.103423\n",
      "Train Epoch: 1 [96/107 (90%)]\tTrain Loss: 0.111306\n",
      "Train Epoch: 1 [100/107 (93%)]\tTrain Loss: 0.100516\n",
      "Train Epoch: 1 [104/107 (97%)]\tTrain Loss: 0.204808\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.79606664 0.65109622 0.5936662  0.8106876  0.75461465 0.5785436\n",
      " 0.34345904 0.95639879 0.25576124 0.12802351 0.8838433  0.12118156\n",
      " 0.65744388 0.71979672 0.91224515 0.38120627 0.69327569 0.42126298\n",
      " 0.19225645 0.6377759  0.71551102 0.90333247 0.79884422 0.70076883\n",
      " 0.6137293  0.58820081 0.58272541 0.91989964 0.85981864 0.95397276\n",
      " 0.94827163 0.9185369  0.8753081  0.23399001 0.16466412 0.28126138\n",
      " 0.37184706 0.8367787  0.74284607 0.28439325 0.50651222 0.47015828\n",
      " 0.74284613 0.96645802 0.93722218 0.46092367 0.8220005  0.72021657\n",
      " 0.6105296  0.29337886 0.83340776 0.35154495 0.67814863 0.90185946\n",
      " 0.45738792 0.58093715 0.78905916 0.4643603  0.29801789 0.92446303\n",
      " 0.90761608 0.96359485 0.92469525 0.86761153 0.98396862 0.98122036\n",
      " 0.74334896 0.99126446 0.94923156 0.60752273 0.69958818 0.7044096\n",
      " 0.56423122 0.71125114 0.93548644 0.87337291 0.83663642 0.74603486\n",
      " 0.99147207 0.98380131 0.90260172 0.93330389 0.88098055 0.71866333\n",
      " 0.73238933 0.6638087  0.88419259 0.87405533 0.24033616 0.35900331\n",
      " 0.10492475 0.75412029 0.82574612 0.95632875 0.88831586 0.81657231\n",
      " 0.74945533 0.50785041 0.63309491 0.74099553 0.76373321 0.56753814\n",
      " 0.71194613 0.34119138 0.46117884 0.45995569 0.32452306 0.3250885\n",
      " 0.3778193  0.78724569 0.66401625 0.16566533 0.91244572 0.39704373\n",
      " 0.24078485 0.28525251 0.64691371 0.93173558]\n",
      "predict [1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 2 [0/107 (0%)]\tTrain Loss: 0.107453\n",
      "Train Epoch: 2 [4/107 (4%)]\tTrain Loss: 0.126003\n",
      "Train Epoch: 2 [8/107 (7%)]\tTrain Loss: 0.308908\n",
      "Train Epoch: 2 [12/107 (11%)]\tTrain Loss: 0.139928\n",
      "Train Epoch: 2 [16/107 (15%)]\tTrain Loss: 0.037316\n",
      "Train Epoch: 2 [20/107 (19%)]\tTrain Loss: 0.137423\n",
      "Train Epoch: 2 [24/107 (22%)]\tTrain Loss: 0.058772\n",
      "Train Epoch: 2 [28/107 (26%)]\tTrain Loss: 0.129053\n",
      "Train Epoch: 2 [32/107 (30%)]\tTrain Loss: 0.074727\n",
      "Train Epoch: 2 [36/107 (34%)]\tTrain Loss: 0.212747\n",
      "Train Epoch: 2 [40/107 (37%)]\tTrain Loss: 0.057298\n",
      "Train Epoch: 2 [44/107 (41%)]\tTrain Loss: 0.315992\n",
      "Train Epoch: 2 [48/107 (45%)]\tTrain Loss: 0.099959\n",
      "Train Epoch: 2 [52/107 (49%)]\tTrain Loss: 0.296092\n",
      "Train Epoch: 2 [56/107 (52%)]\tTrain Loss: 0.160080\n",
      "Train Epoch: 2 [60/107 (56%)]\tTrain Loss: 0.066490\n",
      "Train Epoch: 2 [64/107 (60%)]\tTrain Loss: 0.090523\n",
      "Train Epoch: 2 [68/107 (64%)]\tTrain Loss: 0.031025\n",
      "Train Epoch: 2 [72/107 (67%)]\tTrain Loss: 0.192047\n",
      "Train Epoch: 2 [76/107 (71%)]\tTrain Loss: 0.156979\n",
      "Train Epoch: 2 [80/107 (75%)]\tTrain Loss: 0.227162\n",
      "Train Epoch: 2 [84/107 (79%)]\tTrain Loss: 0.079201\n",
      "Train Epoch: 2 [88/107 (82%)]\tTrain Loss: 0.083881\n",
      "Train Epoch: 2 [92/107 (86%)]\tTrain Loss: 0.039194\n",
      "Train Epoch: 2 [96/107 (90%)]\tTrain Loss: 0.112722\n",
      "Train Epoch: 2 [100/107 (93%)]\tTrain Loss: 0.091651\n",
      "Train Epoch: 2 [104/107 (97%)]\tTrain Loss: 0.265394\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.77128112 0.88162839 0.74843359 0.67600965 0.73370874 0.44572595\n",
      " 0.8369258  0.89931011 0.50665581 0.03093742 0.34553087 0.03888933\n",
      " 0.66197199 0.76805872 0.95060188 0.03639765 0.07317619 0.36823252\n",
      " 0.11446654 0.70047766 0.93918061 0.88400352 0.87733841 0.93958563\n",
      " 0.42573297 0.80378431 0.9068042  0.89785123 0.80316061 0.85834706\n",
      " 0.64223933 0.72150147 0.68070203 0.03705116 0.03637976 0.11634333\n",
      " 0.08554392 0.57547355 0.6389873  0.26823556 0.15466949 0.36239415\n",
      " 0.75198501 0.6165278  0.7789681  0.07310393 0.42740974 0.47454041\n",
      " 0.65624058 0.37655351 0.74901187 0.07344569 0.22796997 0.24577108\n",
      " 0.2098897  0.29722106 0.49291801 0.17751561 0.09213977 0.6651758\n",
      " 0.86017799 0.83020037 0.80435324 0.93551505 0.99176019 0.99937457\n",
      " 0.99028921 0.99998116 0.99993098 0.99197525 0.24799584 0.27442148\n",
      " 0.5425477  0.93621361 0.99049944 0.942729   0.99400699 0.96967334\n",
      " 0.98975414 0.98512059 0.98886991 0.99472284 0.99500161 0.76888645\n",
      " 0.73794377 0.55514145 0.91593969 0.88389832 0.49540254 0.8218407\n",
      " 0.96039045 0.79098976 0.72158086 0.99974221 0.94484556 0.98544878\n",
      " 0.36286679 0.53656018 0.17960443 0.99425298 0.69775796 0.44310364\n",
      " 0.27695364 0.15769163 0.11673237 0.66148835 0.79957801 0.45520532\n",
      " 0.64349014 0.49988574 0.97520113 0.51251155 0.99682295 0.54421026\n",
      " 0.88951606 0.83974212 0.61690456 0.91674769]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 3 [0/107 (0%)]\tTrain Loss: 0.290380\n",
      "Train Epoch: 3 [4/107 (4%)]\tTrain Loss: 0.268830\n",
      "Train Epoch: 3 [8/107 (7%)]\tTrain Loss: 0.213153\n",
      "Train Epoch: 3 [12/107 (11%)]\tTrain Loss: 0.055553\n",
      "Train Epoch: 3 [16/107 (15%)]\tTrain Loss: 0.060793\n",
      "Train Epoch: 3 [20/107 (19%)]\tTrain Loss: 0.151884\n",
      "Train Epoch: 3 [24/107 (22%)]\tTrain Loss: 0.227482\n",
      "Train Epoch: 3 [28/107 (26%)]\tTrain Loss: 0.070534\n",
      "Train Epoch: 3 [32/107 (30%)]\tTrain Loss: 0.074555\n",
      "Train Epoch: 3 [36/107 (34%)]\tTrain Loss: 0.047454\n",
      "Train Epoch: 3 [40/107 (37%)]\tTrain Loss: 0.038996\n",
      "Train Epoch: 3 [44/107 (41%)]\tTrain Loss: 0.131115\n",
      "Train Epoch: 3 [48/107 (45%)]\tTrain Loss: 0.042769\n",
      "Train Epoch: 3 [52/107 (49%)]\tTrain Loss: 0.313037\n",
      "Train Epoch: 3 [56/107 (52%)]\tTrain Loss: 0.037887\n",
      "Train Epoch: 3 [60/107 (56%)]\tTrain Loss: 0.151827\n",
      "Train Epoch: 3 [64/107 (60%)]\tTrain Loss: 0.337754\n",
      "Train Epoch: 3 [68/107 (64%)]\tTrain Loss: 0.665238\n",
      "Train Epoch: 3 [72/107 (67%)]\tTrain Loss: 0.065826\n",
      "Train Epoch: 3 [76/107 (71%)]\tTrain Loss: 0.018983\n",
      "Train Epoch: 3 [80/107 (75%)]\tTrain Loss: 0.035498\n",
      "Train Epoch: 3 [84/107 (79%)]\tTrain Loss: 0.352307\n",
      "Train Epoch: 3 [88/107 (82%)]\tTrain Loss: 0.247248\n",
      "Train Epoch: 3 [92/107 (86%)]\tTrain Loss: 0.011661\n",
      "Train Epoch: 3 [96/107 (90%)]\tTrain Loss: 0.085647\n",
      "Train Epoch: 3 [100/107 (93%)]\tTrain Loss: 0.391556\n",
      "Train Epoch: 3 [104/107 (97%)]\tTrain Loss: 0.244954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.13374150e-01 9.43699181e-01 8.94381225e-01 9.72586811e-01\n",
      " 9.57227290e-01 7.36821413e-01 8.96167934e-01 9.87408757e-01\n",
      " 4.54523236e-01 2.08751136e-03 1.90902010e-01 6.77178730e-04\n",
      " 5.79581618e-01 9.97043431e-01 9.90742862e-01 6.43843770e-01\n",
      " 5.28324783e-01 8.59744966e-01 4.14243303e-02 7.71848619e-01\n",
      " 8.44035149e-01 9.33930039e-01 9.95114923e-01 9.99727070e-01\n",
      " 7.99823165e-01 9.95372832e-01 9.99911904e-01 9.94859695e-01\n",
      " 8.70765209e-01 6.26746178e-01 9.89199638e-01 8.35961699e-01\n",
      " 9.58456755e-01 6.09313021e-04 2.65613460e-04 1.75833015e-03\n",
      " 2.77553983e-02 9.94211257e-01 7.03330457e-01 7.39212573e-01\n",
      " 7.14429200e-01 8.52145478e-02 9.63521063e-01 9.88932967e-01\n",
      " 9.98114705e-01 1.50008455e-01 1.64013267e-01 4.58071500e-01\n",
      " 8.89376104e-01 9.59929287e-01 9.43820655e-01 3.49995613e-01\n",
      " 4.79731619e-01 9.55325365e-01 1.77003921e-03 7.26353973e-02\n",
      " 9.42314148e-01 6.29474074e-02 2.30513397e-03 9.65427697e-01\n",
      " 9.60808754e-01 9.77690637e-01 9.95708704e-01 9.94144022e-01\n",
      " 9.83279228e-01 9.99844790e-01 9.98107791e-01 9.99941826e-01\n",
      " 9.99531150e-01 9.92529809e-01 9.14705932e-01 7.57535756e-01\n",
      " 9.98439729e-01 9.98871028e-01 9.99788344e-01 9.72912908e-01\n",
      " 9.61590946e-01 9.39867854e-01 9.97082531e-01 9.99538422e-01\n",
      " 9.98767138e-01 9.99408484e-01 9.84453142e-01 7.35426664e-01\n",
      " 2.83527613e-01 9.30827975e-01 9.82087314e-01 9.73345995e-01\n",
      " 4.47815150e-01 9.96615827e-01 9.99740779e-01 9.66679633e-01\n",
      " 9.32494760e-01 9.99989748e-01 9.89790976e-01 9.67414320e-01\n",
      " 1.10377088e-01 1.55616283e-01 2.72918463e-01 9.98001277e-01\n",
      " 6.77268505e-01 9.94104981e-01 2.97903538e-01 7.84918606e-01\n",
      " 6.24977291e-01 4.50981945e-01 7.72916496e-01 6.11788705e-02\n",
      " 3.06470960e-01 9.33311999e-01 8.08884203e-01 1.42924637e-01\n",
      " 9.98773754e-01 8.57621431e-01 9.84972596e-01 9.13844407e-01\n",
      " 1.58401743e-01 8.75068486e-01]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "Train Epoch: 4 [0/107 (0%)]\tTrain Loss: 0.307488\n",
      "Train Epoch: 4 [4/107 (4%)]\tTrain Loss: 0.047487\n",
      "Train Epoch: 4 [8/107 (7%)]\tTrain Loss: 0.271903\n",
      "Train Epoch: 4 [12/107 (11%)]\tTrain Loss: 0.024843\n",
      "Train Epoch: 4 [16/107 (15%)]\tTrain Loss: 0.143178\n",
      "Train Epoch: 4 [20/107 (19%)]\tTrain Loss: 0.302254\n",
      "Train Epoch: 4 [24/107 (22%)]\tTrain Loss: 0.139185\n",
      "Train Epoch: 4 [28/107 (26%)]\tTrain Loss: 0.119228\n",
      "Train Epoch: 4 [32/107 (30%)]\tTrain Loss: 0.029077\n",
      "Train Epoch: 4 [36/107 (34%)]\tTrain Loss: 0.046894\n",
      "Train Epoch: 4 [40/107 (37%)]\tTrain Loss: 0.046291\n",
      "Train Epoch: 4 [44/107 (41%)]\tTrain Loss: 0.052652\n",
      "Train Epoch: 4 [48/107 (45%)]\tTrain Loss: 0.116347\n",
      "Train Epoch: 4 [52/107 (49%)]\tTrain Loss: 0.431108\n",
      "Train Epoch: 4 [56/107 (52%)]\tTrain Loss: 0.038543\n",
      "Train Epoch: 4 [60/107 (56%)]\tTrain Loss: 0.256027\n",
      "Train Epoch: 4 [64/107 (60%)]\tTrain Loss: 0.137860\n",
      "Train Epoch: 4 [68/107 (64%)]\tTrain Loss: 0.096742\n",
      "Train Epoch: 4 [72/107 (67%)]\tTrain Loss: 0.391800\n",
      "Train Epoch: 4 [76/107 (71%)]\tTrain Loss: 0.051769\n",
      "Train Epoch: 4 [80/107 (75%)]\tTrain Loss: 0.159440\n",
      "Train Epoch: 4 [84/107 (79%)]\tTrain Loss: 0.169261\n",
      "Train Epoch: 4 [88/107 (82%)]\tTrain Loss: 0.042462\n",
      "Train Epoch: 4 [92/107 (86%)]\tTrain Loss: 0.032003\n",
      "Train Epoch: 4 [96/107 (90%)]\tTrain Loss: 0.260954\n",
      "Train Epoch: 4 [100/107 (93%)]\tTrain Loss: 0.293786\n",
      "Train Epoch: 4 [104/107 (97%)]\tTrain Loss: 0.184240\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.63445133e-01 2.29700701e-03 2.84841168e-03 3.37239146e-01\n",
      " 1.78510502e-01 1.79180503e-01 2.92253844e-03 1.44770086e-01\n",
      " 1.04222326e-02 3.12120486e-02 3.78032923e-01 2.01392584e-02\n",
      " 8.29207078e-02 8.87685735e-03 5.68892621e-03 1.14357885e-04\n",
      " 3.00442777e-03 3.94531906e-01 8.96036625e-02 9.54858884e-02\n",
      " 1.56349733e-01 2.72925824e-01 5.35338163e-01 9.82987761e-01\n",
      " 1.62725195e-01 4.15815264e-01 9.52278852e-01 4.94152278e-01\n",
      " 1.56595316e-02 1.27244983e-02 1.23901125e-02 1.56783890e-02\n",
      " 3.43360640e-02 5.04714495e-04 6.91059162e-04 3.25691444e-03\n",
      " 7.30426842e-03 6.27437294e-01 1.18901290e-01 6.05120044e-03\n",
      " 1.36575312e-03 3.00010643e-03 8.60182568e-02 5.95868230e-02\n",
      " 7.85617292e-01 5.11720963e-02 4.95531976e-01 8.80059749e-02\n",
      " 7.02676475e-01 6.85583413e-01 8.41767669e-01 6.06385805e-02\n",
      " 9.89021957e-02 6.81404620e-02 1.35138169e-01 4.32021506e-02\n",
      " 8.05869162e-01 9.51950438e-03 1.99918225e-02 2.17572793e-01\n",
      " 9.87991750e-01 9.92934108e-01 9.87215161e-01 9.98046637e-01\n",
      " 8.58065426e-01 8.96290362e-01 6.44516110e-01 9.90421414e-01\n",
      " 9.94868040e-01 9.96537685e-01 1.29281640e-01 2.73472428e-01\n",
      " 3.37753505e-01 4.86174405e-01 9.22093868e-01 8.77081990e-01\n",
      " 7.17204034e-01 8.47843111e-01 9.78595436e-01 9.92572248e-01\n",
      " 9.60080326e-01 9.72541392e-01 8.65823746e-01 7.40714610e-01\n",
      " 5.58277369e-01 9.37470615e-01 7.74216771e-01 7.85355687e-01\n",
      " 3.35867815e-02 1.42499372e-01 9.54101026e-01 7.42738724e-01\n",
      " 3.57450992e-01 9.97145951e-01 9.92616832e-01 9.82758462e-01\n",
      " 2.71395117e-01 6.41692221e-01 7.47591674e-01 7.00510204e-01\n",
      " 6.14195108e-01 8.26191664e-01 6.74585775e-02 7.78453231e-01\n",
      " 5.30920804e-01 7.01739371e-01 5.56461871e-01 1.97053291e-02\n",
      " 1.25048831e-01 7.44225144e-01 6.43569648e-01 3.40206996e-02\n",
      " 9.99615788e-01 2.43925720e-01 8.87045264e-01 3.41070026e-01\n",
      " 2.98189968e-02 3.82305324e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "Train Epoch: 5 [0/107 (0%)]\tTrain Loss: 0.139371\n",
      "Train Epoch: 5 [4/107 (4%)]\tTrain Loss: 0.120677\n",
      "Train Epoch: 5 [8/107 (7%)]\tTrain Loss: 0.230916\n",
      "Train Epoch: 5 [12/107 (11%)]\tTrain Loss: 0.105724\n",
      "Train Epoch: 5 [16/107 (15%)]\tTrain Loss: 0.295043\n",
      "Train Epoch: 5 [20/107 (19%)]\tTrain Loss: 0.089787\n",
      "Train Epoch: 5 [24/107 (22%)]\tTrain Loss: 0.076282\n",
      "Train Epoch: 5 [28/107 (26%)]\tTrain Loss: 0.068051\n",
      "Train Epoch: 5 [32/107 (30%)]\tTrain Loss: 0.116977\n",
      "Train Epoch: 5 [36/107 (34%)]\tTrain Loss: 0.016541\n",
      "Train Epoch: 5 [40/107 (37%)]\tTrain Loss: 0.152420\n",
      "Train Epoch: 5 [44/107 (41%)]\tTrain Loss: 0.216665\n",
      "Train Epoch: 5 [48/107 (45%)]\tTrain Loss: 0.119136\n",
      "Train Epoch: 5 [52/107 (49%)]\tTrain Loss: 0.056281\n",
      "Train Epoch: 5 [56/107 (52%)]\tTrain Loss: 0.059928\n",
      "Train Epoch: 5 [60/107 (56%)]\tTrain Loss: 0.160127\n",
      "Train Epoch: 5 [64/107 (60%)]\tTrain Loss: 0.080947\n",
      "Train Epoch: 5 [68/107 (64%)]\tTrain Loss: 0.084540\n",
      "Train Epoch: 5 [72/107 (67%)]\tTrain Loss: 0.158871\n",
      "Train Epoch: 5 [76/107 (71%)]\tTrain Loss: 0.379968\n",
      "Train Epoch: 5 [80/107 (75%)]\tTrain Loss: 0.097358\n",
      "Train Epoch: 5 [84/107 (79%)]\tTrain Loss: 0.173248\n",
      "Train Epoch: 5 [88/107 (82%)]\tTrain Loss: 0.051752\n",
      "Train Epoch: 5 [92/107 (86%)]\tTrain Loss: 0.366042\n",
      "Train Epoch: 5 [96/107 (90%)]\tTrain Loss: 0.460657\n",
      "Train Epoch: 5 [100/107 (93%)]\tTrain Loss: 0.047302\n",
      "Train Epoch: 5 [104/107 (97%)]\tTrain Loss: 0.080901\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.63492954 0.95281833 0.7066232  0.7714684  0.87578321 0.25089151\n",
      " 0.95262897 0.94313771 0.70818222 0.07606678 0.32225552 0.1280916\n",
      " 0.41339067 0.74135393 0.69722694 0.10419315 0.81273818 0.56097484\n",
      " 0.38086739 0.75428224 0.89622265 0.89977086 0.98902589 0.99267548\n",
      " 0.59910411 0.98047596 0.99554574 0.68813419 0.54944146 0.65692812\n",
      " 0.56125534 0.31031942 0.60069805 0.3531681  0.38744563 0.61010575\n",
      " 0.33472556 0.9109509  0.60642201 0.29217461 0.48765048 0.36826402\n",
      " 0.88773978 0.87288761 0.87975127 0.706958   0.40584096 0.50746691\n",
      " 0.98621535 0.69068778 0.97116113 0.27278531 0.2146339  0.32950163\n",
      " 0.27063027 0.63439935 0.58513021 0.46452522 0.25992128 0.20005962\n",
      " 0.9879089  0.98576921 0.99360621 0.98945624 0.65361202 0.983841\n",
      " 0.80077201 0.99900442 0.99592614 0.97808105 0.7199558  0.47795567\n",
      " 0.62702858 0.96219319 0.96046698 0.97604263 0.98551381 0.98259121\n",
      " 0.99572444 0.99926704 0.99832112 0.99746168 0.97174454 0.89373696\n",
      " 0.85563517 0.97339135 0.68893528 0.82230419 0.90198493 0.95157397\n",
      " 0.99650002 0.85784209 0.87416518 0.99946505 0.95922226 0.9982664\n",
      " 0.81785017 0.89380354 0.96440524 0.99515069 0.76107484 0.87838072\n",
      " 0.67799115 0.27868152 0.38827738 0.41300467 0.91249263 0.52086514\n",
      " 0.95376813 0.89464235 0.88451982 0.67933762 0.9993549  0.78229654\n",
      " 0.9372623  0.97326106 0.95664942 0.99344939]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/107 (0%)]\tTrain Loss: 0.118700\n",
      "Train Epoch: 6 [4/107 (4%)]\tTrain Loss: 0.128966\n",
      "Train Epoch: 6 [8/107 (7%)]\tTrain Loss: 0.203262\n",
      "Train Epoch: 6 [12/107 (11%)]\tTrain Loss: 0.326754\n",
      "Train Epoch: 6 [16/107 (15%)]\tTrain Loss: 0.049343\n",
      "Train Epoch: 6 [20/107 (19%)]\tTrain Loss: 0.167736\n",
      "Train Epoch: 6 [24/107 (22%)]\tTrain Loss: 0.037380\n",
      "Train Epoch: 6 [28/107 (26%)]\tTrain Loss: 0.075914\n",
      "Train Epoch: 6 [32/107 (30%)]\tTrain Loss: 0.094501\n",
      "Train Epoch: 6 [36/107 (34%)]\tTrain Loss: 0.100672\n",
      "Train Epoch: 6 [40/107 (37%)]\tTrain Loss: 0.094503\n",
      "Train Epoch: 6 [44/107 (41%)]\tTrain Loss: 0.161291\n",
      "Train Epoch: 6 [48/107 (45%)]\tTrain Loss: 0.116731\n",
      "Train Epoch: 6 [52/107 (49%)]\tTrain Loss: 0.087760\n",
      "Train Epoch: 6 [56/107 (52%)]\tTrain Loss: 0.296684\n",
      "Train Epoch: 6 [60/107 (56%)]\tTrain Loss: 0.238616\n",
      "Train Epoch: 6 [64/107 (60%)]\tTrain Loss: 0.055840\n",
      "Train Epoch: 6 [68/107 (64%)]\tTrain Loss: 0.381576\n",
      "Train Epoch: 6 [72/107 (67%)]\tTrain Loss: 0.236655\n",
      "Train Epoch: 6 [76/107 (71%)]\tTrain Loss: 0.109740\n",
      "Train Epoch: 6 [80/107 (75%)]\tTrain Loss: 0.119893\n",
      "Train Epoch: 6 [84/107 (79%)]\tTrain Loss: 0.103350\n",
      "Train Epoch: 6 [88/107 (82%)]\tTrain Loss: 0.031229\n",
      "Train Epoch: 6 [92/107 (86%)]\tTrain Loss: 0.146626\n",
      "Train Epoch: 6 [96/107 (90%)]\tTrain Loss: 0.071100\n",
      "Train Epoch: 6 [100/107 (93%)]\tTrain Loss: 0.171799\n",
      "Train Epoch: 6 [104/107 (97%)]\tTrain Loss: 0.028569\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.18432273 0.45728567 0.69768977 0.17505008 0.39537755 0.28191447\n",
      " 0.39046979 0.22402331 0.71551311 0.47059783 0.05134214 0.07890286\n",
      " 0.1039183  0.04102917 0.59951568 0.02000474 0.0129418  0.25439477\n",
      " 0.0365622  0.26020777 0.26918277 0.26390591 0.52601212 0.97771114\n",
      " 0.16923386 0.5562247  0.98902345 0.01123674 0.00510084 0.25305921\n",
      " 0.02235294 0.00882502 0.18000923 0.01986473 0.01253538 0.03283218\n",
      " 0.00658566 0.31511217 0.55910748 0.46953446 0.26948586 0.33472341\n",
      " 0.21245398 0.1875111  0.12039711 0.15678798 0.45746312 0.56357306\n",
      " 0.82963413 0.91028792 0.87491125 0.02166289 0.02236378 0.03264815\n",
      " 0.1054626  0.01284445 0.34839731 0.00164764 0.03488034 0.05961422\n",
      " 0.88153845 0.43313521 0.72569692 0.87744355 0.61331666 0.3792071\n",
      " 0.20823103 0.91658348 0.88793635 0.99340868 0.7751103  0.69140899\n",
      " 0.04805415 0.64407933 0.31582952 0.41253537 0.95352668 0.76466191\n",
      " 0.86042196 0.56330973 0.96605575 0.97281182 0.90954697 0.42034885\n",
      " 0.59407723 0.97019267 0.75724232 0.55435908 0.05420695 0.45487711\n",
      " 0.97904098 0.81047004 0.94246632 0.99087453 0.73022187 0.95410365\n",
      " 0.00411225 0.67231029 0.5369091  0.8413865  0.4945147  0.54993957\n",
      " 0.04420228 0.47004083 0.55238795 0.92530245 0.96846235 0.06103576\n",
      " 0.12042881 0.21657795 0.56220686 0.77662045 0.97566491 0.43763283\n",
      " 0.81119514 0.42528933 0.3976396  0.67715257]\n",
      "predict [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "Train Epoch: 7 [0/107 (0%)]\tTrain Loss: 0.192692\n",
      "Train Epoch: 7 [4/107 (4%)]\tTrain Loss: 0.075000\n",
      "Train Epoch: 7 [8/107 (7%)]\tTrain Loss: 0.015854\n",
      "Train Epoch: 7 [12/107 (11%)]\tTrain Loss: 0.037537\n",
      "Train Epoch: 7 [16/107 (15%)]\tTrain Loss: 0.036631\n",
      "Train Epoch: 7 [20/107 (19%)]\tTrain Loss: 0.732581\n",
      "Train Epoch: 7 [24/107 (22%)]\tTrain Loss: 0.031755\n",
      "Train Epoch: 7 [28/107 (26%)]\tTrain Loss: 0.030926\n",
      "Train Epoch: 7 [32/107 (30%)]\tTrain Loss: 0.192397\n",
      "Train Epoch: 7 [36/107 (34%)]\tTrain Loss: 0.081630\n",
      "Train Epoch: 7 [40/107 (37%)]\tTrain Loss: 0.246047\n",
      "Train Epoch: 7 [44/107 (41%)]\tTrain Loss: 0.053565\n",
      "Train Epoch: 7 [48/107 (45%)]\tTrain Loss: 0.469448\n",
      "Train Epoch: 7 [52/107 (49%)]\tTrain Loss: 0.605226\n",
      "Train Epoch: 7 [56/107 (52%)]\tTrain Loss: 0.264302\n",
      "Train Epoch: 7 [60/107 (56%)]\tTrain Loss: 0.232592\n",
      "Train Epoch: 7 [64/107 (60%)]\tTrain Loss: 0.201086\n",
      "Train Epoch: 7 [68/107 (64%)]\tTrain Loss: 0.035038\n",
      "Train Epoch: 7 [72/107 (67%)]\tTrain Loss: 0.018956\n",
      "Train Epoch: 7 [76/107 (71%)]\tTrain Loss: 0.126648\n",
      "Train Epoch: 7 [80/107 (75%)]\tTrain Loss: 0.316035\n",
      "Train Epoch: 7 [84/107 (79%)]\tTrain Loss: 0.060391\n",
      "Train Epoch: 7 [88/107 (82%)]\tTrain Loss: 0.073524\n",
      "Train Epoch: 7 [92/107 (86%)]\tTrain Loss: 0.176016\n",
      "Train Epoch: 7 [96/107 (90%)]\tTrain Loss: 0.064165\n",
      "Train Epoch: 7 [100/107 (93%)]\tTrain Loss: 0.017150\n",
      "Train Epoch: 7 [104/107 (97%)]\tTrain Loss: 0.168277\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.64289474 0.19706275 0.10348471 0.82271445 0.98004764 0.27720731\n",
      " 0.11985263 0.97414035 0.32811776 0.28855097 0.91430128 0.21456611\n",
      " 0.64284796 0.41836226 0.65061986 0.2703566  0.65810978 0.88014358\n",
      " 0.24953283 0.30190614 0.95151645 0.97652745 0.93621182 0.99661332\n",
      " 0.84454715 0.99925905 0.99973136 0.26677576 0.41152418 0.09685735\n",
      " 0.63968295 0.83459508 0.9800393  0.01828714 0.12231721 0.20596044\n",
      " 0.21074195 0.99814939 0.94896901 0.70225954 0.40228143 0.42454731\n",
      " 0.98746699 0.89604247 0.94753695 0.40214378 0.94081503 0.97941816\n",
      " 0.95803857 0.97760952 0.98717946 0.82987982 0.45130494 0.89637899\n",
      " 0.35438055 0.52435553 0.9253934  0.54634911 0.11403163 0.22997074\n",
      " 0.97787535 0.98047274 0.99176824 0.99198169 0.99181116 0.99929404\n",
      " 0.9939813  0.99962187 0.99894041 0.99862611 0.61133909 0.90119755\n",
      " 0.94063377 0.95722228 0.9831717  0.99545801 0.99082488 0.97372788\n",
      " 0.98397541 0.99919611 0.99983764 0.99990177 0.99751425 0.91962624\n",
      " 0.8061254  0.99292833 0.99614739 0.98238569 0.53119206 0.98330933\n",
      " 0.98799974 0.99704009 0.95684409 0.99999177 0.99996495 0.99955374\n",
      " 0.71688068 0.96977556 0.9371165  0.99619919 0.1679588  0.94514191\n",
      " 0.83358818 0.94750208 0.88713479 0.91954863 0.89164549 0.06692792\n",
      " 0.77864778 0.57407999 0.95983166 0.79194528 0.99975365 0.92775649\n",
      " 0.99105173 0.82963896 0.97293776 0.85661572]\n",
      "predict [1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 8 [0/107 (0%)]\tTrain Loss: 0.084243\n",
      "Train Epoch: 8 [4/107 (4%)]\tTrain Loss: 0.073357\n",
      "Train Epoch: 8 [8/107 (7%)]\tTrain Loss: 0.050211\n",
      "Train Epoch: 8 [12/107 (11%)]\tTrain Loss: 0.075125\n",
      "Train Epoch: 8 [16/107 (15%)]\tTrain Loss: 0.020101\n",
      "Train Epoch: 8 [20/107 (19%)]\tTrain Loss: 0.027933\n",
      "Train Epoch: 8 [24/107 (22%)]\tTrain Loss: 0.039691\n",
      "Train Epoch: 8 [28/107 (26%)]\tTrain Loss: 0.159709\n",
      "Train Epoch: 8 [32/107 (30%)]\tTrain Loss: 0.047674\n",
      "Train Epoch: 8 [36/107 (34%)]\tTrain Loss: 0.021841\n",
      "Train Epoch: 8 [40/107 (37%)]\tTrain Loss: 0.404873\n",
      "Train Epoch: 8 [44/107 (41%)]\tTrain Loss: 0.092603\n",
      "Train Epoch: 8 [48/107 (45%)]\tTrain Loss: 0.033662\n",
      "Train Epoch: 8 [52/107 (49%)]\tTrain Loss: 0.124985\n",
      "Train Epoch: 8 [56/107 (52%)]\tTrain Loss: 0.002610\n",
      "Train Epoch: 8 [60/107 (56%)]\tTrain Loss: 0.584101\n",
      "Train Epoch: 8 [64/107 (60%)]\tTrain Loss: 0.010464\n",
      "Train Epoch: 8 [68/107 (64%)]\tTrain Loss: 0.113151\n",
      "Train Epoch: 8 [72/107 (67%)]\tTrain Loss: 0.053827\n",
      "Train Epoch: 8 [76/107 (71%)]\tTrain Loss: 0.023157\n",
      "Train Epoch: 8 [80/107 (75%)]\tTrain Loss: 0.016633\n",
      "Train Epoch: 8 [84/107 (79%)]\tTrain Loss: 0.093088\n",
      "Train Epoch: 8 [88/107 (82%)]\tTrain Loss: 0.039013\n",
      "Train Epoch: 8 [92/107 (86%)]\tTrain Loss: 0.340005\n",
      "Train Epoch: 8 [96/107 (90%)]\tTrain Loss: 0.030425\n",
      "Train Epoch: 8 [100/107 (93%)]\tTrain Loss: 0.038366\n",
      "Train Epoch: 8 [104/107 (97%)]\tTrain Loss: 0.012679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.63323522e-01 8.58134866e-01 3.21878612e-01 1.09396957e-01\n",
      " 3.28059524e-01 5.24132587e-02 6.17883146e-01 3.76348615e-01\n",
      " 5.19584641e-02 1.25201851e-01 7.88124621e-01 2.69881785e-02\n",
      " 4.96728450e-01 6.61125779e-03 1.57330170e-01 5.01763367e-04\n",
      " 3.07700154e-03 6.74968004e-01 6.37439787e-02 4.24548149e-01\n",
      " 5.47817469e-01 7.69863784e-01 5.76454043e-01 9.90350902e-01\n",
      " 4.70117897e-01 9.84506309e-01 9.99024630e-01 5.99217117e-01\n",
      " 4.64927964e-02 8.86315331e-02 4.10126150e-01 6.86569870e-01\n",
      " 8.56704950e-01 2.15509417e-03 3.10315401e-03 1.67652722e-02\n",
      " 1.70679390e-02 9.92803514e-01 9.30965006e-01 1.25139013e-01\n",
      " 1.77606586e-02 4.93203178e-02 8.99429381e-01 1.71633303e-01\n",
      " 5.53841412e-01 1.36182904e-01 8.51547658e-01 9.13032770e-01\n",
      " 8.98990393e-01 6.19456887e-01 7.95280993e-01 1.70343190e-01\n",
      " 1.45657826e-02 4.00394022e-01 1.13017075e-01 8.94716382e-02\n",
      " 7.91037083e-01 1.57199539e-02 2.23985985e-02 1.44217694e-02\n",
      " 9.73935783e-01 9.90147054e-01 9.97764349e-01 9.95759070e-01\n",
      " 9.77265000e-01 9.92585361e-01 6.03554904e-01 9.97806489e-01\n",
      " 9.84165072e-01 9.94478822e-01 4.12249379e-02 1.73249349e-01\n",
      " 7.77090073e-01 9.24665689e-01 9.86259997e-01 9.49505985e-01\n",
      " 9.89183664e-01 9.85598922e-01 9.90429044e-01 9.77754235e-01\n",
      " 9.84361649e-01 9.96402979e-01 9.82363582e-01 9.25641418e-01\n",
      " 2.82708853e-01 9.91945565e-01 9.49047089e-01 9.55263555e-01\n",
      " 2.74711326e-02 9.67581987e-01 8.38066757e-01 9.69569564e-01\n",
      " 8.58649254e-01 9.99027610e-01 9.97772753e-01 8.79282951e-01\n",
      " 1.18407242e-01 7.02077091e-01 8.77332151e-01 9.43109572e-01\n",
      " 6.58737794e-02 9.13635850e-01 9.18260992e-01 3.04531932e-01\n",
      " 1.80669039e-01 8.89419764e-02 4.34106350e-01 1.47910127e-02\n",
      " 7.81478435e-02 3.24886329e-02 3.57646912e-01 1.08562537e-01\n",
      " 9.57229495e-01 4.93742943e-01 5.12996495e-01 3.10083956e-01\n",
      " 9.85082269e-01 9.53447044e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      "Train Epoch: 9 [0/107 (0%)]\tTrain Loss: 0.027856\n",
      "Train Epoch: 9 [4/107 (4%)]\tTrain Loss: 0.014991\n",
      "Train Epoch: 9 [8/107 (7%)]\tTrain Loss: 0.163133\n",
      "Train Epoch: 9 [12/107 (11%)]\tTrain Loss: 0.111659\n",
      "Train Epoch: 9 [16/107 (15%)]\tTrain Loss: 0.331005\n",
      "Train Epoch: 9 [20/107 (19%)]\tTrain Loss: 0.052853\n",
      "Train Epoch: 9 [24/107 (22%)]\tTrain Loss: 0.013433\n",
      "Train Epoch: 9 [28/107 (26%)]\tTrain Loss: 0.267217\n",
      "Train Epoch: 9 [32/107 (30%)]\tTrain Loss: 0.013723\n",
      "Train Epoch: 9 [36/107 (34%)]\tTrain Loss: 0.362923\n",
      "Train Epoch: 9 [40/107 (37%)]\tTrain Loss: 0.070714\n",
      "Train Epoch: 9 [44/107 (41%)]\tTrain Loss: 0.155015\n",
      "Train Epoch: 9 [48/107 (45%)]\tTrain Loss: 0.056722\n",
      "Train Epoch: 9 [52/107 (49%)]\tTrain Loss: 0.110443\n",
      "Train Epoch: 9 [56/107 (52%)]\tTrain Loss: 0.013122\n",
      "Train Epoch: 9 [60/107 (56%)]\tTrain Loss: 0.876349\n",
      "Train Epoch: 9 [64/107 (60%)]\tTrain Loss: 0.252116\n",
      "Train Epoch: 9 [68/107 (64%)]\tTrain Loss: 0.011679\n",
      "Train Epoch: 9 [72/107 (67%)]\tTrain Loss: 0.007553\n",
      "Train Epoch: 9 [76/107 (71%)]\tTrain Loss: 0.430250\n",
      "Train Epoch: 9 [80/107 (75%)]\tTrain Loss: 0.017077\n",
      "Train Epoch: 9 [84/107 (79%)]\tTrain Loss: 0.016513\n",
      "Train Epoch: 9 [88/107 (82%)]\tTrain Loss: 0.181760\n",
      "Train Epoch: 9 [92/107 (86%)]\tTrain Loss: 0.272306\n",
      "Train Epoch: 9 [96/107 (90%)]\tTrain Loss: 0.015088\n",
      "Train Epoch: 9 [100/107 (93%)]\tTrain Loss: 0.014876\n",
      "Train Epoch: 9 [104/107 (97%)]\tTrain Loss: 0.032707\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.03964880e-01 1.06561016e-02 3.04327756e-02 9.03108940e-02\n",
      " 4.75237630e-02 4.39452752e-02 6.04731264e-03 2.19255835e-01\n",
      " 1.81727171e-01 1.57277539e-01 8.93896699e-01 8.45524296e-02\n",
      " 5.77115893e-01 8.34022139e-05 1.99650154e-02 3.22681590e-04\n",
      " 6.40508311e-04 4.80652213e-01 2.36757711e-01 1.18387200e-01\n",
      " 3.46465737e-01 5.95948517e-01 9.44857121e-01 9.93084311e-01\n",
      " 4.26800668e-01 9.78821516e-01 9.96671915e-01 5.11201546e-02\n",
      " 8.00163206e-03 2.36901082e-02 7.68491030e-02 2.03410070e-02\n",
      " 2.76753902e-01 2.47611839e-04 1.21548532e-04 1.22636920e-04\n",
      " 7.47189741e-04 9.71323371e-01 1.61560893e-01 1.05162954e-03\n",
      " 8.52673780e-04 3.62458010e-03 7.26627707e-01 5.14230728e-01\n",
      " 4.60567981e-01 2.90751434e-03 3.43209356e-01 1.43158585e-01\n",
      " 2.31506303e-01 4.99080658e-01 5.93000710e-01 8.81322920e-02\n",
      " 3.06703243e-02 3.18799391e-02 5.20215146e-02 2.77946442e-02\n",
      " 8.86766791e-01 1.64427783e-03 9.30167213e-02 1.15592300e-03\n",
      " 9.40941572e-01 8.93345714e-01 9.91910756e-01 9.93134260e-01\n",
      " 1.30464390e-01 7.28913784e-01 6.30051196e-02 8.76468003e-01\n",
      " 7.46837616e-01 7.31777608e-01 1.21317217e-02 1.31980991e-02\n",
      " 1.42722363e-02 2.41962075e-02 1.53637290e-01 7.17561364e-01\n",
      " 2.20154315e-01 8.19433182e-02 9.96793926e-01 7.49117136e-01\n",
      " 7.43610024e-01 6.88331485e-01 8.48158240e-01 9.35343146e-01\n",
      " 7.78556943e-01 9.59736228e-01 9.85034525e-01 9.21499491e-01\n",
      " 5.84673956e-02 3.58643770e-01 9.78494048e-01 6.59379542e-01\n",
      " 5.49749672e-01 9.99911427e-01 9.98962164e-01 9.87434328e-01\n",
      " 5.72150588e-01 6.61156774e-01 9.20673430e-01 6.34636641e-01\n",
      " 1.19452327e-01 3.45934093e-01 6.35774374e-01 6.49556577e-01\n",
      " 6.73710048e-01 7.89614320e-01 3.95189434e-01 2.17599478e-02\n",
      " 3.60111929e-02 3.89440134e-02 2.44741477e-02 3.37515734e-02\n",
      " 9.99206364e-01 7.15639472e-01 1.87637061e-01 1.31064281e-01\n",
      " 4.37830895e-01 8.88053656e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 10 [0/107 (0%)]\tTrain Loss: 0.152483\n",
      "Train Epoch: 10 [4/107 (4%)]\tTrain Loss: 0.077385\n",
      "Train Epoch: 10 [8/107 (7%)]\tTrain Loss: 0.577884\n",
      "Train Epoch: 10 [12/107 (11%)]\tTrain Loss: 0.014694\n",
      "Train Epoch: 10 [16/107 (15%)]\tTrain Loss: 0.081083\n",
      "Train Epoch: 10 [20/107 (19%)]\tTrain Loss: 0.099232\n",
      "Train Epoch: 10 [24/107 (22%)]\tTrain Loss: 0.033208\n",
      "Train Epoch: 10 [28/107 (26%)]\tTrain Loss: 0.301774\n",
      "Train Epoch: 10 [32/107 (30%)]\tTrain Loss: 0.071663\n",
      "Train Epoch: 10 [36/107 (34%)]\tTrain Loss: 0.037970\n",
      "Train Epoch: 10 [40/107 (37%)]\tTrain Loss: 0.060187\n",
      "Train Epoch: 10 [44/107 (41%)]\tTrain Loss: 0.170167\n",
      "Train Epoch: 10 [48/107 (45%)]\tTrain Loss: 0.217326\n",
      "Train Epoch: 10 [52/107 (49%)]\tTrain Loss: 0.163574\n",
      "Train Epoch: 10 [56/107 (52%)]\tTrain Loss: 0.132065\n",
      "Train Epoch: 10 [60/107 (56%)]\tTrain Loss: 0.157986\n",
      "Train Epoch: 10 [64/107 (60%)]\tTrain Loss: 0.024331\n",
      "Train Epoch: 10 [68/107 (64%)]\tTrain Loss: 0.093726\n",
      "Train Epoch: 10 [72/107 (67%)]\tTrain Loss: 0.036475\n",
      "Train Epoch: 10 [76/107 (71%)]\tTrain Loss: 0.222124\n",
      "Train Epoch: 10 [80/107 (75%)]\tTrain Loss: 0.290459\n",
      "Train Epoch: 10 [84/107 (79%)]\tTrain Loss: 0.484483\n",
      "Train Epoch: 10 [88/107 (82%)]\tTrain Loss: 0.075882\n",
      "Train Epoch: 10 [92/107 (86%)]\tTrain Loss: 0.072752\n",
      "Train Epoch: 10 [96/107 (90%)]\tTrain Loss: 0.031840\n",
      "Train Epoch: 10 [100/107 (93%)]\tTrain Loss: 0.041440\n",
      "Train Epoch: 10 [104/107 (97%)]\tTrain Loss: 0.472205\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.99711326e-02 5.35972238e-01 3.48760396e-01 2.17690751e-01\n",
      " 2.50477344e-01 1.09116370e-02 2.03797147e-01 3.64758402e-01\n",
      " 1.84671599e-02 1.36578172e-01 6.07181132e-01 4.07704897e-02\n",
      " 4.23479408e-01 4.55494449e-02 2.39929035e-01 5.37188724e-04\n",
      " 4.58986557e-04 8.06499362e-01 3.02953482e-01 4.90753114e-01\n",
      " 5.75680196e-01 3.35717738e-01 9.86714900e-01 9.95404363e-01\n",
      " 3.24758351e-01 9.67680097e-01 9.98450994e-01 2.40286320e-01\n",
      " 2.31279194e-01 1.22267105e-01 6.63463891e-01 8.33194137e-01\n",
      " 9.10820961e-01 6.64332416e-03 1.01688839e-02 1.27292454e-01\n",
      " 1.16832614e-01 9.74139094e-01 8.39006543e-01 4.52508293e-02\n",
      " 4.10196222e-02 8.20576474e-02 4.56533074e-01 7.74971843e-01\n",
      " 7.27927089e-01 5.14849782e-01 8.82351995e-01 9.21677053e-01\n",
      " 6.70545936e-01 5.78127265e-01 8.83037508e-01 2.04950999e-02\n",
      " 7.87082128e-03 2.63375938e-02 6.80092052e-02 2.94644851e-02\n",
      " 8.99917722e-01 1.15497485e-02 3.36692035e-02 1.41276773e-02\n",
      " 9.78615761e-01 9.79424953e-01 9.98592079e-01 9.97093678e-01\n",
      " 2.28755608e-01 9.82967257e-01 8.04587722e-01 9.99744952e-01\n",
      " 9.98305082e-01 8.92861903e-01 3.77283633e-01 4.14708555e-01\n",
      " 5.36528409e-01 7.96282589e-01 6.64704800e-01 9.50331211e-01\n",
      " 9.90347147e-01 9.51821685e-01 9.99414921e-01 9.99255240e-01\n",
      " 9.99873757e-01 9.99111950e-01 9.82109308e-01 8.43822062e-01\n",
      " 7.52510846e-01 9.97363746e-01 9.89582419e-01 9.79556441e-01\n",
      " 1.86692342e-01 9.80491638e-01 9.99820054e-01 9.87453580e-01\n",
      " 9.88426983e-01 9.99993563e-01 9.99991298e-01 9.99995351e-01\n",
      " 2.58751571e-01 5.51537633e-01 8.61564934e-01 9.98434722e-01\n",
      " 2.14669615e-01 9.21873093e-01 2.05789641e-01 9.39159751e-01\n",
      " 9.52857614e-01 8.99792373e-01 8.92707109e-01 4.40147132e-01\n",
      " 1.71936437e-01 9.64115500e-01 8.31674457e-01 7.43449092e-01\n",
      " 9.99995470e-01 9.92358506e-01 5.54753602e-01 7.36911595e-01\n",
      " 9.42565441e-01 9.65976417e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 39 FN= 11 FP= 21\n",
      "TP+FP 68\n",
      "precision 0.6911764705882353\n",
      "recall 0.8103448275862069\n",
      "F1 0.746031746031746\n",
      "acc 0.7288135593220338\n",
      "AUCp 0.7301724137931034\n",
      "AUC 0.8221264367816092\n",
      "\n",
      " The epoch is 10, average recall: 0.8103, average precision: 0.6912,average F1: 0.7460, average accuracy: 0.7288, average AUC: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/107 (0%)]\tTrain Loss: 0.066158\n",
      "Train Epoch: 11 [4/107 (4%)]\tTrain Loss: 0.524973\n",
      "Train Epoch: 11 [8/107 (7%)]\tTrain Loss: 0.064328\n",
      "Train Epoch: 11 [12/107 (11%)]\tTrain Loss: 0.006502\n",
      "Train Epoch: 11 [16/107 (15%)]\tTrain Loss: 0.039962\n",
      "Train Epoch: 11 [20/107 (19%)]\tTrain Loss: 0.077863\n",
      "Train Epoch: 11 [24/107 (22%)]\tTrain Loss: 0.033701\n",
      "Train Epoch: 11 [28/107 (26%)]\tTrain Loss: 0.058495\n",
      "Train Epoch: 11 [32/107 (30%)]\tTrain Loss: 0.116759\n",
      "Train Epoch: 11 [36/107 (34%)]\tTrain Loss: 0.066881\n",
      "Train Epoch: 11 [40/107 (37%)]\tTrain Loss: 0.007689\n",
      "Train Epoch: 11 [44/107 (41%)]\tTrain Loss: 0.009234\n",
      "Train Epoch: 11 [48/107 (45%)]\tTrain Loss: 0.030485\n",
      "Train Epoch: 11 [52/107 (49%)]\tTrain Loss: 0.333780\n",
      "Train Epoch: 11 [56/107 (52%)]\tTrain Loss: 0.131399\n",
      "Train Epoch: 11 [60/107 (56%)]\tTrain Loss: 0.052607\n",
      "Train Epoch: 11 [64/107 (60%)]\tTrain Loss: 0.031328\n",
      "Train Epoch: 11 [68/107 (64%)]\tTrain Loss: 0.002138\n",
      "Train Epoch: 11 [72/107 (67%)]\tTrain Loss: 0.131523\n",
      "Train Epoch: 11 [76/107 (71%)]\tTrain Loss: 0.026498\n",
      "Train Epoch: 11 [80/107 (75%)]\tTrain Loss: 0.147640\n",
      "Train Epoch: 11 [84/107 (79%)]\tTrain Loss: 0.485530\n",
      "Train Epoch: 11 [88/107 (82%)]\tTrain Loss: 0.036236\n",
      "Train Epoch: 11 [92/107 (86%)]\tTrain Loss: 0.327757\n",
      "Train Epoch: 11 [96/107 (90%)]\tTrain Loss: 0.014452\n",
      "Train Epoch: 11 [100/107 (93%)]\tTrain Loss: 0.013863\n",
      "Train Epoch: 11 [104/107 (97%)]\tTrain Loss: 0.010618\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.02969635e-01 5.04122555e-01 6.03141367e-01 1.83701236e-02\n",
      " 6.46845205e-03 6.74900785e-03 5.22679329e-01 1.05648180e-02\n",
      " 1.95498839e-02 4.44238633e-02 3.86816710e-02 9.80905816e-03\n",
      " 2.39184983e-02 1.17609918e-03 6.12677215e-03 1.91299740e-04\n",
      " 1.69372197e-05 7.16010481e-02 5.46386316e-02 2.72157062e-02\n",
      " 1.46923065e-01 2.57359177e-01 8.83818150e-01 9.97221589e-01\n",
      " 5.43305464e-02 5.84453821e-01 9.16830659e-01 9.66537464e-03\n",
      " 3.75556154e-03 2.77346876e-02 1.02353007e-01 2.10621700e-01\n",
      " 4.14919704e-01 7.03975209e-04 3.02069035e-04 7.17430550e-04\n",
      " 4.97192494e-04 1.11020938e-01 2.29881853e-02 4.51547123e-04\n",
      " 6.54105854e-04 4.90801758e-04 3.05034630e-02 6.34209290e-02\n",
      " 5.93031757e-02 2.12691873e-02 6.65011048e-01 3.79852802e-01\n",
      " 7.22562373e-01 5.59928358e-01 8.33464205e-01 1.28835125e-03\n",
      " 2.24333610e-02 6.68750145e-03 2.57615596e-02 9.56779905e-03\n",
      " 9.70834136e-01 4.56935435e-04 1.39892315e-02 3.07392217e-02\n",
      " 9.50256109e-01 9.90714312e-01 9.93494570e-01 9.94269371e-01\n",
      " 7.41552055e-01 1.00267336e-01 1.12956189e-01 9.96261418e-01\n",
      " 9.82108355e-01 8.70497763e-01 2.74416685e-01 1.90573543e-01\n",
      " 2.29739293e-01 7.10923910e-01 7.93982625e-01 8.49040687e-01\n",
      " 9.40842569e-01 9.45044935e-01 9.99088526e-01 9.70778763e-01\n",
      " 8.97291362e-01 9.69106734e-01 8.48240912e-01 6.58773780e-01\n",
      " 8.16213310e-01 9.78458226e-01 8.53670895e-01 8.56823742e-01\n",
      " 1.57234222e-02 3.00010085e-01 9.93733466e-01 5.75960994e-01\n",
      " 1.35020778e-01 9.99997377e-01 9.93297756e-01 9.99438345e-01\n",
      " 1.53021932e-01 1.25259072e-01 6.37465417e-02 6.13145888e-01\n",
      " 2.74720006e-02 5.03973365e-01 7.90431723e-03 6.54365778e-01\n",
      " 5.71467400e-01 6.29876137e-01 8.78027141e-01 5.93254017e-03\n",
      " 8.92296527e-03 1.74649790e-01 2.18147531e-01 2.47422513e-02\n",
      " 9.99857187e-01 9.75934148e-01 1.81936055e-01 4.38494712e-01\n",
      " 8.83479714e-01 8.63308370e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 12 [0/107 (0%)]\tTrain Loss: 0.083110\n",
      "Train Epoch: 12 [4/107 (4%)]\tTrain Loss: 0.334480\n",
      "Train Epoch: 12 [8/107 (7%)]\tTrain Loss: 0.203299\n",
      "Train Epoch: 12 [12/107 (11%)]\tTrain Loss: 0.043361\n",
      "Train Epoch: 12 [16/107 (15%)]\tTrain Loss: 0.011087\n",
      "Train Epoch: 12 [20/107 (19%)]\tTrain Loss: 0.014030\n",
      "Train Epoch: 12 [24/107 (22%)]\tTrain Loss: 0.349149\n",
      "Train Epoch: 12 [28/107 (26%)]\tTrain Loss: 0.037485\n",
      "Train Epoch: 12 [32/107 (30%)]\tTrain Loss: 0.110554\n",
      "Train Epoch: 12 [36/107 (34%)]\tTrain Loss: 0.076517\n",
      "Train Epoch: 12 [40/107 (37%)]\tTrain Loss: 0.076495\n",
      "Train Epoch: 12 [44/107 (41%)]\tTrain Loss: 0.068501\n",
      "Train Epoch: 12 [48/107 (45%)]\tTrain Loss: 0.023529\n",
      "Train Epoch: 12 [52/107 (49%)]\tTrain Loss: 0.002378\n",
      "Train Epoch: 12 [56/107 (52%)]\tTrain Loss: 0.164878\n",
      "Train Epoch: 12 [60/107 (56%)]\tTrain Loss: 0.620713\n",
      "Train Epoch: 12 [64/107 (60%)]\tTrain Loss: 0.678447\n",
      "Train Epoch: 12 [68/107 (64%)]\tTrain Loss: 0.008557\n",
      "Train Epoch: 12 [72/107 (67%)]\tTrain Loss: 0.496253\n",
      "Train Epoch: 12 [76/107 (71%)]\tTrain Loss: 0.307339\n",
      "Train Epoch: 12 [80/107 (75%)]\tTrain Loss: 0.297891\n",
      "Train Epoch: 12 [84/107 (79%)]\tTrain Loss: 0.124141\n",
      "Train Epoch: 12 [88/107 (82%)]\tTrain Loss: 0.025478\n",
      "Train Epoch: 12 [92/107 (86%)]\tTrain Loss: 0.176505\n",
      "Train Epoch: 12 [96/107 (90%)]\tTrain Loss: 0.099783\n",
      "Train Epoch: 12 [100/107 (93%)]\tTrain Loss: 0.110058\n",
      "Train Epoch: 12 [104/107 (97%)]\tTrain Loss: 0.010741\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.19700897 0.86900592 0.62562323 0.0566708  0.00986736 0.02616036\n",
      " 0.86083215 0.03951253 0.02775201 0.11385237 0.87256014 0.00536065\n",
      " 0.59369582 0.23316535 0.14335674 0.04778223 0.00214967 0.39511749\n",
      " 0.08470283 0.43216303 0.99934787 0.99995267 0.99999857 0.99999702\n",
      " 0.87040776 0.99990046 0.9921152  0.40835893 0.38317692 0.90992367\n",
      " 0.56409496 0.76762998 0.51355475 0.00194363 0.00178043 0.00221456\n",
      " 0.00304235 0.98343831 0.21690141 0.00371455 0.01354953 0.00511937\n",
      " 0.50887728 0.99480671 0.9925372  0.20761272 0.8581813  0.49003035\n",
      " 0.3500559  0.19300908 0.77716011 0.04488637 0.66483468 0.68158007\n",
      " 0.18756703 0.48620918 0.999856   0.0055272  0.0099423  0.38344541\n",
      " 0.99999762 0.99999762 0.99999964 0.99999988 0.99931693 0.76357508\n",
      " 0.08046874 1.         0.98238003 0.47483793 0.9206146  0.92804778\n",
      " 0.86821157 0.99431473 0.99998093 0.99999917 0.99724543 0.99876118\n",
      " 0.99999976 0.99999058 0.99989617 0.99971634 0.99615002 0.99941742\n",
      " 0.99244761 0.99836618 0.99993932 0.99969184 0.22479823 0.98717099\n",
      " 0.99146891 0.96311527 0.96527928 0.9999975  0.99922132 0.9939844\n",
      " 0.60060382 0.73495442 0.98241067 0.98972183 0.52760369 0.99337524\n",
      " 0.81895864 0.9933095  0.96536702 0.95147729 0.84672219 0.04039924\n",
      " 0.01407251 0.86717755 0.21810897 0.03677033 0.99248636 0.98901063\n",
      " 0.99741369 0.99945706 0.99977785 0.9999882 ]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 13 [0/107 (0%)]\tTrain Loss: 0.361202\n",
      "Train Epoch: 13 [4/107 (4%)]\tTrain Loss: 0.009705\n",
      "Train Epoch: 13 [8/107 (7%)]\tTrain Loss: 0.131392\n",
      "Train Epoch: 13 [12/107 (11%)]\tTrain Loss: 0.049986\n",
      "Train Epoch: 13 [16/107 (15%)]\tTrain Loss: 0.003282\n",
      "Train Epoch: 13 [20/107 (19%)]\tTrain Loss: 0.047521\n",
      "Train Epoch: 13 [24/107 (22%)]\tTrain Loss: 0.044565\n",
      "Train Epoch: 13 [28/107 (26%)]\tTrain Loss: 0.004591\n",
      "Train Epoch: 13 [32/107 (30%)]\tTrain Loss: 0.042887\n",
      "Train Epoch: 13 [36/107 (34%)]\tTrain Loss: 0.224302\n",
      "Train Epoch: 13 [40/107 (37%)]\tTrain Loss: 0.002908\n",
      "Train Epoch: 13 [44/107 (41%)]\tTrain Loss: 0.278602\n",
      "Train Epoch: 13 [48/107 (45%)]\tTrain Loss: 0.024598\n",
      "Train Epoch: 13 [52/107 (49%)]\tTrain Loss: 0.062583\n",
      "Train Epoch: 13 [56/107 (52%)]\tTrain Loss: 0.006060\n",
      "Train Epoch: 13 [60/107 (56%)]\tTrain Loss: 0.100088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [64/107 (60%)]\tTrain Loss: 0.160888\n",
      "Train Epoch: 13 [68/107 (64%)]\tTrain Loss: 0.243686\n",
      "Train Epoch: 13 [72/107 (67%)]\tTrain Loss: 0.029754\n",
      "Train Epoch: 13 [76/107 (71%)]\tTrain Loss: 0.019947\n",
      "Train Epoch: 13 [80/107 (75%)]\tTrain Loss: 0.040387\n",
      "Train Epoch: 13 [84/107 (79%)]\tTrain Loss: 0.334986\n",
      "Train Epoch: 13 [88/107 (82%)]\tTrain Loss: 0.046014\n",
      "Train Epoch: 13 [92/107 (86%)]\tTrain Loss: 0.028408\n",
      "Train Epoch: 13 [96/107 (90%)]\tTrain Loss: 0.004560\n",
      "Train Epoch: 13 [100/107 (93%)]\tTrain Loss: 0.013149\n",
      "Train Epoch: 13 [104/107 (97%)]\tTrain Loss: 0.007981\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.33072972e-01 7.36008048e-01 4.13638741e-01 4.84276563e-01\n",
      " 5.69411814e-01 2.84571797e-01 4.96675074e-01 3.41956049e-01\n",
      " 2.82150239e-01 7.22072005e-01 9.68968451e-01 1.51578292e-01\n",
      " 9.31865156e-01 1.27334530e-02 1.07737675e-01 5.55018662e-04\n",
      " 1.49546168e-03 8.34329367e-01 3.07559818e-02 1.46906897e-01\n",
      " 3.12814891e-01 8.78093600e-01 9.89332914e-01 9.96726274e-01\n",
      " 6.54150248e-01 9.74468946e-01 9.53372598e-01 3.67324322e-01\n",
      " 6.89402297e-02 3.89253616e-01 6.22462630e-01 8.50216269e-01\n",
      " 9.44795549e-01 4.52146027e-03 1.04457373e-03 1.20968213e-02\n",
      " 1.06226346e-02 9.80515718e-01 8.68194938e-01 9.27892886e-03\n",
      " 1.15709323e-02 6.82598725e-02 8.48691285e-01 8.45174313e-01\n",
      " 9.42624450e-01 2.97531903e-01 9.94450867e-01 9.36894000e-01\n",
      " 9.76969182e-01 4.51518774e-01 9.85292614e-01 1.00713640e-01\n",
      " 1.08252754e-02 4.18374509e-01 6.34205639e-02 3.60206991e-01\n",
      " 8.70724082e-01 1.44783333e-02 1.64066195e-01 9.49348658e-02\n",
      " 9.99300003e-01 9.95807767e-01 9.99805987e-01 9.99917984e-01\n",
      " 9.98649418e-01 8.75145674e-01 8.19371343e-01 9.99774635e-01\n",
      " 9.99728024e-01 6.05774283e-01 9.50608313e-01 9.70312953e-01\n",
      " 9.95023131e-01 9.97383773e-01 9.99881625e-01 9.97513771e-01\n",
      " 9.98398960e-01 9.89093542e-01 9.99957085e-01 9.99900579e-01\n",
      " 9.99778926e-01 9.99813020e-01 9.97185409e-01 9.93333638e-01\n",
      " 9.79964614e-01 9.98166680e-01 9.94998574e-01 9.70438600e-01\n",
      " 5.86384654e-01 9.06692863e-01 9.83612776e-01 9.88489926e-01\n",
      " 9.89308417e-01 9.99992490e-01 9.99730885e-01 9.99490142e-01\n",
      " 9.23721731e-01 5.59590816e-01 9.92615342e-01 9.99106586e-01\n",
      " 4.15548295e-01 9.99344289e-01 4.37559336e-01 9.92729247e-01\n",
      " 9.95510221e-01 9.27575827e-01 9.75476503e-01 2.73427755e-01\n",
      " 3.76253039e-01 2.88203716e-01 6.95666730e-01 2.76906103e-01\n",
      " 9.99917150e-01 9.98400867e-01 9.43024755e-01 8.73342931e-01\n",
      " 9.90663052e-01 9.80231762e-01]\n",
      "predict [1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 14 [0/107 (0%)]\tTrain Loss: 0.057544\n",
      "Train Epoch: 14 [4/107 (4%)]\tTrain Loss: 0.045417\n",
      "Train Epoch: 14 [8/107 (7%)]\tTrain Loss: 0.443814\n",
      "Train Epoch: 14 [12/107 (11%)]\tTrain Loss: 0.029934\n",
      "Train Epoch: 14 [16/107 (15%)]\tTrain Loss: 0.170528\n",
      "Train Epoch: 14 [20/107 (19%)]\tTrain Loss: 0.248343\n",
      "Train Epoch: 14 [24/107 (22%)]\tTrain Loss: 0.033600\n",
      "Train Epoch: 14 [28/107 (26%)]\tTrain Loss: 0.020646\n",
      "Train Epoch: 14 [32/107 (30%)]\tTrain Loss: 0.286109\n",
      "Train Epoch: 14 [36/107 (34%)]\tTrain Loss: 0.067206\n",
      "Train Epoch: 14 [40/107 (37%)]\tTrain Loss: 0.015877\n",
      "Train Epoch: 14 [44/107 (41%)]\tTrain Loss: 0.059597\n",
      "Train Epoch: 14 [48/107 (45%)]\tTrain Loss: 0.037767\n",
      "Train Epoch: 14 [52/107 (49%)]\tTrain Loss: 0.005935\n",
      "Train Epoch: 14 [56/107 (52%)]\tTrain Loss: 0.041392\n",
      "Train Epoch: 14 [60/107 (56%)]\tTrain Loss: 0.018882\n",
      "Train Epoch: 14 [64/107 (60%)]\tTrain Loss: 0.013608\n",
      "Train Epoch: 14 [68/107 (64%)]\tTrain Loss: 0.059315\n",
      "Train Epoch: 14 [72/107 (67%)]\tTrain Loss: 0.010716\n",
      "Train Epoch: 14 [76/107 (71%)]\tTrain Loss: 0.050720\n",
      "Train Epoch: 14 [80/107 (75%)]\tTrain Loss: 0.037074\n",
      "Train Epoch: 14 [84/107 (79%)]\tTrain Loss: 0.136345\n",
      "Train Epoch: 14 [88/107 (82%)]\tTrain Loss: 0.006890\n",
      "Train Epoch: 14 [92/107 (86%)]\tTrain Loss: 0.004634\n",
      "Train Epoch: 14 [96/107 (90%)]\tTrain Loss: 0.120497\n",
      "Train Epoch: 14 [100/107 (93%)]\tTrain Loss: 0.011084\n",
      "Train Epoch: 14 [104/107 (97%)]\tTrain Loss: 0.002967\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.00647193e-01 9.54354942e-01 3.74810725e-01 1.66574314e-01\n",
      " 7.82609731e-02 5.15616201e-02 9.34006870e-01 1.09507889e-01\n",
      " 1.10282972e-01 3.57557721e-02 5.99832274e-03 6.24628831e-03\n",
      " 1.38246594e-02 6.88685896e-03 2.39691269e-02 4.44745237e-04\n",
      " 4.52765998e-05 3.06451917e-01 1.27413543e-02 1.83599833e-02\n",
      " 1.87553428e-02 1.03535093e-01 7.78395951e-01 9.98744011e-01\n",
      " 2.11450011e-02 4.47845131e-01 9.83867288e-01 3.08856671e-03\n",
      " 2.62580113e-03 2.67200824e-02 1.29392035e-02 1.26054630e-01\n",
      " 6.50050282e-01 1.37698909e-04 9.13108670e-05 4.36647300e-04\n",
      " 2.79124477e-04 9.13276374e-01 9.88824666e-02 1.37287876e-04\n",
      " 2.66327203e-04 7.15446309e-04 9.24982071e-01 1.11715481e-01\n",
      " 1.76082179e-01 8.29442069e-02 8.86128306e-01 8.69098902e-01\n",
      " 7.31874883e-01 1.85311034e-01 8.91586185e-01 4.89888852e-03\n",
      " 5.20302681e-03 7.69248279e-03 1.29966601e-03 8.04297812e-03\n",
      " 6.24477327e-01 4.52786422e-04 6.64425734e-03 8.74647722e-02\n",
      " 9.96512711e-01 9.84280348e-01 9.99123514e-01 9.99550998e-01\n",
      " 9.00646985e-01 4.02102262e-01 2.68623829e-01 9.95387495e-01\n",
      " 9.90010917e-01 9.77734625e-01 7.44760215e-01 6.01738334e-01\n",
      " 3.66676211e-01 3.18068445e-01 8.93747628e-01 6.79694295e-01\n",
      " 9.99489784e-01 9.96146202e-01 9.99962091e-01 9.75747645e-01\n",
      " 9.88305569e-01 9.66117620e-01 9.41727400e-01 8.32390308e-01\n",
      " 9.61312413e-01 9.98355925e-01 8.13726366e-01 6.51000679e-01\n",
      " 4.20443006e-02 1.74218789e-02 8.85309160e-01 6.67052209e-01\n",
      " 7.38646626e-01 9.99478877e-01 7.96319366e-01 8.42153966e-01\n",
      " 1.28152043e-01 1.26760304e-02 3.09779067e-02 5.08647621e-01\n",
      " 1.78537108e-02 7.44361758e-01 1.02732498e-02 1.99615464e-01\n",
      " 1.46769777e-01 4.34132218e-01 8.43709111e-01 1.87011482e-03\n",
      " 2.22728751e-03 2.60736141e-02 3.08109522e-02 2.16035955e-02\n",
      " 9.71167266e-01 1.34140730e-01 4.81800437e-02 6.74574971e-02\n",
      " 9.72080231e-01 9.43735063e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 15 [0/107 (0%)]\tTrain Loss: 0.031528\n",
      "Train Epoch: 15 [4/107 (4%)]\tTrain Loss: 0.183284\n",
      "Train Epoch: 15 [8/107 (7%)]\tTrain Loss: 0.011680\n",
      "Train Epoch: 15 [12/107 (11%)]\tTrain Loss: 0.075072\n",
      "Train Epoch: 15 [16/107 (15%)]\tTrain Loss: 0.097934\n",
      "Train Epoch: 15 [20/107 (19%)]\tTrain Loss: 0.012896\n",
      "Train Epoch: 15 [24/107 (22%)]\tTrain Loss: 0.006746\n",
      "Train Epoch: 15 [28/107 (26%)]\tTrain Loss: 0.005305\n",
      "Train Epoch: 15 [32/107 (30%)]\tTrain Loss: 0.126904\n",
      "Train Epoch: 15 [36/107 (34%)]\tTrain Loss: 0.014617\n",
      "Train Epoch: 15 [40/107 (37%)]\tTrain Loss: 0.088072\n",
      "Train Epoch: 15 [44/107 (41%)]\tTrain Loss: 0.096021\n",
      "Train Epoch: 15 [48/107 (45%)]\tTrain Loss: 0.014683\n",
      "Train Epoch: 15 [52/107 (49%)]\tTrain Loss: 0.055313\n",
      "Train Epoch: 15 [56/107 (52%)]\tTrain Loss: 0.049607\n",
      "Train Epoch: 15 [60/107 (56%)]\tTrain Loss: 0.414050\n",
      "Train Epoch: 15 [64/107 (60%)]\tTrain Loss: 0.108930\n",
      "Train Epoch: 15 [68/107 (64%)]\tTrain Loss: 0.003131\n",
      "Train Epoch: 15 [72/107 (67%)]\tTrain Loss: 0.073699\n",
      "Train Epoch: 15 [76/107 (71%)]\tTrain Loss: 0.030369\n",
      "Train Epoch: 15 [80/107 (75%)]\tTrain Loss: 0.007497\n",
      "Train Epoch: 15 [84/107 (79%)]\tTrain Loss: 0.007486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [88/107 (82%)]\tTrain Loss: 0.109487\n",
      "Train Epoch: 15 [92/107 (86%)]\tTrain Loss: 0.071715\n",
      "Train Epoch: 15 [96/107 (90%)]\tTrain Loss: 0.009508\n",
      "Train Epoch: 15 [100/107 (93%)]\tTrain Loss: 0.028312\n",
      "Train Epoch: 15 [104/107 (97%)]\tTrain Loss: 0.006046\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.37984523e-01 3.70616257e-01 7.22424611e-02 5.46349108e-01\n",
      " 8.05215120e-01 2.66175251e-02 4.39747214e-01 5.88255644e-01\n",
      " 5.89823201e-02 2.30511539e-02 8.57342243e-01 1.71533157e-03\n",
      " 6.27460361e-01 2.88493605e-03 5.50406352e-02 2.77436775e-04\n",
      " 5.34846913e-04 2.09559813e-01 1.45099759e-02 3.59128535e-01\n",
      " 6.45081550e-02 6.84597671e-01 2.58157045e-01 9.99831080e-01\n",
      " 6.47574306e-01 8.77449334e-01 9.99827087e-01 7.00363610e-03\n",
      " 2.94841663e-03 6.32955655e-02 3.32572311e-02 2.22154871e-01\n",
      " 3.65575820e-01 4.73710752e-05 8.83728262e-06 1.04679260e-02\n",
      " 1.85219124e-02 8.71545494e-01 1.23830698e-01 2.53722159e-04\n",
      " 4.01864498e-04 3.10526550e-04 2.18816593e-01 3.32503766e-01\n",
      " 6.67006850e-01 3.58248390e-02 9.90029514e-01 9.21086967e-01\n",
      " 9.15741920e-01 5.43297887e-01 9.73450363e-01 6.07756898e-02\n",
      " 6.99436059e-04 2.38823574e-02 3.31596966e-04 3.39663494e-03\n",
      " 8.22118044e-01 1.09737630e-04 1.27031943e-02 1.44006610e-02\n",
      " 9.97170150e-01 9.92522299e-01 9.99587357e-01 9.99487519e-01\n",
      " 8.52896571e-01 7.77918518e-01 7.92640328e-01 9.84380126e-01\n",
      " 9.99769032e-01 9.57458735e-01 6.35594904e-01 4.92402613e-01\n",
      " 9.72511709e-01 9.93208706e-01 9.70534503e-01 7.92989671e-01\n",
      " 7.18700171e-01 2.24595964e-01 9.99889851e-01 9.96686637e-01\n",
      " 9.99852657e-01 9.99733746e-01 9.93982613e-01 7.01612294e-01\n",
      " 9.46447134e-01 9.99132097e-01 6.11927390e-01 5.03167748e-01\n",
      " 3.39128077e-01 9.97518063e-01 9.99987841e-01 9.76915717e-01\n",
      " 8.79474282e-01 9.99999881e-01 9.99963045e-01 9.99817193e-01\n",
      " 1.76377013e-01 2.56855749e-02 9.78733122e-01 9.99977589e-01\n",
      " 4.07814272e-02 4.23368692e-01 4.34867203e-01 9.92674053e-01\n",
      " 9.99053061e-01 9.74893987e-01 9.97011900e-01 1.96629576e-02\n",
      " 5.72467685e-01 5.39103568e-01 9.91767228e-01 1.92261357e-02\n",
      " 9.99990821e-01 9.38603759e-01 8.10748398e-01 3.74131411e-01\n",
      " 8.34458351e-01 9.68309641e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 16 [0/107 (0%)]\tTrain Loss: 0.024646\n",
      "Train Epoch: 16 [4/107 (4%)]\tTrain Loss: 0.011284\n",
      "Train Epoch: 16 [8/107 (7%)]\tTrain Loss: 0.350418\n",
      "Train Epoch: 16 [12/107 (11%)]\tTrain Loss: 0.008721\n",
      "Train Epoch: 16 [16/107 (15%)]\tTrain Loss: 0.146908\n",
      "Train Epoch: 16 [20/107 (19%)]\tTrain Loss: 0.060755\n",
      "Train Epoch: 16 [24/107 (22%)]\tTrain Loss: 0.017209\n",
      "Train Epoch: 16 [28/107 (26%)]\tTrain Loss: 0.021709\n",
      "Train Epoch: 16 [32/107 (30%)]\tTrain Loss: 0.025896\n",
      "Train Epoch: 16 [36/107 (34%)]\tTrain Loss: 0.028476\n",
      "Train Epoch: 16 [40/107 (37%)]\tTrain Loss: 0.039507\n",
      "Train Epoch: 16 [44/107 (41%)]\tTrain Loss: 0.339479\n",
      "Train Epoch: 16 [48/107 (45%)]\tTrain Loss: 0.017623\n",
      "Train Epoch: 16 [52/107 (49%)]\tTrain Loss: 0.018147\n",
      "Train Epoch: 16 [56/107 (52%)]\tTrain Loss: 0.086737\n",
      "Train Epoch: 16 [60/107 (56%)]\tTrain Loss: 0.109853\n",
      "Train Epoch: 16 [64/107 (60%)]\tTrain Loss: 0.618124\n",
      "Train Epoch: 16 [68/107 (64%)]\tTrain Loss: 0.159036\n",
      "Train Epoch: 16 [72/107 (67%)]\tTrain Loss: 0.020110\n",
      "Train Epoch: 16 [76/107 (71%)]\tTrain Loss: 0.002521\n",
      "Train Epoch: 16 [80/107 (75%)]\tTrain Loss: 0.011910\n",
      "Train Epoch: 16 [84/107 (79%)]\tTrain Loss: 0.036641\n",
      "Train Epoch: 16 [88/107 (82%)]\tTrain Loss: 0.082395\n",
      "Train Epoch: 16 [92/107 (86%)]\tTrain Loss: 0.016171\n",
      "Train Epoch: 16 [96/107 (90%)]\tTrain Loss: 0.050326\n",
      "Train Epoch: 16 [100/107 (93%)]\tTrain Loss: 0.011892\n",
      "Train Epoch: 16 [104/107 (97%)]\tTrain Loss: 0.005462\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.80787599e-01 6.76926970e-01 3.97414714e-01 2.63687134e-01\n",
      " 4.75075901e-01 1.07845664e-01 5.81343591e-01 1.57561943e-01\n",
      " 1.16178282e-01 8.34373757e-03 2.96785206e-01 8.84430541e-04\n",
      " 1.64366275e-01 2.57948483e-03 2.53106318e-02 1.02267142e-04\n",
      " 1.12408095e-04 4.54255715e-02 3.49384621e-02 2.12266579e-01\n",
      " 3.64407718e-01 5.28394818e-01 9.93008971e-01 9.99774754e-01\n",
      " 7.97095224e-02 9.72800434e-01 9.99756038e-01 3.25540490e-02\n",
      " 7.45049864e-02 1.00070000e-01 3.05358350e-01 5.04511595e-01\n",
      " 6.57203376e-01 5.99107589e-04 1.98219743e-04 1.49952751e-02\n",
      " 2.60319505e-02 4.05998349e-01 9.11113769e-02 5.17452741e-03\n",
      " 1.92529745e-02 1.09803071e-02 7.39045590e-02 1.97230026e-01\n",
      " 6.09883130e-01 2.85544753e-01 9.60556149e-01 9.65674400e-01\n",
      " 9.66533244e-01 2.91749269e-01 9.75927591e-01 7.65908556e-03\n",
      " 8.23548809e-03 1.60921421e-02 4.97688390e-02 1.32165626e-02\n",
      " 9.96561229e-01 1.45862505e-04 3.75558098e-04 3.81335132e-02\n",
      " 9.98405635e-01 9.97461200e-01 9.99193370e-01 9.98626471e-01\n",
      " 9.50562894e-01 9.77001250e-01 7.53333449e-01 9.95553195e-01\n",
      " 9.99422908e-01 9.37513471e-01 9.96203721e-01 9.92150187e-01\n",
      " 9.74740624e-01 9.94255126e-01 9.68823671e-01 7.02108502e-01\n",
      " 9.49515641e-01 9.41836834e-01 9.98667836e-01 9.98184979e-01\n",
      " 9.99851704e-01 9.99768198e-01 9.98899698e-01 4.72772092e-01\n",
      " 9.11127627e-01 9.97985721e-01 9.71687675e-01 9.58631992e-01\n",
      " 3.89591366e-01 9.48162913e-01 9.99716222e-01 9.32205737e-01\n",
      " 7.88653374e-01 9.99999285e-01 9.98549998e-01 9.99618292e-01\n",
      " 1.50329784e-01 4.05573189e-01 6.18899167e-01 9.98928845e-01\n",
      " 4.56227437e-02 8.54335725e-01 3.66414152e-02 9.66608107e-01\n",
      " 9.74261522e-01 9.66313720e-01 9.97131348e-01 3.76626104e-02\n",
      " 1.66425869e-01 4.30096775e-01 3.93400162e-01 5.88105440e-01\n",
      " 9.99964237e-01 9.13218617e-01 3.87232006e-01 2.67606616e-01\n",
      " 1.40790651e-02 4.69955057e-01]\n",
      "predict [1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 17 [0/107 (0%)]\tTrain Loss: 0.010186\n",
      "Train Epoch: 17 [4/107 (4%)]\tTrain Loss: 0.023953\n",
      "Train Epoch: 17 [8/107 (7%)]\tTrain Loss: 0.098306\n",
      "Train Epoch: 17 [12/107 (11%)]\tTrain Loss: 0.256070\n",
      "Train Epoch: 17 [16/107 (15%)]\tTrain Loss: 0.089390\n",
      "Train Epoch: 17 [20/107 (19%)]\tTrain Loss: 0.208235\n",
      "Train Epoch: 17 [24/107 (22%)]\tTrain Loss: 0.251878\n",
      "Train Epoch: 17 [28/107 (26%)]\tTrain Loss: 0.057461\n",
      "Train Epoch: 17 [32/107 (30%)]\tTrain Loss: 0.125661\n",
      "Train Epoch: 17 [36/107 (34%)]\tTrain Loss: 0.016272\n",
      "Train Epoch: 17 [40/107 (37%)]\tTrain Loss: 0.014580\n",
      "Train Epoch: 17 [44/107 (41%)]\tTrain Loss: 0.021190\n",
      "Train Epoch: 17 [48/107 (45%)]\tTrain Loss: 0.150436\n",
      "Train Epoch: 17 [52/107 (49%)]\tTrain Loss: 0.015968\n",
      "Train Epoch: 17 [56/107 (52%)]\tTrain Loss: 0.033998\n",
      "Train Epoch: 17 [60/107 (56%)]\tTrain Loss: 0.051410\n",
      "Train Epoch: 17 [64/107 (60%)]\tTrain Loss: 0.023349\n",
      "Train Epoch: 17 [68/107 (64%)]\tTrain Loss: 0.041012\n",
      "Train Epoch: 17 [72/107 (67%)]\tTrain Loss: 0.066058\n",
      "Train Epoch: 17 [76/107 (71%)]\tTrain Loss: 0.003382\n",
      "Train Epoch: 17 [80/107 (75%)]\tTrain Loss: 0.004400\n",
      "Train Epoch: 17 [84/107 (79%)]\tTrain Loss: 0.001775\n",
      "Train Epoch: 17 [88/107 (82%)]\tTrain Loss: 0.009239\n",
      "Train Epoch: 17 [92/107 (86%)]\tTrain Loss: 0.004913\n",
      "Train Epoch: 17 [96/107 (90%)]\tTrain Loss: 0.550695\n",
      "Train Epoch: 17 [100/107 (93%)]\tTrain Loss: 0.105108\n",
      "Train Epoch: 17 [104/107 (97%)]\tTrain Loss: 0.078228\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.17208529e-02 2.81574018e-02 4.75521758e-03 4.71377894e-02\n",
      " 2.98171770e-02 1.45602820e-03 1.54683944e-02 1.02465123e-01\n",
      " 2.40722578e-03 4.64543561e-03 7.19500531e-04 2.04195408e-03\n",
      " 2.14322447e-03 8.10200145e-05 1.05047727e-03 2.07341909e-05\n",
      " 3.29713730e-05 1.80726230e-01 6.60780468e-04 3.17458273e-03\n",
      " 5.23175905e-03 2.89268732e-01 4.65180874e-01 9.96241927e-01\n",
      " 3.47713046e-02 2.67964095e-01 9.49139416e-01 6.56587537e-04\n",
      " 2.60315603e-04 8.53192993e-04 4.27170191e-03 3.83866555e-03\n",
      " 4.71322462e-02 4.58627292e-05 1.79405961e-05 9.91347362e-04\n",
      " 3.44576058e-03 6.79872632e-01 5.11883140e-01 7.70714309e-04\n",
      " 6.50590111e-04 9.12505086e-04 4.38874185e-01 8.04556906e-03\n",
      " 1.79004075e-03 1.60234142e-03 1.55086130e-01 1.68696642e-01\n",
      " 2.31224149e-01 7.90797453e-03 4.27893579e-01 2.18957488e-04\n",
      " 3.34539945e-04 1.44871083e-04 7.53410102e-04 1.30593800e-03\n",
      " 2.00382546e-01 1.98812013e-05 8.68571270e-03 2.08573393e-03\n",
      " 2.12717071e-01 2.73720205e-01 7.95593083e-01 6.11029327e-01\n",
      " 3.24329361e-02 3.84129345e-01 1.43872336e-01 9.50216174e-01\n",
      " 8.77753556e-01 3.73543411e-01 1.29734829e-01 7.69247934e-02\n",
      " 1.69354596e-03 2.68371291e-02 3.32100600e-01 1.73891503e-02\n",
      " 6.97000504e-01 8.89294595e-02 9.73783553e-01 6.50138736e-01\n",
      " 9.60183322e-01 8.46498907e-01 9.06259477e-01 3.23706716e-01\n",
      " 5.11003494e-01 6.28219843e-01 5.41340828e-01 4.23462987e-01\n",
      " 1.87591382e-03 4.53295261e-02 9.52045500e-01 1.69949472e-01\n",
      " 1.11109935e-01 9.94967639e-01 1.32707134e-01 8.04920495e-01\n",
      " 7.34677678e-03 6.90213442e-02 7.08855106e-04 3.12186688e-01\n",
      " 1.86553020e-02 1.75432831e-01 1.75088807e-03 2.86502088e-03\n",
      " 1.25340493e-02 8.32437202e-02 4.64766145e-01 8.69271159e-03\n",
      " 1.38190817e-02 3.52272531e-03 7.98522234e-02 2.09822550e-01\n",
      " 9.64065313e-01 3.61756273e-02 2.12233979e-03 1.15032699e-02\n",
      " 9.90443289e-01 2.36988813e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/107 (0%)]\tTrain Loss: 0.007258\n",
      "Train Epoch: 18 [4/107 (4%)]\tTrain Loss: 0.006483\n",
      "Train Epoch: 18 [8/107 (7%)]\tTrain Loss: 0.005115\n",
      "Train Epoch: 18 [12/107 (11%)]\tTrain Loss: 0.104650\n",
      "Train Epoch: 18 [16/107 (15%)]\tTrain Loss: 0.104201\n",
      "Train Epoch: 18 [20/107 (19%)]\tTrain Loss: 0.057293\n",
      "Train Epoch: 18 [24/107 (22%)]\tTrain Loss: 0.006343\n",
      "Train Epoch: 18 [28/107 (26%)]\tTrain Loss: 0.015190\n",
      "Train Epoch: 18 [32/107 (30%)]\tTrain Loss: 0.001130\n",
      "Train Epoch: 18 [36/107 (34%)]\tTrain Loss: 0.022320\n",
      "Train Epoch: 18 [40/107 (37%)]\tTrain Loss: 0.153971\n",
      "Train Epoch: 18 [44/107 (41%)]\tTrain Loss: 0.067742\n",
      "Train Epoch: 18 [48/107 (45%)]\tTrain Loss: 0.232953\n",
      "Train Epoch: 18 [52/107 (49%)]\tTrain Loss: 0.027351\n",
      "Train Epoch: 18 [56/107 (52%)]\tTrain Loss: 0.007480\n",
      "Train Epoch: 18 [60/107 (56%)]\tTrain Loss: 0.091708\n",
      "Train Epoch: 18 [64/107 (60%)]\tTrain Loss: 0.144689\n",
      "Train Epoch: 18 [68/107 (64%)]\tTrain Loss: 0.034805\n",
      "Train Epoch: 18 [72/107 (67%)]\tTrain Loss: 0.002910\n",
      "Train Epoch: 18 [76/107 (71%)]\tTrain Loss: 0.015340\n",
      "Train Epoch: 18 [80/107 (75%)]\tTrain Loss: 0.189901\n",
      "Train Epoch: 18 [84/107 (79%)]\tTrain Loss: 0.013372\n",
      "Train Epoch: 18 [88/107 (82%)]\tTrain Loss: 0.082395\n",
      "Train Epoch: 18 [92/107 (86%)]\tTrain Loss: 0.064756\n",
      "Train Epoch: 18 [96/107 (90%)]\tTrain Loss: 0.024230\n",
      "Train Epoch: 18 [100/107 (93%)]\tTrain Loss: 0.354464\n",
      "Train Epoch: 18 [104/107 (97%)]\tTrain Loss: 0.000843\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.88432559e-01 9.68853951e-01 1.41005099e-01 2.65893668e-01\n",
      " 4.74372327e-01 1.61108337e-02 9.18578744e-01 7.69141316e-01\n",
      " 8.19706265e-03 1.02367334e-03 3.10190162e-03 2.31314931e-04\n",
      " 3.47232632e-03 1.84575692e-01 1.55286863e-01 1.48826465e-03\n",
      " 8.21928043e-05 3.23859677e-02 1.47365557e-03 5.91838136e-02\n",
      " 4.03601117e-02 3.89656514e-01 8.45866859e-01 9.99184430e-01\n",
      " 5.37332371e-02 8.45925212e-01 9.99832869e-01 5.02030272e-03\n",
      " 3.80023429e-03 1.13077778e-02 2.58443505e-01 8.74608830e-02\n",
      " 7.93876290e-01 8.29662531e-05 3.08666968e-05 2.15417077e-03\n",
      " 2.64200498e-03 4.26449120e-01 3.87516499e-01 1.24727236e-03\n",
      " 1.33713242e-03 1.58808790e-02 6.76138580e-01 7.80779198e-02\n",
      " 2.90596843e-01 9.91958156e-02 5.72649598e-01 8.57307673e-01\n",
      " 4.50810432e-01 1.67637184e-01 5.20713449e-01 6.92624971e-03\n",
      " 3.31253163e-03 1.66024808e-02 2.21918640e-03 3.28330393e-03\n",
      " 9.78046596e-01 3.56804725e-04 7.09080894e-04 4.00571199e-03\n",
      " 9.97675598e-01 9.99071479e-01 9.99885678e-01 9.99790251e-01\n",
      " 9.90988314e-01 9.73527133e-01 9.06070888e-01 9.99998689e-01\n",
      " 9.99821603e-01 9.99151587e-01 8.97374451e-01 8.10644090e-01\n",
      " 6.15833521e-01 9.97818232e-01 9.99596417e-01 8.52649152e-01\n",
      " 9.99593914e-01 9.98752475e-01 9.99571621e-01 9.98623848e-01\n",
      " 9.99950886e-01 9.99599993e-01 9.95505333e-01 9.24913049e-01\n",
      " 9.42161798e-01 9.99440849e-01 9.00370419e-01 9.22662556e-01\n",
      " 7.83031434e-02 9.64728653e-01 9.99966502e-01 9.82273281e-01\n",
      " 5.76649785e-01 9.99989748e-01 9.99325275e-01 9.99390244e-01\n",
      " 1.89017449e-02 4.71790493e-01 9.24125612e-01 9.73953068e-01\n",
      " 9.30466533e-01 9.15353715e-01 2.62324333e-01 5.23576975e-01\n",
      " 8.71290565e-01 7.13789940e-01 9.98257816e-01 4.05637622e-02\n",
      " 4.35587913e-02 5.74346781e-01 9.29438353e-01 6.60819948e-01\n",
      " 9.99991655e-01 1.11104041e-01 3.53708982e-01 1.09139189e-01\n",
      " 9.99927640e-01 9.99950171e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 19 [0/107 (0%)]\tTrain Loss: 0.312928\n",
      "Train Epoch: 19 [4/107 (4%)]\tTrain Loss: 0.011059\n",
      "Train Epoch: 19 [8/107 (7%)]\tTrain Loss: 0.561699\n",
      "Train Epoch: 19 [12/107 (11%)]\tTrain Loss: 0.005075\n",
      "Train Epoch: 19 [16/107 (15%)]\tTrain Loss: 0.076453\n",
      "Train Epoch: 19 [20/107 (19%)]\tTrain Loss: 0.016744\n",
      "Train Epoch: 19 [24/107 (22%)]\tTrain Loss: 0.001060\n",
      "Train Epoch: 19 [28/107 (26%)]\tTrain Loss: 0.168656\n",
      "Train Epoch: 19 [32/107 (30%)]\tTrain Loss: 0.027876\n",
      "Train Epoch: 19 [36/107 (34%)]\tTrain Loss: 0.257281\n",
      "Train Epoch: 19 [40/107 (37%)]\tTrain Loss: 0.017525\n",
      "Train Epoch: 19 [44/107 (41%)]\tTrain Loss: 0.058767\n",
      "Train Epoch: 19 [48/107 (45%)]\tTrain Loss: 0.105852\n",
      "Train Epoch: 19 [52/107 (49%)]\tTrain Loss: 0.009785\n",
      "Train Epoch: 19 [56/107 (52%)]\tTrain Loss: 0.098196\n",
      "Train Epoch: 19 [60/107 (56%)]\tTrain Loss: 0.006770\n",
      "Train Epoch: 19 [64/107 (60%)]\tTrain Loss: 0.005140\n",
      "Train Epoch: 19 [68/107 (64%)]\tTrain Loss: 0.161804\n",
      "Train Epoch: 19 [72/107 (67%)]\tTrain Loss: 0.031839\n",
      "Train Epoch: 19 [76/107 (71%)]\tTrain Loss: 0.090998\n",
      "Train Epoch: 19 [80/107 (75%)]\tTrain Loss: 0.020734\n",
      "Train Epoch: 19 [84/107 (79%)]\tTrain Loss: 0.047624\n",
      "Train Epoch: 19 [88/107 (82%)]\tTrain Loss: 0.020668\n",
      "Train Epoch: 19 [92/107 (86%)]\tTrain Loss: 0.004820\n",
      "Train Epoch: 19 [96/107 (90%)]\tTrain Loss: 0.075913\n",
      "Train Epoch: 19 [100/107 (93%)]\tTrain Loss: 0.097029\n",
      "Train Epoch: 19 [104/107 (97%)]\tTrain Loss: 0.028111\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.41708583e-01 4.78050053e-01 7.17601106e-02 7.35274434e-01\n",
      " 5.97605109e-01 1.07378718e-02 8.64170939e-02 6.28221452e-01\n",
      " 1.27658963e-01 8.71038660e-02 4.12631214e-01 6.82249293e-03\n",
      " 2.59014875e-01 2.74852395e-01 8.93709898e-01 3.32172844e-04\n",
      " 2.20267568e-04 3.70645911e-01 1.11983512e-02 6.41559735e-02\n",
      " 2.45103955e-01 6.58453405e-01 9.72053170e-01 9.99989152e-01\n",
      " 1.70384735e-01 9.77442384e-01 9.99947786e-01 2.68931244e-03\n",
      " 3.01070930e-03 2.52306089e-02 1.39245009e-02 1.23376563e-01\n",
      " 3.81943703e-01 4.87547404e-05 1.52166922e-05 1.87532208e-03\n",
      " 7.29634659e-03 1.87495366e-01 3.66143659e-02 1.85629097e-03\n",
      " 3.17630381e-03 4.64659929e-03 2.26099923e-01 7.65874922e-01\n",
      " 8.24169636e-01 2.91376952e-02 7.49247611e-01 6.92306459e-01\n",
      " 2.73601145e-01 7.05211103e-01 3.83229524e-01 4.58727300e-01\n",
      " 7.30709080e-03 5.12998044e-01 2.68012198e-04 3.44979786e-03\n",
      " 9.94163930e-01 3.97943018e-04 1.48111423e-02 1.31515013e-02\n",
      " 9.96748924e-01 9.98769701e-01 9.97979939e-01 9.98374343e-01\n",
      " 9.11620021e-01 8.42965722e-01 9.39707875e-01 9.99824703e-01\n",
      " 9.99498844e-01 9.94978845e-01 5.99396348e-01 2.42740437e-01\n",
      " 2.09324196e-01 8.52066278e-01 9.30570185e-01 4.15471792e-01\n",
      " 7.99960315e-01 9.90076289e-02 9.96536493e-01 9.78855908e-01\n",
      " 9.98238921e-01 9.95956242e-01 9.90101933e-01 8.13537896e-01\n",
      " 8.99255514e-01 9.95299041e-01 9.91011381e-01 9.88396585e-01\n",
      " 6.70737587e-03 9.75925863e-01 9.99830604e-01 9.40542579e-01\n",
      " 7.23313808e-01 9.99999523e-01 9.99708593e-01 9.91821468e-01\n",
      " 2.47713372e-01 1.29629254e-01 9.40660834e-01 9.75038707e-01\n",
      " 3.89899462e-01 6.28197730e-01 2.25766003e-01 5.73227227e-01\n",
      " 9.35313642e-01 8.53553951e-01 9.85953271e-01 1.74112190e-02\n",
      " 4.20764573e-02 8.49984229e-01 8.18689227e-01 6.40486479e-02\n",
      " 9.99975801e-01 9.66643870e-01 4.14769143e-01 5.69275856e-01\n",
      " 9.97528017e-01 9.97554719e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 20 [0/107 (0%)]\tTrain Loss: 0.097331\n",
      "Train Epoch: 20 [4/107 (4%)]\tTrain Loss: 0.284920\n",
      "Train Epoch: 20 [8/107 (7%)]\tTrain Loss: 0.032110\n",
      "Train Epoch: 20 [12/107 (11%)]\tTrain Loss: 0.018038\n",
      "Train Epoch: 20 [16/107 (15%)]\tTrain Loss: 0.049760\n",
      "Train Epoch: 20 [20/107 (19%)]\tTrain Loss: 0.002701\n",
      "Train Epoch: 20 [24/107 (22%)]\tTrain Loss: 0.096087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [28/107 (26%)]\tTrain Loss: 0.348677\n",
      "Train Epoch: 20 [32/107 (30%)]\tTrain Loss: 0.252283\n",
      "Train Epoch: 20 [36/107 (34%)]\tTrain Loss: 0.013660\n",
      "Train Epoch: 20 [40/107 (37%)]\tTrain Loss: 0.020161\n",
      "Train Epoch: 20 [44/107 (41%)]\tTrain Loss: 0.039929\n",
      "Train Epoch: 20 [48/107 (45%)]\tTrain Loss: 0.007344\n",
      "Train Epoch: 20 [52/107 (49%)]\tTrain Loss: 0.036976\n",
      "Train Epoch: 20 [56/107 (52%)]\tTrain Loss: 0.124888\n",
      "Train Epoch: 20 [60/107 (56%)]\tTrain Loss: 0.090638\n",
      "Train Epoch: 20 [64/107 (60%)]\tTrain Loss: 0.159330\n",
      "Train Epoch: 20 [68/107 (64%)]\tTrain Loss: 0.028688\n",
      "Train Epoch: 20 [72/107 (67%)]\tTrain Loss: 0.005884\n",
      "Train Epoch: 20 [76/107 (71%)]\tTrain Loss: 0.022015\n",
      "Train Epoch: 20 [80/107 (75%)]\tTrain Loss: 0.021000\n",
      "Train Epoch: 20 [84/107 (79%)]\tTrain Loss: 0.019193\n",
      "Train Epoch: 20 [88/107 (82%)]\tTrain Loss: 0.003844\n",
      "Train Epoch: 20 [92/107 (86%)]\tTrain Loss: 0.258113\n",
      "Train Epoch: 20 [96/107 (90%)]\tTrain Loss: 0.012665\n",
      "Train Epoch: 20 [100/107 (93%)]\tTrain Loss: 0.111044\n",
      "Train Epoch: 20 [104/107 (97%)]\tTrain Loss: 0.014403\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.42686582 0.34549013 0.05945729 0.71844554 0.81854826 0.05270486\n",
      " 0.21326093 0.4920378  0.0545918  0.07728543 0.85558909 0.01582821\n",
      " 0.65338546 0.05966998 0.19601709 0.00177524 0.00206056 0.62351674\n",
      " 0.31393638 0.73903322 0.8030206  0.9576475  0.99852079 0.99999785\n",
      " 0.74645025 0.99910009 0.99990809 0.19751988 0.19711809 0.50037408\n",
      " 0.13823012 0.60311204 0.83953226 0.02813856 0.00549099 0.05022563\n",
      " 0.13393694 0.8524152  0.40608793 0.012332   0.02717697 0.09648512\n",
      " 0.75812364 0.83586508 0.89193201 0.66805995 0.97645682 0.96743351\n",
      " 0.9445948  0.94314545 0.95067179 0.41093481 0.06909283 0.33659002\n",
      " 0.00901636 0.08409841 0.92557538 0.00441756 0.01408117 0.07185061\n",
      " 0.99677795 0.9963336  0.99972135 0.99987841 0.91033965 0.79036808\n",
      " 0.76120776 0.99988055 0.99891269 0.98965073 0.88430607 0.81104827\n",
      " 0.74334282 0.97766966 0.99398863 0.86662722 0.9896729  0.68894953\n",
      " 0.99926442 0.98756498 0.99906629 0.9989053  0.99521697 0.8580972\n",
      " 0.9157328  0.99458718 0.99751568 0.99262905 0.40399852 0.99288046\n",
      " 0.999933   0.93788618 0.87540436 1.         0.99997962 0.99993265\n",
      " 0.71895272 0.21733741 0.96610647 0.9979431  0.32106289 0.84480059\n",
      " 0.50166196 0.91764593 0.99137223 0.95072198 0.95600682 0.28668538\n",
      " 0.32759354 0.96660268 0.63660234 0.23294657 0.99998295 0.95686489\n",
      " 0.66337031 0.69624388 0.99363869 0.9973917 ]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 46 FN= 12 FP= 14\n",
      "TP+FP 60\n",
      "precision 0.7666666666666667\n",
      "recall 0.7931034482758621\n",
      "F1 0.7796610169491527\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7798850574712644\n",
      "AUC 0.8522988505747127\n",
      "\n",
      " The epoch is 20, average recall: 0.7931, average precision: 0.7667,average F1: 0.7797, average accuracy: 0.7797, average AUC: 0.8523\n",
      "Train Epoch: 21 [0/107 (0%)]\tTrain Loss: 0.070866\n",
      "Train Epoch: 21 [4/107 (4%)]\tTrain Loss: 0.097238\n",
      "Train Epoch: 21 [8/107 (7%)]\tTrain Loss: 0.052325\n",
      "Train Epoch: 21 [12/107 (11%)]\tTrain Loss: 0.023162\n",
      "Train Epoch: 21 [16/107 (15%)]\tTrain Loss: 0.302206\n",
      "Train Epoch: 21 [20/107 (19%)]\tTrain Loss: 0.082973\n",
      "Train Epoch: 21 [24/107 (22%)]\tTrain Loss: 0.028720\n",
      "Train Epoch: 21 [28/107 (26%)]\tTrain Loss: 0.391547\n",
      "Train Epoch: 21 [32/107 (30%)]\tTrain Loss: 0.142105\n",
      "Train Epoch: 21 [36/107 (34%)]\tTrain Loss: 0.002281\n",
      "Train Epoch: 21 [40/107 (37%)]\tTrain Loss: 0.016228\n",
      "Train Epoch: 21 [44/107 (41%)]\tTrain Loss: 0.047071\n",
      "Train Epoch: 21 [48/107 (45%)]\tTrain Loss: 0.032829\n",
      "Train Epoch: 21 [52/107 (49%)]\tTrain Loss: 0.013790\n",
      "Train Epoch: 21 [56/107 (52%)]\tTrain Loss: 0.127195\n",
      "Train Epoch: 21 [60/107 (56%)]\tTrain Loss: 0.207467\n",
      "Train Epoch: 21 [64/107 (60%)]\tTrain Loss: 0.188083\n",
      "Train Epoch: 21 [68/107 (64%)]\tTrain Loss: 0.006023\n",
      "Train Epoch: 21 [72/107 (67%)]\tTrain Loss: 0.001626\n",
      "Train Epoch: 21 [76/107 (71%)]\tTrain Loss: 0.040589\n",
      "Train Epoch: 21 [80/107 (75%)]\tTrain Loss: 0.010947\n",
      "Train Epoch: 21 [84/107 (79%)]\tTrain Loss: 0.028228\n",
      "Train Epoch: 21 [88/107 (82%)]\tTrain Loss: 0.001916\n",
      "Train Epoch: 21 [92/107 (86%)]\tTrain Loss: 0.005077\n",
      "Train Epoch: 21 [96/107 (90%)]\tTrain Loss: 0.083376\n",
      "Train Epoch: 21 [100/107 (93%)]\tTrain Loss: 0.003390\n",
      "Train Epoch: 21 [104/107 (97%)]\tTrain Loss: 0.042043\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.91312671e-01 2.77569145e-01 7.75263133e-03 4.83341455e-01\n",
      " 5.47261052e-02 3.73058803e-02 5.97120486e-02 3.52715671e-01\n",
      " 5.11641651e-02 1.76506162e-01 8.70497525e-01 4.18977253e-02\n",
      " 6.84651673e-01 4.55565890e-03 3.12323123e-02 1.94137338e-05\n",
      " 2.86293362e-05 3.89146030e-01 7.44894594e-02 9.58992541e-02\n",
      " 1.17939502e-01 9.53286231e-01 9.82373834e-01 9.99992013e-01\n",
      " 4.46656078e-01 9.85335469e-01 9.99850988e-01 3.57838511e-03\n",
      " 4.75290045e-03 1.00608449e-02 3.71811725e-02 1.36647120e-01\n",
      " 9.55169380e-01 1.21471734e-04 2.38407389e-04 1.43484888e-03\n",
      " 1.67369209e-02 2.36219943e-01 2.23287627e-01 7.17380317e-04\n",
      " 4.48709354e-04 4.30321088e-03 3.04460675e-01 7.12703317e-02\n",
      " 1.18154861e-01 7.23079145e-02 9.11398232e-01 8.05874825e-01\n",
      " 9.06228244e-01 6.56794906e-01 9.60246742e-01 1.05710261e-01\n",
      " 1.55378729e-02 2.16087606e-02 7.65220029e-03 1.64977983e-02\n",
      " 8.76677394e-01 5.71800687e-04 1.64745264e-02 1.61187612e-02\n",
      " 9.94714081e-01 9.98034060e-01 9.99897122e-01 9.99706566e-01\n",
      " 9.20282841e-01 9.41706538e-01 9.14915919e-01 9.99999404e-01\n",
      " 9.99335110e-01 9.83940005e-01 3.50866169e-01 1.32859766e-01\n",
      " 7.86607146e-01 9.71754909e-01 9.98357475e-01 8.60648751e-01\n",
      " 9.85776722e-01 7.98344195e-01 9.99496102e-01 9.91183043e-01\n",
      " 9.99242544e-01 9.99899626e-01 9.99392509e-01 7.63239861e-01\n",
      " 5.62246859e-01 9.96849239e-01 9.86021698e-01 9.42756832e-01\n",
      " 4.87319350e-01 9.95126843e-01 9.99969959e-01 9.75697935e-01\n",
      " 9.34627831e-01 1.00000000e+00 9.99572337e-01 9.99988198e-01\n",
      " 7.29963124e-01 1.18820734e-01 6.76759124e-01 9.96443689e-01\n",
      " 2.17773363e-01 8.45217109e-01 7.27616400e-02 8.62547040e-01\n",
      " 9.21877027e-01 9.52298820e-01 9.31270480e-01 3.36991884e-02\n",
      " 7.35543966e-01 8.93766463e-01 7.79681861e-01 2.18570605e-01\n",
      " 9.99998450e-01 9.74633574e-01 9.21465456e-01 8.50773871e-01\n",
      " 9.88016427e-01 9.94311333e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 22 [0/107 (0%)]\tTrain Loss: 0.078712\n",
      "Train Epoch: 22 [4/107 (4%)]\tTrain Loss: 0.011467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [8/107 (7%)]\tTrain Loss: 0.020440\n",
      "Train Epoch: 22 [12/107 (11%)]\tTrain Loss: 0.012725\n",
      "Train Epoch: 22 [16/107 (15%)]\tTrain Loss: 0.012420\n",
      "Train Epoch: 22 [20/107 (19%)]\tTrain Loss: 0.002295\n",
      "Train Epoch: 22 [24/107 (22%)]\tTrain Loss: 0.021639\n",
      "Train Epoch: 22 [28/107 (26%)]\tTrain Loss: 0.007409\n",
      "Train Epoch: 22 [32/107 (30%)]\tTrain Loss: 0.036948\n",
      "Train Epoch: 22 [36/107 (34%)]\tTrain Loss: 0.000950\n",
      "Train Epoch: 22 [40/107 (37%)]\tTrain Loss: 0.106075\n",
      "Train Epoch: 22 [44/107 (41%)]\tTrain Loss: 0.001886\n",
      "Train Epoch: 22 [48/107 (45%)]\tTrain Loss: 0.002836\n",
      "Train Epoch: 22 [52/107 (49%)]\tTrain Loss: 0.105838\n",
      "Train Epoch: 22 [56/107 (52%)]\tTrain Loss: 0.000810\n",
      "Train Epoch: 22 [60/107 (56%)]\tTrain Loss: 0.007854\n",
      "Train Epoch: 22 [64/107 (60%)]\tTrain Loss: 0.151654\n",
      "Train Epoch: 22 [68/107 (64%)]\tTrain Loss: 0.623412\n",
      "Train Epoch: 22 [72/107 (67%)]\tTrain Loss: 0.049555\n",
      "Train Epoch: 22 [76/107 (71%)]\tTrain Loss: 0.375295\n",
      "Train Epoch: 22 [80/107 (75%)]\tTrain Loss: 0.158526\n",
      "Train Epoch: 22 [84/107 (79%)]\tTrain Loss: 0.010152\n",
      "Train Epoch: 22 [88/107 (82%)]\tTrain Loss: 0.019986\n",
      "Train Epoch: 22 [92/107 (86%)]\tTrain Loss: 0.009274\n",
      "Train Epoch: 22 [96/107 (90%)]\tTrain Loss: 0.065278\n",
      "Train Epoch: 22 [100/107 (93%)]\tTrain Loss: 0.001956\n",
      "Train Epoch: 22 [104/107 (97%)]\tTrain Loss: 0.169614\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.23079129e-01 6.36283820e-03 3.20061081e-04 7.17825234e-01\n",
      " 1.40588641e-01 7.35898130e-03 2.15361714e-02 6.83539152e-01\n",
      " 3.37090790e-02 2.35089008e-03 7.86910713e-01 1.38498275e-04\n",
      " 7.40837455e-01 1.81563245e-03 1.76746733e-02 2.56582625e-05\n",
      " 3.40688894e-05 9.49411094e-01 6.27000257e-02 4.72916663e-01\n",
      " 3.97176176e-01 9.19977009e-01 9.99362648e-01 9.99986291e-01\n",
      " 3.28431666e-01 9.92035687e-01 9.99980330e-01 6.61471903e-01\n",
      " 1.35414496e-01 5.20793080e-01 4.02249843e-01 2.65768349e-01\n",
      " 9.57090259e-01 6.96150391e-06 1.73606568e-05 6.33847015e-03\n",
      " 3.37739731e-03 9.97740507e-01 9.51835811e-01 3.31008658e-02\n",
      " 2.76509635e-02 8.87576863e-02 9.94887054e-01 9.15123045e-01\n",
      " 9.86869633e-01 3.14262398e-02 5.59829712e-01 6.58814192e-01\n",
      " 5.78555107e-01 5.88741601e-01 7.21941590e-01 5.32782823e-02\n",
      " 7.25885779e-02 3.72424722e-02 4.75847954e-03 1.83547825e-01\n",
      " 9.80185270e-01 3.21557891e-04 3.34770866e-02 6.09892532e-02\n",
      " 9.61506307e-01 9.77810144e-01 9.99324441e-01 9.99102235e-01\n",
      " 9.99637365e-01 9.96608853e-01 9.91807640e-01 9.99998450e-01\n",
      " 9.99984384e-01 9.99668717e-01 6.47548318e-01 2.98183501e-01\n",
      " 8.36503863e-01 9.92447376e-01 9.99887466e-01 9.97341812e-01\n",
      " 9.93051648e-01 9.41384017e-01 9.98166919e-01 9.89177048e-01\n",
      " 9.91087496e-01 9.99696255e-01 9.98821795e-01 8.46977711e-01\n",
      " 2.42002323e-01 9.87850964e-01 9.93820965e-01 9.60949540e-01\n",
      " 2.28664488e-01 8.96123528e-01 9.99997377e-01 9.99434650e-01\n",
      " 9.96868193e-01 9.99999762e-01 9.95751977e-01 9.99992490e-01\n",
      " 6.81010365e-01 5.78213222e-02 9.80007887e-01 9.97843862e-01\n",
      " 9.05155957e-01 9.72707689e-01 4.79629971e-02 8.28338087e-01\n",
      " 4.68792737e-01 8.76322150e-01 9.94530261e-01 1.87515214e-01\n",
      " 3.11339442e-02 9.90919709e-01 9.01060104e-01 6.94959760e-01\n",
      " 9.99989033e-01 8.17138135e-01 8.77478898e-01 6.09320164e-01\n",
      " 9.98573303e-01 9.99982595e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 23 [0/107 (0%)]\tTrain Loss: 0.000914\n",
      "Train Epoch: 23 [4/107 (4%)]\tTrain Loss: 0.005527\n",
      "Train Epoch: 23 [8/107 (7%)]\tTrain Loss: 0.010625\n",
      "Train Epoch: 23 [12/107 (11%)]\tTrain Loss: 0.578962\n",
      "Train Epoch: 23 [16/107 (15%)]\tTrain Loss: 0.016987\n",
      "Train Epoch: 23 [20/107 (19%)]\tTrain Loss: 0.006046\n",
      "Train Epoch: 23 [24/107 (22%)]\tTrain Loss: 0.001555\n",
      "Train Epoch: 23 [28/107 (26%)]\tTrain Loss: 0.151641\n",
      "Train Epoch: 23 [32/107 (30%)]\tTrain Loss: 0.013541\n",
      "Train Epoch: 23 [36/107 (34%)]\tTrain Loss: 0.001352\n",
      "Train Epoch: 23 [40/107 (37%)]\tTrain Loss: 0.004111\n",
      "Train Epoch: 23 [44/107 (41%)]\tTrain Loss: 0.331674\n",
      "Train Epoch: 23 [48/107 (45%)]\tTrain Loss: 0.203346\n",
      "Train Epoch: 23 [52/107 (49%)]\tTrain Loss: 0.002479\n",
      "Train Epoch: 23 [56/107 (52%)]\tTrain Loss: 0.080333\n",
      "Train Epoch: 23 [60/107 (56%)]\tTrain Loss: 0.127475\n",
      "Train Epoch: 23 [64/107 (60%)]\tTrain Loss: 0.016532\n",
      "Train Epoch: 23 [68/107 (64%)]\tTrain Loss: 0.019799\n",
      "Train Epoch: 23 [72/107 (67%)]\tTrain Loss: 0.016227\n",
      "Train Epoch: 23 [76/107 (71%)]\tTrain Loss: 0.027310\n",
      "Train Epoch: 23 [80/107 (75%)]\tTrain Loss: 0.037294\n",
      "Train Epoch: 23 [84/107 (79%)]\tTrain Loss: 0.357580\n",
      "Train Epoch: 23 [88/107 (82%)]\tTrain Loss: 0.002310\n",
      "Train Epoch: 23 [92/107 (86%)]\tTrain Loss: 0.057386\n",
      "Train Epoch: 23 [96/107 (90%)]\tTrain Loss: 0.000408\n",
      "Train Epoch: 23 [100/107 (93%)]\tTrain Loss: 0.061226\n",
      "Train Epoch: 23 [104/107 (97%)]\tTrain Loss: 0.001912\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.82322953e-02 9.67310989e-05 2.22649949e-04 1.18663080e-01\n",
      " 7.62052136e-03 2.69434950e-03 1.04989670e-03 1.59812137e-01\n",
      " 7.10171182e-03 8.75453576e-02 5.32564819e-01 2.79868513e-01\n",
      " 3.42519075e-01 1.21738121e-03 1.06461986e-03 2.06559957e-06\n",
      " 9.94033053e-06 7.52880871e-01 4.24021995e-03 5.17659009e-01\n",
      " 2.66154498e-01 9.84888673e-01 9.85425711e-01 9.99946117e-01\n",
      " 3.50124300e-01 9.92401123e-01 9.99520898e-01 3.34020928e-02\n",
      " 2.87399907e-03 3.39473039e-02 7.75911845e-03 3.17658205e-03\n",
      " 3.73579085e-01 9.32517378e-06 9.93471622e-06 3.01348185e-03\n",
      " 6.32959534e-04 7.40784228e-01 8.35310519e-02 1.37318886e-04\n",
      " 1.69393446e-04 3.92409833e-03 6.15676999e-01 2.03547284e-01\n",
      " 6.96493164e-02 2.97363847e-03 2.21801057e-01 1.65776089e-01\n",
      " 1.16999678e-01 1.47878632e-01 1.57422513e-01 3.49889183e-03\n",
      " 3.36855510e-03 7.10401218e-03 1.99584216e-02 3.44250305e-03\n",
      " 8.59918058e-01 8.73078825e-05 8.18896014e-03 7.59950082e-04\n",
      " 9.97374177e-01 9.95695710e-01 9.99996662e-01 9.99995589e-01\n",
      " 1.22490615e-01 6.54598847e-02 1.33945793e-01 9.99832511e-01\n",
      " 8.06327403e-01 8.21581304e-01 5.30083328e-02 1.87983047e-02\n",
      " 2.64702793e-02 2.97680825e-01 9.95203733e-01 7.25782692e-01\n",
      " 8.86506736e-01 4.57903475e-01 9.94538248e-01 9.70198631e-01\n",
      " 9.97166812e-01 9.94734764e-01 9.97326136e-01 9.91299093e-01\n",
      " 5.78594685e-01 9.97501075e-01 8.53555799e-01 4.88958240e-01\n",
      " 6.53167395e-03 7.26929128e-01 9.96868670e-01 1.32854864e-01\n",
      " 3.36108536e-01 9.99865532e-01 9.86846864e-01 9.62397277e-01\n",
      " 4.10909429e-02 8.96650374e-01 9.89166319e-01 9.39845800e-01\n",
      " 5.45282252e-02 6.75969601e-01 1.26619649e-03 6.92178488e-01\n",
      " 2.54281461e-01 6.87973499e-01 1.55040175e-01 1.53639624e-02\n",
      " 9.54344273e-02 1.43417820e-01 1.76371872e-01 4.86979261e-02\n",
      " 9.89243150e-01 1.89015165e-01 3.07337437e-02 2.27284700e-01\n",
      " 9.76285696e-01 9.99506593e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 24 [0/107 (0%)]\tTrain Loss: 0.008501\n",
      "Train Epoch: 24 [4/107 (4%)]\tTrain Loss: 0.048774\n",
      "Train Epoch: 24 [8/107 (7%)]\tTrain Loss: 0.092531\n",
      "Train Epoch: 24 [12/107 (11%)]\tTrain Loss: 0.003546\n",
      "Train Epoch: 24 [16/107 (15%)]\tTrain Loss: 0.036707\n",
      "Train Epoch: 24 [20/107 (19%)]\tTrain Loss: 0.588399\n",
      "Train Epoch: 24 [24/107 (22%)]\tTrain Loss: 0.004368\n",
      "Train Epoch: 24 [28/107 (26%)]\tTrain Loss: 0.732140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [32/107 (30%)]\tTrain Loss: 0.004430\n",
      "Train Epoch: 24 [36/107 (34%)]\tTrain Loss: 0.022136\n",
      "Train Epoch: 24 [40/107 (37%)]\tTrain Loss: 0.200539\n",
      "Train Epoch: 24 [44/107 (41%)]\tTrain Loss: 0.184469\n",
      "Train Epoch: 24 [48/107 (45%)]\tTrain Loss: 0.012660\n",
      "Train Epoch: 24 [52/107 (49%)]\tTrain Loss: 0.227211\n",
      "Train Epoch: 24 [56/107 (52%)]\tTrain Loss: 0.010253\n",
      "Train Epoch: 24 [60/107 (56%)]\tTrain Loss: 0.002773\n",
      "Train Epoch: 24 [64/107 (60%)]\tTrain Loss: 0.137052\n",
      "Train Epoch: 24 [68/107 (64%)]\tTrain Loss: 0.000942\n",
      "Train Epoch: 24 [72/107 (67%)]\tTrain Loss: 0.007772\n",
      "Train Epoch: 24 [76/107 (71%)]\tTrain Loss: 0.017172\n",
      "Train Epoch: 24 [80/107 (75%)]\tTrain Loss: 0.003419\n",
      "Train Epoch: 24 [84/107 (79%)]\tTrain Loss: 0.000407\n",
      "Train Epoch: 24 [88/107 (82%)]\tTrain Loss: 0.014448\n",
      "Train Epoch: 24 [92/107 (86%)]\tTrain Loss: 0.070577\n",
      "Train Epoch: 24 [96/107 (90%)]\tTrain Loss: 0.203355\n",
      "Train Epoch: 24 [100/107 (93%)]\tTrain Loss: 0.015577\n",
      "Train Epoch: 24 [104/107 (97%)]\tTrain Loss: 0.080458\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.39965105e-01 9.10725296e-01 3.44893187e-01 9.83932018e-01\n",
      " 9.64821517e-01 5.69302797e-01 8.08176041e-01 6.58460855e-01\n",
      " 4.67407256e-01 5.57688661e-02 5.73113739e-01 1.82628585e-03\n",
      " 5.69672525e-01 2.07205951e-01 4.69295084e-01 1.29467936e-03\n",
      " 3.27553680e-05 9.31879759e-01 2.88468868e-01 6.10487282e-01\n",
      " 3.55960488e-01 6.08946860e-01 9.99967575e-01 9.99998212e-01\n",
      " 6.68349788e-02 9.99988914e-01 9.99981165e-01 2.94506047e-02\n",
      " 4.76410717e-01 3.14033288e-03 8.05850793e-03 1.38566703e-01\n",
      " 3.49074006e-01 3.65079336e-06 4.67027803e-06 2.62253336e-04\n",
      " 3.49851791e-04 7.11136281e-01 6.96323719e-03 3.54118471e-04\n",
      " 3.41774314e-04 1.10331143e-03 1.39552027e-01 3.95573258e-01\n",
      " 7.96707630e-01 5.50476275e-02 9.59619641e-01 9.78681624e-01\n",
      " 8.63280416e-01 9.59928274e-01 9.37423706e-01 2.31131073e-02\n",
      " 1.69310689e-01 1.80849463e-01 3.51791047e-02 9.22067463e-02\n",
      " 9.87676263e-01 1.95125933e-04 5.42056921e-04 1.56613126e-01\n",
      " 9.99317765e-01 9.99576628e-01 9.99955058e-01 9.99955654e-01\n",
      " 9.72611964e-01 9.82945263e-01 9.99184906e-01 1.00000000e+00\n",
      " 9.99991059e-01 9.93669927e-01 9.94399130e-01 9.84108865e-01\n",
      " 8.01361352e-02 2.74220437e-01 9.34019029e-01 1.63130820e-01\n",
      " 9.99791086e-01 9.98394430e-01 9.99999523e-01 9.99631166e-01\n",
      " 9.99990344e-01 9.99964118e-01 9.99921203e-01 1.72211155e-01\n",
      " 6.65110707e-01 9.93732035e-01 9.99772966e-01 9.94012296e-01\n",
      " 8.49178340e-03 3.32033366e-01 9.99401450e-01 6.39753997e-01\n",
      " 7.00040996e-01 9.99999881e-01 9.99968171e-01 9.94830906e-01\n",
      " 7.87474930e-01 1.25207072e-02 8.48319113e-01 9.65749025e-01\n",
      " 5.55218339e-01 9.62908983e-01 1.31268136e-03 9.36015129e-01\n",
      " 9.54295337e-01 9.85374212e-01 9.79780018e-01 6.08534180e-03\n",
      " 1.99316791e-03 9.93633628e-01 3.31460200e-02 8.19630697e-02\n",
      " 9.99973297e-01 5.58925867e-01 3.55113894e-02 9.55612981e-04\n",
      " 7.38251925e-01 9.99017000e-01]\n",
      "predict [1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 25 [0/107 (0%)]\tTrain Loss: 0.009756\n",
      "Train Epoch: 25 [4/107 (4%)]\tTrain Loss: 0.060502\n",
      "Train Epoch: 25 [8/107 (7%)]\tTrain Loss: 0.001225\n",
      "Train Epoch: 25 [12/107 (11%)]\tTrain Loss: 0.110791\n",
      "Train Epoch: 25 [16/107 (15%)]\tTrain Loss: 0.043048\n",
      "Train Epoch: 25 [20/107 (19%)]\tTrain Loss: 0.000919\n",
      "Train Epoch: 25 [24/107 (22%)]\tTrain Loss: 0.004954\n",
      "Train Epoch: 25 [28/107 (26%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 25 [32/107 (30%)]\tTrain Loss: 0.001898\n",
      "Train Epoch: 25 [36/107 (34%)]\tTrain Loss: 0.008142\n",
      "Train Epoch: 25 [40/107 (37%)]\tTrain Loss: 0.003947\n",
      "Train Epoch: 25 [44/107 (41%)]\tTrain Loss: 0.025367\n",
      "Train Epoch: 25 [48/107 (45%)]\tTrain Loss: 0.019588\n",
      "Train Epoch: 25 [52/107 (49%)]\tTrain Loss: 0.003189\n",
      "Train Epoch: 25 [56/107 (52%)]\tTrain Loss: 0.019516\n",
      "Train Epoch: 25 [60/107 (56%)]\tTrain Loss: 0.026540\n",
      "Train Epoch: 25 [64/107 (60%)]\tTrain Loss: 0.001171\n",
      "Train Epoch: 25 [68/107 (64%)]\tTrain Loss: 0.001446\n",
      "Train Epoch: 25 [72/107 (67%)]\tTrain Loss: 0.000280\n",
      "Train Epoch: 25 [76/107 (71%)]\tTrain Loss: 0.036322\n",
      "Train Epoch: 25 [80/107 (75%)]\tTrain Loss: 0.010816\n",
      "Train Epoch: 25 [84/107 (79%)]\tTrain Loss: 0.008569\n",
      "Train Epoch: 25 [88/107 (82%)]\tTrain Loss: 0.251204\n",
      "Train Epoch: 25 [92/107 (86%)]\tTrain Loss: 0.205900\n",
      "Train Epoch: 25 [96/107 (90%)]\tTrain Loss: 0.007336\n",
      "Train Epoch: 25 [100/107 (93%)]\tTrain Loss: 0.082306\n",
      "Train Epoch: 25 [104/107 (97%)]\tTrain Loss: 0.022055\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.16133261e-01 3.60063851e-01 3.43203619e-02 7.06845105e-01\n",
      " 5.10384500e-01 3.18765640e-01 2.19529971e-01 9.26014423e-01\n",
      " 3.34930539e-01 1.03872031e-01 9.52252030e-01 8.28848593e-03\n",
      " 8.85103822e-01 7.57326884e-03 4.69314978e-02 1.74575206e-02\n",
      " 5.58187079e-04 9.83391404e-01 5.93453199e-02 4.24159825e-01\n",
      " 5.49357593e-01 8.85646522e-01 9.99428809e-01 9.99953270e-01\n",
      " 3.34910691e-01 9.99811113e-01 9.99027729e-01 6.99923709e-02\n",
      " 6.87223151e-02 2.47482181e-01 1.35612056e-01 3.96279991e-01\n",
      " 7.11608529e-01 3.06933798e-04 3.32731695e-04 5.55106485e-03\n",
      " 6.37947163e-03 9.70051289e-01 8.28177810e-01 4.04182868e-03\n",
      " 6.62184041e-03 1.99789945e-02 9.17102873e-01 8.32414269e-01\n",
      " 8.87597322e-01 5.60876548e-01 9.84699309e-01 9.73389447e-01\n",
      " 8.96417022e-01 6.29399180e-01 9.66024518e-01 7.63295218e-02\n",
      " 1.94384471e-01 1.64890647e-01 7.76647255e-02 1.50991231e-01\n",
      " 8.09011757e-01 3.33069009e-03 2.06905287e-02 3.55702154e-02\n",
      " 9.98039067e-01 9.94618535e-01 9.99974847e-01 9.99992371e-01\n",
      " 5.57085395e-01 8.34062934e-01 9.95729625e-01 9.99996185e-01\n",
      " 9.98242021e-01 9.96767521e-01 9.92874861e-01 9.64787245e-01\n",
      " 9.24707294e-01 9.71220255e-01 9.99737084e-01 9.69700098e-01\n",
      " 9.99147773e-01 9.46458697e-01 9.99870539e-01 9.99107659e-01\n",
      " 9.99987721e-01 9.99942064e-01 9.99376237e-01 9.20568824e-01\n",
      " 9.29637492e-01 9.98827159e-01 9.98908162e-01 9.90275502e-01\n",
      " 3.30244243e-01 5.60470879e-01 9.99780118e-01 9.63587582e-01\n",
      " 9.12715733e-01 9.99999404e-01 9.99929667e-01 9.99446929e-01\n",
      " 7.37453222e-01 7.83660829e-01 9.93626475e-01 9.97468114e-01\n",
      " 8.67467523e-01 9.83545661e-01 9.00010988e-02 8.13977480e-01\n",
      " 9.12316442e-01 9.77568567e-01 9.72979307e-01 8.36926773e-02\n",
      " 4.99084964e-02 9.77583528e-01 3.42389137e-01 6.09036148e-01\n",
      " 9.99830484e-01 9.40478146e-01 6.48850083e-01 3.40693384e-01\n",
      " 9.59071398e-01 9.96724427e-01]\n",
      "predict [1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 26 [0/107 (0%)]\tTrain Loss: 0.093688\n",
      "Train Epoch: 26 [4/107 (4%)]\tTrain Loss: 0.065275\n",
      "Train Epoch: 26 [8/107 (7%)]\tTrain Loss: 0.251828\n",
      "Train Epoch: 26 [12/107 (11%)]\tTrain Loss: 0.034281\n",
      "Train Epoch: 26 [16/107 (15%)]\tTrain Loss: 0.006067\n",
      "Train Epoch: 26 [20/107 (19%)]\tTrain Loss: 0.007242\n",
      "Train Epoch: 26 [24/107 (22%)]\tTrain Loss: 0.011275\n",
      "Train Epoch: 26 [28/107 (26%)]\tTrain Loss: 0.003777\n",
      "Train Epoch: 26 [32/107 (30%)]\tTrain Loss: 0.004427\n",
      "Train Epoch: 26 [36/107 (34%)]\tTrain Loss: 0.045163\n",
      "Train Epoch: 26 [40/107 (37%)]\tTrain Loss: 0.016347\n",
      "Train Epoch: 26 [44/107 (41%)]\tTrain Loss: 0.042062\n",
      "Train Epoch: 26 [48/107 (45%)]\tTrain Loss: 0.001884\n",
      "Train Epoch: 26 [52/107 (49%)]\tTrain Loss: 0.034296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [56/107 (52%)]\tTrain Loss: 0.001610\n",
      "Train Epoch: 26 [60/107 (56%)]\tTrain Loss: 0.001317\n",
      "Train Epoch: 26 [64/107 (60%)]\tTrain Loss: 0.170053\n",
      "Train Epoch: 26 [68/107 (64%)]\tTrain Loss: 0.003249\n",
      "Train Epoch: 26 [72/107 (67%)]\tTrain Loss: 0.218403\n",
      "Train Epoch: 26 [76/107 (71%)]\tTrain Loss: 0.279574\n",
      "Train Epoch: 26 [80/107 (75%)]\tTrain Loss: 0.189622\n",
      "Train Epoch: 26 [84/107 (79%)]\tTrain Loss: 0.036532\n",
      "Train Epoch: 26 [88/107 (82%)]\tTrain Loss: 0.009703\n",
      "Train Epoch: 26 [92/107 (86%)]\tTrain Loss: 0.006016\n",
      "Train Epoch: 26 [96/107 (90%)]\tTrain Loss: 0.011533\n",
      "Train Epoch: 26 [100/107 (93%)]\tTrain Loss: 0.022699\n",
      "Train Epoch: 26 [104/107 (97%)]\tTrain Loss: 0.001046\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.52130646e-01 6.27570570e-01 1.33759994e-02 6.94646716e-01\n",
      " 7.55387604e-01 1.28232300e-01 4.95740920e-01 6.04260504e-01\n",
      " 1.65759146e-01 1.73847303e-02 8.66582811e-01 1.67959929e-03\n",
      " 9.18822229e-01 4.31239516e-01 3.19730401e-01 3.08303535e-03\n",
      " 4.71702358e-03 9.86617982e-01 2.50558276e-02 6.00116730e-01\n",
      " 5.66811860e-01 9.57734168e-01 9.98061955e-01 9.99962091e-01\n",
      " 4.44738507e-01 9.99560773e-01 9.99840975e-01 3.24016660e-02\n",
      " 7.91285783e-02 5.86978868e-02 4.35644612e-02 9.40588564e-02\n",
      " 5.44151306e-01 5.79831714e-04 1.31694600e-03 4.10563238e-02\n",
      " 1.46562299e-02 9.97562408e-01 1.44153625e-01 5.43705421e-04\n",
      " 1.55031506e-03 5.92283532e-03 9.83853579e-01 9.11187768e-01\n",
      " 9.74603713e-01 7.03453958e-01 9.38216090e-01 7.64903307e-01\n",
      " 5.93879819e-01 9.40991163e-01 6.72857344e-01 5.53091645e-01\n",
      " 1.01149060e-01 4.74342108e-02 1.82995442e-02 4.23575677e-02\n",
      " 9.58816409e-01 8.26682008e-05 2.39223824e-03 4.13306151e-03\n",
      " 9.80617821e-01 9.80453730e-01 9.98976350e-01 9.99390364e-01\n",
      " 9.76640999e-01 9.99471962e-01 9.99608934e-01 9.99993801e-01\n",
      " 9.99990582e-01 9.80054617e-01 8.08700144e-01 7.15494156e-01\n",
      " 9.32564735e-01 9.63208973e-01 9.99490619e-01 5.28194845e-01\n",
      " 9.99976516e-01 9.99619961e-01 9.99978781e-01 9.96180654e-01\n",
      " 9.99963164e-01 9.99830008e-01 9.99076605e-01 9.24287319e-01\n",
      " 8.13044429e-01 9.81988668e-01 9.98103619e-01 9.89475250e-01\n",
      " 1.75177589e-01 9.60398257e-01 9.99952435e-01 9.63561118e-01\n",
      " 9.85024810e-01 1.00000000e+00 9.99998689e-01 9.99942780e-01\n",
      " 5.24286091e-01 2.43274942e-01 9.79096472e-01 9.94832039e-01\n",
      " 2.53286421e-01 9.87974524e-01 1.89960405e-01 9.91583407e-01\n",
      " 9.80116010e-01 9.88280177e-01 9.92765427e-01 1.42632142e-01\n",
      " 4.47670370e-02 8.30782592e-01 5.36199033e-01 4.00895089e-01\n",
      " 9.99999881e-01 7.00804532e-01 3.40426534e-01 1.96106702e-01\n",
      " 9.55958545e-01 9.99700189e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 27 [0/107 (0%)]\tTrain Loss: 0.041393\n",
      "Train Epoch: 27 [4/107 (4%)]\tTrain Loss: 0.039340\n",
      "Train Epoch: 27 [8/107 (7%)]\tTrain Loss: 0.015726\n",
      "Train Epoch: 27 [12/107 (11%)]\tTrain Loss: 0.004385\n",
      "Train Epoch: 27 [16/107 (15%)]\tTrain Loss: 0.012570\n",
      "Train Epoch: 27 [20/107 (19%)]\tTrain Loss: 0.034323\n",
      "Train Epoch: 27 [24/107 (22%)]\tTrain Loss: 0.195942\n",
      "Train Epoch: 27 [28/107 (26%)]\tTrain Loss: 0.011931\n",
      "Train Epoch: 27 [32/107 (30%)]\tTrain Loss: 0.000585\n",
      "Train Epoch: 27 [36/107 (34%)]\tTrain Loss: 0.003139\n",
      "Train Epoch: 27 [40/107 (37%)]\tTrain Loss: 0.221996\n",
      "Train Epoch: 27 [44/107 (41%)]\tTrain Loss: 0.007520\n",
      "Train Epoch: 27 [48/107 (45%)]\tTrain Loss: 0.002336\n",
      "Train Epoch: 27 [52/107 (49%)]\tTrain Loss: 0.042589\n",
      "Train Epoch: 27 [56/107 (52%)]\tTrain Loss: 0.006174\n",
      "Train Epoch: 27 [60/107 (56%)]\tTrain Loss: 0.006357\n",
      "Train Epoch: 27 [64/107 (60%)]\tTrain Loss: 0.003166\n",
      "Train Epoch: 27 [68/107 (64%)]\tTrain Loss: 0.001410\n",
      "Train Epoch: 27 [72/107 (67%)]\tTrain Loss: 0.361400\n",
      "Train Epoch: 27 [76/107 (71%)]\tTrain Loss: 0.016511\n",
      "Train Epoch: 27 [80/107 (75%)]\tTrain Loss: 0.010166\n",
      "Train Epoch: 27 [84/107 (79%)]\tTrain Loss: 0.007911\n",
      "Train Epoch: 27 [88/107 (82%)]\tTrain Loss: 0.027770\n",
      "Train Epoch: 27 [92/107 (86%)]\tTrain Loss: 0.018546\n",
      "Train Epoch: 27 [96/107 (90%)]\tTrain Loss: 0.004643\n",
      "Train Epoch: 27 [100/107 (93%)]\tTrain Loss: 0.013527\n",
      "Train Epoch: 27 [104/107 (97%)]\tTrain Loss: 0.101497\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.17485398e-02 4.74374771e-01 6.42693043e-02 3.05076092e-01\n",
      " 5.45634739e-02 1.66104343e-02 2.89293438e-01 2.91564167e-01\n",
      " 3.02788150e-02 1.84987485e-02 2.32917473e-01 2.57610879e-03\n",
      " 1.58092454e-01 4.93174195e-02 4.68832329e-02 2.55329604e-03\n",
      " 3.51174298e-04 8.23884547e-01 1.99103057e-01 3.51397216e-01\n",
      " 5.02662599e-01 9.28211987e-01 9.96676922e-01 9.99713957e-01\n",
      " 8.20526958e-01 9.87720430e-01 9.98437703e-01 5.89053452e-01\n",
      " 8.83096308e-02 1.38949543e-01 4.05137926e-01 3.38818192e-01\n",
      " 2.82419086e-01 2.24466762e-03 2.42795795e-03 1.96256880e-02\n",
      " 1.49145667e-02 9.81774926e-01 3.30999881e-01 2.37639155e-03\n",
      " 9.89369769e-03 3.15577276e-02 9.76773143e-01 7.98549712e-01\n",
      " 8.97291064e-01 3.18670273e-02 3.29824716e-01 1.97749510e-01\n",
      " 1.09867789e-01 6.30751252e-01 1.83104947e-01 1.55272081e-01\n",
      " 8.86978135e-02 3.63937691e-02 6.36235699e-02 1.04556652e-02\n",
      " 9.55916941e-01 2.41249014e-04 2.96315122e-02 3.14736702e-02\n",
      " 9.86443877e-01 9.86062586e-01 9.95510697e-01 9.98059571e-01\n",
      " 9.96351361e-01 9.92038250e-01 9.69959676e-01 9.99983430e-01\n",
      " 9.99064863e-01 8.24586153e-01 4.34123904e-01 3.82749081e-01\n",
      " 3.41608644e-01 7.09178209e-01 9.97036219e-01 9.58749890e-01\n",
      " 9.79544997e-01 9.04521823e-01 9.99862790e-01 9.51864243e-01\n",
      " 9.90434647e-01 9.98090565e-01 9.99334514e-01 6.75206661e-01\n",
      " 7.88793206e-01 9.76199269e-01 9.98258770e-01 9.85161543e-01\n",
      " 5.36676347e-01 9.37338412e-01 9.90110457e-01 8.40203106e-01\n",
      " 8.48755419e-01 9.99986649e-01 9.78727758e-01 9.91907239e-01\n",
      " 1.96188718e-01 6.52693868e-01 9.33321238e-01 9.94688272e-01\n",
      " 8.79741132e-01 9.89071965e-01 1.51987761e-01 6.50896907e-01\n",
      " 5.00097334e-01 9.50420678e-01 7.03023911e-01 2.95107931e-01\n",
      " 3.78892124e-01 9.54181135e-01 7.77960479e-01 4.06676471e-01\n",
      " 9.99399304e-01 8.03323388e-01 5.73432744e-02 1.97630361e-01\n",
      " 9.32114482e-01 9.99026895e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 28 [0/107 (0%)]\tTrain Loss: 0.047543\n",
      "Train Epoch: 28 [4/107 (4%)]\tTrain Loss: 0.020948\n",
      "Train Epoch: 28 [8/107 (7%)]\tTrain Loss: 0.003175\n",
      "Train Epoch: 28 [12/107 (11%)]\tTrain Loss: 0.032590\n",
      "Train Epoch: 28 [16/107 (15%)]\tTrain Loss: 0.043511\n",
      "Train Epoch: 28 [20/107 (19%)]\tTrain Loss: 0.032669\n",
      "Train Epoch: 28 [24/107 (22%)]\tTrain Loss: 0.001508\n",
      "Train Epoch: 28 [28/107 (26%)]\tTrain Loss: 0.006307\n",
      "Train Epoch: 28 [32/107 (30%)]\tTrain Loss: 0.178869\n",
      "Train Epoch: 28 [36/107 (34%)]\tTrain Loss: 0.009564\n",
      "Train Epoch: 28 [40/107 (37%)]\tTrain Loss: 0.008948\n",
      "Train Epoch: 28 [44/107 (41%)]\tTrain Loss: 0.299943\n",
      "Train Epoch: 28 [48/107 (45%)]\tTrain Loss: 0.001045\n",
      "Train Epoch: 28 [52/107 (49%)]\tTrain Loss: 0.006308\n",
      "Train Epoch: 28 [56/107 (52%)]\tTrain Loss: 0.001542\n",
      "Train Epoch: 28 [60/107 (56%)]\tTrain Loss: 0.049057\n",
      "Train Epoch: 28 [64/107 (60%)]\tTrain Loss: 0.029325\n",
      "Train Epoch: 28 [68/107 (64%)]\tTrain Loss: 0.072852\n",
      "Train Epoch: 28 [72/107 (67%)]\tTrain Loss: 0.001391\n",
      "Train Epoch: 28 [76/107 (71%)]\tTrain Loss: 0.111666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [80/107 (75%)]\tTrain Loss: 0.053168\n",
      "Train Epoch: 28 [84/107 (79%)]\tTrain Loss: 0.011824\n",
      "Train Epoch: 28 [88/107 (82%)]\tTrain Loss: 0.047445\n",
      "Train Epoch: 28 [92/107 (86%)]\tTrain Loss: 0.000531\n",
      "Train Epoch: 28 [96/107 (90%)]\tTrain Loss: 0.004035\n",
      "Train Epoch: 28 [100/107 (93%)]\tTrain Loss: 0.006822\n",
      "Train Epoch: 28 [104/107 (97%)]\tTrain Loss: 0.000895\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.80921185e-01 9.96895194e-01 3.33607882e-01 7.80012906e-01\n",
      " 3.02973330e-01 3.90047915e-02 9.84483659e-01 8.22245538e-01\n",
      " 2.69664656e-02 1.24244913e-01 5.27489245e-01 8.24998785e-03\n",
      " 1.69626221e-01 3.09391439e-01 6.51654124e-01 1.28494063e-03\n",
      " 1.76823552e-04 9.48560476e-01 3.51184756e-01 4.32704449e-01\n",
      " 5.43984711e-01 9.98173833e-01 9.99056399e-01 9.99999762e-01\n",
      " 9.86534774e-01 9.99810159e-01 1.00000000e+00 7.50187710e-02\n",
      " 1.62480518e-01 6.04229234e-02 4.41898793e-01 9.04209673e-01\n",
      " 7.79791057e-01 1.05334562e-03 1.05699920e-03 9.94166825e-03\n",
      " 7.22740777e-03 9.93353844e-01 7.57530153e-01 3.56151140e-04\n",
      " 5.15355263e-04 3.54463398e-03 9.95597899e-01 2.97913373e-01\n",
      " 7.61813998e-01 6.41088411e-02 9.84850883e-01 9.83836234e-01\n",
      " 6.59086347e-01 6.55916333e-01 8.81327569e-01 6.70802742e-02\n",
      " 1.69018105e-01 4.68726039e-01 7.61364773e-02 1.25499591e-01\n",
      " 9.99812901e-01 4.85618686e-04 4.27907594e-02 3.69251221e-01\n",
      " 9.99830604e-01 9.99084592e-01 9.99955773e-01 9.99936104e-01\n",
      " 9.99997854e-01 9.99899387e-01 9.99945402e-01 1.00000000e+00\n",
      " 9.99993324e-01 9.99992371e-01 8.10936153e-01 8.78725886e-01\n",
      " 8.38011324e-01 9.96270061e-01 9.99856114e-01 8.03275585e-01\n",
      " 9.99819219e-01 9.99217629e-01 9.99999762e-01 9.99909520e-01\n",
      " 9.99998689e-01 9.99999046e-01 9.99980211e-01 8.45788240e-01\n",
      " 7.76897252e-01 9.99897480e-01 9.98198807e-01 9.96145487e-01\n",
      " 6.30884945e-01 9.96362507e-01 9.99995232e-01 9.90193546e-01\n",
      " 9.13183808e-01 1.00000000e+00 9.99999762e-01 9.99979615e-01\n",
      " 8.66134524e-01 8.56909394e-01 8.78546894e-01 9.99125779e-01\n",
      " 8.43849659e-01 9.97047365e-01 3.66623998e-02 9.30803537e-01\n",
      " 9.05010581e-01 9.88336384e-01 9.91388381e-01 3.53249088e-02\n",
      " 3.93312782e-01 9.95201945e-01 9.79416788e-01 9.67529416e-01\n",
      " 9.99999881e-01 8.99119437e-01 6.36047572e-02 1.01610258e-01\n",
      " 9.99966860e-01 9.99999881e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 29 [0/107 (0%)]\tTrain Loss: 0.004368\n",
      "Train Epoch: 29 [4/107 (4%)]\tTrain Loss: 0.004651\n",
      "Train Epoch: 29 [8/107 (7%)]\tTrain Loss: 0.000871\n",
      "Train Epoch: 29 [12/107 (11%)]\tTrain Loss: 0.030857\n",
      "Train Epoch: 29 [16/107 (15%)]\tTrain Loss: 0.001353\n",
      "Train Epoch: 29 [20/107 (19%)]\tTrain Loss: 0.001962\n",
      "Train Epoch: 29 [24/107 (22%)]\tTrain Loss: 0.008038\n",
      "Train Epoch: 29 [28/107 (26%)]\tTrain Loss: 0.024970\n",
      "Train Epoch: 29 [32/107 (30%)]\tTrain Loss: 0.008320\n",
      "Train Epoch: 29 [36/107 (34%)]\tTrain Loss: 0.001803\n",
      "Train Epoch: 29 [40/107 (37%)]\tTrain Loss: 0.014469\n",
      "Train Epoch: 29 [44/107 (41%)]\tTrain Loss: 0.338278\n",
      "Train Epoch: 29 [48/107 (45%)]\tTrain Loss: 0.003950\n",
      "Train Epoch: 29 [52/107 (49%)]\tTrain Loss: 0.010919\n",
      "Train Epoch: 29 [56/107 (52%)]\tTrain Loss: 0.023522\n",
      "Train Epoch: 29 [60/107 (56%)]\tTrain Loss: 0.017226\n",
      "Train Epoch: 29 [64/107 (60%)]\tTrain Loss: 0.007580\n",
      "Train Epoch: 29 [68/107 (64%)]\tTrain Loss: 0.048333\n",
      "Train Epoch: 29 [72/107 (67%)]\tTrain Loss: 0.025879\n",
      "Train Epoch: 29 [76/107 (71%)]\tTrain Loss: 0.086056\n",
      "Train Epoch: 29 [80/107 (75%)]\tTrain Loss: 0.002891\n",
      "Train Epoch: 29 [84/107 (79%)]\tTrain Loss: 0.013264\n",
      "Train Epoch: 29 [88/107 (82%)]\tTrain Loss: 0.016323\n",
      "Train Epoch: 29 [92/107 (86%)]\tTrain Loss: 0.007976\n",
      "Train Epoch: 29 [96/107 (90%)]\tTrain Loss: 0.020739\n",
      "Train Epoch: 29 [100/107 (93%)]\tTrain Loss: 0.021671\n",
      "Train Epoch: 29 [104/107 (97%)]\tTrain Loss: 0.003463\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.17274773e-01 8.37050498e-01 2.67595313e-02 7.83955634e-01\n",
      " 3.82805139e-01 2.84775775e-02 7.20080376e-01 9.94486034e-01\n",
      " 6.61399886e-02 9.53897238e-02 5.34301758e-01 3.37566882e-02\n",
      " 1.52684554e-01 2.02753264e-02 3.83231401e-01 1.01403659e-03\n",
      " 3.91594658e-04 9.98257697e-01 2.48111114e-01 6.15506649e-01\n",
      " 7.68258631e-01 9.99854684e-01 9.99952197e-01 9.99989271e-01\n",
      " 9.98740733e-01 9.99797881e-01 9.99936461e-01 7.63878644e-01\n",
      " 5.01484752e-01 3.43276948e-01 9.43700016e-01 9.77556169e-01\n",
      " 9.02367949e-01 1.83394190e-03 1.44214870e-03 4.36661169e-02\n",
      " 7.28668869e-02 9.99735653e-01 7.62727737e-01 2.40993034e-03\n",
      " 4.00623959e-03 6.38811812e-02 9.97862160e-01 7.02631891e-01\n",
      " 9.90771174e-01 1.70632273e-01 9.95522857e-01 9.55407202e-01\n",
      " 4.82349992e-01 2.18560398e-01 8.18805814e-01 1.19611053e-02\n",
      " 9.29350965e-03 7.53332227e-02 3.23844433e-01 4.54064235e-02\n",
      " 9.99812305e-01 1.42359862e-03 7.22246468e-02 3.00765485e-02\n",
      " 9.99935865e-01 9.99921203e-01 9.99997139e-01 9.99997854e-01\n",
      " 9.99993086e-01 9.99922633e-01 9.99998808e-01 1.00000000e+00\n",
      " 9.99977231e-01 9.99745190e-01 7.81740308e-01 8.51982594e-01\n",
      " 8.40218186e-01 9.98941958e-01 9.99999166e-01 9.96027112e-01\n",
      " 9.99440968e-01 9.95479703e-01 9.99999523e-01 9.99899864e-01\n",
      " 9.99998689e-01 9.99972939e-01 9.99554455e-01 9.50998783e-01\n",
      " 9.52031434e-01 9.99879479e-01 9.99296904e-01 9.99177039e-01\n",
      " 9.12955225e-01 9.95202661e-01 9.99511838e-01 8.68376553e-01\n",
      " 9.82870042e-01 9.99998808e-01 9.99967456e-01 9.99878526e-01\n",
      " 9.16837156e-01 9.51619744e-01 9.99811351e-01 9.99861360e-01\n",
      " 9.73923743e-01 9.99400616e-01 4.05103296e-01 7.78275192e-01\n",
      " 5.57544410e-01 8.97810400e-01 8.71420622e-01 4.98420298e-01\n",
      " 4.13775355e-01 9.95981216e-01 8.42704713e-01 4.86824334e-01\n",
      " 9.99101639e-01 9.95626330e-01 3.83284569e-01 5.60831249e-01\n",
      " 9.99997973e-01 9.99998093e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 30 [0/107 (0%)]\tTrain Loss: 0.014141\n",
      "Train Epoch: 30 [4/107 (4%)]\tTrain Loss: 0.109240\n",
      "Train Epoch: 30 [8/107 (7%)]\tTrain Loss: 0.029686\n",
      "Train Epoch: 30 [12/107 (11%)]\tTrain Loss: 0.009842\n",
      "Train Epoch: 30 [16/107 (15%)]\tTrain Loss: 0.101535\n",
      "Train Epoch: 30 [20/107 (19%)]\tTrain Loss: 0.000764\n",
      "Train Epoch: 30 [24/107 (22%)]\tTrain Loss: 0.005362\n",
      "Train Epoch: 30 [28/107 (26%)]\tTrain Loss: 0.003244\n",
      "Train Epoch: 30 [32/107 (30%)]\tTrain Loss: 0.000597\n",
      "Train Epoch: 30 [36/107 (34%)]\tTrain Loss: 0.000780\n",
      "Train Epoch: 30 [40/107 (37%)]\tTrain Loss: 0.003184\n",
      "Train Epoch: 30 [44/107 (41%)]\tTrain Loss: 0.003749\n",
      "Train Epoch: 30 [48/107 (45%)]\tTrain Loss: 0.003389\n",
      "Train Epoch: 30 [52/107 (49%)]\tTrain Loss: 0.003509\n",
      "Train Epoch: 30 [56/107 (52%)]\tTrain Loss: 0.009054\n",
      "Train Epoch: 30 [60/107 (56%)]\tTrain Loss: 0.000850\n",
      "Train Epoch: 30 [64/107 (60%)]\tTrain Loss: 0.007510\n",
      "Train Epoch: 30 [68/107 (64%)]\tTrain Loss: 0.047324\n",
      "Train Epoch: 30 [72/107 (67%)]\tTrain Loss: 0.004378\n",
      "Train Epoch: 30 [76/107 (71%)]\tTrain Loss: 0.040932\n",
      "Train Epoch: 30 [80/107 (75%)]\tTrain Loss: 0.152249\n",
      "Train Epoch: 30 [84/107 (79%)]\tTrain Loss: 0.006885\n",
      "Train Epoch: 30 [88/107 (82%)]\tTrain Loss: 0.000424\n",
      "Train Epoch: 30 [92/107 (86%)]\tTrain Loss: 0.005353\n",
      "Train Epoch: 30 [96/107 (90%)]\tTrain Loss: 0.011109\n",
      "Train Epoch: 30 [100/107 (93%)]\tTrain Loss: 0.020567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [104/107 (97%)]\tTrain Loss: 0.048755\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.51580751e-01 8.46894860e-01 2.68035680e-02 9.96955037e-01\n",
      " 9.70647871e-01 1.01296827e-01 5.55986881e-01 9.83349919e-01\n",
      " 7.53835142e-01 6.23065710e-01 9.96320128e-01 3.78445238e-02\n",
      " 9.92200792e-01 2.51450296e-03 6.25940859e-01 3.11734475e-05\n",
      " 1.78100003e-04 9.92869794e-01 4.35482174e-01 4.35108542e-01\n",
      " 7.36606658e-01 9.99808252e-01 9.99999642e-01 9.99999523e-01\n",
      " 9.92416859e-01 9.99988556e-01 9.99996901e-01 1.23218834e-01\n",
      " 8.94585624e-03 3.72531377e-02 1.09986048e-02 2.31406853e-01\n",
      " 5.74718416e-01 5.95939578e-04 1.29076780e-03 3.69231813e-02\n",
      " 4.33316559e-01 9.99511480e-01 1.99789014e-02 2.63136985e-06\n",
      " 2.48405031e-05 3.06377129e-04 9.24523056e-01 9.94463503e-01\n",
      " 9.99993443e-01 8.29063505e-02 9.98929322e-01 9.84504223e-01\n",
      " 6.72742486e-01 8.97496760e-01 9.19587016e-01 8.50607455e-01\n",
      " 3.74163175e-03 6.84214652e-01 5.41936715e-05 6.60180986e-01\n",
      " 9.99910951e-01 1.72814009e-06 1.91912234e-01 1.46187423e-02\n",
      " 9.99978304e-01 9.99952555e-01 9.99998212e-01 9.99999285e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99940991e-01 1.96268439e-01 4.33463812e-01\n",
      " 9.73314345e-01 9.99277413e-01 1.00000000e+00 9.56577957e-01\n",
      " 9.99857068e-01 9.98472631e-01 1.00000000e+00 9.99999642e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99999046e-01 4.76946115e-01\n",
      " 9.06152308e-01 9.99796689e-01 9.99286354e-01 9.91611421e-01\n",
      " 8.86808574e-01 9.99948382e-01 9.99970436e-01 9.99322176e-01\n",
      " 9.99999642e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99547660e-01 4.34265316e-01 9.94957507e-01 9.99992490e-01\n",
      " 7.20205963e-01 9.97511268e-01 1.63486339e-02 9.98630822e-01\n",
      " 6.00292444e-01 9.95481253e-01 9.68260050e-01 9.13340330e-01\n",
      " 6.48298383e-01 7.01547503e-01 9.88551855e-01 4.66324568e-01\n",
      " 1.00000000e+00 9.99991894e-01 1.76028997e-01 2.53693759e-01\n",
      " 9.99268353e-01 9.99967575e-01]\n",
      "predict [1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 49 TN= 38 FN= 9 FP= 22\n",
      "TP+FP 71\n",
      "precision 0.6901408450704225\n",
      "recall 0.8448275862068966\n",
      "F1 0.7596899224806202\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7390804597701149\n",
      "AUC 0.8373563218390805\n",
      "\n",
      " The epoch is 30, average recall: 0.8448, average precision: 0.6901,average F1: 0.7597, average accuracy: 0.7373, average AUC: 0.8374\n",
      "Train Epoch: 31 [0/107 (0%)]\tTrain Loss: 0.000749\n",
      "Train Epoch: 31 [4/107 (4%)]\tTrain Loss: 0.003423\n",
      "Train Epoch: 31 [8/107 (7%)]\tTrain Loss: 0.001109\n",
      "Train Epoch: 31 [12/107 (11%)]\tTrain Loss: 0.003771\n",
      "Train Epoch: 31 [16/107 (15%)]\tTrain Loss: 0.005877\n",
      "Train Epoch: 31 [20/107 (19%)]\tTrain Loss: 0.043404\n",
      "Train Epoch: 31 [24/107 (22%)]\tTrain Loss: 0.001794\n",
      "Train Epoch: 31 [28/107 (26%)]\tTrain Loss: 0.000131\n",
      "Train Epoch: 31 [32/107 (30%)]\tTrain Loss: 0.000474\n",
      "Train Epoch: 31 [36/107 (34%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 31 [40/107 (37%)]\tTrain Loss: 0.077392\n",
      "Train Epoch: 31 [44/107 (41%)]\tTrain Loss: 0.017525\n",
      "Train Epoch: 31 [48/107 (45%)]\tTrain Loss: 0.033533\n",
      "Train Epoch: 31 [52/107 (49%)]\tTrain Loss: 0.007777\n",
      "Train Epoch: 31 [56/107 (52%)]\tTrain Loss: 0.386071\n",
      "Train Epoch: 31 [60/107 (56%)]\tTrain Loss: 0.013438\n",
      "Train Epoch: 31 [64/107 (60%)]\tTrain Loss: 0.019641\n",
      "Train Epoch: 31 [68/107 (64%)]\tTrain Loss: 0.001442\n",
      "Train Epoch: 31 [72/107 (67%)]\tTrain Loss: 0.008960\n",
      "Train Epoch: 31 [76/107 (71%)]\tTrain Loss: 0.009087\n",
      "Train Epoch: 31 [80/107 (75%)]\tTrain Loss: 0.149081\n",
      "Train Epoch: 31 [84/107 (79%)]\tTrain Loss: 0.074668\n",
      "Train Epoch: 31 [88/107 (82%)]\tTrain Loss: 0.079220\n",
      "Train Epoch: 31 [92/107 (86%)]\tTrain Loss: 0.030309\n",
      "Train Epoch: 31 [96/107 (90%)]\tTrain Loss: 0.004460\n",
      "Train Epoch: 31 [100/107 (93%)]\tTrain Loss: 0.001228\n",
      "Train Epoch: 31 [104/107 (97%)]\tTrain Loss: 0.033495\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.13661984e-01 9.85000849e-01 1.86936900e-01 9.50056136e-01\n",
      " 9.85032976e-01 3.71832661e-02 8.92352700e-01 9.96110499e-01\n",
      " 1.14147790e-01 1.37413740e-01 6.29669487e-01 3.34790908e-02\n",
      " 8.11963558e-01 3.79872974e-03 1.78639919e-01 7.04327552e-03\n",
      " 3.29083065e-04 9.95524645e-01 8.90198350e-03 2.18416154e-01\n",
      " 1.84684724e-01 9.99731600e-01 9.98919606e-01 9.99897957e-01\n",
      " 9.99925494e-01 9.92862284e-01 9.99972582e-01 5.47558852e-02\n",
      " 3.21481051e-03 1.73262149e-01 1.79415420e-01 2.76106536e-01\n",
      " 7.03759074e-01 7.67493667e-03 1.52182998e-02 7.91134592e-03\n",
      " 1.29934549e-02 9.99818742e-01 9.37834382e-01 9.33073345e-04\n",
      " 2.58292607e-03 1.33370291e-02 9.99489188e-01 9.73901510e-01\n",
      " 9.56878364e-01 1.58437222e-01 9.76790547e-01 9.84403908e-01\n",
      " 7.44352400e-01 6.39308572e-01 8.56706142e-01 2.74079330e-02\n",
      " 4.18557115e-02 5.54078957e-03 1.53105771e-02 6.12977333e-02\n",
      " 9.98342037e-01 2.97111081e-04 5.75951561e-02 8.78758281e-02\n",
      " 9.99606550e-01 9.98320401e-01 9.99943256e-01 9.99991775e-01\n",
      " 9.99998927e-01 9.99768436e-01 9.99943256e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99895573e-01 9.63579178e-01 8.16818058e-01\n",
      " 9.91587460e-01 9.96845901e-01 9.99929905e-01 9.97291386e-01\n",
      " 9.99929667e-01 9.99099493e-01 9.99999285e-01 9.99859452e-01\n",
      " 9.99998927e-01 9.99998212e-01 9.99870420e-01 9.45531845e-01\n",
      " 9.36858773e-01 9.98700380e-01 9.94927168e-01 9.95841444e-01\n",
      " 4.12498832e-01 9.95651543e-01 9.99117911e-01 9.89006996e-01\n",
      " 9.98655677e-01 9.99999046e-01 9.99970913e-01 9.99994159e-01\n",
      " 5.93898475e-01 9.94201481e-01 9.90591705e-01 9.99895811e-01\n",
      " 9.75540996e-01 9.97832716e-01 2.66670417e-02 6.67458832e-01\n",
      " 9.04281378e-01 9.79142070e-01 9.58632350e-01 4.96793509e-01\n",
      " 5.43789029e-01 9.62730825e-01 9.88134623e-01 8.68487000e-01\n",
      " 9.99994755e-01 9.87886310e-01 2.43552830e-02 7.82778203e-01\n",
      " 9.99996662e-01 9.99963641e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 32 [0/107 (0%)]\tTrain Loss: 0.033327\n",
      "Train Epoch: 32 [4/107 (4%)]\tTrain Loss: 0.000936\n",
      "Train Epoch: 32 [8/107 (7%)]\tTrain Loss: 0.039951\n",
      "Train Epoch: 32 [12/107 (11%)]\tTrain Loss: 0.011330\n",
      "Train Epoch: 32 [16/107 (15%)]\tTrain Loss: 0.042416\n",
      "Train Epoch: 32 [20/107 (19%)]\tTrain Loss: 0.020563\n",
      "Train Epoch: 32 [24/107 (22%)]\tTrain Loss: 0.134644\n",
      "Train Epoch: 32 [28/107 (26%)]\tTrain Loss: 0.081573\n",
      "Train Epoch: 32 [32/107 (30%)]\tTrain Loss: 0.145034\n",
      "Train Epoch: 32 [36/107 (34%)]\tTrain Loss: 0.000761\n",
      "Train Epoch: 32 [40/107 (37%)]\tTrain Loss: 0.028445\n",
      "Train Epoch: 32 [44/107 (41%)]\tTrain Loss: 0.008073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [48/107 (45%)]\tTrain Loss: 0.411618\n",
      "Train Epoch: 32 [52/107 (49%)]\tTrain Loss: 0.076133\n",
      "Train Epoch: 32 [56/107 (52%)]\tTrain Loss: 0.009506\n",
      "Train Epoch: 32 [60/107 (56%)]\tTrain Loss: 0.002590\n",
      "Train Epoch: 32 [64/107 (60%)]\tTrain Loss: 0.153629\n",
      "Train Epoch: 32 [68/107 (64%)]\tTrain Loss: 0.092585\n",
      "Train Epoch: 32 [72/107 (67%)]\tTrain Loss: 0.029680\n",
      "Train Epoch: 32 [76/107 (71%)]\tTrain Loss: 0.029886\n",
      "Train Epoch: 32 [80/107 (75%)]\tTrain Loss: 0.015673\n",
      "Train Epoch: 32 [84/107 (79%)]\tTrain Loss: 0.003810\n",
      "Train Epoch: 32 [88/107 (82%)]\tTrain Loss: 0.012160\n",
      "Train Epoch: 32 [92/107 (86%)]\tTrain Loss: 0.001812\n",
      "Train Epoch: 32 [96/107 (90%)]\tTrain Loss: 0.004232\n",
      "Train Epoch: 32 [100/107 (93%)]\tTrain Loss: 0.007155\n",
      "Train Epoch: 32 [104/107 (97%)]\tTrain Loss: 0.000885\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.99550068e-01 9.84196842e-01 4.41985503e-02 4.28935349e-01\n",
      " 9.54338014e-01 8.14763457e-02 8.91178966e-01 7.58585036e-01\n",
      " 5.37298657e-02 9.87519771e-02 2.00844303e-01 1.68601032e-02\n",
      " 1.40859962e-01 3.30630392e-02 2.01731831e-01 3.33151926e-04\n",
      " 1.39215274e-03 9.90285695e-01 1.38976956e-02 7.06854686e-02\n",
      " 8.93712789e-02 9.94518220e-01 9.98876750e-01 9.99963641e-01\n",
      " 9.97121155e-01 9.99665141e-01 9.99951839e-01 3.15818167e-03\n",
      " 1.71598773e-02 1.04192477e-02 3.20213474e-03 2.61384398e-01\n",
      " 1.64239660e-01 1.27302529e-03 1.34252687e-03 7.03522516e-03\n",
      " 7.27932621e-03 9.95955467e-01 6.67997301e-01 1.64284967e-04\n",
      " 1.19226323e-04 3.05343117e-03 9.67335105e-01 1.49204984e-01\n",
      " 4.38313484e-01 6.47567809e-01 9.86871362e-01 9.26828504e-01\n",
      " 7.40005612e-01 4.74048018e-01 8.59378397e-01 5.71136214e-02\n",
      " 4.74988222e-02 4.80903648e-02 3.71833495e-03 8.52881465e-03\n",
      " 9.96236742e-01 3.14561476e-04 1.42505430e-02 2.22707149e-02\n",
      " 9.95160282e-01 9.52547967e-01 9.97433245e-01 9.99766409e-01\n",
      " 9.98881400e-01 9.96286154e-01 9.99932051e-01 9.99999046e-01\n",
      " 9.99913931e-01 9.99811709e-01 9.50788558e-01 9.23909664e-01\n",
      " 9.50545549e-01 9.53681588e-01 9.99125779e-01 4.46850032e-01\n",
      " 9.99888182e-01 9.97580171e-01 9.99999881e-01 9.99769509e-01\n",
      " 9.99998212e-01 9.99991894e-01 9.99401093e-01 5.08259177e-01\n",
      " 9.19837117e-01 9.97531891e-01 9.95294392e-01 9.98269796e-01\n",
      " 8.92755985e-02 8.99263442e-01 9.99999166e-01 8.72815251e-01\n",
      " 9.49374437e-01 9.99998689e-01 9.99991059e-01 9.99981284e-01\n",
      " 4.59656686e-01 9.59279656e-01 9.81383979e-01 9.95686054e-01\n",
      " 8.31812501e-01 9.89092469e-01 2.33211517e-02 9.84820008e-01\n",
      " 9.63878870e-01 9.99660254e-01 9.96486902e-01 1.48425147e-01\n",
      " 6.07799040e-03 7.46226072e-01 4.58961278e-01 9.13243592e-01\n",
      " 9.99974251e-01 9.38319385e-01 1.59977674e-02 4.41664411e-03\n",
      " 9.99965906e-01 9.99914527e-01]\n",
      "predict [1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 33 [0/107 (0%)]\tTrain Loss: 0.040327\n",
      "Train Epoch: 33 [4/107 (4%)]\tTrain Loss: 0.003057\n",
      "Train Epoch: 33 [8/107 (7%)]\tTrain Loss: 0.041529\n",
      "Train Epoch: 33 [12/107 (11%)]\tTrain Loss: 0.013936\n",
      "Train Epoch: 33 [16/107 (15%)]\tTrain Loss: 0.002479\n",
      "Train Epoch: 33 [20/107 (19%)]\tTrain Loss: 0.313505\n",
      "Train Epoch: 33 [24/107 (22%)]\tTrain Loss: 0.006133\n",
      "Train Epoch: 33 [28/107 (26%)]\tTrain Loss: 0.000629\n",
      "Train Epoch: 33 [32/107 (30%)]\tTrain Loss: 0.010169\n",
      "Train Epoch: 33 [36/107 (34%)]\tTrain Loss: 0.012972\n",
      "Train Epoch: 33 [40/107 (37%)]\tTrain Loss: 0.001815\n",
      "Train Epoch: 33 [44/107 (41%)]\tTrain Loss: 0.011062\n",
      "Train Epoch: 33 [48/107 (45%)]\tTrain Loss: 0.024256\n",
      "Train Epoch: 33 [52/107 (49%)]\tTrain Loss: 0.004534\n",
      "Train Epoch: 33 [56/107 (52%)]\tTrain Loss: 0.022510\n",
      "Train Epoch: 33 [60/107 (56%)]\tTrain Loss: 0.001321\n",
      "Train Epoch: 33 [64/107 (60%)]\tTrain Loss: 0.000769\n",
      "Train Epoch: 33 [68/107 (64%)]\tTrain Loss: 0.000247\n",
      "Train Epoch: 33 [72/107 (67%)]\tTrain Loss: 0.000290\n",
      "Train Epoch: 33 [76/107 (71%)]\tTrain Loss: 0.008818\n",
      "Train Epoch: 33 [80/107 (75%)]\tTrain Loss: 0.001481\n",
      "Train Epoch: 33 [84/107 (79%)]\tTrain Loss: 0.002387\n",
      "Train Epoch: 33 [88/107 (82%)]\tTrain Loss: 0.003792\n",
      "Train Epoch: 33 [92/107 (86%)]\tTrain Loss: 0.177734\n",
      "Train Epoch: 33 [96/107 (90%)]\tTrain Loss: 0.001699\n",
      "Train Epoch: 33 [100/107 (93%)]\tTrain Loss: 0.021266\n",
      "Train Epoch: 33 [104/107 (97%)]\tTrain Loss: 0.034220\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.04514584e-01 9.28649306e-01 2.39041418e-01 1.00583225e-01\n",
      " 3.04515988e-01 3.18526551e-02 9.07984376e-01 4.95648831e-01\n",
      " 2.13340353e-02 1.37498323e-02 6.23286888e-02 2.04202277e-03\n",
      " 5.47472835e-02 6.31001021e-04 8.98987893e-03 1.92141393e-04\n",
      " 8.74978105e-06 7.86381483e-01 2.45663105e-04 1.45227648e-02\n",
      " 1.50159234e-02 8.44626069e-01 8.80101562e-01 9.96612966e-01\n",
      " 9.03357327e-01 9.15658355e-01 9.98331368e-01 2.15933006e-03\n",
      " 5.65574854e-04 1.28898158e-04 6.99696224e-03 1.32026430e-02\n",
      " 6.25557303e-02 3.70116031e-05 5.94401325e-04 3.28765309e-05\n",
      " 4.51287575e-04 8.33581328e-01 4.52006198e-02 5.58423108e-06\n",
      " 7.01282761e-06 1.93282976e-05 8.96334112e-01 5.30266669e-03\n",
      " 3.52963731e-02 3.81180532e-02 3.70566905e-01 4.15914029e-01\n",
      " 2.44847059e-01 1.25122175e-01 2.73589343e-01 1.30582857e-03\n",
      " 4.08455409e-04 9.26022010e-04 2.74593709e-03 5.48821758e-04\n",
      " 9.41438854e-01 7.34915602e-07 3.26704467e-03 1.60431024e-03\n",
      " 9.77459013e-01 9.07922745e-01 9.93190229e-01 9.97997940e-01\n",
      " 9.67427433e-01 6.47567093e-01 8.42648089e-01 9.99745309e-01\n",
      " 9.51646864e-01 9.62203681e-01 8.41376066e-01 3.92616063e-01\n",
      " 3.05947602e-01 7.86068738e-01 9.95355844e-01 1.53617695e-01\n",
      " 9.97642696e-01 9.78207648e-01 9.97997105e-01 9.62055266e-01\n",
      " 9.97364938e-01 9.98552501e-01 9.87109900e-01 5.07624924e-01\n",
      " 6.37496352e-01 9.53788161e-01 8.74212384e-01 9.33454692e-01\n",
      " 2.68232115e-02 8.64610970e-01 9.76608157e-01 3.19036663e-01\n",
      " 2.15138033e-01 9.98814344e-01 9.97061908e-01 9.58579659e-01\n",
      " 3.40463594e-02 9.56321597e-01 9.13484752e-01 8.61227632e-01\n",
      " 5.01778960e-01 9.75556910e-01 2.76656896e-02 1.95959315e-01\n",
      " 4.17220235e-01 8.80469203e-01 8.98556471e-01 6.22529015e-02\n",
      " 5.27089015e-02 3.54688764e-02 1.80905819e-01 7.83702135e-01\n",
      " 9.69147027e-01 8.62078369e-01 7.81760272e-03 1.60954217e-03\n",
      " 9.99411941e-01 9.70757782e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 34 [0/107 (0%)]\tTrain Loss: 0.005197\n",
      "Train Epoch: 34 [4/107 (4%)]\tTrain Loss: 0.003576\n",
      "Train Epoch: 34 [8/107 (7%)]\tTrain Loss: 0.000530\n",
      "Train Epoch: 34 [12/107 (11%)]\tTrain Loss: 0.007385\n",
      "Train Epoch: 34 [16/107 (15%)]\tTrain Loss: 0.209581\n",
      "Train Epoch: 34 [20/107 (19%)]\tTrain Loss: 0.000720\n",
      "Train Epoch: 34 [24/107 (22%)]\tTrain Loss: 0.001496\n",
      "Train Epoch: 34 [28/107 (26%)]\tTrain Loss: 0.023926\n",
      "Train Epoch: 34 [32/107 (30%)]\tTrain Loss: 0.001129\n",
      "Train Epoch: 34 [36/107 (34%)]\tTrain Loss: 0.001860\n",
      "Train Epoch: 34 [40/107 (37%)]\tTrain Loss: 0.044125\n",
      "Train Epoch: 34 [44/107 (41%)]\tTrain Loss: 0.032090\n",
      "Train Epoch: 34 [48/107 (45%)]\tTrain Loss: 0.013685\n",
      "Train Epoch: 34 [52/107 (49%)]\tTrain Loss: 0.001528\n",
      "Train Epoch: 34 [56/107 (52%)]\tTrain Loss: 0.003282\n",
      "Train Epoch: 34 [60/107 (56%)]\tTrain Loss: 0.000694\n",
      "Train Epoch: 34 [64/107 (60%)]\tTrain Loss: 0.012432\n",
      "Train Epoch: 34 [68/107 (64%)]\tTrain Loss: 0.000201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [72/107 (67%)]\tTrain Loss: 0.322655\n",
      "Train Epoch: 34 [76/107 (71%)]\tTrain Loss: 0.028245\n",
      "Train Epoch: 34 [80/107 (75%)]\tTrain Loss: 0.009318\n",
      "Train Epoch: 34 [84/107 (79%)]\tTrain Loss: 0.101260\n",
      "Train Epoch: 34 [88/107 (82%)]\tTrain Loss: 0.001428\n",
      "Train Epoch: 34 [92/107 (86%)]\tTrain Loss: 0.002358\n",
      "Train Epoch: 34 [96/107 (90%)]\tTrain Loss: 0.000395\n",
      "Train Epoch: 34 [100/107 (93%)]\tTrain Loss: 0.002136\n",
      "Train Epoch: 34 [104/107 (97%)]\tTrain Loss: 0.217984\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.54003257e-02 8.22898030e-01 1.36940286e-01 3.23111236e-01\n",
      " 7.67449439e-02 4.49921861e-02 9.32862461e-01 3.47217709e-01\n",
      " 3.04716919e-02 8.23761448e-02 4.89016682e-01 2.39374978e-03\n",
      " 1.38113067e-01 4.85940720e-04 2.49319840e-02 1.22568076e-06\n",
      " 7.23443600e-06 9.85370398e-01 1.03662694e-02 2.61675566e-01\n",
      " 1.81509584e-01 9.76378083e-01 9.99531865e-01 9.99981046e-01\n",
      " 9.24115717e-01 9.98726308e-01 9.99584496e-01 8.61684009e-02\n",
      " 3.92855983e-03 1.71468104e-03 3.61137331e-01 5.14221787e-02\n",
      " 7.54747629e-01 1.83636985e-05 8.21421418e-06 2.38142544e-04\n",
      " 1.17720896e-03 9.86800432e-01 1.50758833e-01 2.92225604e-06\n",
      " 8.26137057e-06 1.17438918e-04 9.06420469e-01 1.97685704e-01\n",
      " 8.85276198e-01 1.67813182e-01 8.85743678e-01 7.40853369e-01\n",
      " 7.13261664e-01 5.97877383e-01 8.06131482e-01 3.85833974e-03\n",
      " 2.44385619e-02 1.79994898e-03 1.34855300e-01 3.81954189e-04\n",
      " 9.98472631e-01 4.30829778e-06 2.81408168e-02 1.15792258e-02\n",
      " 9.99348819e-01 9.98493910e-01 9.99883413e-01 9.99964476e-01\n",
      " 9.99700904e-01 9.78290915e-01 9.95667100e-01 9.99998927e-01\n",
      " 9.91283298e-01 9.97145832e-01 9.57795203e-01 7.96330988e-01\n",
      " 8.86382818e-01 9.89608705e-01 9.99835253e-01 9.99328375e-01\n",
      " 9.98356283e-01 9.94763374e-01 9.99996066e-01 9.98946369e-01\n",
      " 9.99902010e-01 9.99645829e-01 9.98777807e-01 9.84062791e-01\n",
      " 9.31624949e-01 9.99827862e-01 9.96330082e-01 9.98536229e-01\n",
      " 4.99615490e-01 8.24592769e-01 9.99869943e-01 6.88839316e-01\n",
      " 7.18256474e-01 9.99995708e-01 9.99737322e-01 9.99821007e-01\n",
      " 5.79116821e-01 8.67466748e-01 9.97530878e-01 9.28027630e-01\n",
      " 8.88391078e-01 9.98943627e-01 5.17325997e-02 9.64271188e-01\n",
      " 8.98890316e-01 9.83766317e-01 9.88726735e-01 3.79099965e-01\n",
      " 1.00185592e-02 9.81533706e-01 7.24905133e-01 2.25946829e-01\n",
      " 9.95357931e-01 9.83548462e-01 2.05489639e-02 3.50240737e-01\n",
      " 9.98877466e-01 9.94661033e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 35 [0/107 (0%)]\tTrain Loss: 0.008975\n",
      "Train Epoch: 35 [4/107 (4%)]\tTrain Loss: 0.105480\n",
      "Train Epoch: 35 [8/107 (7%)]\tTrain Loss: 0.001414\n",
      "Train Epoch: 35 [12/107 (11%)]\tTrain Loss: 0.001923\n",
      "Train Epoch: 35 [16/107 (15%)]\tTrain Loss: 0.001377\n",
      "Train Epoch: 35 [20/107 (19%)]\tTrain Loss: 0.022170\n",
      "Train Epoch: 35 [24/107 (22%)]\tTrain Loss: 0.001975\n",
      "Train Epoch: 35 [28/107 (26%)]\tTrain Loss: 0.038201\n",
      "Train Epoch: 35 [32/107 (30%)]\tTrain Loss: 0.017301\n",
      "Train Epoch: 35 [36/107 (34%)]\tTrain Loss: 0.008479\n",
      "Train Epoch: 35 [40/107 (37%)]\tTrain Loss: 0.003078\n",
      "Train Epoch: 35 [44/107 (41%)]\tTrain Loss: 0.019720\n",
      "Train Epoch: 35 [48/107 (45%)]\tTrain Loss: 0.027043\n",
      "Train Epoch: 35 [52/107 (49%)]\tTrain Loss: 0.011990\n",
      "Train Epoch: 35 [56/107 (52%)]\tTrain Loss: 0.000149\n",
      "Train Epoch: 35 [60/107 (56%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 35 [64/107 (60%)]\tTrain Loss: 0.002658\n",
      "Train Epoch: 35 [68/107 (64%)]\tTrain Loss: 0.048643\n",
      "Train Epoch: 35 [72/107 (67%)]\tTrain Loss: 0.002169\n",
      "Train Epoch: 35 [76/107 (71%)]\tTrain Loss: 0.200171\n",
      "Train Epoch: 35 [80/107 (75%)]\tTrain Loss: 0.057711\n",
      "Train Epoch: 35 [84/107 (79%)]\tTrain Loss: 0.014329\n",
      "Train Epoch: 35 [88/107 (82%)]\tTrain Loss: 0.006163\n",
      "Train Epoch: 35 [92/107 (86%)]\tTrain Loss: 0.018652\n",
      "Train Epoch: 35 [96/107 (90%)]\tTrain Loss: 0.109303\n",
      "Train Epoch: 35 [100/107 (93%)]\tTrain Loss: 0.007652\n",
      "Train Epoch: 35 [104/107 (97%)]\tTrain Loss: 0.018075\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.23666537e-02 9.95549798e-01 4.37849790e-01 8.47927094e-01\n",
      " 9.81420934e-01 1.43189713e-01 9.92271781e-01 9.95421708e-01\n",
      " 9.73100588e-03 4.28476110e-02 5.99216104e-01 5.71641140e-03\n",
      " 7.67814040e-01 9.93593247e-04 7.28738029e-03 4.21707227e-04\n",
      " 7.57235102e-05 9.99581993e-01 3.86269833e-03 1.99686244e-01\n",
      " 2.69987643e-01 9.99401808e-01 9.97730672e-01 9.99972105e-01\n",
      " 9.99930382e-01 9.97591376e-01 9.99896407e-01 2.71293577e-02\n",
      " 5.93108358e-03 1.60101766e-03 3.33946198e-01 9.06457845e-03\n",
      " 2.25158289e-01 3.22484248e-03 1.17101171e-03 3.76087381e-03\n",
      " 5.69276931e-03 9.99964356e-01 9.92152274e-01 1.41255208e-04\n",
      " 5.34536492e-04 8.50605220e-03 9.99888659e-01 8.04088265e-02\n",
      " 4.68894094e-02 4.05607261e-02 5.63673973e-01 6.38496339e-01\n",
      " 6.57431006e-01 4.50762868e-01 7.99194455e-01 7.63523672e-03\n",
      " 7.62676401e-03 2.40070969e-02 2.09980428e-01 1.06307853e-03\n",
      " 9.99115050e-01 6.35487158e-05 5.16018039e-03 2.17843149e-02\n",
      " 9.96914268e-01 9.96082008e-01 9.99381423e-01 9.99657154e-01\n",
      " 9.92029011e-01 9.55220640e-01 9.99823987e-01 1.00000000e+00\n",
      " 9.99995828e-01 9.99110997e-01 9.72393930e-01 9.38233852e-01\n",
      " 9.55239356e-01 9.97600496e-01 9.99996781e-01 9.37756181e-01\n",
      " 9.99933839e-01 9.98676240e-01 9.99986172e-01 9.99015450e-01\n",
      " 9.99996781e-01 9.99996781e-01 9.99846816e-01 9.38533545e-01\n",
      " 9.85417724e-01 9.99470174e-01 9.93826568e-01 9.97975171e-01\n",
      " 8.82349253e-01 9.07268703e-01 9.99999166e-01 9.80107427e-01\n",
      " 9.97812390e-01 1.00000000e+00 9.99999285e-01 9.99999881e-01\n",
      " 1.92301691e-01 9.99036074e-01 9.99988794e-01 9.99421597e-01\n",
      " 9.76112902e-01 9.96257782e-01 1.61447331e-01 9.55493689e-01\n",
      " 7.95876443e-01 9.93539512e-01 9.99777853e-01 7.55996048e-01\n",
      " 3.09225857e-01 9.89085495e-01 9.46425915e-01 9.96198595e-01\n",
      " 9.99976635e-01 9.99837160e-01 5.89128993e-02 2.67148204e-02\n",
      " 1.00000000e+00 9.97104943e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 36 [0/107 (0%)]\tTrain Loss: 0.004774\n",
      "Train Epoch: 36 [4/107 (4%)]\tTrain Loss: 0.016732\n",
      "Train Epoch: 36 [8/107 (7%)]\tTrain Loss: 0.002302\n",
      "Train Epoch: 36 [12/107 (11%)]\tTrain Loss: 0.038084\n",
      "Train Epoch: 36 [16/107 (15%)]\tTrain Loss: 0.060209\n",
      "Train Epoch: 36 [20/107 (19%)]\tTrain Loss: 0.001024\n",
      "Train Epoch: 36 [24/107 (22%)]\tTrain Loss: 0.008773\n",
      "Train Epoch: 36 [28/107 (26%)]\tTrain Loss: 0.034261\n",
      "Train Epoch: 36 [32/107 (30%)]\tTrain Loss: 0.000583\n",
      "Train Epoch: 36 [36/107 (34%)]\tTrain Loss: 0.001399\n",
      "Train Epoch: 36 [40/107 (37%)]\tTrain Loss: 0.008171\n",
      "Train Epoch: 36 [44/107 (41%)]\tTrain Loss: 0.040488\n",
      "Train Epoch: 36 [48/107 (45%)]\tTrain Loss: 0.033965\n",
      "Train Epoch: 36 [52/107 (49%)]\tTrain Loss: 0.028438\n",
      "Train Epoch: 36 [56/107 (52%)]\tTrain Loss: 0.068566\n",
      "Train Epoch: 36 [60/107 (56%)]\tTrain Loss: 0.001253\n",
      "Train Epoch: 36 [64/107 (60%)]\tTrain Loss: 0.038740\n",
      "Train Epoch: 36 [68/107 (64%)]\tTrain Loss: 0.068264\n",
      "Train Epoch: 36 [72/107 (67%)]\tTrain Loss: 0.086224\n",
      "Train Epoch: 36 [76/107 (71%)]\tTrain Loss: 0.450984\n",
      "Train Epoch: 36 [80/107 (75%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 36 [84/107 (79%)]\tTrain Loss: 0.000128\n",
      "Train Epoch: 36 [88/107 (82%)]\tTrain Loss: 0.252471\n",
      "Train Epoch: 36 [92/107 (86%)]\tTrain Loss: 0.000059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [96/107 (90%)]\tTrain Loss: 0.001035\n",
      "Train Epoch: 36 [100/107 (93%)]\tTrain Loss: 0.002845\n",
      "Train Epoch: 36 [104/107 (97%)]\tTrain Loss: 0.034010\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.11058706e-02 8.30126882e-01 2.64052749e-02 9.86184776e-01\n",
      " 9.89745438e-01 7.16468394e-02 6.35308206e-01 9.94314253e-01\n",
      " 4.20402065e-02 3.26848209e-01 9.81158078e-01 3.83910626e-01\n",
      " 9.69247818e-01 6.03463151e-04 4.44901772e-02 3.66675016e-03\n",
      " 2.91951397e-03 9.99869943e-01 1.64852202e-01 2.51065284e-01\n",
      " 2.14839607e-01 9.99953628e-01 9.99997616e-01 9.99998927e-01\n",
      " 9.99999046e-01 9.99982953e-01 9.99998927e-01 1.55138774e-02\n",
      " 2.12157905e-01 4.51635234e-02 9.24967885e-01 7.80001044e-01\n",
      " 8.72276247e-01 2.01505143e-03 1.53672937e-02 3.28089893e-01\n",
      " 1.30889356e-01 9.99966025e-01 9.98979390e-01 4.43690107e-04\n",
      " 2.31767446e-03 3.22292633e-02 9.99074221e-01 9.97806966e-01\n",
      " 9.87758458e-01 9.36034560e-01 9.87112463e-01 9.32770848e-01\n",
      " 8.05610955e-01 7.21207619e-01 8.60873878e-01 4.79300916e-01\n",
      " 8.75485539e-02 2.82141324e-02 8.98530960e-01 3.28061022e-02\n",
      " 9.99957561e-01 1.77845781e-04 8.13964605e-02 1.00036807e-01\n",
      " 9.99996543e-01 9.99969125e-01 9.99999881e-01 1.00000000e+00\n",
      " 9.97805536e-01 9.99440014e-01 9.99976277e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.99856591e-01 9.74882782e-01 9.52692807e-01\n",
      " 9.99976993e-01 9.99973655e-01 1.00000000e+00 9.99993443e-01\n",
      " 9.99999404e-01 9.99894142e-01 9.99999881e-01 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99966383e-01 9.99998927e-01\n",
      " 9.99997854e-01 9.99999166e-01 9.99967575e-01 9.99980688e-01\n",
      " 8.47696364e-01 9.99994636e-01 9.99999762e-01 9.99287307e-01\n",
      " 9.99981999e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 5.64146757e-01 9.99999881e-01 1.00000000e+00 9.99869585e-01\n",
      " 9.95212078e-01 9.99999046e-01 9.80647206e-01 9.99699354e-01\n",
      " 9.99683022e-01 9.99964356e-01 9.99882817e-01 8.17154109e-01\n",
      " 9.94500399e-01 9.98513520e-01 9.96660590e-01 9.99517441e-01\n",
      " 9.99999762e-01 9.99994516e-01 3.19677830e-01 9.99368012e-01\n",
      " 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 37 [0/107 (0%)]\tTrain Loss: 0.005165\n",
      "Train Epoch: 37 [4/107 (4%)]\tTrain Loss: 0.076992\n",
      "Train Epoch: 37 [8/107 (7%)]\tTrain Loss: 0.005472\n",
      "Train Epoch: 37 [12/107 (11%)]\tTrain Loss: 0.000172\n",
      "Train Epoch: 37 [16/107 (15%)]\tTrain Loss: 0.026112\n",
      "Train Epoch: 37 [20/107 (19%)]\tTrain Loss: 0.001221\n",
      "Train Epoch: 37 [24/107 (22%)]\tTrain Loss: 0.000944\n",
      "Train Epoch: 37 [28/107 (26%)]\tTrain Loss: 0.001140\n",
      "Train Epoch: 37 [32/107 (30%)]\tTrain Loss: 0.003527\n",
      "Train Epoch: 37 [36/107 (34%)]\tTrain Loss: 0.143701\n",
      "Train Epoch: 37 [40/107 (37%)]\tTrain Loss: 0.000692\n",
      "Train Epoch: 37 [44/107 (41%)]\tTrain Loss: 0.132564\n",
      "Train Epoch: 37 [48/107 (45%)]\tTrain Loss: 0.062667\n",
      "Train Epoch: 37 [52/107 (49%)]\tTrain Loss: 0.010117\n",
      "Train Epoch: 37 [56/107 (52%)]\tTrain Loss: 0.031231\n",
      "Train Epoch: 37 [60/107 (56%)]\tTrain Loss: 0.183532\n",
      "Train Epoch: 37 [64/107 (60%)]\tTrain Loss: 0.006085\n",
      "Train Epoch: 37 [68/107 (64%)]\tTrain Loss: 0.000610\n",
      "Train Epoch: 37 [72/107 (67%)]\tTrain Loss: 0.002600\n",
      "Train Epoch: 37 [76/107 (71%)]\tTrain Loss: 0.003309\n",
      "Train Epoch: 37 [80/107 (75%)]\tTrain Loss: 0.347160\n",
      "Train Epoch: 37 [84/107 (79%)]\tTrain Loss: 0.002438\n",
      "Train Epoch: 37 [88/107 (82%)]\tTrain Loss: 0.004034\n",
      "Train Epoch: 37 [92/107 (86%)]\tTrain Loss: 0.017027\n",
      "Train Epoch: 37 [96/107 (90%)]\tTrain Loss: 0.001385\n",
      "Train Epoch: 37 [100/107 (93%)]\tTrain Loss: 0.013236\n",
      "Train Epoch: 37 [104/107 (97%)]\tTrain Loss: 0.001049\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.51726180e-02 8.51336777e-01 1.16857864e-01 7.83148110e-01\n",
      " 5.63394010e-01 5.49298944e-03 2.58075148e-01 8.85764778e-01\n",
      " 1.84699558e-02 3.89721291e-03 1.79433882e-01 1.78014394e-04\n",
      " 4.16567981e-01 1.81748613e-03 1.72854923e-02 6.85544437e-05\n",
      " 1.71191023e-05 8.25696051e-01 9.53884646e-02 1.49983332e-01\n",
      " 5.79370558e-02 9.49170351e-01 9.96351957e-01 9.99980092e-01\n",
      " 8.83650839e-01 9.98703837e-01 9.99935985e-01 1.15756840e-02\n",
      " 3.10274139e-02 1.54190455e-02 8.88589859e-01 8.61455560e-01\n",
      " 8.00996900e-01 1.29878554e-05 9.49450769e-05 2.01347726e-03\n",
      " 1.60128402e-03 9.41024423e-01 4.86615419e-01 1.02706708e-05\n",
      " 3.12836855e-05 8.42810987e-05 9.88008380e-01 8.10681403e-01\n",
      " 8.66011918e-01 6.64909899e-01 9.06136751e-01 7.49616683e-01\n",
      " 6.89495027e-01 4.28334981e-01 9.10368621e-01 7.45761034e-04\n",
      " 8.31031427e-03 7.04689510e-03 1.15189008e-01 5.59337810e-03\n",
      " 9.99829054e-01 1.61856929e-06 2.15073559e-03 5.09416908e-02\n",
      " 9.99978065e-01 9.99920130e-01 9.99994874e-01 9.99997735e-01\n",
      " 9.99347508e-01 9.78971481e-01 9.99796808e-01 9.99998689e-01\n",
      " 9.99020934e-01 9.99110639e-01 8.50546896e-01 4.53355908e-01\n",
      " 9.32009995e-01 9.99121368e-01 9.99950647e-01 9.95590806e-01\n",
      " 9.99876380e-01 9.96788740e-01 9.99964595e-01 9.99909401e-01\n",
      " 9.99997854e-01 9.99995470e-01 9.99957204e-01 9.80839014e-01\n",
      " 9.62481439e-01 9.98830736e-01 9.99715626e-01 9.99727786e-01\n",
      " 4.07364592e-02 9.26835060e-01 9.99285400e-01 8.93044591e-01\n",
      " 9.82773185e-01 1.00000000e+00 9.99833107e-01 9.99890089e-01\n",
      " 1.58732936e-01 4.86252993e-01 9.96657252e-01 9.26083624e-01\n",
      " 5.03179967e-01 9.98332441e-01 2.72848085e-02 9.39991593e-01\n",
      " 8.21467698e-01 9.81082797e-01 9.93473828e-01 4.19046953e-02\n",
      " 3.80297862e-02 9.80102241e-01 3.98931563e-01 3.62155527e-01\n",
      " 9.99962330e-01 9.78644490e-01 8.59924406e-02 3.31788868e-01\n",
      " 9.87704873e-01 8.21581841e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 38 [0/107 (0%)]\tTrain Loss: 0.001677\n",
      "Train Epoch: 38 [4/107 (4%)]\tTrain Loss: 0.014004\n",
      "Train Epoch: 38 [8/107 (7%)]\tTrain Loss: 0.000218\n",
      "Train Epoch: 38 [12/107 (11%)]\tTrain Loss: 0.020763\n",
      "Train Epoch: 38 [16/107 (15%)]\tTrain Loss: 0.030309\n",
      "Train Epoch: 38 [20/107 (19%)]\tTrain Loss: 0.000356\n",
      "Train Epoch: 38 [24/107 (22%)]\tTrain Loss: 0.001259\n",
      "Train Epoch: 38 [28/107 (26%)]\tTrain Loss: 0.127471\n",
      "Train Epoch: 38 [32/107 (30%)]\tTrain Loss: 0.035944\n",
      "Train Epoch: 38 [36/107 (34%)]\tTrain Loss: 0.003676\n",
      "Train Epoch: 38 [40/107 (37%)]\tTrain Loss: 0.009597\n",
      "Train Epoch: 38 [44/107 (41%)]\tTrain Loss: 0.004314\n",
      "Train Epoch: 38 [48/107 (45%)]\tTrain Loss: 0.002023\n",
      "Train Epoch: 38 [52/107 (49%)]\tTrain Loss: 0.029142\n",
      "Train Epoch: 38 [56/107 (52%)]\tTrain Loss: 0.011522\n",
      "Train Epoch: 38 [60/107 (56%)]\tTrain Loss: 0.014188\n",
      "Train Epoch: 38 [64/107 (60%)]\tTrain Loss: 0.000471\n",
      "Train Epoch: 38 [68/107 (64%)]\tTrain Loss: 0.029373\n",
      "Train Epoch: 38 [72/107 (67%)]\tTrain Loss: 0.025048\n",
      "Train Epoch: 38 [76/107 (71%)]\tTrain Loss: 0.000283\n",
      "Train Epoch: 38 [80/107 (75%)]\tTrain Loss: 0.005931\n",
      "Train Epoch: 38 [84/107 (79%)]\tTrain Loss: 0.012448\n",
      "Train Epoch: 38 [88/107 (82%)]\tTrain Loss: 0.479130\n",
      "Train Epoch: 38 [92/107 (86%)]\tTrain Loss: 0.005199\n",
      "Train Epoch: 38 [96/107 (90%)]\tTrain Loss: 0.000516\n",
      "Train Epoch: 38 [100/107 (93%)]\tTrain Loss: 0.001022\n",
      "Train Epoch: 38 [104/107 (97%)]\tTrain Loss: 0.003459\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.00750022e-01 9.17618930e-01 8.37784633e-02 8.54572535e-01\n",
      " 3.13966513e-01 6.43944414e-03 5.41941941e-01 8.39911520e-01\n",
      " 1.08537348e-02 6.56501716e-03 6.76548898e-01 4.89425183e-05\n",
      " 6.93205774e-01 3.46429981e-02 2.12441180e-02 2.26593038e-04\n",
      " 6.62586099e-05 4.38657343e-01 5.26089296e-02 2.44570524e-02\n",
      " 1.47058740e-01 9.32784855e-01 9.98136282e-01 9.99936700e-01\n",
      " 7.05671728e-01 9.98256624e-01 9.99596655e-01 3.68028274e-03\n",
      " 5.86707413e-01 8.91433060e-02 6.09924734e-01 9.65122879e-01\n",
      " 8.74697864e-01 1.59114119e-04 3.24308261e-04 8.81285639e-04\n",
      " 5.01615647e-03 9.51215327e-01 7.03389049e-01 8.30239223e-05\n",
      " 3.78726545e-04 4.64784913e-03 9.13265824e-01 7.38431752e-01\n",
      " 9.44564342e-01 8.46585631e-01 9.61114824e-01 8.36966157e-01\n",
      " 5.39582193e-01 3.76793414e-01 8.36331725e-01 4.12178412e-03\n",
      " 1.38198249e-02 4.07231092e-01 5.21249712e-01 2.46499851e-02\n",
      " 9.98295009e-01 1.57021626e-04 1.08516515e-05 1.37235345e-02\n",
      " 9.99852657e-01 9.98219788e-01 9.99895334e-01 9.99843836e-01\n",
      " 9.99978781e-01 9.99559224e-01 9.99993205e-01 9.99996901e-01\n",
      " 9.99971986e-01 9.99774754e-01 8.10737550e-01 6.22583389e-01\n",
      " 9.87506509e-01 9.97232616e-01 9.99995947e-01 9.75008547e-01\n",
      " 9.99232173e-01 9.91093218e-01 9.99800384e-01 9.99913216e-01\n",
      " 9.99994993e-01 9.99991298e-01 9.99909520e-01 8.50151837e-01\n",
      " 7.59296656e-01 9.99099016e-01 9.72664952e-01 9.90489006e-01\n",
      " 7.07901865e-02 8.97562087e-01 9.99086976e-01 9.57483292e-01\n",
      " 9.88919556e-01 1.00000000e+00 9.99971747e-01 9.99978185e-01\n",
      " 6.34488761e-01 6.79748207e-02 9.28060591e-01 9.80208099e-01\n",
      " 2.23329425e-01 9.97209728e-01 1.79118477e-02 9.90749300e-01\n",
      " 9.28656697e-01 9.79799211e-01 9.80914354e-01 3.34204584e-02\n",
      " 6.87094592e-03 9.86630201e-01 4.42232639e-01 5.86753376e-02\n",
      " 9.99985456e-01 9.76685345e-01 1.29207104e-01 5.94838895e-03\n",
      " 9.54038441e-01 9.31403995e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [0/107 (0%)]\tTrain Loss: 0.013872\n",
      "Train Epoch: 39 [4/107 (4%)]\tTrain Loss: 0.003565\n",
      "Train Epoch: 39 [8/107 (7%)]\tTrain Loss: 0.018991\n",
      "Train Epoch: 39 [12/107 (11%)]\tTrain Loss: 0.001741\n",
      "Train Epoch: 39 [16/107 (15%)]\tTrain Loss: 0.005912\n",
      "Train Epoch: 39 [20/107 (19%)]\tTrain Loss: 0.002335\n",
      "Train Epoch: 39 [24/107 (22%)]\tTrain Loss: 0.005194\n",
      "Train Epoch: 39 [28/107 (26%)]\tTrain Loss: 0.000207\n",
      "Train Epoch: 39 [32/107 (30%)]\tTrain Loss: 0.002629\n",
      "Train Epoch: 39 [36/107 (34%)]\tTrain Loss: 0.001138\n",
      "Train Epoch: 39 [40/107 (37%)]\tTrain Loss: 0.001811\n",
      "Train Epoch: 39 [44/107 (41%)]\tTrain Loss: 0.042928\n",
      "Train Epoch: 39 [48/107 (45%)]\tTrain Loss: 0.000675\n",
      "Train Epoch: 39 [52/107 (49%)]\tTrain Loss: 0.000784\n",
      "Train Epoch: 39 [56/107 (52%)]\tTrain Loss: 0.132107\n",
      "Train Epoch: 39 [60/107 (56%)]\tTrain Loss: 0.002784\n",
      "Train Epoch: 39 [64/107 (60%)]\tTrain Loss: 0.001049\n",
      "Train Epoch: 39 [68/107 (64%)]\tTrain Loss: 0.075314\n",
      "Train Epoch: 39 [72/107 (67%)]\tTrain Loss: 0.012709\n",
      "Train Epoch: 39 [76/107 (71%)]\tTrain Loss: 0.000817\n",
      "Train Epoch: 39 [80/107 (75%)]\tTrain Loss: 0.000233\n",
      "Train Epoch: 39 [84/107 (79%)]\tTrain Loss: 0.004523\n",
      "Train Epoch: 39 [88/107 (82%)]\tTrain Loss: 0.006201\n",
      "Train Epoch: 39 [92/107 (86%)]\tTrain Loss: 0.000677\n",
      "Train Epoch: 39 [96/107 (90%)]\tTrain Loss: 0.004674\n",
      "Train Epoch: 39 [100/107 (93%)]\tTrain Loss: 0.022815\n",
      "Train Epoch: 39 [104/107 (97%)]\tTrain Loss: 0.012510\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.97317440e-03 8.33567619e-01 8.14592168e-02 3.67518775e-02\n",
      " 9.42219421e-03 5.43694245e-04 4.26799804e-01 2.78268028e-02\n",
      " 2.49225064e-03 6.21863408e-03 7.08423436e-01 8.48107622e-04\n",
      " 5.79375684e-01 9.70243200e-05 2.94646830e-04 1.18571070e-05\n",
      " 1.55478119e-05 1.01582602e-01 5.97486347e-02 4.86203469e-02\n",
      " 1.39822746e-02 9.71239686e-01 9.99822557e-01 9.99715149e-01\n",
      " 8.80470216e-01 9.98751044e-01 9.82457101e-01 1.77689008e-02\n",
      " 3.79332006e-01 7.43508991e-03 1.99817475e-02 5.95525682e-01\n",
      " 7.95295775e-01 4.00286399e-06 9.95523692e-07 3.16672347e-04\n",
      " 8.92738160e-03 8.48949015e-01 9.37587619e-02 2.16519857e-05\n",
      " 1.41764031e-04 1.82878648e-04 9.29771125e-01 6.05608933e-02\n",
      " 7.79599607e-01 4.41886671e-03 8.20168555e-01 7.84015894e-01\n",
      " 4.13535774e-01 5.64427525e-02 5.43314159e-01 2.99100677e-04\n",
      " 1.09423231e-03 1.76232518e-03 3.50269326e-03 2.22021408e-04\n",
      " 9.93518770e-01 2.54836186e-06 2.62403092e-03 2.42481683e-03\n",
      " 9.99956608e-01 9.99913573e-01 9.99995589e-01 9.99987960e-01\n",
      " 9.99367535e-01 9.98989522e-01 9.96123254e-01 9.99999762e-01\n",
      " 9.99716222e-01 9.78942931e-01 3.99871379e-01 7.87774846e-02\n",
      " 4.99344729e-02 4.56876665e-01 9.99320388e-01 9.79819179e-01\n",
      " 8.51094425e-01 9.49082375e-01 9.99985576e-01 9.99549448e-01\n",
      " 9.99872804e-01 9.99140382e-01 9.99565780e-01 9.88006711e-01\n",
      " 8.48624051e-01 9.99536753e-01 9.98040259e-01 9.99243736e-01\n",
      " 7.33582601e-02 7.56806672e-01 9.98929441e-01 1.87067911e-01\n",
      " 7.18485340e-02 9.99999642e-01 9.80458379e-01 9.99709070e-01\n",
      " 7.75555298e-02 2.90981587e-02 9.32225287e-01 9.79450524e-01\n",
      " 7.22750425e-01 8.92276227e-01 1.66285802e-02 7.81124890e-01\n",
      " 7.06867129e-02 5.29691041e-01 5.32589793e-01 4.12573814e-02\n",
      " 8.15329375e-04 7.50369728e-01 5.05674422e-01 1.61037389e-02\n",
      " 9.99125063e-01 9.16663945e-01 2.54394323e-01 9.13422331e-02\n",
      " 9.99965191e-01 9.99130666e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 40 [0/107 (0%)]\tTrain Loss: 0.003687\n",
      "Train Epoch: 40 [4/107 (4%)]\tTrain Loss: 0.002477\n",
      "Train Epoch: 40 [8/107 (7%)]\tTrain Loss: 0.003419\n",
      "Train Epoch: 40 [12/107 (11%)]\tTrain Loss: 0.008334\n",
      "Train Epoch: 40 [16/107 (15%)]\tTrain Loss: 0.013498\n",
      "Train Epoch: 40 [20/107 (19%)]\tTrain Loss: 0.239872\n",
      "Train Epoch: 40 [24/107 (22%)]\tTrain Loss: 0.037305\n",
      "Train Epoch: 40 [28/107 (26%)]\tTrain Loss: 0.024277\n",
      "Train Epoch: 40 [32/107 (30%)]\tTrain Loss: 0.000262\n",
      "Train Epoch: 40 [36/107 (34%)]\tTrain Loss: 0.004863\n",
      "Train Epoch: 40 [40/107 (37%)]\tTrain Loss: 0.032952\n",
      "Train Epoch: 40 [44/107 (41%)]\tTrain Loss: 0.002127\n",
      "Train Epoch: 40 [48/107 (45%)]\tTrain Loss: 0.016479\n",
      "Train Epoch: 40 [52/107 (49%)]\tTrain Loss: 0.000655\n",
      "Train Epoch: 40 [56/107 (52%)]\tTrain Loss: 0.014943\n",
      "Train Epoch: 40 [60/107 (56%)]\tTrain Loss: 0.001817\n",
      "Train Epoch: 40 [64/107 (60%)]\tTrain Loss: 0.037219\n",
      "Train Epoch: 40 [68/107 (64%)]\tTrain Loss: 0.000516\n",
      "Train Epoch: 40 [72/107 (67%)]\tTrain Loss: 0.000444\n",
      "Train Epoch: 40 [76/107 (71%)]\tTrain Loss: 0.001270\n",
      "Train Epoch: 40 [80/107 (75%)]\tTrain Loss: 0.000700\n",
      "Train Epoch: 40 [84/107 (79%)]\tTrain Loss: 0.000367\n",
      "Train Epoch: 40 [88/107 (82%)]\tTrain Loss: 0.002922\n",
      "Train Epoch: 40 [92/107 (86%)]\tTrain Loss: 0.000652\n",
      "Train Epoch: 40 [96/107 (90%)]\tTrain Loss: 0.014088\n",
      "Train Epoch: 40 [100/107 (93%)]\tTrain Loss: 0.086896\n",
      "Train Epoch: 40 [104/107 (97%)]\tTrain Loss: 0.001475\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.90268848e-02 9.97187078e-01 4.59400386e-01 2.06374601e-01\n",
      " 1.28614023e-01 2.36041937e-03 9.52487171e-01 2.38245517e-01\n",
      " 9.69823566e-04 6.81342743e-03 4.61386055e-01 4.79253271e-04\n",
      " 4.21245217e-01 1.96883120e-04 7.79300753e-04 3.75898117e-06\n",
      " 8.81918386e-05 1.56886801e-01 1.15606394e-02 1.25446573e-01\n",
      " 5.40642254e-02 9.44521725e-01 9.97044742e-01 9.99835014e-01\n",
      " 9.69814479e-01 9.93713915e-01 9.99839425e-01 2.06820555e-02\n",
      " 6.17101252e-01 1.19939866e-02 1.12962760e-01 4.69105154e-01\n",
      " 7.20392406e-01 3.81102545e-05 2.68456697e-05 4.19213921e-02\n",
      " 1.47878490e-02 9.90311384e-01 9.24502790e-01 5.64785907e-04\n",
      " 3.73909180e-03 9.97035671e-03 9.90420163e-01 1.22777507e-01\n",
      " 2.01519489e-01 1.58672947e-02 9.71290112e-01 9.80501056e-01\n",
      " 9.18367982e-01 8.68594572e-02 9.35352504e-01 4.13447742e-05\n",
      " 2.97039025e-03 2.42094253e-03 1.42819852e-01 8.85655696e-04\n",
      " 9.88334298e-01 9.21267056e-05 3.79478879e-04 9.97367036e-03\n",
      " 9.99994636e-01 9.99973059e-01 9.99999642e-01 9.99998093e-01\n",
      " 9.98590887e-01 9.96835053e-01 9.92396057e-01 9.99999166e-01\n",
      " 9.99803603e-01 9.99230742e-01 7.90413558e-01 1.60738006e-01\n",
      " 1.11939527e-01 9.63389695e-01 9.94587541e-01 5.36808789e-01\n",
      " 9.99388099e-01 9.99169230e-01 9.99997497e-01 9.99876380e-01\n",
      " 9.99998450e-01 9.99977827e-01 9.99993205e-01 9.92492020e-01\n",
      " 9.50296462e-01 9.99879122e-01 9.97239590e-01 9.97649848e-01\n",
      " 5.46321273e-01 9.70385373e-01 9.99990582e-01 6.13374591e-01\n",
      " 5.77244639e-01 9.99999762e-01 9.99742091e-01 9.99983907e-01\n",
      " 1.58491775e-01 3.21586907e-01 9.99016047e-01 9.99576509e-01\n",
      " 9.32395458e-01 9.30885613e-01 4.95377295e-02 4.68568861e-01\n",
      " 1.67200252e-01 9.05523717e-01 9.44551289e-01 3.13395530e-01\n",
      " 1.18208425e-02 9.67969418e-01 9.85488594e-01 6.72024190e-01\n",
      " 9.99999285e-01 9.47619021e-01 4.23183851e-02 4.47615571e-02\n",
      " 9.99998808e-01 9.99994755e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 51 TN= 40 FN= 7 FP= 20\n",
      "TP+FP 71\n",
      "precision 0.7183098591549296\n",
      "recall 0.8793103448275862\n",
      "F1 0.7906976744186047\n",
      "acc 0.7711864406779662\n",
      "AUCp 0.7729885057471265\n",
      "AUC 0.8468390804597701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 40, average recall: 0.8793, average precision: 0.7183,average F1: 0.7907, average accuracy: 0.7712, average AUC: 0.8468\n",
      "Train Epoch: 41 [0/107 (0%)]\tTrain Loss: 0.001209\n",
      "Train Epoch: 41 [4/107 (4%)]\tTrain Loss: 0.000480\n",
      "Train Epoch: 41 [8/107 (7%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 41 [12/107 (11%)]\tTrain Loss: 0.011651\n",
      "Train Epoch: 41 [16/107 (15%)]\tTrain Loss: 0.025811\n",
      "Train Epoch: 41 [20/107 (19%)]\tTrain Loss: 0.003802\n",
      "Train Epoch: 41 [24/107 (22%)]\tTrain Loss: 0.000681\n",
      "Train Epoch: 41 [28/107 (26%)]\tTrain Loss: 0.003757\n",
      "Train Epoch: 41 [32/107 (30%)]\tTrain Loss: 0.047946\n",
      "Train Epoch: 41 [36/107 (34%)]\tTrain Loss: 0.002302\n",
      "Train Epoch: 41 [40/107 (37%)]\tTrain Loss: 0.001151\n",
      "Train Epoch: 41 [44/107 (41%)]\tTrain Loss: 0.000552\n",
      "Train Epoch: 41 [48/107 (45%)]\tTrain Loss: 0.013029\n",
      "Train Epoch: 41 [52/107 (49%)]\tTrain Loss: 0.000815\n",
      "Train Epoch: 41 [56/107 (52%)]\tTrain Loss: 0.043921\n",
      "Train Epoch: 41 [60/107 (56%)]\tTrain Loss: 0.035106\n",
      "Train Epoch: 41 [64/107 (60%)]\tTrain Loss: 0.001771\n",
      "Train Epoch: 41 [68/107 (64%)]\tTrain Loss: 0.001160\n",
      "Train Epoch: 41 [72/107 (67%)]\tTrain Loss: 0.000203\n",
      "Train Epoch: 41 [76/107 (71%)]\tTrain Loss: 0.001018\n",
      "Train Epoch: 41 [80/107 (75%)]\tTrain Loss: 0.032989\n",
      "Train Epoch: 41 [84/107 (79%)]\tTrain Loss: 0.004495\n",
      "Train Epoch: 41 [88/107 (82%)]\tTrain Loss: 0.005855\n",
      "Train Epoch: 41 [92/107 (86%)]\tTrain Loss: 0.002051\n",
      "Train Epoch: 41 [96/107 (90%)]\tTrain Loss: 0.006872\n",
      "Train Epoch: 41 [100/107 (93%)]\tTrain Loss: 0.001616\n",
      "Train Epoch: 41 [104/107 (97%)]\tTrain Loss: 0.000246\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.06185910e-02 9.97346997e-01 1.22600742e-01 1.96273401e-01\n",
      " 5.14451563e-02 4.04080935e-03 9.09241557e-01 9.96875167e-02\n",
      " 1.13167951e-03 1.92850642e-02 6.69416547e-01 7.37911032e-04\n",
      " 4.54153925e-01 1.49408384e-04 9.28850845e-03 2.48643460e-06\n",
      " 3.07029086e-06 2.59184092e-02 1.31377205e-01 1.73538551e-01\n",
      " 1.68388113e-01 8.13919961e-01 9.97429907e-01 9.99898672e-01\n",
      " 7.46342242e-01 9.99396682e-01 9.99956131e-01 1.58765525e-01\n",
      " 1.41536176e-01 1.80109385e-02 8.55086505e-01 6.09540045e-01\n",
      " 8.61488223e-01 1.90758942e-06 1.59879653e-06 1.84688048e-04\n",
      " 5.09691832e-04 3.01805794e-01 9.12511230e-01 1.33034642e-04\n",
      " 1.24322891e-03 3.21112550e-03 2.76018351e-01 2.39253491e-01\n",
      " 5.65781355e-01 1.06152087e-01 9.83822525e-01 9.83301938e-01\n",
      " 9.94511843e-01 7.17224717e-01 9.88088191e-01 2.26918783e-04\n",
      " 1.25804590e-03 3.36134410e-03 7.92675257e-01 2.39319153e-04\n",
      " 9.99015450e-01 9.07264712e-06 1.51440408e-03 8.12873431e-03\n",
      " 9.99997497e-01 9.99996781e-01 9.99999642e-01 9.99999881e-01\n",
      " 9.99986649e-01 9.99593794e-01 9.84625220e-01 9.99999881e-01\n",
      " 9.99962211e-01 9.99629498e-01 9.68433201e-01 7.88028240e-01\n",
      " 9.28937137e-01 9.99564350e-01 9.99931574e-01 9.98989880e-01\n",
      " 9.99995112e-01 9.99985814e-01 9.99990821e-01 9.99994278e-01\n",
      " 9.99999881e-01 9.99999881e-01 9.99999881e-01 9.97659564e-01\n",
      " 9.89262044e-01 9.99971867e-01 9.99539614e-01 9.99649405e-01\n",
      " 1.83146149e-01 9.99213576e-01 9.99982834e-01 9.76587355e-01\n",
      " 9.25183952e-01 1.00000000e+00 9.99965906e-01 9.99994874e-01\n",
      " 4.17621374e-01 5.68515599e-01 9.99939561e-01 9.99923706e-01\n",
      " 9.47385073e-01 9.99254167e-01 8.52313545e-03 8.39498341e-01\n",
      " 4.27345186e-01 9.84204948e-01 9.99039352e-01 3.96740407e-01\n",
      " 3.98736261e-03 9.84866917e-01 9.83390510e-01 3.48695308e-01\n",
      " 1.00000000e+00 9.81685996e-01 6.39269650e-01 3.31451535e-01\n",
      " 9.97802079e-01 9.99375761e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 42 [0/107 (0%)]\tTrain Loss: 0.003909\n",
      "Train Epoch: 42 [4/107 (4%)]\tTrain Loss: 0.000954\n",
      "Train Epoch: 42 [8/107 (7%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 42 [12/107 (11%)]\tTrain Loss: 0.002304\n",
      "Train Epoch: 42 [16/107 (15%)]\tTrain Loss: 0.008296\n",
      "Train Epoch: 42 [20/107 (19%)]\tTrain Loss: 0.008032\n",
      "Train Epoch: 42 [24/107 (22%)]\tTrain Loss: 0.003106\n",
      "Train Epoch: 42 [28/107 (26%)]\tTrain Loss: 0.003644\n",
      "Train Epoch: 42 [32/107 (30%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 42 [36/107 (34%)]\tTrain Loss: 0.027822\n",
      "Train Epoch: 42 [40/107 (37%)]\tTrain Loss: 0.000224\n",
      "Train Epoch: 42 [44/107 (41%)]\tTrain Loss: 0.001021\n",
      "Train Epoch: 42 [48/107 (45%)]\tTrain Loss: 0.003452\n",
      "Train Epoch: 42 [52/107 (49%)]\tTrain Loss: 0.000314\n",
      "Train Epoch: 42 [56/107 (52%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 42 [60/107 (56%)]\tTrain Loss: 0.002153\n",
      "Train Epoch: 42 [64/107 (60%)]\tTrain Loss: 0.001433\n",
      "Train Epoch: 42 [68/107 (64%)]\tTrain Loss: 0.011505\n",
      "Train Epoch: 42 [72/107 (67%)]\tTrain Loss: 0.025562\n",
      "Train Epoch: 42 [76/107 (71%)]\tTrain Loss: 0.000718\n",
      "Train Epoch: 42 [80/107 (75%)]\tTrain Loss: 0.004530\n",
      "Train Epoch: 42 [84/107 (79%)]\tTrain Loss: 0.000180\n",
      "Train Epoch: 42 [88/107 (82%)]\tTrain Loss: 0.019064\n",
      "Train Epoch: 42 [92/107 (86%)]\tTrain Loss: 0.001312\n",
      "Train Epoch: 42 [96/107 (90%)]\tTrain Loss: 0.001339\n",
      "Train Epoch: 42 [100/107 (93%)]\tTrain Loss: 0.001627\n",
      "Train Epoch: 42 [104/107 (97%)]\tTrain Loss: 0.008672\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.75488040e-01 9.97982979e-01 1.17798902e-01 7.25907683e-01\n",
      " 1.48262337e-01 3.40225473e-02 5.12493849e-01 6.16933525e-01\n",
      " 8.51009414e-03 2.68951394e-02 1.88678473e-01 5.39344549e-03\n",
      " 1.50534093e-01 2.93769198e-03 1.09265417e-01 2.00233626e-04\n",
      " 1.08350148e-04 1.93063736e-01 2.23030522e-03 3.30157541e-02\n",
      " 8.03238060e-03 6.09937310e-01 9.98840988e-01 9.99947071e-01\n",
      " 6.63459480e-01 9.97098327e-01 9.99952555e-01 6.35353988e-03\n",
      " 2.57071685e-02 2.55223946e-03 4.64130253e-01 1.60448581e-01\n",
      " 2.64933228e-01 2.56884287e-05 1.39896974e-05 1.32666505e-03\n",
      " 7.81863404e-04 4.49402601e-01 7.21344411e-01 1.55435162e-04\n",
      " 8.86880967e-04 9.68928041e-04 2.00577229e-01 2.22151075e-02\n",
      " 1.48932666e-01 6.73006624e-02 9.67906535e-01 9.75420356e-01\n",
      " 9.53368127e-01 6.71947375e-02 9.77240384e-01 1.59902673e-04\n",
      " 6.55204896e-03 2.79492997e-02 1.72055498e-01 1.28581189e-02\n",
      " 9.99211431e-01 7.80608156e-04 8.11312161e-03 1.07244343e-01\n",
      " 9.99994993e-01 9.99992490e-01 9.99999404e-01 9.99999762e-01\n",
      " 9.97258902e-01 9.99629140e-01 9.99100327e-01 9.99999404e-01\n",
      " 9.99966025e-01 9.99656796e-01 9.88080263e-01 8.50447476e-01\n",
      " 9.70462620e-01 9.99548733e-01 9.99778450e-01 9.85156536e-01\n",
      " 9.99990582e-01 9.99996543e-01 9.99997139e-01 9.99908447e-01\n",
      " 9.99999046e-01 9.99999642e-01 9.99999404e-01 8.32902730e-01\n",
      " 8.79215300e-01 9.99822319e-01 9.99295831e-01 9.99601901e-01\n",
      " 2.14300677e-01 3.97004217e-01 9.99565542e-01 9.46537077e-01\n",
      " 9.24148619e-01 9.99999762e-01 9.99837637e-01 9.99966979e-01\n",
      " 7.51942396e-01 4.69905585e-01 9.99812543e-01 9.90001798e-01\n",
      " 9.03387606e-01 9.94918406e-01 2.63719819e-03 2.69852728e-01\n",
      " 2.64451116e-01 8.53324652e-01 9.83501077e-01 2.62426287e-02\n",
      " 9.17230174e-02 9.19552863e-01 5.40141582e-01 1.02474034e-01\n",
      " 9.99963641e-01 8.01441252e-01 6.38420053e-04 6.77469128e-04\n",
      " 9.99661922e-01 9.86554623e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 43 [0/107 (0%)]\tTrain Loss: 0.003373\n",
      "Train Epoch: 43 [4/107 (4%)]\tTrain Loss: 0.001768\n",
      "Train Epoch: 43 [8/107 (7%)]\tTrain Loss: 0.002960\n",
      "Train Epoch: 43 [12/107 (11%)]\tTrain Loss: 0.024164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [16/107 (15%)]\tTrain Loss: 0.030031\n",
      "Train Epoch: 43 [20/107 (19%)]\tTrain Loss: 0.009928\n",
      "Train Epoch: 43 [24/107 (22%)]\tTrain Loss: 0.002523\n",
      "Train Epoch: 43 [28/107 (26%)]\tTrain Loss: 0.122098\n",
      "Train Epoch: 43 [32/107 (30%)]\tTrain Loss: 0.011307\n",
      "Train Epoch: 43 [36/107 (34%)]\tTrain Loss: 0.036848\n",
      "Train Epoch: 43 [40/107 (37%)]\tTrain Loss: 0.007253\n",
      "Train Epoch: 43 [44/107 (41%)]\tTrain Loss: 0.002220\n",
      "Train Epoch: 43 [48/107 (45%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 43 [52/107 (49%)]\tTrain Loss: 0.000121\n",
      "Train Epoch: 43 [56/107 (52%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 43 [60/107 (56%)]\tTrain Loss: 0.001893\n",
      "Train Epoch: 43 [64/107 (60%)]\tTrain Loss: 0.019618\n",
      "Train Epoch: 43 [68/107 (64%)]\tTrain Loss: 0.000179\n",
      "Train Epoch: 43 [72/107 (67%)]\tTrain Loss: 0.000510\n",
      "Train Epoch: 43 [76/107 (71%)]\tTrain Loss: 0.008192\n",
      "Train Epoch: 43 [80/107 (75%)]\tTrain Loss: 0.001756\n",
      "Train Epoch: 43 [84/107 (79%)]\tTrain Loss: 0.004347\n",
      "Train Epoch: 43 [88/107 (82%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 43 [92/107 (86%)]\tTrain Loss: 0.001412\n",
      "Train Epoch: 43 [96/107 (90%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 43 [100/107 (93%)]\tTrain Loss: 0.000246\n",
      "Train Epoch: 43 [104/107 (97%)]\tTrain Loss: 0.000442\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.74307968e-02 9.98481810e-01 1.98805317e-01 3.78537141e-02\n",
      " 3.06767281e-02 9.70181916e-03 8.28630745e-01 1.15302883e-01\n",
      " 6.59627654e-03 9.67390276e-03 6.09509833e-02 4.94605582e-03\n",
      " 7.21757952e-03 6.49121648e-04 8.16186704e-03 2.97153310e-05\n",
      " 9.94567199e-06 2.14856919e-02 3.36326251e-04 4.70537357e-02\n",
      " 9.91150811e-02 4.22687113e-01 9.89703119e-01 9.99998569e-01\n",
      " 5.73433876e-01 9.97128665e-01 9.99988437e-01 2.73568422e-01\n",
      " 2.65279151e-02 9.45107138e-04 1.94995869e-02 6.13522576e-03\n",
      " 7.29993284e-02 1.60498894e-05 8.71603334e-06 9.37302655e-04\n",
      " 3.14283679e-04 3.06875288e-01 4.43774275e-02 3.56582609e-06\n",
      " 9.53535528e-06 5.16614673e-05 4.80978116e-02 2.34148488e-03\n",
      " 6.41854405e-01 2.56904447e-03 6.12773895e-01 6.51058018e-01\n",
      " 7.48575509e-01 3.97403270e-01 8.94286156e-01 1.89230377e-05\n",
      " 6.55600044e-04 1.60927128e-04 3.91226402e-03 7.28160230e-05\n",
      " 9.96110737e-01 3.53111886e-06 4.66865022e-03 2.26161722e-03\n",
      " 9.99949574e-01 9.99462068e-01 9.99928713e-01 9.99992609e-01\n",
      " 9.99996543e-01 9.97122705e-01 9.79402721e-01 9.99999404e-01\n",
      " 9.99997139e-01 9.99973416e-01 9.75317121e-01 6.96795225e-01\n",
      " 7.80487657e-01 9.99648333e-01 9.99997854e-01 9.72625136e-01\n",
      " 9.99981999e-01 9.99989271e-01 9.99997735e-01 9.98857975e-01\n",
      " 9.99999166e-01 9.99999404e-01 9.99999166e-01 5.54408073e-01\n",
      " 2.44893447e-01 9.99969363e-01 9.97252285e-01 9.99533772e-01\n",
      " 2.78744489e-01 4.97865558e-01 9.99990582e-01 9.30854559e-01\n",
      " 4.76852864e-01 1.00000000e+00 9.99982238e-01 9.99995589e-01\n",
      " 1.51142374e-01 2.44882852e-01 9.97109234e-01 9.16710198e-01\n",
      " 7.77500033e-01 9.92737710e-01 5.19876741e-03 6.75155073e-02\n",
      " 2.31458619e-02 5.37773252e-01 9.88703310e-01 6.65674498e-03\n",
      " 1.79132319e-03 5.71819305e-01 7.73668736e-02 2.80841470e-01\n",
      " 9.99836564e-01 9.49004516e-02 2.28660487e-04 6.59127545e-05\n",
      " 9.97911990e-01 9.55867290e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 44 [0/107 (0%)]\tTrain Loss: 0.007259\n",
      "Train Epoch: 44 [4/107 (4%)]\tTrain Loss: 0.040085\n",
      "Train Epoch: 44 [8/107 (7%)]\tTrain Loss: 0.028441\n",
      "Train Epoch: 44 [12/107 (11%)]\tTrain Loss: 0.127701\n",
      "Train Epoch: 44 [16/107 (15%)]\tTrain Loss: 0.004897\n",
      "Train Epoch: 44 [20/107 (19%)]\tTrain Loss: 0.003352\n",
      "Train Epoch: 44 [24/107 (22%)]\tTrain Loss: 0.005679\n",
      "Train Epoch: 44 [28/107 (26%)]\tTrain Loss: 0.004533\n",
      "Train Epoch: 44 [32/107 (30%)]\tTrain Loss: 0.003921\n",
      "Train Epoch: 44 [36/107 (34%)]\tTrain Loss: 0.007022\n",
      "Train Epoch: 44 [40/107 (37%)]\tTrain Loss: 0.064270\n",
      "Train Epoch: 44 [44/107 (41%)]\tTrain Loss: 0.000633\n",
      "Train Epoch: 44 [48/107 (45%)]\tTrain Loss: 0.000225\n",
      "Train Epoch: 44 [52/107 (49%)]\tTrain Loss: 0.024883\n",
      "Train Epoch: 44 [56/107 (52%)]\tTrain Loss: 0.000692\n",
      "Train Epoch: 44 [60/107 (56%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 44 [64/107 (60%)]\tTrain Loss: 0.206302\n",
      "Train Epoch: 44 [68/107 (64%)]\tTrain Loss: 0.090074\n",
      "Train Epoch: 44 [72/107 (67%)]\tTrain Loss: 0.032097\n",
      "Train Epoch: 44 [76/107 (71%)]\tTrain Loss: 0.000250\n",
      "Train Epoch: 44 [80/107 (75%)]\tTrain Loss: 0.004144\n",
      "Train Epoch: 44 [84/107 (79%)]\tTrain Loss: 0.002337\n",
      "Train Epoch: 44 [88/107 (82%)]\tTrain Loss: 0.307495\n",
      "Train Epoch: 44 [92/107 (86%)]\tTrain Loss: 0.026372\n",
      "Train Epoch: 44 [96/107 (90%)]\tTrain Loss: 0.029377\n",
      "Train Epoch: 44 [100/107 (93%)]\tTrain Loss: 0.070978\n",
      "Train Epoch: 44 [104/107 (97%)]\tTrain Loss: 0.052485\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.22547299e-02 8.35713327e-01 4.11817878e-02 6.05157077e-01\n",
      " 3.55156451e-01 3.03862314e-03 1.39693692e-01 8.56999874e-01\n",
      " 4.95565832e-02 6.62532374e-02 3.79154056e-01 1.05922446e-01\n",
      " 1.10611469e-01 1.19285015e-02 2.58232914e-02 3.70172085e-04\n",
      " 5.75134647e-04 7.87362218e-01 3.58140543e-02 8.90053213e-01\n",
      " 6.68348968e-01 5.46446919e-01 9.99952793e-01 9.99994993e-01\n",
      " 5.62063694e-01 9.99891281e-01 9.99996781e-01 7.23082542e-01\n",
      " 2.13401198e-01 3.69228460e-02 2.99812853e-01 4.70778793e-02\n",
      " 1.24006413e-01 4.36407485e-04 1.06146115e-04 1.04355011e-02\n",
      " 2.29736902e-02 9.83869731e-01 5.84719896e-01 1.17500727e-04\n",
      " 4.60705196e-04 7.93185725e-04 5.09569764e-01 1.84199691e-01\n",
      " 9.71693873e-01 1.29704967e-01 2.12625414e-01 1.19708613e-01\n",
      " 3.20817888e-01 2.71935850e-01 4.34732139e-01 7.19011587e-04\n",
      " 2.12121367e-01 3.93264834e-03 3.85365576e-01 7.81666785e-02\n",
      " 9.87283468e-01 1.80909550e-03 1.08002797e-01 1.06416881e-01\n",
      " 9.68789101e-01 9.39149499e-01 9.83188331e-01 9.92095411e-01\n",
      " 9.99358118e-01 9.67580199e-01 9.56241786e-01 9.98940408e-01\n",
      " 9.99814689e-01 9.72028196e-01 4.72122490e-01 2.53001060e-02\n",
      " 6.86983764e-01 7.35676110e-01 9.99027967e-01 9.60212886e-01\n",
      " 9.88881290e-01 9.72233772e-01 9.99951124e-01 9.74460959e-01\n",
      " 9.99628305e-01 9.99990940e-01 9.99914527e-01 9.35654461e-01\n",
      " 7.05000520e-01 9.83410418e-01 9.96677518e-01 9.90354538e-01\n",
      " 9.76186752e-01 2.53459424e-01 9.99866843e-01 8.88197899e-01\n",
      " 9.42487895e-01 9.99999881e-01 9.99995470e-01 9.99999642e-01\n",
      " 9.79876161e-01 6.18956447e-01 9.69602466e-01 9.93906915e-01\n",
      " 6.41345680e-01 9.59700227e-01 3.27567309e-02 8.13296080e-01\n",
      " 7.36002505e-01 9.99062121e-01 9.90487278e-01 1.40125323e-02\n",
      " 4.46840096e-03 9.88471031e-01 7.73834661e-02 7.72860050e-01\n",
      " 9.99969482e-01 5.10973334e-01 1.43719865e-02 5.98967657e-04\n",
      " 9.98813629e-01 1.37744397e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 45 [0/107 (0%)]\tTrain Loss: 0.002354\n",
      "Train Epoch: 45 [4/107 (4%)]\tTrain Loss: 0.001372\n",
      "Train Epoch: 45 [8/107 (7%)]\tTrain Loss: 0.006426\n",
      "Train Epoch: 45 [12/107 (11%)]\tTrain Loss: 0.119053\n",
      "Train Epoch: 45 [16/107 (15%)]\tTrain Loss: 0.001616\n",
      "Train Epoch: 45 [20/107 (19%)]\tTrain Loss: 0.086155\n",
      "Train Epoch: 45 [24/107 (22%)]\tTrain Loss: 0.043522\n",
      "Train Epoch: 45 [28/107 (26%)]\tTrain Loss: 0.001013\n",
      "Train Epoch: 45 [32/107 (30%)]\tTrain Loss: 0.336521\n",
      "Train Epoch: 45 [36/107 (34%)]\tTrain Loss: 0.004814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [40/107 (37%)]\tTrain Loss: 0.009162\n",
      "Train Epoch: 45 [44/107 (41%)]\tTrain Loss: 0.028504\n",
      "Train Epoch: 45 [48/107 (45%)]\tTrain Loss: 0.001040\n",
      "Train Epoch: 45 [52/107 (49%)]\tTrain Loss: 0.001301\n",
      "Train Epoch: 45 [56/107 (52%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 45 [60/107 (56%)]\tTrain Loss: 0.016489\n",
      "Train Epoch: 45 [64/107 (60%)]\tTrain Loss: 0.006873\n",
      "Train Epoch: 45 [68/107 (64%)]\tTrain Loss: 0.008691\n",
      "Train Epoch: 45 [72/107 (67%)]\tTrain Loss: 0.007335\n",
      "Train Epoch: 45 [76/107 (71%)]\tTrain Loss: 0.086061\n",
      "Train Epoch: 45 [80/107 (75%)]\tTrain Loss: 0.007728\n",
      "Train Epoch: 45 [84/107 (79%)]\tTrain Loss: 0.040782\n",
      "Train Epoch: 45 [88/107 (82%)]\tTrain Loss: 0.003310\n",
      "Train Epoch: 45 [92/107 (86%)]\tTrain Loss: 0.007375\n",
      "Train Epoch: 45 [96/107 (90%)]\tTrain Loss: 0.000293\n",
      "Train Epoch: 45 [100/107 (93%)]\tTrain Loss: 0.014356\n",
      "Train Epoch: 45 [104/107 (97%)]\tTrain Loss: 0.000471\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.02263773e-02 9.98942316e-01 8.86478543e-01 3.64011377e-01\n",
      " 3.68831120e-02 1.32953320e-02 9.88967478e-01 3.44345599e-01\n",
      " 3.82865667e-02 7.01170356e-04 3.14832740e-02 1.21099038e-05\n",
      " 1.29051572e-02 2.04286575e-02 4.29770440e-01 3.09262214e-06\n",
      " 2.41950033e-07 1.70078591e-01 1.01683624e-02 6.63479209e-01\n",
      " 1.70376450e-01 4.65135604e-01 9.99460042e-01 9.99908686e-01\n",
      " 2.33044326e-01 9.99719322e-01 9.99308467e-01 4.47135180e-01\n",
      " 2.24985853e-02 1.43968621e-02 4.67143167e-04 4.58245538e-02\n",
      " 6.95128858e-01 5.65896357e-07 1.41368560e-07 3.76172102e-06\n",
      " 2.82131485e-04 8.04494023e-01 5.09790471e-03 3.11060973e-08\n",
      " 8.67020731e-08 3.85739725e-07 4.45724577e-01 3.30339521e-01\n",
      " 5.87125361e-01 5.89670474e-03 3.00710768e-01 1.00088850e-01\n",
      " 5.84360659e-01 1.11093663e-01 8.10171723e-01 1.23878242e-03\n",
      " 3.32943717e-04 7.10004591e-04 1.96517194e-05 2.00563751e-04\n",
      " 9.60582793e-01 7.14441555e-08 5.95957390e-04 7.10177817e-04\n",
      " 9.87831175e-01 9.88510191e-01 9.97450888e-01 9.98476326e-01\n",
      " 9.99984860e-01 9.99732316e-01 9.99040306e-01 9.99981403e-01\n",
      " 9.99828458e-01 9.96028423e-01 6.85236692e-01 5.02160937e-02\n",
      " 8.06350887e-01 8.70294511e-01 9.98161137e-01 9.97848153e-01\n",
      " 9.98876750e-01 9.98016596e-01 9.99986291e-01 9.90155697e-01\n",
      " 9.98927891e-01 9.99783099e-01 9.99713361e-01 9.86597896e-01\n",
      " 8.34167600e-01 9.97501910e-01 9.98615503e-01 9.96365190e-01\n",
      " 5.95145762e-01 1.26957661e-02 9.82494891e-01 9.95434463e-01\n",
      " 7.53463864e-01 9.99998689e-01 9.99865174e-01 9.99526143e-01\n",
      " 2.13057533e-01 1.71997473e-02 9.22750831e-01 8.97376955e-01\n",
      " 1.36415958e-01 9.81208801e-01 2.48286217e-01 3.35892975e-01\n",
      " 9.88766775e-02 9.08591688e-01 9.72818375e-01 3.49620543e-03\n",
      " 9.46098371e-05 6.92762852e-01 2.70332932e-01 8.25660676e-02\n",
      " 9.99781072e-01 2.05489248e-02 4.30838251e-03 1.61023941e-04\n",
      " 9.31544960e-01 9.10710990e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 46 [0/107 (0%)]\tTrain Loss: 0.000327\n",
      "Train Epoch: 46 [4/107 (4%)]\tTrain Loss: 0.053688\n",
      "Train Epoch: 46 [8/107 (7%)]\tTrain Loss: 0.024661\n",
      "Train Epoch: 46 [12/107 (11%)]\tTrain Loss: 0.007033\n",
      "Train Epoch: 46 [16/107 (15%)]\tTrain Loss: 0.006289\n",
      "Train Epoch: 46 [20/107 (19%)]\tTrain Loss: 0.000795\n",
      "Train Epoch: 46 [24/107 (22%)]\tTrain Loss: 0.002785\n",
      "Train Epoch: 46 [28/107 (26%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 46 [32/107 (30%)]\tTrain Loss: 0.007037\n",
      "Train Epoch: 46 [36/107 (34%)]\tTrain Loss: 0.013863\n",
      "Train Epoch: 46 [40/107 (37%)]\tTrain Loss: 0.011233\n",
      "Train Epoch: 46 [44/107 (41%)]\tTrain Loss: 0.000194\n",
      "Train Epoch: 46 [48/107 (45%)]\tTrain Loss: 0.006068\n",
      "Train Epoch: 46 [52/107 (49%)]\tTrain Loss: 0.000451\n",
      "Train Epoch: 46 [56/107 (52%)]\tTrain Loss: 0.000815\n",
      "Train Epoch: 46 [60/107 (56%)]\tTrain Loss: 0.089295\n",
      "Train Epoch: 46 [64/107 (60%)]\tTrain Loss: 0.007710\n",
      "Train Epoch: 46 [68/107 (64%)]\tTrain Loss: 0.016378\n",
      "Train Epoch: 46 [72/107 (67%)]\tTrain Loss: 0.002269\n",
      "Train Epoch: 46 [76/107 (71%)]\tTrain Loss: 0.004900\n",
      "Train Epoch: 46 [80/107 (75%)]\tTrain Loss: 0.004209\n",
      "Train Epoch: 46 [84/107 (79%)]\tTrain Loss: 0.025190\n",
      "Train Epoch: 46 [88/107 (82%)]\tTrain Loss: 0.021645\n",
      "Train Epoch: 46 [92/107 (86%)]\tTrain Loss: 0.000389\n",
      "Train Epoch: 46 [96/107 (90%)]\tTrain Loss: 0.001503\n",
      "Train Epoch: 46 [100/107 (93%)]\tTrain Loss: 0.000144\n",
      "Train Epoch: 46 [104/107 (97%)]\tTrain Loss: 0.005270\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.47048533e-01 9.91903961e-01 2.40820855e-01 4.91880774e-01\n",
      " 2.19098613e-01 2.10509785e-02 9.47661936e-01 7.04766929e-01\n",
      " 4.53208461e-02 1.04897628e-02 6.22488499e-01 1.87119772e-03\n",
      " 5.48991799e-01 6.81025500e-04 3.12664397e-02 1.69151226e-05\n",
      " 4.62270873e-05 2.91307479e-01 1.09077292e-02 2.71670073e-01\n",
      " 2.92765170e-01 6.20596170e-01 9.99868870e-01 9.98905063e-01\n",
      " 6.26860261e-01 9.99710381e-01 9.99619603e-01 1.40983477e-01\n",
      " 4.42721061e-02 2.96096820e-02 4.79928069e-02 3.05917673e-02\n",
      " 4.13777441e-01 2.53051228e-04 1.17956377e-04 3.03664507e-04\n",
      " 4.38869232e-03 9.11687613e-01 5.14719665e-01 1.00693105e-05\n",
      " 2.76209012e-05 7.29570238e-05 8.06421220e-01 2.74849534e-01\n",
      " 6.35141969e-01 5.11823893e-01 8.46704662e-01 5.06115794e-01\n",
      " 9.33622777e-01 1.28637448e-01 9.37589347e-01 4.30831307e-04\n",
      " 8.99503648e-04 6.46361010e-03 4.59918985e-03 2.83475238e-04\n",
      " 9.57901001e-01 7.08378138e-06 5.52343111e-03 2.10207375e-03\n",
      " 9.98447895e-01 9.84134018e-01 9.99621272e-01 9.99821126e-01\n",
      " 9.99814212e-01 9.93566692e-01 9.96618629e-01 9.99855161e-01\n",
      " 9.99183118e-01 9.98640835e-01 8.84288669e-01 4.98466700e-01\n",
      " 9.49042976e-01 9.92305100e-01 9.99803364e-01 9.94787574e-01\n",
      " 9.95892048e-01 9.89591300e-01 9.99991894e-01 9.98876512e-01\n",
      " 9.99981046e-01 9.99982715e-01 9.99950290e-01 9.97913182e-01\n",
      " 9.77795482e-01 9.99876142e-01 9.96197224e-01 9.90901470e-01\n",
      " 6.61115289e-01 5.53153574e-01 9.99988198e-01 9.88607347e-01\n",
      " 9.62561846e-01 9.99999762e-01 9.99991179e-01 9.99998569e-01\n",
      " 3.16946268e-01 8.99123490e-01 9.99919772e-01 9.99523520e-01\n",
      " 7.96000183e-01 9.93967533e-01 2.64218092e-01 9.78633761e-01\n",
      " 8.42849731e-01 9.98507440e-01 9.97899055e-01 8.39826018e-02\n",
      " 2.89604347e-03 8.05700958e-01 6.59832299e-01 7.37357676e-01\n",
      " 9.99994278e-01 9.28833365e-01 4.44380164e-01 1.60726102e-03\n",
      " 9.99216914e-01 9.99682546e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 47 [0/107 (0%)]\tTrain Loss: 0.006865\n",
      "Train Epoch: 47 [4/107 (4%)]\tTrain Loss: 0.005318\n",
      "Train Epoch: 47 [8/107 (7%)]\tTrain Loss: 0.020682\n",
      "Train Epoch: 47 [12/107 (11%)]\tTrain Loss: 0.040778\n",
      "Train Epoch: 47 [16/107 (15%)]\tTrain Loss: 0.011904\n",
      "Train Epoch: 47 [20/107 (19%)]\tTrain Loss: 0.020406\n",
      "Train Epoch: 47 [24/107 (22%)]\tTrain Loss: 0.041852\n",
      "Train Epoch: 47 [28/107 (26%)]\tTrain Loss: 0.012137\n",
      "Train Epoch: 47 [32/107 (30%)]\tTrain Loss: 0.000702\n",
      "Train Epoch: 47 [36/107 (34%)]\tTrain Loss: 0.000209\n",
      "Train Epoch: 47 [40/107 (37%)]\tTrain Loss: 0.000195\n",
      "Train Epoch: 47 [44/107 (41%)]\tTrain Loss: 0.001260\n",
      "Train Epoch: 47 [48/107 (45%)]\tTrain Loss: 0.001474\n",
      "Train Epoch: 47 [52/107 (49%)]\tTrain Loss: 0.087237\n",
      "Train Epoch: 47 [56/107 (52%)]\tTrain Loss: 0.001635\n",
      "Train Epoch: 47 [60/107 (56%)]\tTrain Loss: 0.019946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [64/107 (60%)]\tTrain Loss: 0.000410\n",
      "Train Epoch: 47 [68/107 (64%)]\tTrain Loss: 0.000193\n",
      "Train Epoch: 47 [72/107 (67%)]\tTrain Loss: 0.016477\n",
      "Train Epoch: 47 [76/107 (71%)]\tTrain Loss: 0.010394\n",
      "Train Epoch: 47 [80/107 (75%)]\tTrain Loss: 0.000106\n",
      "Train Epoch: 47 [84/107 (79%)]\tTrain Loss: 0.169617\n",
      "Train Epoch: 47 [88/107 (82%)]\tTrain Loss: 0.000153\n",
      "Train Epoch: 47 [92/107 (86%)]\tTrain Loss: 0.000328\n",
      "Train Epoch: 47 [96/107 (90%)]\tTrain Loss: 0.004772\n",
      "Train Epoch: 47 [100/107 (93%)]\tTrain Loss: 0.076225\n",
      "Train Epoch: 47 [104/107 (97%)]\tTrain Loss: 0.008280\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.82385787e-01 9.98977780e-01 6.67193711e-01 9.02640283e-01\n",
      " 4.51523513e-02 3.17988664e-01 9.92442787e-01 9.94224250e-01\n",
      " 2.29590774e-01 5.22897020e-03 8.74424040e-01 1.55040098e-03\n",
      " 7.34326243e-01 7.58316601e-04 1.97515711e-01 1.98092857e-06\n",
      " 7.22080222e-06 9.70044017e-01 1.55661395e-03 5.67602776e-02\n",
      " 4.84397672e-02 8.56444120e-01 9.95948255e-01 9.99659419e-01\n",
      " 3.10619444e-01 9.96489048e-01 9.96805429e-01 7.86845535e-02\n",
      " 5.27663331e-04 3.03545524e-03 3.90458107e-03 4.32351604e-03\n",
      " 7.37381816e-01 1.20725243e-04 8.00672133e-05 1.44287033e-05\n",
      " 3.55502078e-03 9.99500155e-01 6.54713869e-01 1.47964471e-07\n",
      " 6.73264253e-07 1.61204855e-06 9.98740971e-01 5.18533647e-01\n",
      " 1.54595852e-01 7.70714357e-02 8.86544466e-01 2.57222801e-01\n",
      " 9.81540799e-01 1.67347029e-01 9.48798120e-01 2.24157819e-03\n",
      " 3.20777217e-05 6.36690157e-03 2.37154563e-05 8.02531576e-06\n",
      " 9.59496915e-01 7.34327870e-08 5.14322333e-02 2.19872003e-04\n",
      " 9.97264981e-01 9.89448547e-01 9.99771297e-01 9.99838233e-01\n",
      " 9.99926567e-01 9.99886870e-01 9.99893308e-01 9.99995351e-01\n",
      " 9.99995828e-01 9.98703003e-01 9.40548778e-01 1.55980095e-01\n",
      " 8.65176618e-01 9.75714982e-01 9.99982953e-01 9.95856464e-01\n",
      " 9.99883294e-01 9.99295473e-01 9.99999285e-01 9.99479234e-01\n",
      " 9.99966621e-01 9.99988317e-01 9.99996305e-01 9.94970620e-01\n",
      " 9.71959829e-01 9.99954820e-01 9.97450650e-01 9.98427868e-01\n",
      " 2.08177850e-01 5.24270773e-01 9.99820888e-01 9.97869611e-01\n",
      " 9.85581458e-01 9.99999881e-01 9.99973178e-01 9.99999642e-01\n",
      " 5.05539536e-01 5.69183767e-01 9.93712366e-01 9.99182522e-01\n",
      " 6.58164322e-01 9.95624363e-01 7.83830464e-01 9.43698108e-01\n",
      " 1.19161703e-01 9.64949250e-01 9.99081969e-01 2.71727055e-01\n",
      " 9.63560212e-03 8.65656793e-01 8.76060605e-01 9.31209385e-01\n",
      " 9.99976516e-01 5.90192318e-01 1.74482495e-01 1.55364722e-03\n",
      " 9.99998569e-01 9.99968648e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 48 [0/107 (0%)]\tTrain Loss: 0.000740\n",
      "Train Epoch: 48 [4/107 (4%)]\tTrain Loss: 0.003171\n",
      "Train Epoch: 48 [8/107 (7%)]\tTrain Loss: 0.007203\n",
      "Train Epoch: 48 [12/107 (11%)]\tTrain Loss: 0.002613\n",
      "Train Epoch: 48 [16/107 (15%)]\tTrain Loss: 0.006144\n",
      "Train Epoch: 48 [20/107 (19%)]\tTrain Loss: 0.001620\n",
      "Train Epoch: 48 [24/107 (22%)]\tTrain Loss: 0.000363\n",
      "Train Epoch: 48 [28/107 (26%)]\tTrain Loss: 0.001956\n",
      "Train Epoch: 48 [32/107 (30%)]\tTrain Loss: 0.016711\n",
      "Train Epoch: 48 [36/107 (34%)]\tTrain Loss: 0.019570\n",
      "Train Epoch: 48 [40/107 (37%)]\tTrain Loss: 0.000228\n",
      "Train Epoch: 48 [44/107 (41%)]\tTrain Loss: 0.003274\n",
      "Train Epoch: 48 [48/107 (45%)]\tTrain Loss: 0.002289\n",
      "Train Epoch: 48 [52/107 (49%)]\tTrain Loss: 0.003853\n",
      "Train Epoch: 48 [56/107 (52%)]\tTrain Loss: 0.007994\n",
      "Train Epoch: 48 [60/107 (56%)]\tTrain Loss: 0.002041\n",
      "Train Epoch: 48 [64/107 (60%)]\tTrain Loss: 0.000158\n",
      "Train Epoch: 48 [68/107 (64%)]\tTrain Loss: 0.006076\n",
      "Train Epoch: 48 [72/107 (67%)]\tTrain Loss: 0.312794\n",
      "Train Epoch: 48 [76/107 (71%)]\tTrain Loss: 0.135975\n",
      "Train Epoch: 48 [80/107 (75%)]\tTrain Loss: 0.000290\n",
      "Train Epoch: 48 [84/107 (79%)]\tTrain Loss: 0.082450\n",
      "Train Epoch: 48 [88/107 (82%)]\tTrain Loss: 0.004960\n",
      "Train Epoch: 48 [92/107 (86%)]\tTrain Loss: 0.001272\n",
      "Train Epoch: 48 [96/107 (90%)]\tTrain Loss: 0.012965\n",
      "Train Epoch: 48 [100/107 (93%)]\tTrain Loss: 0.011148\n",
      "Train Epoch: 48 [104/107 (97%)]\tTrain Loss: 0.003298\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.38977915e-01 9.95982647e-01 8.01059663e-01 1.70974553e-01\n",
      " 2.00598445e-02 5.04620820e-02 9.88779426e-01 5.03310442e-01\n",
      " 6.29132316e-02 1.63935386e-02 2.36293420e-01 3.04763275e-03\n",
      " 1.38079882e-01 5.28043928e-03 7.68976882e-02 1.31213770e-03\n",
      " 4.13033158e-05 7.87657559e-01 2.72438694e-02 1.83304802e-01\n",
      " 1.38981134e-01 3.21945578e-01 9.75608647e-01 9.96473849e-01\n",
      " 1.03630193e-01 9.68629122e-01 9.61501002e-01 3.31108004e-01\n",
      " 3.88318673e-02 1.24357613e-02 4.15857285e-01 6.34397790e-02\n",
      " 7.57643044e-01 1.06424151e-03 2.06240526e-04 3.01744119e-04\n",
      " 3.82885570e-03 9.39399898e-01 4.84131098e-01 2.00652375e-05\n",
      " 3.43745669e-05 1.33259440e-04 7.98545718e-01 1.02956079e-01\n",
      " 7.47573450e-02 2.95165181e-03 5.33640981e-01 4.63570237e-01\n",
      " 8.44560146e-01 3.58447209e-02 8.26154113e-01 2.50353268e-03\n",
      " 3.85532691e-03 3.11900512e-03 2.40688981e-03 2.97531975e-03\n",
      " 8.72545481e-01 3.83719926e-05 5.61169200e-02 4.46847081e-03\n",
      " 9.70301628e-01 9.73304093e-01 9.97613907e-01 9.97039378e-01\n",
      " 9.99960303e-01 9.98584032e-01 9.95761216e-01 9.99963880e-01\n",
      " 9.99708593e-01 9.82977748e-01 7.88206339e-01 8.85055736e-02\n",
      " 7.42476702e-01 9.47819471e-01 9.98376250e-01 9.60356653e-01\n",
      " 9.88485456e-01 9.98456240e-01 9.99980450e-01 9.87571120e-01\n",
      " 9.96595800e-01 9.99122918e-01 9.99079227e-01 9.52703238e-01\n",
      " 2.52160400e-01 9.99597371e-01 9.94221628e-01 9.95613575e-01\n",
      " 8.27118635e-01 2.00387359e-01 9.52996075e-01 8.65098119e-01\n",
      " 6.68217361e-01 9.99929070e-01 9.53298330e-01 9.99837160e-01\n",
      " 4.36131626e-01 1.21420085e-01 9.95456457e-01 9.29515600e-01\n",
      " 5.05330324e-01 8.81353199e-01 1.69326738e-01 3.79410475e-01\n",
      " 5.46148308e-02 4.73029763e-01 9.31330740e-01 4.60476309e-01\n",
      " 1.38372672e-03 7.27115989e-01 7.95021415e-01 3.83451134e-01\n",
      " 9.94420946e-01 3.30593586e-01 7.32467100e-02 3.19891190e-03\n",
      " 9.99951482e-01 9.97862995e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 49 [0/107 (0%)]\tTrain Loss: 0.003926\n",
      "Train Epoch: 49 [4/107 (4%)]\tTrain Loss: 0.008388\n",
      "Train Epoch: 49 [8/107 (7%)]\tTrain Loss: 0.000317\n",
      "Train Epoch: 49 [12/107 (11%)]\tTrain Loss: 0.013434\n",
      "Train Epoch: 49 [16/107 (15%)]\tTrain Loss: 0.001104\n",
      "Train Epoch: 49 [20/107 (19%)]\tTrain Loss: 0.002118\n",
      "Train Epoch: 49 [24/107 (22%)]\tTrain Loss: 0.000250\n",
      "Train Epoch: 49 [28/107 (26%)]\tTrain Loss: 0.001881\n",
      "Train Epoch: 49 [32/107 (30%)]\tTrain Loss: 0.057441\n",
      "Train Epoch: 49 [36/107 (34%)]\tTrain Loss: 0.005216\n",
      "Train Epoch: 49 [40/107 (37%)]\tTrain Loss: 0.000264\n",
      "Train Epoch: 49 [44/107 (41%)]\tTrain Loss: 0.004999\n",
      "Train Epoch: 49 [48/107 (45%)]\tTrain Loss: 0.104320\n",
      "Train Epoch: 49 [52/107 (49%)]\tTrain Loss: 0.022158\n",
      "Train Epoch: 49 [56/107 (52%)]\tTrain Loss: 0.001234\n",
      "Train Epoch: 49 [60/107 (56%)]\tTrain Loss: 0.000420\n",
      "Train Epoch: 49 [64/107 (60%)]\tTrain Loss: 0.008404\n",
      "Train Epoch: 49 [68/107 (64%)]\tTrain Loss: 0.019612\n",
      "Train Epoch: 49 [72/107 (67%)]\tTrain Loss: 0.005593\n",
      "Train Epoch: 49 [76/107 (71%)]\tTrain Loss: 0.002159\n",
      "Train Epoch: 49 [80/107 (75%)]\tTrain Loss: 0.007871\n",
      "Train Epoch: 49 [84/107 (79%)]\tTrain Loss: 0.000194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [88/107 (82%)]\tTrain Loss: 0.001031\n",
      "Train Epoch: 49 [92/107 (86%)]\tTrain Loss: 0.013512\n",
      "Train Epoch: 49 [96/107 (90%)]\tTrain Loss: 0.002110\n",
      "Train Epoch: 49 [100/107 (93%)]\tTrain Loss: 0.001400\n",
      "Train Epoch: 49 [104/107 (97%)]\tTrain Loss: 0.000266\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.80238961e-02 9.91440773e-01 2.14828432e-01 2.65883446e-01\n",
      " 1.01382956e-01 6.19696267e-02 9.24336433e-01 7.93799698e-01\n",
      " 1.13600999e-01 4.10441123e-03 2.48921007e-01 2.79668951e-04\n",
      " 3.00386608e-01 4.72019456e-04 8.34066793e-02 2.51160800e-05\n",
      " 2.40728610e-07 4.45663124e-01 5.04709743e-02 1.13978244e-01\n",
      " 1.82971939e-01 8.79403889e-01 9.95637476e-01 9.99673486e-01\n",
      " 8.69787276e-01 9.95445132e-01 9.99543965e-01 1.16114832e-01\n",
      " 1.22769037e-03 3.57393897e-03 5.37325852e-02 5.10579087e-02\n",
      " 5.15520632e-01 9.74807699e-05 3.21082131e-04 5.06499134e-07\n",
      " 2.67811329e-03 9.77863729e-01 3.66311699e-01 9.99222181e-08\n",
      " 4.35751389e-07 5.94268670e-07 9.59483206e-01 6.58611357e-02\n",
      " 3.44371080e-01 6.74869446e-03 6.79351389e-01 5.95600188e-01\n",
      " 8.19254160e-01 8.58743116e-02 8.87385905e-01 9.53166396e-04\n",
      " 2.32011123e-04 4.20734333e-03 4.18784749e-03 3.97654017e-04\n",
      " 9.44607973e-01 1.70088242e-07 3.50273214e-02 2.70323653e-04\n",
      " 9.99583185e-01 9.99109566e-01 9.99983907e-01 9.99983191e-01\n",
      " 9.99679923e-01 9.80805039e-01 9.88481522e-01 9.99980092e-01\n",
      " 9.98421431e-01 9.87671018e-01 8.87413144e-01 3.13278437e-01\n",
      " 8.76904607e-01 9.91433620e-01 9.99929905e-01 9.93880868e-01\n",
      " 9.98887360e-01 9.97257769e-01 9.99984622e-01 9.98071134e-01\n",
      " 9.99873161e-01 9.99906421e-01 9.99951363e-01 9.97545183e-01\n",
      " 9.20672774e-01 9.99807060e-01 9.96089697e-01 9.94454920e-01\n",
      " 8.11267495e-01 9.94502425e-01 9.99286473e-01 9.30920541e-01\n",
      " 5.51500559e-01 9.99999762e-01 9.99930501e-01 9.99997616e-01\n",
      " 4.73115146e-01 8.67572129e-01 9.99995232e-01 9.95497942e-01\n",
      " 5.65373480e-01 9.84324813e-01 7.87374079e-01 9.32112515e-01\n",
      " 9.96502116e-02 8.58039021e-01 9.90456998e-01 4.95169073e-01\n",
      " 3.88555266e-02 7.15025485e-01 9.47670221e-01 9.09435868e-01\n",
      " 9.99794185e-01 6.32222414e-01 1.32395297e-01 1.18104573e-02\n",
      " 9.99990344e-01 9.99991775e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 50 [0/107 (0%)]\tTrain Loss: 0.025740\n",
      "Train Epoch: 50 [4/107 (4%)]\tTrain Loss: 0.084392\n",
      "Train Epoch: 50 [8/107 (7%)]\tTrain Loss: 0.002945\n",
      "Train Epoch: 50 [12/107 (11%)]\tTrain Loss: 0.003505\n",
      "Train Epoch: 50 [16/107 (15%)]\tTrain Loss: 0.002310\n",
      "Train Epoch: 50 [20/107 (19%)]\tTrain Loss: 0.007603\n",
      "Train Epoch: 50 [24/107 (22%)]\tTrain Loss: 0.033029\n",
      "Train Epoch: 50 [28/107 (26%)]\tTrain Loss: 0.001617\n",
      "Train Epoch: 50 [32/107 (30%)]\tTrain Loss: 0.004308\n",
      "Train Epoch: 50 [36/107 (34%)]\tTrain Loss: 0.005018\n",
      "Train Epoch: 50 [40/107 (37%)]\tTrain Loss: 0.034731\n",
      "Train Epoch: 50 [44/107 (41%)]\tTrain Loss: 0.001883\n",
      "Train Epoch: 50 [48/107 (45%)]\tTrain Loss: 0.001581\n",
      "Train Epoch: 50 [52/107 (49%)]\tTrain Loss: 0.006028\n",
      "Train Epoch: 50 [56/107 (52%)]\tTrain Loss: 0.001870\n",
      "Train Epoch: 50 [60/107 (56%)]\tTrain Loss: 0.000511\n",
      "Train Epoch: 50 [64/107 (60%)]\tTrain Loss: 0.002059\n",
      "Train Epoch: 50 [68/107 (64%)]\tTrain Loss: 0.001304\n",
      "Train Epoch: 50 [72/107 (67%)]\tTrain Loss: 0.039093\n",
      "Train Epoch: 50 [76/107 (71%)]\tTrain Loss: 0.002929\n",
      "Train Epoch: 50 [80/107 (75%)]\tTrain Loss: 0.002990\n",
      "Train Epoch: 50 [84/107 (79%)]\tTrain Loss: 0.000918\n",
      "Train Epoch: 50 [88/107 (82%)]\tTrain Loss: 0.000741\n",
      "Train Epoch: 50 [92/107 (86%)]\tTrain Loss: 0.000460\n",
      "Train Epoch: 50 [96/107 (90%)]\tTrain Loss: 0.001226\n",
      "Train Epoch: 50 [100/107 (93%)]\tTrain Loss: 0.001492\n",
      "Train Epoch: 50 [104/107 (97%)]\tTrain Loss: 0.000621\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.03039476e-02 9.76753712e-01 9.88341197e-02 5.12580991e-01\n",
      " 7.99411833e-02 2.89653447e-02 8.00259411e-01 7.72831500e-01\n",
      " 1.40074436e-02 7.27449683e-03 5.04850686e-01 2.26923963e-04\n",
      " 1.63350791e-01 5.94425328e-05 1.05395215e-02 9.95777282e-06\n",
      " 2.36199057e-07 4.26987946e-01 1.01428712e-03 1.75708625e-02\n",
      " 7.93213844e-02 5.49112320e-01 9.96182978e-01 9.99449551e-01\n",
      " 3.15778315e-01 9.84915137e-01 9.94931519e-01 3.26762870e-02\n",
      " 6.04876736e-03 4.39988944e-04 5.44917226e-01 2.84052696e-02\n",
      " 4.73831087e-01 6.85364066e-05 1.09391076e-04 1.90648279e-05\n",
      " 3.76166514e-04 9.86968100e-01 1.87794775e-01 9.35243989e-08\n",
      " 8.06576566e-07 1.99041210e-06 7.64408231e-01 2.00886622e-01\n",
      " 7.00457215e-01 6.26287758e-02 9.40729797e-01 7.90873885e-01\n",
      " 8.28994095e-01 1.93579104e-02 9.06558335e-01 5.06367476e-04\n",
      " 2.99655157e-03 1.32301301e-02 8.16908374e-04 1.72256143e-03\n",
      " 9.63128567e-01 2.96073040e-07 1.60761905e-04 2.54079094e-03\n",
      " 9.99806821e-01 9.99418020e-01 9.99973893e-01 9.99992371e-01\n",
      " 9.99990225e-01 9.96639848e-01 9.95554507e-01 9.99987125e-01\n",
      " 9.99828696e-01 9.89627123e-01 9.64470744e-01 6.55839264e-01\n",
      " 9.62881923e-01 9.98070061e-01 9.99978542e-01 9.97983813e-01\n",
      " 9.99246120e-01 9.97864187e-01 9.99992371e-01 9.98217762e-01\n",
      " 9.99967575e-01 9.99967217e-01 9.99919653e-01 9.83669877e-01\n",
      " 8.81169081e-01 9.99782622e-01 9.99321222e-01 9.96581376e-01\n",
      " 5.24644196e-01 3.32666278e-01 9.04208481e-01 9.56221581e-01\n",
      " 9.13565814e-01 9.99999642e-01 9.99910235e-01 9.99971151e-01\n",
      " 3.15615118e-01 5.26864678e-02 9.98585939e-01 9.14648473e-01\n",
      " 4.49261814e-02 9.92975354e-01 7.95022473e-02 9.86253858e-01\n",
      " 2.31111169e-01 9.20236170e-01 9.67581332e-01 8.28897282e-02\n",
      " 2.71030585e-03 8.81004632e-01 5.90897977e-01 3.56858432e-01\n",
      " 9.96768713e-01 1.08553261e-01 2.06579687e-03 2.49653094e-04\n",
      " 9.98524129e-01 9.97922957e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 43 FN= 11 FP= 17\n",
      "TP+FP 64\n",
      "precision 0.734375\n",
      "recall 0.8103448275862069\n",
      "F1 0.7704918032786885\n",
      "acc 0.7627118644067796\n",
      "AUCp 0.7635057471264367\n",
      "AUC 0.8614942528735633\n",
      "\n",
      " The epoch is 50, average recall: 0.8103, average precision: 0.7344,average F1: 0.7705, average accuracy: 0.7627, average AUC: 0.8615\n",
      "Train Epoch: 51 [0/107 (0%)]\tTrain Loss: 0.000316\n",
      "Train Epoch: 51 [4/107 (4%)]\tTrain Loss: 0.009601\n",
      "Train Epoch: 51 [8/107 (7%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 51 [12/107 (11%)]\tTrain Loss: 0.000480\n",
      "Train Epoch: 51 [16/107 (15%)]\tTrain Loss: 0.002133\n",
      "Train Epoch: 51 [20/107 (19%)]\tTrain Loss: 0.000495\n",
      "Train Epoch: 51 [24/107 (22%)]\tTrain Loss: 0.005908\n",
      "Train Epoch: 51 [28/107 (26%)]\tTrain Loss: 0.000665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [32/107 (30%)]\tTrain Loss: 0.000917\n",
      "Train Epoch: 51 [36/107 (34%)]\tTrain Loss: 0.000320\n",
      "Train Epoch: 51 [40/107 (37%)]\tTrain Loss: 0.006185\n",
      "Train Epoch: 51 [44/107 (41%)]\tTrain Loss: 0.001016\n",
      "Train Epoch: 51 [48/107 (45%)]\tTrain Loss: 0.008625\n",
      "Train Epoch: 51 [52/107 (49%)]\tTrain Loss: 0.006107\n",
      "Train Epoch: 51 [56/107 (52%)]\tTrain Loss: 0.003776\n",
      "Train Epoch: 51 [60/107 (56%)]\tTrain Loss: 0.002312\n",
      "Train Epoch: 51 [64/107 (60%)]\tTrain Loss: 0.000315\n",
      "Train Epoch: 51 [68/107 (64%)]\tTrain Loss: 0.000121\n",
      "Train Epoch: 51 [72/107 (67%)]\tTrain Loss: 0.001217\n",
      "Train Epoch: 51 [76/107 (71%)]\tTrain Loss: 0.027690\n",
      "Train Epoch: 51 [80/107 (75%)]\tTrain Loss: 0.000340\n",
      "Train Epoch: 51 [84/107 (79%)]\tTrain Loss: 0.006998\n",
      "Train Epoch: 51 [88/107 (82%)]\tTrain Loss: 0.001140\n",
      "Train Epoch: 51 [92/107 (86%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 51 [96/107 (90%)]\tTrain Loss: 0.002225\n",
      "Train Epoch: 51 [100/107 (93%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 51 [104/107 (97%)]\tTrain Loss: 0.004195\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.71742398e-02 9.97825146e-01 5.84049560e-02 1.66126207e-01\n",
      " 8.59536231e-02 2.49229930e-02 9.69246328e-01 3.08064431e-01\n",
      " 3.64217944e-02 7.42693245e-02 3.05040747e-01 1.39415928e-03\n",
      " 2.24745125e-01 5.07348683e-03 3.77308577e-02 1.25199324e-04\n",
      " 1.68518764e-05 4.68911767e-01 8.45529065e-02 2.04157099e-01\n",
      " 9.00195360e-01 8.77225757e-01 9.99966979e-01 9.99988437e-01\n",
      " 8.37695062e-01 9.99920726e-01 9.99956012e-01 3.80867571e-01\n",
      " 3.04620415e-02 4.51015367e-04 9.68754590e-01 2.25690249e-02\n",
      " 5.76729238e-01 2.75157101e-04 1.07014457e-04 2.71638244e-04\n",
      " 1.06566853e-03 9.40520525e-01 2.12796137e-01 1.50818114e-05\n",
      " 4.58857176e-05 4.57135582e-04 6.07788526e-02 1.18897669e-01\n",
      " 7.51927435e-01 2.52888918e-01 7.29754150e-01 3.86797369e-01\n",
      " 6.21614516e-01 8.18938836e-02 8.03692520e-01 2.25538388e-04\n",
      " 4.09104563e-02 1.61535293e-02 1.19671464e-01 1.06510529e-02\n",
      " 9.98011708e-01 1.02043778e-04 2.78316205e-03 1.88551396e-02\n",
      " 9.99980927e-01 9.99920368e-01 9.99999046e-01 9.99999285e-01\n",
      " 9.99993920e-01 9.91693318e-01 9.92926419e-01 9.99998689e-01\n",
      " 9.99938488e-01 9.98307467e-01 8.05545926e-01 4.71993715e-01\n",
      " 9.91144180e-01 9.99551475e-01 9.99999762e-01 9.99967456e-01\n",
      " 9.99795496e-01 9.99953032e-01 9.99999046e-01 9.96321917e-01\n",
      " 9.99978304e-01 9.99989629e-01 9.99986529e-01 9.98490214e-01\n",
      " 8.17187428e-01 9.99982715e-01 9.99871492e-01 9.99213696e-01\n",
      " 9.95165467e-01 9.85250831e-01 9.99799550e-01 9.78492558e-01\n",
      " 9.20194268e-01 1.00000000e+00 9.99996781e-01 9.99999881e-01\n",
      " 6.56047106e-01 9.61896718e-01 9.99997973e-01 9.79416609e-01\n",
      " 3.69549721e-01 9.98317003e-01 1.49554327e-01 9.96317863e-01\n",
      " 5.87014854e-01 9.55726445e-01 9.94130909e-01 6.08812988e-01\n",
      " 1.15145752e-02 9.73075569e-01 9.93108749e-01 8.59842062e-01\n",
      " 9.99971271e-01 8.19045603e-01 3.41820181e-03 1.64532906e-03\n",
      " 9.99982476e-01 9.99989867e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 52 [0/107 (0%)]\tTrain Loss: 0.000953\n",
      "Train Epoch: 52 [4/107 (4%)]\tTrain Loss: 0.000090\n",
      "Train Epoch: 52 [8/107 (7%)]\tTrain Loss: 0.001283\n",
      "Train Epoch: 52 [12/107 (11%)]\tTrain Loss: 0.020118\n",
      "Train Epoch: 52 [16/107 (15%)]\tTrain Loss: 0.010440\n",
      "Train Epoch: 52 [20/107 (19%)]\tTrain Loss: 0.009641\n",
      "Train Epoch: 52 [24/107 (22%)]\tTrain Loss: 0.198216\n",
      "Train Epoch: 52 [28/107 (26%)]\tTrain Loss: 0.000875\n",
      "Train Epoch: 52 [32/107 (30%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 52 [36/107 (34%)]\tTrain Loss: 0.001900\n",
      "Train Epoch: 52 [40/107 (37%)]\tTrain Loss: 0.025337\n",
      "Train Epoch: 52 [44/107 (41%)]\tTrain Loss: 0.002722\n",
      "Train Epoch: 52 [48/107 (45%)]\tTrain Loss: 0.017760\n",
      "Train Epoch: 52 [52/107 (49%)]\tTrain Loss: 0.000143\n",
      "Train Epoch: 52 [56/107 (52%)]\tTrain Loss: 0.000552\n",
      "Train Epoch: 52 [60/107 (56%)]\tTrain Loss: 0.002855\n",
      "Train Epoch: 52 [64/107 (60%)]\tTrain Loss: 0.002323\n",
      "Train Epoch: 52 [68/107 (64%)]\tTrain Loss: 0.000667\n",
      "Train Epoch: 52 [72/107 (67%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 52 [76/107 (71%)]\tTrain Loss: 0.004733\n",
      "Train Epoch: 52 [80/107 (75%)]\tTrain Loss: 0.000922\n",
      "Train Epoch: 52 [84/107 (79%)]\tTrain Loss: 0.002220\n",
      "Train Epoch: 52 [88/107 (82%)]\tTrain Loss: 0.001989\n",
      "Train Epoch: 52 [92/107 (86%)]\tTrain Loss: 0.002157\n",
      "Train Epoch: 52 [96/107 (90%)]\tTrain Loss: 0.002195\n",
      "Train Epoch: 52 [100/107 (93%)]\tTrain Loss: 0.001753\n",
      "Train Epoch: 52 [104/107 (97%)]\tTrain Loss: 0.000266\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.48747543e-02 8.40376914e-01 2.02696957e-03 2.22754478e-02\n",
      " 1.30223678e-02 5.09200208e-02 3.34319994e-02 5.66102751e-03\n",
      " 2.63928343e-02 3.31400358e-03 3.20168100e-02 3.42710409e-04\n",
      " 1.85021646e-02 4.96215827e-04 1.74433850e-02 1.07223395e-05\n",
      " 5.25573398e-07 1.99974120e-01 4.71986277e-04 5.96420700e-03\n",
      " 2.80501358e-02 3.22878152e-01 9.98511374e-01 9.99845266e-01\n",
      " 2.97020376e-01 9.99452531e-01 9.99267638e-01 6.69925474e-04\n",
      " 1.03688997e-03 1.15193334e-05 1.59931593e-02 3.83835693e-04\n",
      " 1.42550960e-01 1.65448699e-04 1.24738697e-04 3.88925582e-06\n",
      " 4.93627391e-04 3.43929291e-01 5.98734170e-02 5.64858453e-08\n",
      " 2.22943711e-07 1.82929102e-06 5.97969489e-03 1.04838917e-02\n",
      " 5.92980981e-02 9.31140129e-03 8.19114387e-01 2.97314674e-01\n",
      " 6.07751310e-01 8.76852050e-02 8.12084436e-01 7.00487290e-05\n",
      " 6.30486320e-05 3.58547550e-03 7.96948909e-04 1.40304197e-04\n",
      " 9.45270360e-01 7.42121387e-08 1.50246022e-04 2.23365030e-04\n",
      " 9.99442160e-01 9.99644279e-01 9.99923348e-01 9.99839902e-01\n",
      " 9.99841213e-01 9.88326609e-01 9.90392089e-01 9.99897122e-01\n",
      " 9.97566700e-01 9.95847821e-01 4.79677200e-01 2.45678768e-01\n",
      " 6.09103799e-01 9.74217951e-01 9.99924898e-01 5.81502676e-01\n",
      " 9.67602074e-01 8.74113202e-01 9.99923229e-01 9.46149826e-01\n",
      " 9.99174416e-01 9.99480426e-01 9.98970032e-01 9.93517280e-01\n",
      " 6.63137436e-01 9.99537945e-01 9.99090672e-01 9.96447027e-01\n",
      " 1.38235241e-01 7.76871741e-01 9.74851966e-01 9.20678377e-01\n",
      " 7.04646885e-01 9.99995470e-01 9.99252260e-01 9.99920726e-01\n",
      " 2.99591899e-01 3.26954722e-01 9.91489828e-01 9.84402180e-01\n",
      " 4.48112302e-02 9.91216421e-01 1.33588657e-01 4.82832044e-01\n",
      " 2.33116727e-02 5.96326292e-01 8.88692856e-01 1.56065255e-01\n",
      " 2.43415572e-02 8.11800957e-01 8.97830188e-01 7.94403434e-01\n",
      " 9.99600112e-01 1.69618070e-01 2.53370556e-04 4.62192460e-04\n",
      " 9.98509824e-01 9.98755693e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 53 [0/107 (0%)]\tTrain Loss: 0.000255\n",
      "Train Epoch: 53 [4/107 (4%)]\tTrain Loss: 0.011809\n",
      "Train Epoch: 53 [8/107 (7%)]\tTrain Loss: 0.001623\n",
      "Train Epoch: 53 [12/107 (11%)]\tTrain Loss: 0.017051\n",
      "Train Epoch: 53 [16/107 (15%)]\tTrain Loss: 0.000598\n",
      "Train Epoch: 53 [20/107 (19%)]\tTrain Loss: 0.005584\n",
      "Train Epoch: 53 [24/107 (22%)]\tTrain Loss: 0.001351\n",
      "Train Epoch: 53 [28/107 (26%)]\tTrain Loss: 0.002023\n",
      "Train Epoch: 53 [32/107 (30%)]\tTrain Loss: 0.003823\n",
      "Train Epoch: 53 [36/107 (34%)]\tTrain Loss: 0.005848\n",
      "Train Epoch: 53 [40/107 (37%)]\tTrain Loss: 0.000157\n",
      "Train Epoch: 53 [44/107 (41%)]\tTrain Loss: 0.000390\n",
      "Train Epoch: 53 [48/107 (45%)]\tTrain Loss: 0.000433\n",
      "Train Epoch: 53 [52/107 (49%)]\tTrain Loss: 0.027760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [56/107 (52%)]\tTrain Loss: 0.006742\n",
      "Train Epoch: 53 [60/107 (56%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 53 [64/107 (60%)]\tTrain Loss: 0.001654\n",
      "Train Epoch: 53 [68/107 (64%)]\tTrain Loss: 0.023890\n",
      "Train Epoch: 53 [72/107 (67%)]\tTrain Loss: 0.024965\n",
      "Train Epoch: 53 [76/107 (71%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 53 [80/107 (75%)]\tTrain Loss: 0.000165\n",
      "Train Epoch: 53 [84/107 (79%)]\tTrain Loss: 0.015062\n",
      "Train Epoch: 53 [88/107 (82%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 53 [92/107 (86%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 53 [96/107 (90%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 53 [100/107 (93%)]\tTrain Loss: 0.000628\n",
      "Train Epoch: 53 [104/107 (97%)]\tTrain Loss: 0.005221\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.58285692e-02 6.76486433e-01 1.42106856e-03 8.67678225e-02\n",
      " 3.67580615e-02 3.81501056e-02 1.01461550e-02 7.14212805e-02\n",
      " 1.62998326e-02 7.42972689e-03 2.95254104e-02 6.34268217e-05\n",
      " 7.35231936e-02 5.09524369e-04 5.14885187e-02 2.73494279e-05\n",
      " 1.30490225e-05 7.90023446e-01 1.75026292e-03 5.23292087e-03\n",
      " 1.34592690e-02 3.62104885e-02 9.99876499e-01 9.99972701e-01\n",
      " 1.19726714e-02 9.99893785e-01 9.99965787e-01 5.35812054e-04\n",
      " 9.30867624e-03 2.49483182e-05 3.66252754e-03 6.84878265e-04\n",
      " 1.47307307e-01 7.93459330e-05 3.47415807e-05 7.61326055e-06\n",
      " 4.37137205e-04 2.50569791e-01 3.39067839e-02 1.02981680e-07\n",
      " 2.19697142e-07 2.99718386e-06 2.40369644e-02 1.45157622e-02\n",
      " 1.71406776e-01 2.17266008e-02 6.67681515e-01 2.76315272e-01\n",
      " 7.69456863e-01 1.30534813e-01 8.80317569e-01 5.64628644e-05\n",
      " 4.97667534e-05 1.86513439e-02 4.13803995e-04 1.22347439e-03\n",
      " 9.88903463e-01 3.77376580e-07 3.26754147e-04 3.01015563e-04\n",
      " 9.99929905e-01 9.99785244e-01 9.99981642e-01 9.99952197e-01\n",
      " 9.99643564e-01 9.82671559e-01 9.99449432e-01 9.99995112e-01\n",
      " 9.99970436e-01 9.98322666e-01 4.93433416e-01 1.86335295e-01\n",
      " 9.55402076e-01 9.98175144e-01 9.99996185e-01 6.77587926e-01\n",
      " 9.99755681e-01 9.90587175e-01 9.99701798e-01 9.83805001e-01\n",
      " 9.99942064e-01 9.99953985e-01 9.99972343e-01 9.91850317e-01\n",
      " 7.19964564e-01 9.99879360e-01 9.99825895e-01 9.99139190e-01\n",
      " 1.44065931e-01 8.93179417e-01 9.97517943e-01 9.92495775e-01\n",
      " 9.55581963e-01 1.00000000e+00 9.99998331e-01 9.99999762e-01\n",
      " 5.56770504e-01 2.43680969e-01 9.96610582e-01 9.98693407e-01\n",
      " 1.13630578e-01 9.92185950e-01 3.17740254e-02 9.07595336e-01\n",
      " 6.67168647e-02 9.88971889e-01 9.96863127e-01 4.36399430e-02\n",
      " 6.20308844e-03 9.29207861e-01 9.30593789e-01 9.61382926e-01\n",
      " 9.99998927e-01 7.99431920e-01 2.93104269e-04 1.52159933e-04\n",
      " 9.99902725e-01 9.99103725e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 54 [0/107 (0%)]\tTrain Loss: 0.003207\n",
      "Train Epoch: 54 [4/107 (4%)]\tTrain Loss: 0.002442\n",
      "Train Epoch: 54 [8/107 (7%)]\tTrain Loss: 0.001717\n",
      "Train Epoch: 54 [12/107 (11%)]\tTrain Loss: 0.002985\n",
      "Train Epoch: 54 [16/107 (15%)]\tTrain Loss: 0.003601\n",
      "Train Epoch: 54 [20/107 (19%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 54 [24/107 (22%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 54 [28/107 (26%)]\tTrain Loss: 0.000371\n",
      "Train Epoch: 54 [32/107 (30%)]\tTrain Loss: 0.000312\n",
      "Train Epoch: 54 [36/107 (34%)]\tTrain Loss: 0.002291\n",
      "Train Epoch: 54 [40/107 (37%)]\tTrain Loss: 0.000440\n",
      "Train Epoch: 54 [44/107 (41%)]\tTrain Loss: 0.002017\n",
      "Train Epoch: 54 [48/107 (45%)]\tTrain Loss: 0.000273\n",
      "Train Epoch: 54 [52/107 (49%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 54 [56/107 (52%)]\tTrain Loss: 0.000077\n",
      "Train Epoch: 54 [60/107 (56%)]\tTrain Loss: 0.001202\n",
      "Train Epoch: 54 [64/107 (60%)]\tTrain Loss: 0.001791\n",
      "Train Epoch: 54 [68/107 (64%)]\tTrain Loss: 0.000267\n",
      "Train Epoch: 54 [72/107 (67%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 54 [76/107 (71%)]\tTrain Loss: 0.000568\n",
      "Train Epoch: 54 [80/107 (75%)]\tTrain Loss: 0.023810\n",
      "Train Epoch: 54 [84/107 (79%)]\tTrain Loss: 0.000492\n",
      "Train Epoch: 54 [88/107 (82%)]\tTrain Loss: 0.002761\n",
      "Train Epoch: 54 [92/107 (86%)]\tTrain Loss: 0.000409\n",
      "Train Epoch: 54 [96/107 (90%)]\tTrain Loss: 0.000441\n",
      "Train Epoch: 54 [100/107 (93%)]\tTrain Loss: 0.023508\n",
      "Train Epoch: 54 [104/107 (97%)]\tTrain Loss: 0.000356\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.78945009e-02 8.55428994e-01 2.51930696e-03 1.05704051e-02\n",
      " 7.37853860e-03 5.57441777e-03 3.65657061e-02 2.38477904e-02\n",
      " 5.88058867e-03 1.36352924e-03 2.40473524e-02 4.17484262e-05\n",
      " 1.21345539e-02 1.27476378e-04 7.39929872e-03 3.59519290e-05\n",
      " 5.55837062e-07 1.69396028e-02 2.72464450e-03 6.66130939e-03\n",
      " 1.25461966e-02 6.61150962e-02 9.99963760e-01 9.99985218e-01\n",
      " 1.54814214e-01 9.99418020e-01 9.99959588e-01 8.55717226e-04\n",
      " 5.79892716e-04 1.43901532e-04 6.84000785e-04 1.64348248e-03\n",
      " 2.75461636e-02 7.38698145e-05 7.16318118e-06 3.65657115e-07\n",
      " 6.12423028e-05 7.26999715e-02 2.27668285e-02 1.06165587e-07\n",
      " 4.75150728e-07 6.56177872e-06 1.04889832e-02 1.40343653e-02\n",
      " 1.06755137e-01 1.30501967e-02 2.95630246e-01 2.01112375e-01\n",
      " 7.55402029e-01 4.40087169e-02 8.39939177e-01 2.46181389e-05\n",
      " 1.98769339e-05 1.07848005e-04 1.28371903e-04 9.12225863e-04\n",
      " 9.19913232e-01 3.17510853e-08 5.13567866e-05 8.01313945e-05\n",
      " 9.99910474e-01 9.99839664e-01 9.99996305e-01 9.99973774e-01\n",
      " 9.99283850e-01 8.11651230e-01 9.94591653e-01 9.99996305e-01\n",
      " 9.99759257e-01 9.93373871e-01 4.36892629e-01 1.69411451e-01\n",
      " 8.99731100e-01 9.97536659e-01 9.99977231e-01 4.49973196e-01\n",
      " 9.98480022e-01 9.96530116e-01 9.99651909e-01 9.54856694e-01\n",
      " 9.99853849e-01 9.99974251e-01 9.99980807e-01 9.97761965e-01\n",
      " 9.47798669e-01 9.99468029e-01 9.99241948e-01 9.96099114e-01\n",
      " 2.45674580e-01 8.54976654e-01 9.96164322e-01 9.71636593e-01\n",
      " 5.50123394e-01 1.00000000e+00 9.99992371e-01 9.99998808e-01\n",
      " 4.51240987e-01 8.43089044e-01 9.99946475e-01 9.98401582e-01\n",
      " 2.48119876e-01 9.90298450e-01 1.04500996e-02 2.65938669e-01\n",
      " 5.36829755e-02 8.72796178e-01 9.92152512e-01 6.55213818e-02\n",
      " 3.86754470e-03 1.23581514e-01 9.69769597e-01 7.15082526e-01\n",
      " 9.99992371e-01 8.68392408e-01 1.09115848e-03 5.11741266e-04\n",
      " 9.99935150e-01 9.99944329e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 55 [0/107 (0%)]\tTrain Loss: 0.018402\n",
      "Train Epoch: 55 [4/107 (4%)]\tTrain Loss: 0.001565\n",
      "Train Epoch: 55 [8/107 (7%)]\tTrain Loss: 0.021200\n",
      "Train Epoch: 55 [12/107 (11%)]\tTrain Loss: 0.007532\n",
      "Train Epoch: 55 [16/107 (15%)]\tTrain Loss: 0.000431\n",
      "Train Epoch: 55 [20/107 (19%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 55 [24/107 (22%)]\tTrain Loss: 0.001422\n",
      "Train Epoch: 55 [28/107 (26%)]\tTrain Loss: 0.000638\n",
      "Train Epoch: 55 [32/107 (30%)]\tTrain Loss: 0.001832\n",
      "Train Epoch: 55 [36/107 (34%)]\tTrain Loss: 0.006355\n",
      "Train Epoch: 55 [40/107 (37%)]\tTrain Loss: 0.015604\n",
      "Train Epoch: 55 [44/107 (41%)]\tTrain Loss: 0.002014\n",
      "Train Epoch: 55 [48/107 (45%)]\tTrain Loss: 0.002591\n",
      "Train Epoch: 55 [52/107 (49%)]\tTrain Loss: 0.000956\n",
      "Train Epoch: 55 [56/107 (52%)]\tTrain Loss: 0.000630\n",
      "Train Epoch: 55 [60/107 (56%)]\tTrain Loss: 0.000202\n",
      "Train Epoch: 55 [64/107 (60%)]\tTrain Loss: 0.004019\n",
      "Train Epoch: 55 [68/107 (64%)]\tTrain Loss: 0.182548\n",
      "Train Epoch: 55 [72/107 (67%)]\tTrain Loss: 0.000243\n",
      "Train Epoch: 55 [76/107 (71%)]\tTrain Loss: 0.001316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [80/107 (75%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 55 [84/107 (79%)]\tTrain Loss: 0.003724\n",
      "Train Epoch: 55 [88/107 (82%)]\tTrain Loss: 0.008806\n",
      "Train Epoch: 55 [92/107 (86%)]\tTrain Loss: 0.001727\n",
      "Train Epoch: 55 [96/107 (90%)]\tTrain Loss: 0.011375\n",
      "Train Epoch: 55 [100/107 (93%)]\tTrain Loss: 0.008523\n",
      "Train Epoch: 55 [104/107 (97%)]\tTrain Loss: 0.009485\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.83475146e-02 1.16205728e-02 7.85253826e-04 8.64036456e-02\n",
      " 9.79632065e-02 9.58194211e-03 2.94117630e-03 2.09330693e-01\n",
      " 4.72367108e-02 5.78286536e-02 8.20702195e-01 4.87105502e-03\n",
      " 5.93633175e-01 1.07802572e-02 1.55135319e-01 4.16469033e-04\n",
      " 6.39601058e-05 1.34283587e-01 8.17218542e-01 2.60176122e-01\n",
      " 3.27890843e-01 2.76933640e-01 9.99938965e-01 9.99967575e-01\n",
      " 2.75216669e-01 9.99807298e-01 9.99881387e-01 7.90097006e-03\n",
      " 1.42409772e-01 7.69731635e-03 7.20098708e-03 2.61118729e-02\n",
      " 7.90722817e-02 6.46675937e-04 5.19036723e-04 4.35739668e-04\n",
      " 8.28767195e-03 4.35452253e-01 2.02891275e-01 3.65137355e-04\n",
      " 1.15309271e-03 7.50742061e-03 1.14764839e-01 3.90592694e-01\n",
      " 3.39525878e-01 3.13459665e-01 8.31788003e-01 8.21681261e-01\n",
      " 9.54546392e-01 3.86610776e-01 9.68469739e-01 6.02655858e-03\n",
      " 4.92638908e-03 1.48821324e-02 1.48698211e-01 4.77554947e-02\n",
      " 8.28988791e-01 7.95879751e-05 4.70970292e-04 3.32345767e-03\n",
      " 9.99917626e-01 9.99758661e-01 9.99995351e-01 9.99995708e-01\n",
      " 9.80534375e-01 8.12926471e-01 9.56286490e-01 9.99989390e-01\n",
      " 9.99349296e-01 9.97347355e-01 7.49350309e-01 6.75798595e-01\n",
      " 9.04456437e-01 9.96516705e-01 9.97293055e-01 6.44326031e-01\n",
      " 3.63562733e-01 2.06422165e-01 9.99920130e-01 9.88569796e-01\n",
      " 9.99873400e-01 9.99342144e-01 9.99878526e-01 9.89502788e-01\n",
      " 9.06542540e-01 9.99986410e-01 9.95156705e-01 9.36987996e-01\n",
      " 1.47695467e-02 9.41822946e-01 9.95756090e-01 9.71077323e-01\n",
      " 5.29958010e-01 1.00000000e+00 9.99615192e-01 9.99984145e-01\n",
      " 4.77151781e-01 6.88137054e-01 9.99998569e-01 9.97406304e-01\n",
      " 3.56584817e-01 9.70298827e-01 7.84622580e-02 9.92914915e-01\n",
      " 8.49906623e-01 9.82748449e-01 9.97101367e-01 4.73005325e-01\n",
      " 9.10681020e-03 9.55568910e-01 9.89173770e-01 2.50689894e-01\n",
      " 9.99941826e-01 9.18777168e-01 5.04438989e-02 5.50037064e-02\n",
      " 9.94112194e-01 9.90180731e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 56 [0/107 (0%)]\tTrain Loss: 0.002748\n",
      "Train Epoch: 56 [4/107 (4%)]\tTrain Loss: 0.003427\n",
      "Train Epoch: 56 [8/107 (7%)]\tTrain Loss: 0.000976\n",
      "Train Epoch: 56 [12/107 (11%)]\tTrain Loss: 0.008345\n",
      "Train Epoch: 56 [16/107 (15%)]\tTrain Loss: 0.001287\n",
      "Train Epoch: 56 [20/107 (19%)]\tTrain Loss: 0.001296\n",
      "Train Epoch: 56 [24/107 (22%)]\tTrain Loss: 0.001848\n",
      "Train Epoch: 56 [28/107 (26%)]\tTrain Loss: 0.004499\n",
      "Train Epoch: 56 [32/107 (30%)]\tTrain Loss: 0.002614\n",
      "Train Epoch: 56 [36/107 (34%)]\tTrain Loss: 0.001392\n",
      "Train Epoch: 56 [40/107 (37%)]\tTrain Loss: 0.009984\n",
      "Train Epoch: 56 [44/107 (41%)]\tTrain Loss: 0.002364\n",
      "Train Epoch: 56 [48/107 (45%)]\tTrain Loss: 0.002274\n",
      "Train Epoch: 56 [52/107 (49%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 56 [56/107 (52%)]\tTrain Loss: 0.002478\n",
      "Train Epoch: 56 [60/107 (56%)]\tTrain Loss: 0.000116\n",
      "Train Epoch: 56 [64/107 (60%)]\tTrain Loss: 0.000257\n",
      "Train Epoch: 56 [68/107 (64%)]\tTrain Loss: 0.003842\n",
      "Train Epoch: 56 [72/107 (67%)]\tTrain Loss: 0.004170\n",
      "Train Epoch: 56 [76/107 (71%)]\tTrain Loss: 0.000854\n",
      "Train Epoch: 56 [80/107 (75%)]\tTrain Loss: 0.000282\n",
      "Train Epoch: 56 [84/107 (79%)]\tTrain Loss: 0.000261\n",
      "Train Epoch: 56 [88/107 (82%)]\tTrain Loss: 0.000462\n",
      "Train Epoch: 56 [92/107 (86%)]\tTrain Loss: 0.015244\n",
      "Train Epoch: 56 [96/107 (90%)]\tTrain Loss: 0.000505\n",
      "Train Epoch: 56 [100/107 (93%)]\tTrain Loss: 0.000152\n",
      "Train Epoch: 56 [104/107 (97%)]\tTrain Loss: 0.046313\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.46690722e-04 3.31903808e-03 3.94866831e-04 8.38737236e-04\n",
      " 2.73249279e-05 2.38990731e-04 5.98473882e-04 4.50151303e-04\n",
      " 1.10534870e-03 7.65308097e-04 3.00227548e-03 3.09554489e-05\n",
      " 2.56078131e-02 2.03252330e-05 1.20411860e-03 6.02453838e-08\n",
      " 2.37350473e-09 1.32687812e-04 7.12003617e-04 3.86300357e-03\n",
      " 5.16532268e-03 2.27574892e-02 6.34694517e-01 9.99526381e-01\n",
      " 2.88854372e-02 6.45969808e-01 9.85667288e-01 1.60744185e-05\n",
      " 4.40806471e-05 1.48991976e-05 1.14692135e-07 4.68709050e-06\n",
      " 2.67325388e-03 2.20898229e-07 7.15180519e-08 4.58945371e-09\n",
      " 3.68924816e-06 2.36329972e-03 4.24803817e-04 5.22988941e-08\n",
      " 2.23317812e-07 5.94440451e-07 4.24311816e-04 8.56964325e-04\n",
      " 1.28425763e-03 1.22698357e-05 2.80608167e-03 2.71761157e-02\n",
      " 4.74654287e-01 5.38881123e-02 8.27024162e-01 3.60416811e-06\n",
      " 9.73975602e-08 2.62839035e-06 1.27161641e-07 4.48746277e-06\n",
      " 3.89762700e-01 3.31548289e-10 2.87335261e-05 4.61174864e-07\n",
      " 9.93940592e-01 9.91763115e-01 9.99047458e-01 9.97422218e-01\n",
      " 7.59813666e-01 4.31347966e-01 4.00797904e-01 9.99956489e-01\n",
      " 9.99119580e-01 6.75863028e-01 4.14374694e-02 2.15713517e-03\n",
      " 3.10491276e-04 6.48227036e-02 7.26809576e-02 2.21177144e-03\n",
      " 3.64021391e-01 1.72420293e-01 9.96330559e-01 1.29776403e-01\n",
      " 7.93519735e-01 9.13590908e-01 9.99423862e-01 4.16855276e-01\n",
      " 3.32927033e-02 9.71571863e-01 6.94448769e-01 5.28172374e-01\n",
      " 4.30594991e-05 1.84315994e-01 5.46198487e-01 7.67134428e-02\n",
      " 1.45452041e-02 9.99971628e-01 7.58888841e-01 9.84471619e-01\n",
      " 1.30105093e-02 8.22934264e-04 2.38527954e-01 5.93393266e-01\n",
      " 2.26937947e-04 8.24663322e-03 2.42509428e-04 1.42694404e-02\n",
      " 1.49295127e-04 3.12928855e-03 2.57468253e-01 1.61452626e-03\n",
      " 5.92599157e-04 4.76289104e-04 1.30312387e-02 1.39797349e-02\n",
      " 9.44685280e-01 1.21195046e-02 2.08922022e-04 6.38920392e-05\n",
      " 6.99985981e-01 3.41526985e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 57 [0/107 (0%)]\tTrain Loss: 0.026550\n",
      "Train Epoch: 57 [4/107 (4%)]\tTrain Loss: 0.000472\n",
      "Train Epoch: 57 [8/107 (7%)]\tTrain Loss: 0.009768\n",
      "Train Epoch: 57 [12/107 (11%)]\tTrain Loss: 0.000568\n",
      "Train Epoch: 57 [16/107 (15%)]\tTrain Loss: 0.005295\n",
      "Train Epoch: 57 [20/107 (19%)]\tTrain Loss: 0.305327\n",
      "Train Epoch: 57 [24/107 (22%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 57 [28/107 (26%)]\tTrain Loss: 0.000245\n",
      "Train Epoch: 57 [32/107 (30%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 57 [36/107 (34%)]\tTrain Loss: 0.001901\n",
      "Train Epoch: 57 [40/107 (37%)]\tTrain Loss: 0.083425\n",
      "Train Epoch: 57 [44/107 (41%)]\tTrain Loss: 0.000379\n",
      "Train Epoch: 57 [48/107 (45%)]\tTrain Loss: 0.001535\n",
      "Train Epoch: 57 [52/107 (49%)]\tTrain Loss: 0.000317\n",
      "Train Epoch: 57 [56/107 (52%)]\tTrain Loss: 0.000346\n",
      "Train Epoch: 57 [60/107 (56%)]\tTrain Loss: 0.007364\n",
      "Train Epoch: 57 [64/107 (60%)]\tTrain Loss: 0.000498\n",
      "Train Epoch: 57 [68/107 (64%)]\tTrain Loss: 0.003044\n",
      "Train Epoch: 57 [72/107 (67%)]\tTrain Loss: 0.002555\n",
      "Train Epoch: 57 [76/107 (71%)]\tTrain Loss: 0.001175\n",
      "Train Epoch: 57 [80/107 (75%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 57 [84/107 (79%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 57 [88/107 (82%)]\tTrain Loss: 0.009748\n",
      "Train Epoch: 57 [92/107 (86%)]\tTrain Loss: 0.001951\n",
      "Train Epoch: 57 [96/107 (90%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 57 [100/107 (93%)]\tTrain Loss: 0.002440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [104/107 (97%)]\tTrain Loss: 0.002039\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.26128197e-02 2.14227870e-01 9.13451705e-03 1.94171835e-02\n",
      " 4.96947905e-03 1.25750457e-03 1.78988911e-02 1.20033072e-02\n",
      " 4.03796416e-03 6.36320710e-02 7.05148280e-01 1.36246602e-03\n",
      " 8.16440105e-01 8.02878814e-04 4.74279793e-03 1.04169585e-05\n",
      " 2.52309360e-06 2.35297848e-02 1.22171408e-02 4.40474078e-02\n",
      " 7.02616051e-02 4.08780903e-01 9.99951601e-01 9.99867916e-01\n",
      " 4.75246042e-01 9.99903679e-01 9.99690890e-01 1.49917603e-02\n",
      " 1.90887377e-02 7.87208555e-04 5.64826420e-04 1.57959037e-03\n",
      " 1.91280991e-01 3.38126338e-05 1.25181441e-05 2.50866360e-05\n",
      " 4.75566689e-04 1.94407701e-01 1.23023041e-01 5.42048074e-05\n",
      " 8.46696639e-05 5.88069903e-04 1.48575222e-02 1.52614757e-01\n",
      " 4.20761347e-01 3.33790854e-02 5.65179884e-01 7.26284564e-01\n",
      " 9.49217260e-01 1.20924629e-01 9.55937207e-01 5.89803531e-05\n",
      " 1.48508712e-04 4.15032293e-04 3.65130999e-03 3.02602234e-03\n",
      " 9.07591403e-01 1.48692129e-06 4.71042760e-04 4.35246760e-03\n",
      " 9.99972582e-01 9.99826849e-01 9.99993801e-01 9.99984264e-01\n",
      " 9.97686744e-01 9.45729673e-01 9.42955673e-01 9.99999881e-01\n",
      " 9.99893188e-01 9.87275124e-01 7.61816859e-01 2.31982633e-01\n",
      " 1.62458792e-01 8.08357716e-01 9.83733594e-01 6.98086798e-01\n",
      " 9.84525263e-01 9.75708604e-01 9.99988437e-01 9.90121901e-01\n",
      " 9.99549925e-01 9.99522209e-01 9.99991298e-01 9.97776926e-01\n",
      " 9.59329367e-01 9.99726474e-01 9.99565780e-01 9.97819781e-01\n",
      " 2.04575993e-03 9.96328294e-01 9.61054146e-01 7.78101921e-01\n",
      " 6.95895731e-01 9.99999762e-01 9.99068797e-01 9.99706089e-01\n",
      " 1.67597562e-01 1.29847184e-01 9.98239756e-01 9.91425037e-01\n",
      " 3.67128197e-03 8.41818273e-01 1.37332100e-02 9.05074298e-01\n",
      " 2.68016439e-02 9.35741901e-01 9.70499992e-01 2.78194472e-02\n",
      " 9.31850751e-04 4.61987883e-01 4.96872544e-01 7.34989643e-02\n",
      " 9.97353673e-01 3.78900439e-01 4.47611250e-02 2.20804103e-02\n",
      " 9.95048583e-01 9.77247000e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 58 [0/107 (0%)]\tTrain Loss: 0.005205\n",
      "Train Epoch: 58 [4/107 (4%)]\tTrain Loss: 0.001842\n",
      "Train Epoch: 58 [8/107 (7%)]\tTrain Loss: 0.001069\n",
      "Train Epoch: 58 [12/107 (11%)]\tTrain Loss: 0.000607\n",
      "Train Epoch: 58 [16/107 (15%)]\tTrain Loss: 0.000568\n",
      "Train Epoch: 58 [20/107 (19%)]\tTrain Loss: 0.000943\n",
      "Train Epoch: 58 [24/107 (22%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 58 [28/107 (26%)]\tTrain Loss: 0.000480\n",
      "Train Epoch: 58 [32/107 (30%)]\tTrain Loss: 0.000272\n",
      "Train Epoch: 58 [36/107 (34%)]\tTrain Loss: 0.000510\n",
      "Train Epoch: 58 [40/107 (37%)]\tTrain Loss: 0.000623\n",
      "Train Epoch: 58 [44/107 (41%)]\tTrain Loss: 0.001606\n",
      "Train Epoch: 58 [48/107 (45%)]\tTrain Loss: 0.002536\n",
      "Train Epoch: 58 [52/107 (49%)]\tTrain Loss: 0.003417\n",
      "Train Epoch: 58 [56/107 (52%)]\tTrain Loss: 0.021477\n",
      "Train Epoch: 58 [60/107 (56%)]\tTrain Loss: 0.158467\n",
      "Train Epoch: 58 [64/107 (60%)]\tTrain Loss: 0.007378\n",
      "Train Epoch: 58 [68/107 (64%)]\tTrain Loss: 0.031906\n",
      "Train Epoch: 58 [72/107 (67%)]\tTrain Loss: 0.000545\n",
      "Train Epoch: 58 [76/107 (71%)]\tTrain Loss: 0.000265\n",
      "Train Epoch: 58 [80/107 (75%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 58 [84/107 (79%)]\tTrain Loss: 0.009451\n",
      "Train Epoch: 58 [88/107 (82%)]\tTrain Loss: 0.000573\n",
      "Train Epoch: 58 [92/107 (86%)]\tTrain Loss: 0.046145\n",
      "Train Epoch: 58 [96/107 (90%)]\tTrain Loss: 0.001034\n",
      "Train Epoch: 58 [100/107 (93%)]\tTrain Loss: 0.001691\n",
      "Train Epoch: 58 [104/107 (97%)]\tTrain Loss: 0.002810\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02102388 0.70531058 0.01375406 0.33549467 0.16948642 0.00675914\n",
      " 0.09495553 0.25918213 0.00626274 0.04696215 0.82709575 0.00127242\n",
      " 0.38039458 0.08407371 0.26420695 0.01113339 0.01231751 0.50874317\n",
      " 0.01497915 0.21292977 0.35596451 0.25860834 0.99992132 0.99997699\n",
      " 0.41103274 0.99989736 0.99999285 0.14501195 0.15837029 0.016048\n",
      " 0.43014014 0.01738093 0.40038106 0.00332885 0.00191924 0.01457815\n",
      " 0.06317555 0.74098343 0.92416108 0.12574281 0.05937256 0.62456989\n",
      " 0.10425108 0.63019454 0.73605025 0.08463042 0.47253081 0.49515215\n",
      " 0.91280484 0.24562697 0.92282617 0.00153289 0.04722748 0.01623463\n",
      " 0.43811837 0.07971695 0.96007532 0.00210227 0.00135345 0.61277413\n",
      " 0.9993332  0.99922264 0.99998832 0.99992943 0.99999368 0.99693954\n",
      " 0.99710733 1.         0.99998474 0.9961338  0.92234159 0.43675941\n",
      " 0.98626745 0.99874926 0.99992836 0.91565186 0.99766785 0.96830195\n",
      " 0.99998796 0.99715376 0.99999523 0.99997914 0.99999845 0.99782479\n",
      " 0.98891175 0.99996936 0.99917883 0.9981851  0.37745494 0.99980968\n",
      " 0.99984324 0.96924341 0.80281353 1.         0.99996901 0.99999976\n",
      " 0.30895352 0.77662885 0.99983919 0.99969864 0.15888853 0.96117336\n",
      " 0.14523213 0.68569797 0.40303928 0.91410661 0.95017171 0.67722696\n",
      " 0.00839246 0.97946769 0.9847489  0.85887754 0.99998784 0.45476648\n",
      " 0.09161428 0.22184886 0.99841344 0.99750632]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 59 [0/107 (0%)]\tTrain Loss: 0.001313\n",
      "Train Epoch: 59 [4/107 (4%)]\tTrain Loss: 0.038755\n",
      "Train Epoch: 59 [8/107 (7%)]\tTrain Loss: 0.000955\n",
      "Train Epoch: 59 [12/107 (11%)]\tTrain Loss: 0.000156\n",
      "Train Epoch: 59 [16/107 (15%)]\tTrain Loss: 0.003517\n",
      "Train Epoch: 59 [20/107 (19%)]\tTrain Loss: 0.061642\n",
      "Train Epoch: 59 [24/107 (22%)]\tTrain Loss: 0.001624\n",
      "Train Epoch: 59 [28/107 (26%)]\tTrain Loss: 0.001611\n",
      "Train Epoch: 59 [32/107 (30%)]\tTrain Loss: 0.000568\n",
      "Train Epoch: 59 [36/107 (34%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 59 [40/107 (37%)]\tTrain Loss: 0.001288\n",
      "Train Epoch: 59 [44/107 (41%)]\tTrain Loss: 0.000639\n",
      "Train Epoch: 59 [48/107 (45%)]\tTrain Loss: 0.000604\n",
      "Train Epoch: 59 [52/107 (49%)]\tTrain Loss: 0.000705\n",
      "Train Epoch: 59 [56/107 (52%)]\tTrain Loss: 0.001349\n",
      "Train Epoch: 59 [60/107 (56%)]\tTrain Loss: 0.000384\n",
      "Train Epoch: 59 [64/107 (60%)]\tTrain Loss: 0.000168\n",
      "Train Epoch: 59 [68/107 (64%)]\tTrain Loss: 0.000155\n",
      "Train Epoch: 59 [72/107 (67%)]\tTrain Loss: 0.000481\n",
      "Train Epoch: 59 [76/107 (71%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 59 [80/107 (75%)]\tTrain Loss: 0.001191\n",
      "Train Epoch: 59 [84/107 (79%)]\tTrain Loss: 0.007335\n",
      "Train Epoch: 59 [88/107 (82%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 59 [92/107 (86%)]\tTrain Loss: 0.014027\n",
      "Train Epoch: 59 [96/107 (90%)]\tTrain Loss: 0.000413\n",
      "Train Epoch: 59 [100/107 (93%)]\tTrain Loss: 0.001579\n",
      "Train Epoch: 59 [104/107 (97%)]\tTrain Loss: 0.009309\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.39519514e-03 8.22970331e-01 2.66711526e-02 5.57902083e-02\n",
      " 8.14189576e-03 5.11942315e-04 2.92140365e-01 2.45538335e-02\n",
      " 1.04283413e-03 8.60182010e-03 1.21078510e-02 5.05811004e-05\n",
      " 2.57780720e-02 1.07177151e-02 3.28206532e-02 8.47843548e-05\n",
      " 7.32303524e-05 6.81659520e-01 1.84948780e-02 1.11687288e-01\n",
      " 3.09723645e-01 1.26397938e-01 9.99729574e-01 9.99989867e-01\n",
      " 4.27616715e-01 9.99697566e-01 9.99989152e-01 2.74790108e-01\n",
      " 1.75424412e-01 9.42793617e-04 5.67305624e-01 3.16754077e-03\n",
      " 3.35965037e-01 1.35696218e-05 5.89652336e-06 3.30600888e-04\n",
      " 2.26174161e-04 8.42356503e-01 7.50189185e-01 6.25271408e-04\n",
      " 5.73954312e-04 1.12328464e-02 1.62404642e-01 1.17726147e-01\n",
      " 5.40071189e-01 6.26090262e-03 8.08669031e-02 1.63886383e-01\n",
      " 7.26601005e-01 1.73993990e-01 8.60255897e-01 5.06155993e-05\n",
      " 3.35829146e-03 3.20230203e-04 5.10382988e-02 9.03167203e-03\n",
      " 9.77158964e-01 2.39829733e-05 2.86726485e-04 4.28885184e-02\n",
      " 9.98618841e-01 9.97030258e-01 9.99987364e-01 9.99300241e-01\n",
      " 9.99991894e-01 9.65099692e-01 9.91833568e-01 9.99999762e-01\n",
      " 9.99965310e-01 9.99782264e-01 6.51450098e-01 1.85409725e-01\n",
      " 9.54929411e-01 9.99738872e-01 9.99950767e-01 8.56152356e-01\n",
      " 9.99444306e-01 9.92287874e-01 9.99986172e-01 9.55908895e-01\n",
      " 9.99819458e-01 9.99731481e-01 9.99965191e-01 9.98844624e-01\n",
      " 9.52989280e-01 9.99994278e-01 9.99082685e-01 9.97095823e-01\n",
      " 6.16126418e-01 9.66068208e-01 9.99847531e-01 7.84763753e-01\n",
      " 5.32480061e-01 1.00000000e+00 9.99835134e-01 9.99999881e-01\n",
      " 2.09061071e-01 3.30376714e-01 9.98878658e-01 9.92022514e-01\n",
      " 1.03489626e-02 9.76879060e-01 5.61915599e-02 1.96208164e-01\n",
      " 7.13207796e-02 6.27748191e-01 9.85999882e-01 1.54694170e-01\n",
      " 1.77154364e-03 9.40363884e-01 9.14312243e-01 9.01765347e-01\n",
      " 9.99970794e-01 3.43459010e-01 7.48400437e-03 6.45273477e-02\n",
      " 9.99998569e-01 9.99745309e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [0/107 (0%)]\tTrain Loss: 0.002111\n",
      "Train Epoch: 60 [4/107 (4%)]\tTrain Loss: 0.000145\n",
      "Train Epoch: 60 [8/107 (7%)]\tTrain Loss: 0.002158\n",
      "Train Epoch: 60 [12/107 (11%)]\tTrain Loss: 0.166033\n",
      "Train Epoch: 60 [16/107 (15%)]\tTrain Loss: 0.022700\n",
      "Train Epoch: 60 [20/107 (19%)]\tTrain Loss: 0.007727\n",
      "Train Epoch: 60 [24/107 (22%)]\tTrain Loss: 0.001773\n",
      "Train Epoch: 60 [28/107 (26%)]\tTrain Loss: 0.000399\n",
      "Train Epoch: 60 [32/107 (30%)]\tTrain Loss: 0.003711\n",
      "Train Epoch: 60 [36/107 (34%)]\tTrain Loss: 0.000167\n",
      "Train Epoch: 60 [40/107 (37%)]\tTrain Loss: 0.000135\n",
      "Train Epoch: 60 [44/107 (41%)]\tTrain Loss: 0.003444\n",
      "Train Epoch: 60 [48/107 (45%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 60 [52/107 (49%)]\tTrain Loss: 0.001772\n",
      "Train Epoch: 60 [56/107 (52%)]\tTrain Loss: 0.001245\n",
      "Train Epoch: 60 [60/107 (56%)]\tTrain Loss: 0.000691\n",
      "Train Epoch: 60 [64/107 (60%)]\tTrain Loss: 0.001401\n",
      "Train Epoch: 60 [68/107 (64%)]\tTrain Loss: 0.006624\n",
      "Train Epoch: 60 [72/107 (67%)]\tTrain Loss: 0.006125\n",
      "Train Epoch: 60 [76/107 (71%)]\tTrain Loss: 0.000776\n",
      "Train Epoch: 60 [80/107 (75%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 60 [84/107 (79%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 60 [88/107 (82%)]\tTrain Loss: 0.010058\n",
      "Train Epoch: 60 [92/107 (86%)]\tTrain Loss: 0.054275\n",
      "Train Epoch: 60 [96/107 (90%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 60 [100/107 (93%)]\tTrain Loss: 0.001136\n",
      "Train Epoch: 60 [104/107 (97%)]\tTrain Loss: 0.000683\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.30117848e-03 7.57950068e-01 1.75053347e-03 1.19945727e-01\n",
      " 1.78850518e-04 8.54569080e-04 7.09384382e-02 6.21713027e-02\n",
      " 6.62914477e-03 1.39893852e-02 2.52944112e-01 3.65184387e-05\n",
      " 2.43161887e-01 3.63476749e-04 2.05728579e-02 4.67881449e-07\n",
      " 1.13345811e-06 7.54869640e-01 7.27180779e-01 3.09138626e-01\n",
      " 2.56412506e-01 8.97391558e-01 9.99791443e-01 9.99975562e-01\n",
      " 7.13796675e-01 9.99252737e-01 9.99802172e-01 1.56834260e-01\n",
      " 5.97128510e-01 9.11948271e-03 6.42452016e-02 1.49033383e-01\n",
      " 8.31969678e-01 8.74635930e-07 6.63534138e-06 2.57521606e-06\n",
      " 4.81322117e-04 9.87056911e-01 9.94299278e-02 1.73043713e-06\n",
      " 9.44229839e-07 4.50060770e-06 9.35630322e-01 6.86681032e-01\n",
      " 9.62863564e-01 3.26244184e-03 2.32937559e-01 1.35485664e-01\n",
      " 7.82725573e-01 1.41723126e-01 9.58652377e-01 1.74125598e-04\n",
      " 1.92091902e-04 1.05696316e-04 1.80529505e-02 2.89197220e-03\n",
      " 9.78092551e-01 9.19787446e-09 5.19265560e-03 1.14726666e-02\n",
      " 9.99440134e-01 9.97887194e-01 9.99892235e-01 9.99428451e-01\n",
      " 9.99963760e-01 9.86747146e-01 9.81187761e-01 9.99997139e-01\n",
      " 9.99428689e-01 9.99091983e-01 7.58655608e-01 4.47147638e-01\n",
      " 8.76336157e-01 9.66367722e-01 9.97840762e-01 9.94766831e-01\n",
      " 9.96287584e-01 9.71205533e-01 9.99974608e-01 9.95977461e-01\n",
      " 9.97334123e-01 9.99344289e-01 9.99579608e-01 9.96804953e-01\n",
      " 9.58943665e-01 9.99880552e-01 9.99035597e-01 9.98727977e-01\n",
      " 4.53859270e-01 9.72233295e-01 9.77120996e-01 8.89051139e-01\n",
      " 8.46933365e-01 9.99993682e-01 9.96367812e-01 9.99799311e-01\n",
      " 7.00827658e-01 4.72874850e-01 9.45502818e-01 9.89392638e-01\n",
      " 1.39620462e-02 9.92350399e-01 1.70495272e-01 1.11683838e-01\n",
      " 2.41579581e-02 9.06466842e-01 9.86566246e-01 3.04878771e-01\n",
      " 8.14718939e-03 1.65809825e-01 8.71149600e-01 6.74387753e-01\n",
      " 9.90818441e-01 6.20773435e-01 1.36956871e-02 5.17736301e-02\n",
      " 9.99919295e-01 9.99967694e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 52 FN= 13 FP= 8\n",
      "TP+FP 53\n",
      "precision 0.8490566037735849\n",
      "recall 0.7758620689655172\n",
      "F1 0.8108108108108107\n",
      "acc 0.8220338983050848\n",
      "AUCp 0.821264367816092\n",
      "AUC 0.8698275862068965\n",
      "\n",
      " The epoch is 60, average recall: 0.7759, average precision: 0.8491,average F1: 0.8108, average accuracy: 0.8220, average AUC: 0.8698\n",
      "Train Epoch: 61 [0/107 (0%)]\tTrain Loss: 0.004771\n",
      "Train Epoch: 61 [4/107 (4%)]\tTrain Loss: 0.000429\n",
      "Train Epoch: 61 [8/107 (7%)]\tTrain Loss: 0.000296\n",
      "Train Epoch: 61 [12/107 (11%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 61 [16/107 (15%)]\tTrain Loss: 0.000511\n",
      "Train Epoch: 61 [20/107 (19%)]\tTrain Loss: 0.060837\n",
      "Train Epoch: 61 [24/107 (22%)]\tTrain Loss: 0.000171\n",
      "Train Epoch: 61 [28/107 (26%)]\tTrain Loss: 0.026535\n",
      "Train Epoch: 61 [32/107 (30%)]\tTrain Loss: 0.012772\n",
      "Train Epoch: 61 [36/107 (34%)]\tTrain Loss: 0.000526\n",
      "Train Epoch: 61 [40/107 (37%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 61 [44/107 (41%)]\tTrain Loss: 0.001375\n",
      "Train Epoch: 61 [48/107 (45%)]\tTrain Loss: 0.000540\n",
      "Train Epoch: 61 [52/107 (49%)]\tTrain Loss: 0.000766\n",
      "Train Epoch: 61 [56/107 (52%)]\tTrain Loss: 0.005525\n",
      "Train Epoch: 61 [60/107 (56%)]\tTrain Loss: 0.001113\n",
      "Train Epoch: 61 [64/107 (60%)]\tTrain Loss: 0.092413\n",
      "Train Epoch: 61 [68/107 (64%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 61 [72/107 (67%)]\tTrain Loss: 0.000584\n",
      "Train Epoch: 61 [76/107 (71%)]\tTrain Loss: 0.002053\n",
      "Train Epoch: 61 [80/107 (75%)]\tTrain Loss: 0.023840\n",
      "Train Epoch: 61 [84/107 (79%)]\tTrain Loss: 0.001491\n",
      "Train Epoch: 61 [88/107 (82%)]\tTrain Loss: 0.001539\n",
      "Train Epoch: 61 [92/107 (86%)]\tTrain Loss: 0.068238\n",
      "Train Epoch: 61 [96/107 (90%)]\tTrain Loss: 0.004955\n",
      "Train Epoch: 61 [100/107 (93%)]\tTrain Loss: 0.000991\n",
      "Train Epoch: 61 [104/107 (97%)]\tTrain Loss: 0.000047\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.03827231e-01 9.50768888e-01 2.17675567e-02 4.28075045e-02\n",
      " 1.26556335e-02 1.26593411e-02 2.00129971e-01 3.18876579e-02\n",
      " 7.74731999e-03 1.49295963e-02 1.76540822e-01 9.78183583e-04\n",
      " 2.43775889e-01 1.79131404e-02 9.40321758e-03 1.71702786e-03\n",
      " 6.05582260e-04 7.31770813e-01 1.12280613e-02 6.96068779e-02\n",
      " 4.38494757e-02 4.19441909e-01 9.88264322e-01 9.99963880e-01\n",
      " 2.74651974e-01 9.98831809e-01 9.99926686e-01 2.13520572e-01\n",
      " 1.34488955e-01 1.19736232e-03 4.16478246e-01 1.64476901e-01\n",
      " 7.55370319e-01 5.59400069e-04 2.49860168e-04 2.19062297e-03\n",
      " 1.41079910e-03 9.13227975e-01 9.16991174e-01 1.08754430e-02\n",
      " 2.83406465e-03 1.25755981e-01 4.76626396e-01 1.32041723e-01\n",
      " 5.83519280e-01 4.86165844e-02 9.28350747e-01 9.57264900e-01\n",
      " 9.85181510e-01 8.12328905e-02 9.95838404e-01 3.50778355e-05\n",
      " 2.87263114e-02 6.12927193e-04 2.95903534e-01 1.78249255e-02\n",
      " 9.40718174e-01 1.32474393e-04 1.95477484e-03 8.62297714e-02\n",
      " 9.99523878e-01 9.98990476e-01 9.99984503e-01 9.99964356e-01\n",
      " 9.99943256e-01 9.74551857e-01 8.81530404e-01 9.99999762e-01\n",
      " 9.99840975e-01 9.99702036e-01 9.48789239e-01 8.67096603e-01\n",
      " 8.67278755e-01 9.94783461e-01 9.99468029e-01 9.14327860e-01\n",
      " 9.97487545e-01 9.79407907e-01 9.99969959e-01 9.94339526e-01\n",
      " 9.99620795e-01 9.99920011e-01 9.99946713e-01 9.99587953e-01\n",
      " 9.53584433e-01 9.99997854e-01 9.99280155e-01 9.98493791e-01\n",
      " 3.28923129e-02 9.98257577e-01 9.74324346e-01 8.74444127e-01\n",
      " 7.45445788e-01 9.99998927e-01 9.99091387e-01 9.99853373e-01\n",
      " 1.82162747e-01 6.42774582e-01 9.13418472e-01 9.99389052e-01\n",
      " 2.27328867e-01 9.92095172e-01 5.50094604e-01 9.39124301e-02\n",
      " 2.84115195e-01 9.74942267e-01 9.96767759e-01 6.60510540e-01\n",
      " 3.06686498e-02 6.26538098e-01 9.36583161e-01 9.55284476e-01\n",
      " 9.99239326e-01 3.88407737e-01 2.40695924e-02 1.08321905e-02\n",
      " 9.99991536e-01 9.99990940e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62 [0/107 (0%)]\tTrain Loss: 0.002204\n",
      "Train Epoch: 62 [4/107 (4%)]\tTrain Loss: 0.003195\n",
      "Train Epoch: 62 [8/107 (7%)]\tTrain Loss: 0.000225\n",
      "Train Epoch: 62 [12/107 (11%)]\tTrain Loss: 0.005966\n",
      "Train Epoch: 62 [16/107 (15%)]\tTrain Loss: 0.015066\n",
      "Train Epoch: 62 [20/107 (19%)]\tTrain Loss: 0.001358\n",
      "Train Epoch: 62 [24/107 (22%)]\tTrain Loss: 0.008999\n",
      "Train Epoch: 62 [28/107 (26%)]\tTrain Loss: 0.000323\n",
      "Train Epoch: 62 [32/107 (30%)]\tTrain Loss: 0.003182\n",
      "Train Epoch: 62 [36/107 (34%)]\tTrain Loss: 0.000416\n",
      "Train Epoch: 62 [40/107 (37%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 62 [44/107 (41%)]\tTrain Loss: 0.001835\n",
      "Train Epoch: 62 [48/107 (45%)]\tTrain Loss: 0.003801\n",
      "Train Epoch: 62 [52/107 (49%)]\tTrain Loss: 0.000366\n",
      "Train Epoch: 62 [56/107 (52%)]\tTrain Loss: 0.011252\n",
      "Train Epoch: 62 [60/107 (56%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 62 [64/107 (60%)]\tTrain Loss: 0.068225\n",
      "Train Epoch: 62 [68/107 (64%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 62 [72/107 (67%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 62 [76/107 (71%)]\tTrain Loss: 0.005969\n",
      "Train Epoch: 62 [80/107 (75%)]\tTrain Loss: 0.003766\n",
      "Train Epoch: 62 [84/107 (79%)]\tTrain Loss: 0.000188\n",
      "Train Epoch: 62 [88/107 (82%)]\tTrain Loss: 0.017186\n",
      "Train Epoch: 62 [92/107 (86%)]\tTrain Loss: 0.012170\n",
      "Train Epoch: 62 [96/107 (90%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 62 [100/107 (93%)]\tTrain Loss: 0.000363\n",
      "Train Epoch: 62 [104/107 (97%)]\tTrain Loss: 0.000181\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.50581433e-04 7.72487581e-01 6.59038022e-04 1.01037184e-02\n",
      " 3.80614474e-05 1.47620915e-04 1.01850852e-02 1.19231651e-02\n",
      " 5.00621856e-04 8.15001404e-05 5.47042251e-01 2.45368688e-06\n",
      " 3.59254956e-01 5.88053190e-05 9.82672325e-04 1.56327542e-06\n",
      " 1.01134596e-07 5.85572660e-01 1.02833025e-02 1.23956770e-01\n",
      " 9.26608369e-02 9.21238780e-01 9.97721612e-01 9.99902129e-01\n",
      " 7.38356769e-01 9.99146342e-01 9.99849081e-01 4.26969910e-03\n",
      " 7.61280861e-03 1.42525346e-03 5.25165489e-03 4.42390554e-02\n",
      " 7.22318530e-01 3.95119628e-07 1.55033348e-07 3.43525016e-06\n",
      " 3.08610106e-05 9.04852092e-01 8.92171264e-01 9.23524276e-05\n",
      " 2.15959262e-05 2.48002750e-03 4.56099361e-01 1.64499894e-01\n",
      " 5.97907364e-01 7.25116441e-03 7.55909741e-01 7.36812294e-01\n",
      " 9.22159255e-01 3.23208421e-02 9.50438380e-01 1.31116417e-06\n",
      " 2.02634052e-04 1.57194136e-05 4.21742313e-02 6.29191520e-04\n",
      " 8.16085160e-01 3.66430619e-08 1.11097521e-04 3.27682309e-03\n",
      " 9.99726713e-01 9.99613345e-01 9.99991894e-01 9.99969244e-01\n",
      " 9.99949813e-01 9.40490246e-01 7.08969116e-01 9.99999523e-01\n",
      " 9.99803245e-01 9.99720633e-01 8.23555410e-01 7.85496235e-01\n",
      " 9.04905438e-01 9.96176004e-01 9.90028083e-01 4.52233225e-01\n",
      " 9.98414278e-01 9.13332283e-01 9.99898911e-01 9.95493889e-01\n",
      " 9.99764621e-01 9.99863625e-01 9.99879003e-01 9.99716341e-01\n",
      " 9.93801653e-01 9.99996185e-01 9.98534203e-01 9.95191693e-01\n",
      " 1.33761857e-03 9.99684811e-01 9.86562431e-01 5.52765667e-01\n",
      " 5.15845120e-01 9.99999166e-01 9.99535322e-01 9.99956608e-01\n",
      " 1.17809005e-01 9.33704853e-01 9.98133719e-01 9.99741495e-01\n",
      " 1.36651054e-01 9.91268158e-01 6.03619874e-01 1.45486191e-01\n",
      " 1.97880752e-02 9.77002740e-01 9.94424462e-01 6.29220068e-01\n",
      " 3.57977785e-02 6.85140967e-01 9.96608615e-01 9.78127003e-01\n",
      " 9.99739707e-01 6.80476606e-01 4.73631825e-03 3.22241499e-03\n",
      " 9.99999046e-01 9.99999046e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 63 [0/107 (0%)]\tTrain Loss: 0.000193\n",
      "Train Epoch: 63 [4/107 (4%)]\tTrain Loss: 0.005456\n",
      "Train Epoch: 63 [8/107 (7%)]\tTrain Loss: 0.000134\n",
      "Train Epoch: 63 [12/107 (11%)]\tTrain Loss: 0.002726\n",
      "Train Epoch: 63 [16/107 (15%)]\tTrain Loss: 0.097742\n",
      "Train Epoch: 63 [20/107 (19%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 63 [24/107 (22%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 63 [28/107 (26%)]\tTrain Loss: 0.000620\n",
      "Train Epoch: 63 [32/107 (30%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 63 [36/107 (34%)]\tTrain Loss: 0.000272\n",
      "Train Epoch: 63 [40/107 (37%)]\tTrain Loss: 0.024325\n",
      "Train Epoch: 63 [44/107 (41%)]\tTrain Loss: 0.000148\n",
      "Train Epoch: 63 [48/107 (45%)]\tTrain Loss: 0.001375\n",
      "Train Epoch: 63 [52/107 (49%)]\tTrain Loss: 0.006094\n",
      "Train Epoch: 63 [56/107 (52%)]\tTrain Loss: 0.000529\n",
      "Train Epoch: 63 [60/107 (56%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 63 [64/107 (60%)]\tTrain Loss: 0.000153\n",
      "Train Epoch: 63 [68/107 (64%)]\tTrain Loss: 0.029698\n",
      "Train Epoch: 63 [72/107 (67%)]\tTrain Loss: 0.000186\n",
      "Train Epoch: 63 [76/107 (71%)]\tTrain Loss: 0.004160\n",
      "Train Epoch: 63 [80/107 (75%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 63 [84/107 (79%)]\tTrain Loss: 0.001872\n",
      "Train Epoch: 63 [88/107 (82%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 63 [92/107 (86%)]\tTrain Loss: 0.002713\n",
      "Train Epoch: 63 [96/107 (90%)]\tTrain Loss: 0.000217\n",
      "Train Epoch: 63 [100/107 (93%)]\tTrain Loss: 0.001184\n",
      "Train Epoch: 63 [104/107 (97%)]\tTrain Loss: 0.000473\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.79177334e-04 8.93075466e-01 7.95235392e-03 1.06821246e-02\n",
      " 3.13858705e-04 1.49544649e-04 3.54847610e-01 1.59268323e-02\n",
      " 2.66084389e-04 1.54597976e-03 6.50286138e-01 6.78633387e-06\n",
      " 4.91427064e-01 1.96507448e-04 5.39376459e-04 9.68813856e-06\n",
      " 4.62895514e-06 6.66316211e-01 5.29781729e-02 2.83385515e-01\n",
      " 2.77052850e-01 8.84670198e-01 9.99645352e-01 9.99867797e-01\n",
      " 8.30973387e-01 9.99595940e-01 9.99408245e-01 1.35892751e-02\n",
      " 1.04107410e-01 4.13402542e-03 6.26830338e-03 2.63890289e-02\n",
      " 5.32842278e-01 3.26070676e-06 2.94250799e-06 1.63010976e-04\n",
      " 2.63778842e-04 9.69011426e-01 8.36293101e-01 6.69367204e-04\n",
      " 1.37895637e-04 4.50452790e-03 5.55457890e-01 5.19682407e-01\n",
      " 8.66397142e-01 2.78942240e-03 5.95838904e-01 3.99994969e-01\n",
      " 7.30680764e-01 1.05962954e-01 7.60158181e-01 4.41789189e-06\n",
      " 2.87198607e-04 9.84855651e-05 2.06548840e-01 2.92000081e-03\n",
      " 7.64491916e-01 1.23023696e-07 1.20930970e-04 2.07060855e-03\n",
      " 9.98724401e-01 9.99325156e-01 9.99948740e-01 9.99709427e-01\n",
      " 9.99949217e-01 9.64155614e-01 7.26494610e-01 9.99995470e-01\n",
      " 9.99409556e-01 9.96079743e-01 5.69710612e-01 3.20236385e-01\n",
      " 6.98975265e-01 9.88818824e-01 9.95019794e-01 8.24607134e-01\n",
      " 9.88705873e-01 8.67589176e-01 9.99973297e-01 9.80094910e-01\n",
      " 9.99269426e-01 9.99308705e-01 9.99627948e-01 9.96815145e-01\n",
      " 9.48283315e-01 9.99933720e-01 9.98746991e-01 9.91301239e-01\n",
      " 1.58158168e-02 9.95464265e-01 9.88820255e-01 4.50732172e-01\n",
      " 5.65102816e-01 9.99999285e-01 9.99628186e-01 9.99976039e-01\n",
      " 2.06651703e-01 9.19542968e-01 9.98390436e-01 9.99375641e-01\n",
      " 9.84820575e-02 9.56677020e-01 6.52292609e-01 9.18822706e-01\n",
      " 1.35049269e-01 9.93086755e-01 9.89251196e-01 7.00992644e-01\n",
      " 9.67154279e-02 9.48897183e-01 9.96343315e-01 9.66363490e-01\n",
      " 9.99627709e-01 9.22730029e-01 3.79086174e-02 3.53803746e-02\n",
      " 9.99906778e-01 9.99881387e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 64 [0/107 (0%)]\tTrain Loss: 0.000124\n",
      "Train Epoch: 64 [4/107 (4%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 64 [8/107 (7%)]\tTrain Loss: 0.008620\n",
      "Train Epoch: 64 [12/107 (11%)]\tTrain Loss: 0.001314\n",
      "Train Epoch: 64 [16/107 (15%)]\tTrain Loss: 0.003447\n",
      "Train Epoch: 64 [20/107 (19%)]\tTrain Loss: 0.000274\n",
      "Train Epoch: 64 [24/107 (22%)]\tTrain Loss: 0.000496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [28/107 (26%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 64 [32/107 (30%)]\tTrain Loss: 0.000699\n",
      "Train Epoch: 64 [36/107 (34%)]\tTrain Loss: 0.002063\n",
      "Train Epoch: 64 [40/107 (37%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 64 [44/107 (41%)]\tTrain Loss: 0.011213\n",
      "Train Epoch: 64 [48/107 (45%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 64 [52/107 (49%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 64 [56/107 (52%)]\tTrain Loss: 0.016225\n",
      "Train Epoch: 64 [60/107 (56%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 64 [64/107 (60%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 64 [68/107 (64%)]\tTrain Loss: 0.000196\n",
      "Train Epoch: 64 [72/107 (67%)]\tTrain Loss: 0.000478\n",
      "Train Epoch: 64 [76/107 (71%)]\tTrain Loss: 0.000164\n",
      "Train Epoch: 64 [80/107 (75%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 64 [84/107 (79%)]\tTrain Loss: 0.000228\n",
      "Train Epoch: 64 [88/107 (82%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 64 [92/107 (86%)]\tTrain Loss: 0.001600\n",
      "Train Epoch: 64 [96/107 (90%)]\tTrain Loss: 0.000144\n",
      "Train Epoch: 64 [100/107 (93%)]\tTrain Loss: 0.003284\n",
      "Train Epoch: 64 [104/107 (97%)]\tTrain Loss: 0.016046\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.69624613e-04 8.66774857e-01 3.28314188e-03 5.67046972e-03\n",
      " 2.84935377e-04 1.00190606e-04 1.71102196e-01 7.88090006e-03\n",
      " 1.34212343e-04 2.44874565e-04 4.28562164e-01 1.19738854e-06\n",
      " 3.22334111e-01 1.91579034e-04 9.23996326e-04 1.02567810e-05\n",
      " 2.00993168e-06 5.60672343e-01 2.00735070e-02 1.64355919e-01\n",
      " 1.87781394e-01 8.37631643e-01 9.99286830e-01 9.99870300e-01\n",
      " 6.01265132e-01 9.99432266e-01 9.99717772e-01 7.53327226e-03\n",
      " 3.26406397e-02 1.58180052e-03 6.24658307e-03 8.82882252e-03\n",
      " 5.51308990e-01 7.21313029e-07 9.69767484e-07 1.74893903e-05\n",
      " 5.53076279e-05 9.71719563e-01 7.18478084e-01 1.53067536e-04\n",
      " 2.79054530e-05 1.74897606e-03 6.45298004e-01 4.53589737e-01\n",
      " 7.85634160e-01 2.54402519e-03 6.13789320e-01 4.49622810e-01\n",
      " 8.52340937e-01 6.43422380e-02 9.17688727e-01 4.66684105e-06\n",
      " 3.04045185e-04 1.86986406e-04 4.39232700e-02 3.16008576e-03\n",
      " 8.65889430e-01 5.41806635e-08 3.24766079e-05 3.11084837e-03\n",
      " 9.98908281e-01 9.99142408e-01 9.99974132e-01 9.99895692e-01\n",
      " 9.99988556e-01 9.86406267e-01 8.81470263e-01 9.99994993e-01\n",
      " 9.99901414e-01 9.98259485e-01 4.71380442e-01 1.70533568e-01\n",
      " 8.48891795e-01 9.89936352e-01 9.97350335e-01 8.36989939e-01\n",
      " 9.90975440e-01 8.93992901e-01 9.99981046e-01 9.89696860e-01\n",
      " 9.99787390e-01 9.99918222e-01 9.99866366e-01 9.97173190e-01\n",
      " 9.08670604e-01 9.99935746e-01 9.98071909e-01 9.92939115e-01\n",
      " 8.70708376e-03 9.96404409e-01 9.95183408e-01 7.18028188e-01\n",
      " 5.34798861e-01 9.99999881e-01 9.99921679e-01 9.99992847e-01\n",
      " 1.73506632e-01 7.85386741e-01 9.92059708e-01 9.99429882e-01\n",
      " 6.00815229e-02 9.70425248e-01 3.45180929e-01 9.38178957e-01\n",
      " 8.31623450e-02 9.96889770e-01 9.92700279e-01 4.41697657e-01\n",
      " 1.23298848e-02 9.08594787e-01 9.86375511e-01 9.06965554e-01\n",
      " 9.99936342e-01 7.82495379e-01 9.95187648e-03 9.61951539e-03\n",
      " 9.99750435e-01 9.99833226e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 65 [0/107 (0%)]\tTrain Loss: 0.000181\n",
      "Train Epoch: 65 [4/107 (4%)]\tTrain Loss: 0.116218\n",
      "Train Epoch: 65 [8/107 (7%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 65 [12/107 (11%)]\tTrain Loss: 0.379281\n",
      "Train Epoch: 65 [16/107 (15%)]\tTrain Loss: 0.005400\n",
      "Train Epoch: 65 [20/107 (19%)]\tTrain Loss: 0.000684\n",
      "Train Epoch: 65 [24/107 (22%)]\tTrain Loss: 0.000243\n",
      "Train Epoch: 65 [28/107 (26%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 65 [32/107 (30%)]\tTrain Loss: 0.000592\n",
      "Train Epoch: 65 [36/107 (34%)]\tTrain Loss: 0.031479\n",
      "Train Epoch: 65 [40/107 (37%)]\tTrain Loss: 0.001171\n",
      "Train Epoch: 65 [44/107 (41%)]\tTrain Loss: 0.002767\n",
      "Train Epoch: 65 [48/107 (45%)]\tTrain Loss: 0.000776\n",
      "Train Epoch: 65 [52/107 (49%)]\tTrain Loss: 0.001523\n",
      "Train Epoch: 65 [56/107 (52%)]\tTrain Loss: 0.001310\n",
      "Train Epoch: 65 [60/107 (56%)]\tTrain Loss: 0.000982\n",
      "Train Epoch: 65 [64/107 (60%)]\tTrain Loss: 0.046672\n",
      "Train Epoch: 65 [68/107 (64%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 65 [72/107 (67%)]\tTrain Loss: 0.000818\n",
      "Train Epoch: 65 [76/107 (71%)]\tTrain Loss: 0.004853\n",
      "Train Epoch: 65 [80/107 (75%)]\tTrain Loss: 0.002388\n",
      "Train Epoch: 65 [84/107 (79%)]\tTrain Loss: 0.002282\n",
      "Train Epoch: 65 [88/107 (82%)]\tTrain Loss: 0.010460\n",
      "Train Epoch: 65 [92/107 (86%)]\tTrain Loss: 0.000152\n",
      "Train Epoch: 65 [96/107 (90%)]\tTrain Loss: 0.012589\n",
      "Train Epoch: 65 [100/107 (93%)]\tTrain Loss: 0.003178\n",
      "Train Epoch: 65 [104/107 (97%)]\tTrain Loss: 0.000565\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.70959253e-02 9.28967476e-01 8.27658642e-03 3.52993876e-01\n",
      " 1.16287451e-02 4.76183882e-03 4.78345528e-02 4.86122817e-01\n",
      " 4.97200899e-03 4.77216095e-02 9.56852794e-01 9.75651375e-04\n",
      " 9.28923368e-01 1.01502659e-02 1.72093101e-02 7.21494667e-04\n",
      " 6.98610675e-04 9.28587914e-01 2.02482212e-02 5.64433813e-01\n",
      " 5.65155149e-01 9.79547620e-01 9.99173343e-01 9.99981284e-01\n",
      " 9.15229857e-01 9.99114215e-01 9.99912143e-01 1.14227004e-01\n",
      " 6.10165372e-02 7.63455126e-03 5.08095138e-02 9.08369292e-03\n",
      " 6.14637017e-01 1.17763400e-03 2.54245428e-03 7.42708612e-03\n",
      " 4.22432367e-03 9.94570434e-01 9.87080634e-01 7.69662205e-03\n",
      " 3.91120790e-03 2.19014958e-01 9.39541280e-01 9.36959624e-01\n",
      " 9.65318143e-01 2.64481250e-02 7.22524166e-01 6.36797190e-01\n",
      " 9.05844390e-01 2.83752412e-01 9.29162383e-01 3.82807339e-03\n",
      " 2.89305542e-02 1.98574122e-02 4.68697518e-01 8.58828276e-02\n",
      " 9.86443639e-01 3.02049029e-05 2.60010385e-03 5.69859669e-02\n",
      " 9.99490738e-01 9.98920798e-01 9.99982834e-01 9.99930501e-01\n",
      " 9.99998212e-01 9.99042451e-01 9.93576705e-01 9.99999046e-01\n",
      " 9.99956012e-01 9.99031544e-01 8.32209945e-01 4.22750026e-01\n",
      " 9.75002766e-01 9.99672055e-01 9.99970078e-01 9.48921680e-01\n",
      " 9.96087313e-01 8.49832296e-01 9.99942541e-01 9.97006834e-01\n",
      " 9.99938607e-01 9.99939442e-01 9.99988079e-01 9.88294482e-01\n",
      " 9.23213542e-01 9.99944210e-01 9.99461591e-01 9.96158957e-01\n",
      " 1.11664698e-01 9.99961853e-01 9.99336183e-01 9.67069030e-01\n",
      " 9.75085855e-01 1.00000000e+00 9.99990940e-01 9.99999642e-01\n",
      " 6.04803979e-01 9.99018431e-01 9.99718249e-01 9.99973655e-01\n",
      " 7.75135398e-01 9.93338525e-01 9.19467986e-01 9.96210814e-01\n",
      " 3.46917897e-01 9.99060810e-01 9.98620391e-01 9.80383933e-01\n",
      " 9.26872134e-01 9.93501246e-01 9.99144077e-01 9.99343455e-01\n",
      " 9.99997973e-01 9.98099744e-01 8.36223550e-03 8.90970509e-03\n",
      " 9.99939203e-01 9.99977112e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 66 [0/107 (0%)]\tTrain Loss: 0.002039\n",
      "Train Epoch: 66 [4/107 (4%)]\tTrain Loss: 0.019552\n",
      "Train Epoch: 66 [8/107 (7%)]\tTrain Loss: 0.000307\n",
      "Train Epoch: 66 [12/107 (11%)]\tTrain Loss: 0.002861\n",
      "Train Epoch: 66 [16/107 (15%)]\tTrain Loss: 0.015045\n",
      "Train Epoch: 66 [20/107 (19%)]\tTrain Loss: 0.000943\n",
      "Train Epoch: 66 [24/107 (22%)]\tTrain Loss: 0.002239\n",
      "Train Epoch: 66 [28/107 (26%)]\tTrain Loss: 0.037286\n",
      "Train Epoch: 66 [32/107 (30%)]\tTrain Loss: 0.000297\n",
      "Train Epoch: 66 [36/107 (34%)]\tTrain Loss: 0.000332\n",
      "Train Epoch: 66 [40/107 (37%)]\tTrain Loss: 0.000129\n",
      "Train Epoch: 66 [44/107 (41%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 66 [48/107 (45%)]\tTrain Loss: 0.000289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [52/107 (49%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 66 [56/107 (52%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 66 [60/107 (56%)]\tTrain Loss: 0.001281\n",
      "Train Epoch: 66 [64/107 (60%)]\tTrain Loss: 0.008267\n",
      "Train Epoch: 66 [68/107 (64%)]\tTrain Loss: 0.004952\n",
      "Train Epoch: 66 [72/107 (67%)]\tTrain Loss: 0.000337\n",
      "Train Epoch: 66 [76/107 (71%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 66 [80/107 (75%)]\tTrain Loss: 0.000327\n",
      "Train Epoch: 66 [84/107 (79%)]\tTrain Loss: 0.001742\n",
      "Train Epoch: 66 [88/107 (82%)]\tTrain Loss: 0.001397\n",
      "Train Epoch: 66 [92/107 (86%)]\tTrain Loss: 0.000603\n",
      "Train Epoch: 66 [96/107 (90%)]\tTrain Loss: 0.000242\n",
      "Train Epoch: 66 [100/107 (93%)]\tTrain Loss: 0.000137\n",
      "Train Epoch: 66 [104/107 (97%)]\tTrain Loss: 0.000586\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.07553322e-03 9.57073748e-01 4.31757979e-03 3.35913040e-02\n",
      " 2.30503530e-04 5.29546698e-04 3.66583839e-02 1.22587224e-02\n",
      " 4.62507480e-04 1.17467658e-03 4.50530469e-01 1.54567078e-05\n",
      " 4.90357459e-01 1.68171158e-04 8.51587451e-04 2.14861916e-06\n",
      " 9.19632271e-07 8.59303653e-01 1.17838825e-03 8.72003362e-02\n",
      " 6.58882335e-02 7.19138086e-01 9.87544954e-01 9.99958754e-01\n",
      " 2.77048618e-01 9.95368481e-01 9.99702036e-01 6.78108446e-03\n",
      " 2.36834190e-03 5.05033939e-04 2.03205496e-02 1.40748033e-03\n",
      " 5.71144164e-01 4.07185695e-07 6.82605730e-07 2.73738187e-05\n",
      " 2.12277482e-05 9.54218030e-01 8.86441529e-01 2.45918509e-05\n",
      " 1.02659187e-05 6.72011636e-04 5.57631373e-01 5.49544811e-01\n",
      " 7.99767494e-01 8.76735896e-04 3.32868218e-01 5.96718252e-01\n",
      " 7.54434168e-01 7.12313652e-02 9.24709618e-01 8.20778878e-05\n",
      " 5.84556209e-03 3.20186489e-04 5.45608737e-02 7.46652950e-03\n",
      " 9.72622097e-01 6.01751594e-07 6.22744192e-05 3.32576549e-03\n",
      " 9.99750555e-01 9.99556482e-01 9.99990940e-01 9.99969721e-01\n",
      " 9.99997020e-01 9.92238462e-01 9.33228910e-01 9.99997377e-01\n",
      " 9.99759614e-01 9.98858571e-01 4.31729048e-01 1.45218968e-01\n",
      " 8.45247209e-01 9.95427489e-01 9.99770224e-01 7.98899829e-01\n",
      " 9.98615384e-01 9.43877220e-01 9.99931812e-01 9.90122020e-01\n",
      " 9.99408364e-01 9.99876380e-01 9.99976397e-01 9.46826994e-01\n",
      " 5.22291005e-01 9.99930620e-01 9.99416113e-01 9.96710539e-01\n",
      " 4.03686147e-03 9.89292026e-01 9.95459974e-01 8.04333746e-01\n",
      " 8.26167881e-01 9.99999642e-01 9.99859810e-01 9.99981523e-01\n",
      " 1.37445375e-01 8.88900578e-01 8.72575521e-01 9.97708440e-01\n",
      " 2.07202002e-01 9.91593838e-01 1.99322984e-01 6.38779759e-01\n",
      " 3.11576836e-02 9.97727215e-01 9.94151056e-01 3.75939399e-01\n",
      " 5.29918931e-02 8.44072104e-01 5.74284077e-01 9.51070368e-01\n",
      " 9.99863744e-01 8.04477215e-01 3.78026161e-04 1.40067670e-04\n",
      " 9.99804676e-01 9.99874234e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 67 [0/107 (0%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 67 [4/107 (4%)]\tTrain Loss: 0.002329\n",
      "Train Epoch: 67 [8/107 (7%)]\tTrain Loss: 0.002560\n",
      "Train Epoch: 67 [12/107 (11%)]\tTrain Loss: 0.000176\n",
      "Train Epoch: 67 [16/107 (15%)]\tTrain Loss: 0.005431\n",
      "Train Epoch: 67 [20/107 (19%)]\tTrain Loss: 0.000861\n",
      "Train Epoch: 67 [24/107 (22%)]\tTrain Loss: 0.001584\n",
      "Train Epoch: 67 [28/107 (26%)]\tTrain Loss: 0.000806\n",
      "Train Epoch: 67 [32/107 (30%)]\tTrain Loss: 0.000935\n",
      "Train Epoch: 67 [36/107 (34%)]\tTrain Loss: 0.000231\n",
      "Train Epoch: 67 [40/107 (37%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 67 [44/107 (41%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 67 [48/107 (45%)]\tTrain Loss: 0.000305\n",
      "Train Epoch: 67 [52/107 (49%)]\tTrain Loss: 0.000906\n",
      "Train Epoch: 67 [56/107 (52%)]\tTrain Loss: 0.000361\n",
      "Train Epoch: 67 [60/107 (56%)]\tTrain Loss: 0.005030\n",
      "Train Epoch: 67 [64/107 (60%)]\tTrain Loss: 0.000110\n",
      "Train Epoch: 67 [68/107 (64%)]\tTrain Loss: 0.000216\n",
      "Train Epoch: 67 [72/107 (67%)]\tTrain Loss: 0.054384\n",
      "Train Epoch: 67 [76/107 (71%)]\tTrain Loss: 0.004579\n",
      "Train Epoch: 67 [80/107 (75%)]\tTrain Loss: 0.000730\n",
      "Train Epoch: 67 [84/107 (79%)]\tTrain Loss: 0.005284\n",
      "Train Epoch: 67 [88/107 (82%)]\tTrain Loss: 0.000904\n",
      "Train Epoch: 67 [92/107 (86%)]\tTrain Loss: 0.000417\n",
      "Train Epoch: 67 [96/107 (90%)]\tTrain Loss: 0.002188\n",
      "Train Epoch: 67 [100/107 (93%)]\tTrain Loss: 0.004569\n",
      "Train Epoch: 67 [104/107 (97%)]\tTrain Loss: 0.000267\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.30171720e-03 9.65490282e-01 1.89390592e-02 9.49896798e-02\n",
      " 5.50131947e-02 7.34208152e-04 4.02155131e-01 4.57635336e-02\n",
      " 4.50276770e-04 2.04593185e-02 4.46875244e-01 5.25168551e-04\n",
      " 2.54476905e-01 4.63294052e-03 5.66623872e-03 7.31792898e-05\n",
      " 4.29518004e-05 8.04836333e-01 8.67256895e-03 5.75399101e-02\n",
      " 8.37144405e-02 8.46586347e-01 9.95530546e-01 9.99175131e-01\n",
      " 7.67563403e-01 9.88648593e-01 9.88747954e-01 2.28556674e-02\n",
      " 1.49768721e-02 1.31614320e-03 2.34658364e-02 2.41022035e-02\n",
      " 7.38556266e-01 2.30932696e-04 1.93390180e-04 9.32452851e-04\n",
      " 1.52618493e-04 9.82260048e-01 9.19245601e-01 1.09399704e-03\n",
      " 2.52945028e-04 6.51130751e-02 8.89645755e-01 6.85066938e-01\n",
      " 5.61342359e-01 9.91967227e-03 7.30818987e-01 7.56485224e-01\n",
      " 6.16944790e-01 4.27733362e-02 7.29827106e-01 4.86076018e-03\n",
      " 2.01367617e-01 1.99049301e-02 1.88672498e-01 1.87790431e-02\n",
      " 7.26210475e-01 9.26111024e-05 3.51468261e-05 2.04189215e-02\n",
      " 9.97847676e-01 9.98642266e-01 9.99935150e-01 9.99668956e-01\n",
      " 9.99957085e-01 9.92498577e-01 9.74679112e-01 9.99992013e-01\n",
      " 9.96557117e-01 9.97103393e-01 3.72517407e-01 2.27873355e-01\n",
      " 8.52334499e-01 9.86450911e-01 9.96863961e-01 7.55736947e-01\n",
      " 9.98052120e-01 9.94395018e-01 9.99472797e-01 9.93310809e-01\n",
      " 9.98443186e-01 9.98869240e-01 9.97916400e-01 9.94954050e-01\n",
      " 9.04023707e-01 9.99957085e-01 9.96169031e-01 9.73115265e-01\n",
      " 8.11960083e-03 9.93640840e-01 9.68131304e-01 8.22317660e-01\n",
      " 5.61195731e-01 9.99992013e-01 9.93779838e-01 9.99782503e-01\n",
      " 2.56836236e-01 9.92662549e-01 9.99499440e-01 9.86636698e-01\n",
      " 8.12255561e-01 9.90565419e-01 6.33927107e-01 9.50698197e-01\n",
      " 4.71126735e-01 9.48568344e-01 9.32551146e-01 9.07193899e-01\n",
      " 9.43754911e-02 9.26258266e-01 9.94846582e-01 8.93842757e-01\n",
      " 9.99003351e-01 8.40548813e-01 2.56228051e-03 1.12542948e-02\n",
      " 9.99858618e-01 9.99811113e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 68 [0/107 (0%)]\tTrain Loss: 0.025019\n",
      "Train Epoch: 68 [4/107 (4%)]\tTrain Loss: 0.001045\n",
      "Train Epoch: 68 [8/107 (7%)]\tTrain Loss: 0.014165\n",
      "Train Epoch: 68 [12/107 (11%)]\tTrain Loss: 0.005013\n",
      "Train Epoch: 68 [16/107 (15%)]\tTrain Loss: 0.004147\n",
      "Train Epoch: 68 [20/107 (19%)]\tTrain Loss: 0.000738\n",
      "Train Epoch: 68 [24/107 (22%)]\tTrain Loss: 0.003892\n",
      "Train Epoch: 68 [28/107 (26%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 68 [32/107 (30%)]\tTrain Loss: 0.001676\n",
      "Train Epoch: 68 [36/107 (34%)]\tTrain Loss: 0.000353\n",
      "Train Epoch: 68 [40/107 (37%)]\tTrain Loss: 0.000640\n",
      "Train Epoch: 68 [44/107 (41%)]\tTrain Loss: 0.000327\n",
      "Train Epoch: 68 [48/107 (45%)]\tTrain Loss: 0.000496\n",
      "Train Epoch: 68 [52/107 (49%)]\tTrain Loss: 0.004052\n",
      "Train Epoch: 68 [56/107 (52%)]\tTrain Loss: 0.001286\n",
      "Train Epoch: 68 [60/107 (56%)]\tTrain Loss: 0.000979\n",
      "Train Epoch: 68 [64/107 (60%)]\tTrain Loss: 0.000548\n",
      "Train Epoch: 68 [68/107 (64%)]\tTrain Loss: 0.005681\n",
      "Train Epoch: 68 [72/107 (67%)]\tTrain Loss: 0.004675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 68 [76/107 (71%)]\tTrain Loss: 0.000158\n",
      "Train Epoch: 68 [80/107 (75%)]\tTrain Loss: 0.000377\n",
      "Train Epoch: 68 [84/107 (79%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 68 [88/107 (82%)]\tTrain Loss: 0.000239\n",
      "Train Epoch: 68 [92/107 (86%)]\tTrain Loss: 0.020467\n",
      "Train Epoch: 68 [96/107 (90%)]\tTrain Loss: 0.000400\n",
      "Train Epoch: 68 [100/107 (93%)]\tTrain Loss: 0.000198\n",
      "Train Epoch: 68 [104/107 (97%)]\tTrain Loss: 0.001589\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.27858126e-03 9.84577000e-01 2.65307147e-02 4.92143482e-02\n",
      " 2.71317945e-03 4.24605270e-04 7.50592589e-01 9.76406690e-03\n",
      " 5.90742857e-04 2.19061859e-02 6.40252829e-01 1.20472454e-04\n",
      " 3.09144467e-01 9.89794382e-04 2.17564916e-03 1.35927785e-05\n",
      " 2.04590833e-06 5.53988457e-01 9.22795851e-03 1.29290700e-01\n",
      " 3.50098461e-01 7.50833988e-01 9.98370111e-01 9.99834180e-01\n",
      " 7.67336071e-01 9.95476067e-01 9.96289015e-01 9.87444725e-03\n",
      " 4.23889747e-03 1.10628712e-03 7.54803512e-03 1.81358820e-03\n",
      " 6.37648106e-01 2.71107456e-05 7.76903289e-06 1.39425014e-04\n",
      " 3.41611048e-05 9.80871916e-01 8.25786054e-01 5.59401014e-05\n",
      " 2.09119826e-05 5.12227835e-03 2.61120409e-01 4.69500422e-01\n",
      " 1.52893618e-01 2.81511177e-03 2.28683874e-01 2.92474031e-01\n",
      " 7.49527216e-01 2.93202158e-02 8.12359452e-01 6.63319486e-04\n",
      " 2.35507358e-02 5.39360708e-03 8.35043266e-02 7.57355709e-03\n",
      " 8.60675633e-01 2.01898365e-06 5.01976647e-05 3.32253682e-03\n",
      " 9.98619318e-01 9.98455405e-01 9.99947667e-01 9.99764860e-01\n",
      " 9.99988794e-01 9.90651846e-01 9.30459023e-01 9.99997616e-01\n",
      " 9.99222159e-01 9.98772323e-01 1.93934113e-01 5.53377010e-02\n",
      " 8.55693340e-01 9.92279649e-01 9.89876568e-01 6.27628565e-01\n",
      " 9.99682546e-01 9.97995734e-01 9.99903202e-01 9.95292783e-01\n",
      " 9.99581397e-01 9.99465525e-01 9.99653339e-01 9.95441198e-01\n",
      " 8.67484510e-01 9.99962211e-01 9.98297751e-01 9.85267282e-01\n",
      " 2.02339888e-02 9.94397938e-01 9.95079517e-01 9.04578149e-01\n",
      " 6.17161512e-01 9.99999285e-01 9.98890340e-01 9.99966025e-01\n",
      " 3.28312933e-01 9.84046519e-01 9.99850988e-01 9.96507108e-01\n",
      " 7.86953807e-01 9.88756239e-01 3.00367177e-01 9.69313562e-01\n",
      " 2.05705002e-01 9.85582471e-01 9.76478696e-01 9.25002158e-01\n",
      " 4.19810377e-02 9.52010274e-01 9.96616542e-01 9.00632679e-01\n",
      " 9.99939203e-01 9.09641087e-01 1.80954661e-03 2.02800240e-03\n",
      " 9.99950171e-01 9.99936104e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 69 [0/107 (0%)]\tTrain Loss: 0.000732\n",
      "Train Epoch: 69 [4/107 (4%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 69 [8/107 (7%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 69 [12/107 (11%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 69 [16/107 (15%)]\tTrain Loss: 0.048861\n",
      "Train Epoch: 69 [20/107 (19%)]\tTrain Loss: 0.000510\n",
      "Train Epoch: 69 [24/107 (22%)]\tTrain Loss: 0.001894\n",
      "Train Epoch: 69 [28/107 (26%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 69 [32/107 (30%)]\tTrain Loss: 0.001150\n",
      "Train Epoch: 69 [36/107 (34%)]\tTrain Loss: 0.000517\n",
      "Train Epoch: 69 [40/107 (37%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 69 [44/107 (41%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 69 [48/107 (45%)]\tTrain Loss: 0.000542\n",
      "Train Epoch: 69 [52/107 (49%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 69 [56/107 (52%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 69 [60/107 (56%)]\tTrain Loss: 0.000351\n",
      "Train Epoch: 69 [64/107 (60%)]\tTrain Loss: 0.000659\n",
      "Train Epoch: 69 [68/107 (64%)]\tTrain Loss: 0.001048\n",
      "Train Epoch: 69 [72/107 (67%)]\tTrain Loss: 0.000735\n",
      "Train Epoch: 69 [76/107 (71%)]\tTrain Loss: 0.000288\n",
      "Train Epoch: 69 [80/107 (75%)]\tTrain Loss: 0.000584\n",
      "Train Epoch: 69 [84/107 (79%)]\tTrain Loss: 0.000503\n",
      "Train Epoch: 69 [88/107 (82%)]\tTrain Loss: 0.000101\n",
      "Train Epoch: 69 [92/107 (86%)]\tTrain Loss: 0.000366\n",
      "Train Epoch: 69 [96/107 (90%)]\tTrain Loss: 0.000130\n",
      "Train Epoch: 69 [100/107 (93%)]\tTrain Loss: 0.031442\n",
      "Train Epoch: 69 [104/107 (97%)]\tTrain Loss: 0.001171\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.45779054e-03 9.91905332e-01 2.89539583e-02 8.61001238e-02\n",
      " 5.56958234e-03 4.68554324e-04 6.39578819e-01 3.44211571e-02\n",
      " 3.37540638e-04 3.46325571e-03 7.94691026e-01 1.88949052e-05\n",
      " 6.61052942e-01 4.46557859e-03 4.03265795e-03 7.64757988e-06\n",
      " 2.24914288e-06 4.15227294e-01 3.69478459e-03 2.92437524e-02\n",
      " 1.92656666e-01 7.58500576e-01 9.99428451e-01 9.99931216e-01\n",
      " 5.69489181e-01 9.97183263e-01 9.98434842e-01 7.46368524e-03\n",
      " 5.76968817e-03 6.34193013e-04 1.40318125e-02 2.86414986e-03\n",
      " 8.32946718e-01 7.90088052e-06 3.63695267e-06 8.66168630e-05\n",
      " 6.83936669e-05 9.90493953e-01 9.33933139e-01 6.92362955e-05\n",
      " 1.38738224e-05 2.38223653e-03 2.54557103e-01 3.39844137e-01\n",
      " 6.45343959e-01 2.21882993e-03 4.82806414e-01 5.89561522e-01\n",
      " 8.78709376e-01 2.54467335e-02 8.46831203e-01 5.62572386e-04\n",
      " 1.56136416e-02 9.64777172e-03 2.25867853e-02 5.24349650e-03\n",
      " 9.14341927e-01 4.70015181e-07 1.64103676e-05 2.14128802e-03\n",
      " 9.99647737e-01 9.99462783e-01 9.99988556e-01 9.99967098e-01\n",
      " 9.99999404e-01 9.99092102e-01 9.94230270e-01 9.99999881e-01\n",
      " 9.99908447e-01 9.98900771e-01 7.10797966e-01 2.28188992e-01\n",
      " 9.29141462e-01 9.96396601e-01 9.99663830e-01 4.64240223e-01\n",
      " 9.99907613e-01 9.98990357e-01 9.99976993e-01 9.99103308e-01\n",
      " 9.99928117e-01 9.99812543e-01 9.99911666e-01 9.92033660e-01\n",
      " 8.27728212e-01 9.99978065e-01 9.98821557e-01 9.95791316e-01\n",
      " 6.80417288e-03 9.94442761e-01 9.98912811e-01 9.19865131e-01\n",
      " 7.68923879e-01 9.99999642e-01 9.99544680e-01 9.99989033e-01\n",
      " 3.14533234e-01 8.37682009e-01 9.99619603e-01 9.99217868e-01\n",
      " 1.92039877e-01 9.90932822e-01 2.86765933e-01 9.84259188e-01\n",
      " 1.32467031e-01 9.95402098e-01 9.93019760e-01 8.36856544e-01\n",
      " 1.87297873e-02 9.28669453e-01 9.95553553e-01 9.38142657e-01\n",
      " 9.99956727e-01 9.78127837e-01 2.03178148e-03 2.63131480e-03\n",
      " 9.99869704e-01 9.99842167e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 70 [0/107 (0%)]\tTrain Loss: 0.000457\n",
      "Train Epoch: 70 [4/107 (4%)]\tTrain Loss: 0.033731\n",
      "Train Epoch: 70 [8/107 (7%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 70 [12/107 (11%)]\tTrain Loss: 0.000185\n",
      "Train Epoch: 70 [16/107 (15%)]\tTrain Loss: 0.000372\n",
      "Train Epoch: 70 [20/107 (19%)]\tTrain Loss: 0.000201\n",
      "Train Epoch: 70 [24/107 (22%)]\tTrain Loss: 0.000444\n",
      "Train Epoch: 70 [28/107 (26%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 70 [32/107 (30%)]\tTrain Loss: 0.000919\n",
      "Train Epoch: 70 [36/107 (34%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 70 [40/107 (37%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 70 [44/107 (41%)]\tTrain Loss: 0.002463\n",
      "Train Epoch: 70 [48/107 (45%)]\tTrain Loss: 0.047652\n",
      "Train Epoch: 70 [52/107 (49%)]\tTrain Loss: 0.000251\n",
      "Train Epoch: 70 [56/107 (52%)]\tTrain Loss: 0.000229\n",
      "Train Epoch: 70 [60/107 (56%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 70 [64/107 (60%)]\tTrain Loss: 0.002779\n",
      "Train Epoch: 70 [68/107 (64%)]\tTrain Loss: 0.002628\n",
      "Train Epoch: 70 [72/107 (67%)]\tTrain Loss: 0.000219\n",
      "Train Epoch: 70 [76/107 (71%)]\tTrain Loss: 0.000514\n",
      "Train Epoch: 70 [80/107 (75%)]\tTrain Loss: 0.000744\n",
      "Train Epoch: 70 [84/107 (79%)]\tTrain Loss: 0.000143\n",
      "Train Epoch: 70 [88/107 (82%)]\tTrain Loss: 0.000551\n",
      "Train Epoch: 70 [92/107 (86%)]\tTrain Loss: 0.000355\n",
      "Train Epoch: 70 [96/107 (90%)]\tTrain Loss: 0.000301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 [100/107 (93%)]\tTrain Loss: 0.011461\n",
      "Train Epoch: 70 [104/107 (97%)]\tTrain Loss: 0.000609\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.14195438e-02 9.89497781e-01 1.76030155e-02 8.48495886e-02\n",
      " 3.57571989e-02 1.47444452e-03 8.07352662e-01 6.09284118e-02\n",
      " 1.33778085e-03 1.49728730e-02 3.65622997e-01 1.23120422e-04\n",
      " 3.11769754e-01 3.26541183e-03 3.38692917e-03 3.75963391e-05\n",
      " 1.23849695e-05 4.82237101e-01 1.36709912e-03 1.38634127e-02\n",
      " 1.56341698e-02 5.81222415e-01 9.89635766e-01 9.99651194e-01\n",
      " 2.62223810e-01 9.43322420e-01 9.88630652e-01 1.67492568e-03\n",
      " 9.79851652e-03 1.12575176e-03 3.31727136e-03 5.11536421e-03\n",
      " 5.88530660e-01 1.29922613e-04 1.32253554e-05 3.20752588e-04\n",
      " 1.12511894e-04 9.11280751e-01 8.34101915e-01 3.03458928e-05\n",
      " 1.38592186e-05 7.92408711e-04 3.37220848e-01 4.77935858e-02\n",
      " 2.04860285e-01 3.36261140e-03 4.72481102e-01 4.53119397e-01\n",
      " 6.67364776e-01 1.54678281e-02 8.55338216e-01 2.93661328e-03\n",
      " 7.46690761e-03 4.75797849e-03 1.23248005e-03 6.06895424e-03\n",
      " 8.00400078e-01 7.90932290e-07 1.15079602e-04 1.44281075e-03\n",
      " 9.99151826e-01 9.99087691e-01 9.99950886e-01 9.99879599e-01\n",
      " 9.99886990e-01 9.69176710e-01 8.81839812e-01 9.99993086e-01\n",
      " 9.97778714e-01 9.95527208e-01 4.60851103e-01 3.23308796e-01\n",
      " 8.68284822e-01 9.67455328e-01 9.58905280e-01 4.44605350e-01\n",
      " 9.99738395e-01 9.99161482e-01 9.99921203e-01 9.89891052e-01\n",
      " 9.98725235e-01 9.98229682e-01 9.97870803e-01 9.94593799e-01\n",
      " 9.01011229e-01 9.99714077e-01 9.95631933e-01 9.81626272e-01\n",
      " 1.30086136e-03 9.14471984e-01 9.37261641e-01 7.74520099e-01\n",
      " 4.16237921e-01 9.99805629e-01 9.76522207e-01 9.88863587e-01\n",
      " 4.56981137e-02 9.52375591e-01 9.94317591e-01 9.94740963e-01\n",
      " 5.00477016e-01 9.80882704e-01 4.60956872e-01 9.09493446e-01\n",
      " 1.59056693e-01 9.22402442e-01 9.43939924e-01 3.19149226e-01\n",
      " 3.45112123e-02 8.35426390e-01 9.67411041e-01 6.43326402e-01\n",
      " 9.95554507e-01 1.28989190e-01 1.42940832e-03 9.75481293e-04\n",
      " 9.99935985e-01 9.99459326e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 48 TN= 43 FN= 10 FP= 17\n",
      "TP+FP 65\n",
      "precision 0.7384615384615385\n",
      "recall 0.8275862068965517\n",
      "F1 0.7804878048780489\n",
      "acc 0.7711864406779662\n",
      "AUCp 0.7721264367816092\n",
      "AUC 0.8718390804597701\n",
      "\n",
      " The epoch is 70, average recall: 0.8276, average precision: 0.7385,average F1: 0.7805, average accuracy: 0.7712, average AUC: 0.8718\n",
      "Train Epoch: 71 [0/107 (0%)]\tTrain Loss: 0.001299\n",
      "Train Epoch: 71 [4/107 (4%)]\tTrain Loss: 0.000832\n",
      "Train Epoch: 71 [8/107 (7%)]\tTrain Loss: 0.006407\n",
      "Train Epoch: 71 [12/107 (11%)]\tTrain Loss: 0.000514\n",
      "Train Epoch: 71 [16/107 (15%)]\tTrain Loss: 0.058208\n",
      "Train Epoch: 71 [20/107 (19%)]\tTrain Loss: 0.000363\n",
      "Train Epoch: 71 [24/107 (22%)]\tTrain Loss: 0.000278\n",
      "Train Epoch: 71 [28/107 (26%)]\tTrain Loss: 0.001128\n",
      "Train Epoch: 71 [32/107 (30%)]\tTrain Loss: 0.013929\n",
      "Train Epoch: 71 [36/107 (34%)]\tTrain Loss: 0.000198\n",
      "Train Epoch: 71 [40/107 (37%)]\tTrain Loss: 0.011412\n",
      "Train Epoch: 71 [44/107 (41%)]\tTrain Loss: 0.000750\n",
      "Train Epoch: 71 [48/107 (45%)]\tTrain Loss: 0.000306\n",
      "Train Epoch: 71 [52/107 (49%)]\tTrain Loss: 0.000684\n",
      "Train Epoch: 71 [56/107 (52%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 71 [60/107 (56%)]\tTrain Loss: 0.000252\n",
      "Train Epoch: 71 [64/107 (60%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 71 [68/107 (64%)]\tTrain Loss: 0.000442\n",
      "Train Epoch: 71 [72/107 (67%)]\tTrain Loss: 0.000266\n",
      "Train Epoch: 71 [76/107 (71%)]\tTrain Loss: 0.000335\n",
      "Train Epoch: 71 [80/107 (75%)]\tTrain Loss: 0.003580\n",
      "Train Epoch: 71 [84/107 (79%)]\tTrain Loss: 0.001572\n",
      "Train Epoch: 71 [88/107 (82%)]\tTrain Loss: 0.001025\n",
      "Train Epoch: 71 [92/107 (86%)]\tTrain Loss: 0.001155\n",
      "Train Epoch: 71 [96/107 (90%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 71 [100/107 (93%)]\tTrain Loss: 0.001102\n",
      "Train Epoch: 71 [104/107 (97%)]\tTrain Loss: 0.001184\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.25910128e-02 9.95183885e-01 4.04107869e-02 1.39285207e-01\n",
      " 4.30952013e-02 1.31477416e-03 8.48114908e-01 1.26712546e-01\n",
      " 4.81145363e-03 6.83106929e-02 8.36248338e-01 1.62757013e-03\n",
      " 8.00452471e-01 3.71623132e-03 2.63711880e-03 3.76816242e-05\n",
      " 5.04299860e-05 5.29524148e-01 1.23895640e-02 9.12200809e-02\n",
      " 3.26265097e-01 9.39882338e-01 9.98447001e-01 9.99898076e-01\n",
      " 8.85191917e-01 9.92262602e-01 9.96231496e-01 1.05195791e-01\n",
      " 8.63728896e-02 2.67839478e-03 1.37897003e-02 4.09043301e-03\n",
      " 4.92527843e-01 5.77526109e-04 8.61920198e-05 3.42116505e-03\n",
      " 1.03109586e-03 9.87417579e-01 9.17665422e-01 5.36268708e-05\n",
      " 4.28362437e-05 9.56149539e-04 7.43774176e-01 7.14724287e-02\n",
      " 6.66883409e-01 2.26237648e-03 2.67547876e-01 1.47337139e-01\n",
      " 6.21378303e-01 6.25199378e-02 8.38845730e-01 2.61345273e-03\n",
      " 2.57738438e-02 3.29217245e-03 7.39405770e-03 2.39322223e-02\n",
      " 9.64403689e-01 1.15641672e-06 7.84362666e-03 8.46193917e-03\n",
      " 9.98170137e-01 9.98122752e-01 9.99801815e-01 9.99634266e-01\n",
      " 9.99975085e-01 9.87587512e-01 9.58806515e-01 9.99987006e-01\n",
      " 9.99350011e-01 9.95748580e-01 4.78369206e-01 1.53275400e-01\n",
      " 8.79222274e-01 9.92191732e-01 9.98892367e-01 6.81797028e-01\n",
      " 9.99926686e-01 9.99384046e-01 9.99939680e-01 9.91163015e-01\n",
      " 9.99186099e-01 9.99377549e-01 9.99133646e-01 9.92943108e-01\n",
      " 9.28501368e-01 9.99583185e-01 9.98530865e-01 9.90220308e-01\n",
      " 2.84943338e-02 9.92802322e-01 9.87933218e-01 8.03540707e-01\n",
      " 7.69194245e-01 9.99988675e-01 9.96797621e-01 9.99734342e-01\n",
      " 6.87080681e-01 9.78470683e-01 9.98316169e-01 9.98070896e-01\n",
      " 5.97773671e-01 9.68362629e-01 5.60437500e-01 9.71684873e-01\n",
      " 1.15607508e-01 9.76120293e-01 9.75248873e-01 4.78278965e-01\n",
      " 1.41397014e-01 9.05676067e-01 9.79471922e-01 9.52529371e-01\n",
      " 9.97643173e-01 7.38057435e-01 5.50392829e-03 3.23298760e-03\n",
      " 9.99980211e-01 9.99557555e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 72 [0/107 (0%)]\tTrain Loss: 0.000878\n",
      "Train Epoch: 72 [4/107 (4%)]\tTrain Loss: 0.000479\n",
      "Train Epoch: 72 [8/107 (7%)]\tTrain Loss: 0.046661\n",
      "Train Epoch: 72 [12/107 (11%)]\tTrain Loss: 0.001911\n",
      "Train Epoch: 72 [16/107 (15%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 72 [20/107 (19%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 72 [24/107 (22%)]\tTrain Loss: 0.000128\n",
      "Train Epoch: 72 [28/107 (26%)]\tTrain Loss: 0.000393\n",
      "Train Epoch: 72 [32/107 (30%)]\tTrain Loss: 0.006051\n",
      "Train Epoch: 72 [36/107 (34%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 72 [40/107 (37%)]\tTrain Loss: 0.000190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [44/107 (41%)]\tTrain Loss: 0.001897\n",
      "Train Epoch: 72 [48/107 (45%)]\tTrain Loss: 0.001081\n",
      "Train Epoch: 72 [52/107 (49%)]\tTrain Loss: 0.000382\n",
      "Train Epoch: 72 [56/107 (52%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 72 [60/107 (56%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 72 [64/107 (60%)]\tTrain Loss: 0.000131\n",
      "Train Epoch: 72 [68/107 (64%)]\tTrain Loss: 0.001171\n",
      "Train Epoch: 72 [72/107 (67%)]\tTrain Loss: 0.000193\n",
      "Train Epoch: 72 [76/107 (71%)]\tTrain Loss: 0.000373\n",
      "Train Epoch: 72 [80/107 (75%)]\tTrain Loss: 0.002422\n",
      "Train Epoch: 72 [84/107 (79%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 72 [88/107 (82%)]\tTrain Loss: 0.000883\n",
      "Train Epoch: 72 [92/107 (86%)]\tTrain Loss: 0.000432\n",
      "Train Epoch: 72 [96/107 (90%)]\tTrain Loss: 0.000218\n",
      "Train Epoch: 72 [100/107 (93%)]\tTrain Loss: 0.001613\n",
      "Train Epoch: 72 [104/107 (97%)]\tTrain Loss: 0.001028\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.79247297e-02 9.99605477e-01 4.81073819e-02 1.33040562e-01\n",
      " 1.10215181e-02 1.08793029e-03 9.74562824e-01 2.88056023e-02\n",
      " 3.76957143e-03 8.65475554e-03 2.30662838e-01 4.48559476e-05\n",
      " 7.66121522e-02 1.23163324e-03 1.80813496e-03 7.31054661e-06\n",
      " 3.09021652e-06 7.99673438e-01 3.03052296e-03 1.99627243e-02\n",
      " 8.34259689e-02 9.40746486e-01 9.99716699e-01 9.99964595e-01\n",
      " 4.60154712e-01 9.99283612e-01 9.99816477e-01 8.69335011e-02\n",
      " 1.04107372e-01 4.05590690e-04 3.33948135e-01 2.09026597e-02\n",
      " 8.04259002e-01 9.17790112e-06 3.24726079e-06 5.52303864e-05\n",
      " 3.06302427e-05 9.88086104e-01 8.02708328e-01 9.74566410e-06\n",
      " 3.28628380e-06 9.72550260e-05 7.92967796e-01 6.31797984e-02\n",
      " 5.66627443e-01 2.92249140e-03 7.58934855e-01 7.13538826e-01\n",
      " 8.28815877e-01 2.48075947e-02 9.46529448e-01 9.84955695e-04\n",
      " 4.46853973e-02 7.98761204e-04 4.20537498e-03 4.29574260e-03\n",
      " 9.85647559e-01 2.90363005e-07 4.15520975e-04 1.33004291e-02\n",
      " 9.99799669e-01 9.99846339e-01 9.99995947e-01 9.99987721e-01\n",
      " 9.99995232e-01 9.94347870e-01 9.90546346e-01 9.99999404e-01\n",
      " 9.99822915e-01 9.99603331e-01 7.70703614e-01 6.80013895e-01\n",
      " 9.61625159e-01 9.90108132e-01 9.99270618e-01 9.00468886e-01\n",
      " 9.99988317e-01 9.99976516e-01 9.99992728e-01 9.98239517e-01\n",
      " 9.99908447e-01 9.99821246e-01 9.99878883e-01 9.99614835e-01\n",
      " 8.97098243e-01 9.99997020e-01 9.99607980e-01 9.99107897e-01\n",
      " 8.78467504e-03 9.68887329e-01 9.98612761e-01 8.38612258e-01\n",
      " 7.51925588e-01 9.99985814e-01 9.97195721e-01 9.99697328e-01\n",
      " 1.05668277e-01 9.65194762e-01 9.97495592e-01 9.97040927e-01\n",
      " 1.03342518e-01 9.94729221e-01 3.31716627e-01 8.78197849e-01\n",
      " 3.94819230e-01 9.90139127e-01 9.94492650e-01 1.69317201e-01\n",
      " 2.47824155e-02 9.28808868e-01 9.52960670e-01 8.08244288e-01\n",
      " 9.99371946e-01 3.43240499e-01 8.58346233e-04 1.49559753e-03\n",
      " 9.99998808e-01 9.99854445e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 73 [0/107 (0%)]\tTrain Loss: 0.000433\n",
      "Train Epoch: 73 [4/107 (4%)]\tTrain Loss: 0.002194\n",
      "Train Epoch: 73 [8/107 (7%)]\tTrain Loss: 0.018250\n",
      "Train Epoch: 73 [12/107 (11%)]\tTrain Loss: 0.000274\n",
      "Train Epoch: 73 [16/107 (15%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 73 [20/107 (19%)]\tTrain Loss: 0.005488\n",
      "Train Epoch: 73 [24/107 (22%)]\tTrain Loss: 0.028510\n",
      "Train Epoch: 73 [28/107 (26%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 73 [32/107 (30%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 73 [36/107 (34%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 73 [40/107 (37%)]\tTrain Loss: 0.007829\n",
      "Train Epoch: 73 [44/107 (41%)]\tTrain Loss: 0.000105\n",
      "Train Epoch: 73 [48/107 (45%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 73 [52/107 (49%)]\tTrain Loss: 0.000198\n",
      "Train Epoch: 73 [56/107 (52%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 73 [60/107 (56%)]\tTrain Loss: 0.000217\n",
      "Train Epoch: 73 [64/107 (60%)]\tTrain Loss: 0.007595\n",
      "Train Epoch: 73 [68/107 (64%)]\tTrain Loss: 0.000123\n",
      "Train Epoch: 73 [72/107 (67%)]\tTrain Loss: 0.000599\n",
      "Train Epoch: 73 [76/107 (71%)]\tTrain Loss: 0.005655\n",
      "Train Epoch: 73 [80/107 (75%)]\tTrain Loss: 0.000194\n",
      "Train Epoch: 73 [84/107 (79%)]\tTrain Loss: 0.000630\n",
      "Train Epoch: 73 [88/107 (82%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 73 [92/107 (86%)]\tTrain Loss: 0.001014\n",
      "Train Epoch: 73 [96/107 (90%)]\tTrain Loss: 0.005690\n",
      "Train Epoch: 73 [100/107 (93%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 73 [104/107 (97%)]\tTrain Loss: 0.000015\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.31247321e-03 9.96205032e-01 1.33290160e-02 5.11658788e-02\n",
      " 3.89237702e-03 2.00852883e-04 9.59214270e-01 7.99320173e-03\n",
      " 7.91232276e-04 5.92325535e-03 2.27361605e-01 5.87855357e-05\n",
      " 8.88437554e-02 4.25256672e-04 8.38647422e-04 2.84727093e-07\n",
      " 7.15340832e-07 7.49952018e-01 3.99809191e-03 1.12154912e-02\n",
      " 1.02548629e-01 9.15045679e-01 9.99844909e-01 9.99957681e-01\n",
      " 7.98540175e-01 9.99631524e-01 9.99656677e-01 5.27612492e-02\n",
      " 5.70153929e-02 1.31678345e-04 2.14783385e-01 5.20675443e-03\n",
      " 7.09862351e-01 2.62394883e-06 1.92307152e-06 3.22884371e-05\n",
      " 3.25516339e-05 9.87687647e-01 9.30055618e-01 2.77859317e-06\n",
      " 1.47153764e-06 4.62535063e-05 3.64129871e-01 2.62749549e-02\n",
      " 4.29921389e-01 1.43584143e-03 6.63634598e-01 4.92522985e-01\n",
      " 8.00836444e-01 3.38011943e-02 8.97418499e-01 3.10426462e-04\n",
      " 9.70534422e-03 3.42617539e-04 2.03266274e-02 1.18175335e-03\n",
      " 9.83841896e-01 1.08774898e-07 7.98407345e-05 2.29333597e-03\n",
      " 9.99302626e-01 9.99648333e-01 9.99988198e-01 9.99964595e-01\n",
      " 9.99990106e-01 9.87135589e-01 9.80352521e-01 9.99999523e-01\n",
      " 9.99616385e-01 9.97359574e-01 6.79779589e-01 6.02644861e-01\n",
      " 7.04913855e-01 9.18053448e-01 9.98137593e-01 7.98187077e-01\n",
      " 9.99966741e-01 9.99887228e-01 9.99988914e-01 9.96706188e-01\n",
      " 9.99809325e-01 9.99559820e-01 9.99881148e-01 9.99522686e-01\n",
      " 8.14412475e-01 9.99994993e-01 9.99556005e-01 9.98696983e-01\n",
      " 4.28857189e-03 9.82438743e-01 9.99418616e-01 3.95342052e-01\n",
      " 6.20756269e-01 9.99993920e-01 9.99179542e-01 9.99819458e-01\n",
      " 6.42325133e-02 9.83948410e-01 9.95648563e-01 9.91833091e-01\n",
      " 1.36478283e-02 9.82337475e-01 2.68001288e-01 8.86940300e-01\n",
      " 5.02207100e-01 9.89973187e-01 9.82624233e-01 5.78055829e-02\n",
      " 3.72232050e-02 8.63069713e-01 8.20380747e-01 8.73993754e-01\n",
      " 9.99171257e-01 4.30222422e-01 3.44084459e-04 1.08908175e-03\n",
      " 9.99982119e-01 9.98084188e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 74 [0/107 (0%)]\tTrain Loss: 0.000538\n",
      "Train Epoch: 74 [4/107 (4%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 74 [8/107 (7%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 74 [12/107 (11%)]\tTrain Loss: 0.000912\n",
      "Train Epoch: 74 [16/107 (15%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 74 [20/107 (19%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 74 [24/107 (22%)]\tTrain Loss: 0.000232\n",
      "Train Epoch: 74 [28/107 (26%)]\tTrain Loss: 0.022053\n",
      "Train Epoch: 74 [32/107 (30%)]\tTrain Loss: 0.004279\n",
      "Train Epoch: 74 [36/107 (34%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 74 [40/107 (37%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 74 [44/107 (41%)]\tTrain Loss: 0.001318\n",
      "Train Epoch: 74 [48/107 (45%)]\tTrain Loss: 0.000428\n",
      "Train Epoch: 74 [52/107 (49%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 74 [56/107 (52%)]\tTrain Loss: 0.000841\n",
      "Train Epoch: 74 [60/107 (56%)]\tTrain Loss: 0.000268\n",
      "Train Epoch: 74 [64/107 (60%)]\tTrain Loss: 0.006468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [68/107 (64%)]\tTrain Loss: 0.001181\n",
      "Train Epoch: 74 [72/107 (67%)]\tTrain Loss: 0.000440\n",
      "Train Epoch: 74 [76/107 (71%)]\tTrain Loss: 0.000442\n",
      "Train Epoch: 74 [80/107 (75%)]\tTrain Loss: 0.000185\n",
      "Train Epoch: 74 [84/107 (79%)]\tTrain Loss: 0.003100\n",
      "Train Epoch: 74 [88/107 (82%)]\tTrain Loss: 0.174239\n",
      "Train Epoch: 74 [92/107 (86%)]\tTrain Loss: 0.004131\n",
      "Train Epoch: 74 [96/107 (90%)]\tTrain Loss: 0.000312\n",
      "Train Epoch: 74 [100/107 (93%)]\tTrain Loss: 0.003249\n",
      "Train Epoch: 74 [104/107 (97%)]\tTrain Loss: 0.000718\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.52945610e-04 9.57519293e-01 1.14566851e-02 3.29319499e-02\n",
      " 2.25398014e-03 5.52040117e-04 7.42643476e-01 4.96316981e-03\n",
      " 1.31682167e-03 1.43525854e-03 8.62629041e-02 1.40511183e-05\n",
      " 4.74242680e-02 1.82705247e-04 1.44244090e-03 4.39962150e-07\n",
      " 6.86833346e-08 6.21202849e-02 8.01873219e-04 1.92017443e-02\n",
      " 8.21181387e-02 6.70340061e-01 9.91518080e-01 9.99428809e-01\n",
      " 1.76746771e-01 9.85027909e-01 9.93181884e-01 1.86581891e-02\n",
      " 5.44882240e-03 1.77183698e-04 7.02258665e-03 8.81511543e-04\n",
      " 3.75454783e-01 7.79612208e-07 5.56705459e-07 6.49252033e-05\n",
      " 9.22682466e-06 9.26521778e-01 7.58020103e-01 1.46804211e-06\n",
      " 3.89650353e-07 2.94631445e-05 4.74530682e-02 1.18909329e-02\n",
      " 5.51349185e-02 2.49079254e-04 1.51661411e-01 6.76080883e-02\n",
      " 6.56900644e-01 4.39517684e-02 6.90659821e-01 1.13154652e-04\n",
      " 3.98913573e-04 4.83603981e-05 2.96960294e-04 6.67192915e-04\n",
      " 7.20462024e-01 3.85179222e-09 4.81154493e-05 9.29547648e-04\n",
      " 9.39837515e-01 9.73202467e-01 9.97338593e-01 9.97066438e-01\n",
      " 9.99858260e-01 9.71741617e-01 9.42201138e-01 9.99964237e-01\n",
      " 9.99528408e-01 9.82738912e-01 3.63189280e-01 1.09443717e-01\n",
      " 5.47823250e-01 8.83068919e-01 9.31667030e-01 1.72905967e-01\n",
      " 9.99200642e-01 9.92515385e-01 9.99765456e-01 9.82033074e-01\n",
      " 9.98749495e-01 9.91580307e-01 9.98982847e-01 9.44345832e-01\n",
      " 3.54548007e-01 9.99393821e-01 9.86333311e-01 9.73017335e-01\n",
      " 3.39659397e-03 7.10700274e-01 9.94480252e-01 5.26881099e-01\n",
      " 5.28019190e-01 9.99956369e-01 9.85440314e-01 9.99640346e-01\n",
      " 1.51271885e-02 4.76469189e-01 9.51382518e-01 9.93832231e-01\n",
      " 1.08098881e-02 8.05822790e-01 1.19786769e-01 6.90434694e-01\n",
      " 2.02384323e-01 8.89530778e-01 9.59997833e-01 1.14683248e-01\n",
      " 2.03157403e-02 7.13375390e-01 8.34411800e-01 6.84970498e-01\n",
      " 9.97445822e-01 1.69834450e-01 1.31601468e-03 3.65714863e-04\n",
      " 9.97732282e-01 9.72443402e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 75 [0/107 (0%)]\tTrain Loss: 0.001936\n",
      "Train Epoch: 75 [4/107 (4%)]\tTrain Loss: 0.026488\n",
      "Train Epoch: 75 [8/107 (7%)]\tTrain Loss: 0.000997\n",
      "Train Epoch: 75 [12/107 (11%)]\tTrain Loss: 0.001802\n",
      "Train Epoch: 75 [16/107 (15%)]\tTrain Loss: 0.000399\n",
      "Train Epoch: 75 [20/107 (19%)]\tTrain Loss: 0.000324\n",
      "Train Epoch: 75 [24/107 (22%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 75 [28/107 (26%)]\tTrain Loss: 0.000145\n",
      "Train Epoch: 75 [32/107 (30%)]\tTrain Loss: 0.000633\n",
      "Train Epoch: 75 [36/107 (34%)]\tTrain Loss: 0.000282\n",
      "Train Epoch: 75 [40/107 (37%)]\tTrain Loss: 0.020150\n",
      "Train Epoch: 75 [44/107 (41%)]\tTrain Loss: 0.000444\n",
      "Train Epoch: 75 [48/107 (45%)]\tTrain Loss: 0.000805\n",
      "Train Epoch: 75 [52/107 (49%)]\tTrain Loss: 0.001604\n",
      "Train Epoch: 75 [56/107 (52%)]\tTrain Loss: 0.004842\n",
      "Train Epoch: 75 [60/107 (56%)]\tTrain Loss: 0.016324\n",
      "Train Epoch: 75 [64/107 (60%)]\tTrain Loss: 0.001856\n",
      "Train Epoch: 75 [68/107 (64%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 75 [72/107 (67%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 75 [76/107 (71%)]\tTrain Loss: 0.000437\n",
      "Train Epoch: 75 [80/107 (75%)]\tTrain Loss: 0.003274\n",
      "Train Epoch: 75 [84/107 (79%)]\tTrain Loss: 0.000213\n",
      "Train Epoch: 75 [88/107 (82%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 75 [92/107 (86%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 75 [96/107 (90%)]\tTrain Loss: 0.000310\n",
      "Train Epoch: 75 [100/107 (93%)]\tTrain Loss: 0.000204\n",
      "Train Epoch: 75 [104/107 (97%)]\tTrain Loss: 0.000220\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.17207620e-03 9.91512716e-01 1.22664068e-02 2.08875194e-01\n",
      " 1.57675892e-02 9.21813597e-04 8.74246538e-01 8.37463140e-02\n",
      " 3.39847896e-03 2.56939828e-02 5.62117517e-01 1.21962614e-04\n",
      " 5.29174924e-01 2.11096392e-03 1.13329394e-02 6.58455929e-06\n",
      " 2.30628348e-06 4.77975339e-01 1.45877595e-03 1.53016532e-02\n",
      " 1.21103175e-01 9.67417538e-01 9.99139309e-01 9.99911904e-01\n",
      " 8.56552482e-01 9.97499526e-01 9.99199331e-01 9.17358920e-02\n",
      " 4.24159281e-02 2.53549515e-04 5.74004911e-02 3.60097596e-03\n",
      " 5.96209526e-01 1.33079220e-05 3.50996379e-06 3.29850212e-04\n",
      " 2.45083502e-05 9.89579976e-01 9.25053179e-01 7.53396444e-06\n",
      " 2.25107215e-06 1.23913371e-04 2.54445136e-01 3.95582803e-02\n",
      " 1.43974945e-01 1.59143738e-03 7.04763889e-01 7.02020109e-01\n",
      " 9.47014511e-01 2.03765735e-01 9.57542121e-01 6.02549524e-04\n",
      " 3.46499472e-03 1.26510602e-03 1.07714273e-02 3.37755377e-03\n",
      " 9.40113068e-01 1.30246235e-07 1.75111069e-04 5.28343860e-03\n",
      " 9.92338181e-01 9.94703352e-01 9.99717057e-01 9.99197781e-01\n",
      " 9.99972820e-01 9.96545494e-01 9.94786024e-01 9.99998212e-01\n",
      " 9.99863267e-01 9.96825337e-01 9.15595293e-01 5.62893093e-01\n",
      " 9.14519250e-01 9.86949384e-01 9.90990162e-01 3.45861971e-01\n",
      " 9.99852896e-01 9.98867393e-01 9.99961257e-01 9.97651279e-01\n",
      " 9.99884009e-01 9.99641180e-01 9.99913096e-01 9.95236218e-01\n",
      " 8.97827148e-01 9.99951959e-01 9.97574151e-01 9.92243230e-01\n",
      " 5.63905239e-02 9.85884905e-01 9.99813497e-01 9.07224119e-01\n",
      " 8.30610573e-01 9.99998212e-01 9.99513984e-01 9.99989748e-01\n",
      " 1.49407789e-01 9.77980256e-01 9.98837292e-01 9.99427080e-01\n",
      " 2.86373526e-01 9.71522033e-01 2.67509967e-01 9.87648249e-01\n",
      " 9.06899989e-01 9.94404912e-01 9.94315684e-01 6.36215866e-01\n",
      " 5.05426936e-02 9.06544387e-01 9.95760620e-01 9.68301952e-01\n",
      " 9.99799669e-01 7.00289428e-01 2.43618595e-03 4.26973391e-04\n",
      " 9.99920726e-01 9.98552382e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 76 [0/107 (0%)]\tTrain Loss: 0.000767\n",
      "Train Epoch: 76 [4/107 (4%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 76 [8/107 (7%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 76 [12/107 (11%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 76 [16/107 (15%)]\tTrain Loss: 0.001355\n",
      "Train Epoch: 76 [20/107 (19%)]\tTrain Loss: 0.000869\n",
      "Train Epoch: 76 [24/107 (22%)]\tTrain Loss: 0.001262\n",
      "Train Epoch: 76 [28/107 (26%)]\tTrain Loss: 0.001032\n",
      "Train Epoch: 76 [32/107 (30%)]\tTrain Loss: 0.000141\n",
      "Train Epoch: 76 [36/107 (34%)]\tTrain Loss: 0.000441\n",
      "Train Epoch: 76 [40/107 (37%)]\tTrain Loss: 0.000243\n",
      "Train Epoch: 76 [44/107 (41%)]\tTrain Loss: 0.000910\n",
      "Train Epoch: 76 [48/107 (45%)]\tTrain Loss: 0.000253\n",
      "Train Epoch: 76 [52/107 (49%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 76 [56/107 (52%)]\tTrain Loss: 0.000178\n",
      "Train Epoch: 76 [60/107 (56%)]\tTrain Loss: 0.000209\n",
      "Train Epoch: 76 [64/107 (60%)]\tTrain Loss: 0.000578\n",
      "Train Epoch: 76 [68/107 (64%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 76 [72/107 (67%)]\tTrain Loss: 0.000475\n",
      "Train Epoch: 76 [76/107 (71%)]\tTrain Loss: 0.001776\n",
      "Train Epoch: 76 [80/107 (75%)]\tTrain Loss: 0.001356\n",
      "Train Epoch: 76 [84/107 (79%)]\tTrain Loss: 0.000144\n",
      "Train Epoch: 76 [88/107 (82%)]\tTrain Loss: 0.000373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 76 [92/107 (86%)]\tTrain Loss: 0.000144\n",
      "Train Epoch: 76 [96/107 (90%)]\tTrain Loss: 0.000650\n",
      "Train Epoch: 76 [100/107 (93%)]\tTrain Loss: 0.001032\n",
      "Train Epoch: 76 [104/107 (97%)]\tTrain Loss: 0.000016\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.77209687e-02 9.98102844e-01 3.31611112e-02 3.05555731e-01\n",
      " 2.99342889e-02 2.87140277e-03 9.04032886e-01 1.10514663e-01\n",
      " 9.38218646e-03 2.92182025e-02 4.31466401e-01 8.98992439e-05\n",
      " 3.89647871e-01 7.07377912e-03 3.75367738e-02 2.96870385e-05\n",
      " 6.82498376e-06 7.49856532e-01 2.97287037e-03 2.69657727e-02\n",
      " 1.57457799e-01 9.66032624e-01 9.99814570e-01 9.99975085e-01\n",
      " 7.19843507e-01 9.99535561e-01 9.99946713e-01 2.44884476e-01\n",
      " 1.43166900e-01 3.55315802e-04 1.81524575e-01 2.11594086e-02\n",
      " 7.65267491e-01 1.40621723e-05 8.55191320e-06 2.71143625e-04\n",
      " 2.80752138e-05 9.92833138e-01 9.24547791e-01 1.22914307e-05\n",
      " 5.60620356e-06 1.23339210e-04 4.85280186e-01 8.30905810e-02\n",
      " 5.02179146e-01 1.10835275e-02 8.63300502e-01 7.40140498e-01\n",
      " 9.77905214e-01 3.82275462e-01 9.82109666e-01 6.97685580e-04\n",
      " 1.11663593e-02 3.08717508e-03 1.92145370e-02 7.57144485e-03\n",
      " 9.83413756e-01 1.02116751e-07 2.09907259e-04 1.64239891e-02\n",
      " 9.98862624e-01 9.99102116e-01 9.99968052e-01 9.99940276e-01\n",
      " 9.99994993e-01 9.99501109e-01 9.98945534e-01 9.99999762e-01\n",
      " 9.99981165e-01 9.99309659e-01 9.67240512e-01 8.75511289e-01\n",
      " 9.77187812e-01 9.98046517e-01 9.99202311e-01 8.22653949e-01\n",
      " 9.99965429e-01 9.99877691e-01 9.99990225e-01 9.99626517e-01\n",
      " 9.99989390e-01 9.99954224e-01 9.99990702e-01 9.97231901e-01\n",
      " 9.29563522e-01 9.99988198e-01 9.99500155e-01 9.98905540e-01\n",
      " 7.67583326e-02 9.97460186e-01 9.99946356e-01 9.57677662e-01\n",
      " 9.49072421e-01 9.99999762e-01 9.99928236e-01 9.99998689e-01\n",
      " 3.06441575e-01 9.74330544e-01 9.99416709e-01 9.99843478e-01\n",
      " 3.54280680e-01 9.92967844e-01 4.45858002e-01 9.97670949e-01\n",
      " 9.81289804e-01 9.99243498e-01 9.98090446e-01 5.67201614e-01\n",
      " 8.81007761e-02 9.55883920e-01 9.90244091e-01 9.79761958e-01\n",
      " 9.99960780e-01 7.68573225e-01 1.04209185e-02 1.12611218e-03\n",
      " 9.99993205e-01 9.99455869e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 77 [0/107 (0%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 77 [4/107 (4%)]\tTrain Loss: 0.000632\n",
      "Train Epoch: 77 [8/107 (7%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 77 [12/107 (11%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 77 [16/107 (15%)]\tTrain Loss: 0.000849\n",
      "Train Epoch: 77 [20/107 (19%)]\tTrain Loss: 0.000152\n",
      "Train Epoch: 77 [24/107 (22%)]\tTrain Loss: 0.000254\n",
      "Train Epoch: 77 [28/107 (26%)]\tTrain Loss: 0.000462\n",
      "Train Epoch: 77 [32/107 (30%)]\tTrain Loss: 0.000307\n",
      "Train Epoch: 77 [36/107 (34%)]\tTrain Loss: 0.002367\n",
      "Train Epoch: 77 [40/107 (37%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 77 [44/107 (41%)]\tTrain Loss: 0.000355\n",
      "Train Epoch: 77 [48/107 (45%)]\tTrain Loss: 0.000298\n",
      "Train Epoch: 77 [52/107 (49%)]\tTrain Loss: 0.000129\n",
      "Train Epoch: 77 [56/107 (52%)]\tTrain Loss: 0.001225\n",
      "Train Epoch: 77 [60/107 (56%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 77 [64/107 (60%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 77 [68/107 (64%)]\tTrain Loss: 0.000128\n",
      "Train Epoch: 77 [72/107 (67%)]\tTrain Loss: 0.000256\n",
      "Train Epoch: 77 [76/107 (71%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 77 [80/107 (75%)]\tTrain Loss: 0.004485\n",
      "Train Epoch: 77 [84/107 (79%)]\tTrain Loss: 0.000437\n",
      "Train Epoch: 77 [88/107 (82%)]\tTrain Loss: 0.000137\n",
      "Train Epoch: 77 [92/107 (86%)]\tTrain Loss: 0.000710\n",
      "Train Epoch: 77 [96/107 (90%)]\tTrain Loss: 0.000175\n",
      "Train Epoch: 77 [100/107 (93%)]\tTrain Loss: 0.000258\n",
      "Train Epoch: 77 [104/107 (97%)]\tTrain Loss: 0.000007\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.75744331e-03 9.97073650e-01 1.26363393e-02 1.56037048e-01\n",
      " 8.41785315e-03 6.25852961e-04 4.94626462e-01 4.06214744e-02\n",
      " 3.75552918e-03 1.71047002e-02 1.95834965e-01 6.28919297e-05\n",
      " 2.13123724e-01 9.34054551e-04 1.27322748e-02 2.07278094e-06\n",
      " 1.82868078e-07 5.50567508e-01 5.77296771e-04 1.37156909e-02\n",
      " 3.66676338e-02 8.21094513e-01 9.99245763e-01 9.99981523e-01\n",
      " 3.47870082e-01 9.99340594e-01 9.99960780e-01 6.03070967e-02\n",
      " 2.43826117e-02 1.42810808e-04 7.40654469e-02 3.00523359e-03\n",
      " 6.24981999e-01 1.72785803e-06 5.19243770e-07 3.16842597e-05\n",
      " 5.89392766e-06 9.88352239e-01 8.55177939e-01 4.94946335e-07\n",
      " 2.93681239e-07 8.05794662e-06 1.20930903e-01 1.19401356e-02\n",
      " 2.94487774e-01 1.04301807e-03 7.08454072e-01 5.86926043e-01\n",
      " 9.72698569e-01 2.27736756e-01 9.85345840e-01 1.85654950e-04\n",
      " 2.96398252e-03 8.46721989e-04 2.82751233e-03 2.09320011e-03\n",
      " 9.91557717e-01 1.42251206e-08 7.84349322e-05 3.68045829e-03\n",
      " 9.99343574e-01 9.99562204e-01 9.99976158e-01 9.99954700e-01\n",
      " 9.99995828e-01 9.99115765e-01 9.98114824e-01 9.99999762e-01\n",
      " 9.99974132e-01 9.99359787e-01 9.19866741e-01 7.66188562e-01\n",
      " 9.67351377e-01 9.96475041e-01 9.99447167e-01 4.49899524e-01\n",
      " 9.99938846e-01 9.99768555e-01 9.99987721e-01 9.98861551e-01\n",
      " 9.99972463e-01 9.99933362e-01 9.99990225e-01 9.95257556e-01\n",
      " 8.73802602e-01 9.99993801e-01 9.99356925e-01 9.98632729e-01\n",
      " 2.63210945e-02 9.91666615e-01 9.99817431e-01 9.42654729e-01\n",
      " 8.66459608e-01 9.99999762e-01 9.99898314e-01 9.99992967e-01\n",
      " 1.45258620e-01 9.44022536e-01 9.99060214e-01 9.99444544e-01\n",
      " 9.86248702e-02 9.79478121e-01 7.92072341e-02 9.89299417e-01\n",
      " 9.28367674e-01 9.97929215e-01 9.96139586e-01 2.49170274e-01\n",
      " 2.13132165e-02 9.08810019e-01 8.84437263e-01 9.41720903e-01\n",
      " 9.99897003e-01 2.65187770e-01 1.26722711e-03 1.04227729e-04\n",
      " 9.99983311e-01 9.99464810e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 78 [0/107 (0%)]\tTrain Loss: 0.000144\n",
      "Train Epoch: 78 [4/107 (4%)]\tTrain Loss: 0.000735\n",
      "Train Epoch: 78 [8/107 (7%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 78 [12/107 (11%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 78 [16/107 (15%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 78 [20/107 (19%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 78 [24/107 (22%)]\tTrain Loss: 0.000857\n",
      "Train Epoch: 78 [28/107 (26%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 78 [32/107 (30%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 78 [36/107 (34%)]\tTrain Loss: 0.000160\n",
      "Train Epoch: 78 [40/107 (37%)]\tTrain Loss: 0.024525\n",
      "Train Epoch: 78 [44/107 (41%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 78 [48/107 (45%)]\tTrain Loss: 0.010949\n",
      "Train Epoch: 78 [52/107 (49%)]\tTrain Loss: 0.000238\n",
      "Train Epoch: 78 [56/107 (52%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 78 [60/107 (56%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 78 [64/107 (60%)]\tTrain Loss: 0.001004\n",
      "Train Epoch: 78 [68/107 (64%)]\tTrain Loss: 0.000380\n",
      "Train Epoch: 78 [72/107 (67%)]\tTrain Loss: 0.003742\n",
      "Train Epoch: 78 [76/107 (71%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 78 [80/107 (75%)]\tTrain Loss: 0.001897\n",
      "Train Epoch: 78 [84/107 (79%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 78 [88/107 (82%)]\tTrain Loss: 0.000638\n",
      "Train Epoch: 78 [92/107 (86%)]\tTrain Loss: 0.002429\n",
      "Train Epoch: 78 [96/107 (90%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 78 [100/107 (93%)]\tTrain Loss: 0.000339\n",
      "Train Epoch: 78 [104/107 (97%)]\tTrain Loss: 0.001162\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.56847069e-02 9.98707533e-01 1.09108508e-01 5.57904005e-01\n",
      " 7.09141120e-02 2.96893902e-03 9.75789070e-01 3.94699544e-01\n",
      " 7.33163441e-03 2.07041472e-01 7.67241836e-01 5.62236062e-04\n",
      " 7.28315234e-01 4.63859458e-03 1.15380310e-01 1.25684464e-05\n",
      " 1.70750372e-05 9.23128188e-01 6.05374277e-02 5.70427515e-02\n",
      " 1.97235927e-01 9.91794765e-01 9.99992728e-01 9.99990582e-01\n",
      " 9.52839434e-01 9.99942899e-01 9.99941707e-01 3.70442271e-01\n",
      " 8.38954031e-01 1.41486013e-03 7.49255598e-01 8.20694491e-02\n",
      " 9.24126744e-01 4.68434882e-05 1.59789670e-05 3.70563241e-04\n",
      " 2.61759385e-04 9.98549521e-01 9.73042488e-01 1.50696906e-05\n",
      " 6.34291609e-06 2.17010136e-04 9.09391940e-01 3.63408267e-01\n",
      " 9.19961870e-01 2.41782889e-02 9.68724430e-01 9.32527006e-01\n",
      " 9.80655551e-01 4.41078931e-01 9.86973882e-01 2.24151020e-03\n",
      " 3.29480618e-02 8.74385796e-03 2.00501710e-01 3.97362858e-02\n",
      " 9.95383799e-01 6.90507193e-07 7.26371713e-04 3.41432355e-02\n",
      " 9.99569595e-01 9.99782383e-01 9.99986291e-01 9.99970198e-01\n",
      " 9.99997616e-01 9.99741971e-01 9.99645114e-01 1.00000000e+00\n",
      " 9.99988437e-01 9.99599040e-01 9.58173990e-01 9.22346115e-01\n",
      " 9.86196816e-01 9.98712897e-01 9.99750197e-01 8.62296820e-01\n",
      " 9.99965906e-01 9.99878526e-01 9.99993682e-01 9.99764979e-01\n",
      " 9.99985576e-01 9.99909639e-01 9.99982715e-01 9.99493957e-01\n",
      " 9.83150661e-01 9.99994874e-01 9.99689341e-01 9.99169946e-01\n",
      " 1.22022532e-01 9.98364389e-01 9.99959946e-01 9.72435653e-01\n",
      " 9.76558566e-01 9.99999881e-01 9.99942660e-01 9.99999166e-01\n",
      " 4.42590922e-01 9.93196011e-01 9.99922991e-01 9.99782026e-01\n",
      " 5.40237427e-01 9.97310996e-01 7.10917890e-01 9.99257028e-01\n",
      " 9.94237900e-01 9.99337852e-01 9.98761892e-01 7.36870408e-01\n",
      " 1.25612244e-01 9.85260010e-01 9.96203721e-01 9.83996928e-01\n",
      " 9.99961853e-01 9.70531106e-01 8.43112450e-03 4.51645115e-03\n",
      " 9.99992371e-01 9.99871969e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79 [0/107 (0%)]\tTrain Loss: 0.000679\n",
      "Train Epoch: 79 [4/107 (4%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 79 [8/107 (7%)]\tTrain Loss: 0.001202\n",
      "Train Epoch: 79 [12/107 (11%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 79 [16/107 (15%)]\tTrain Loss: 0.006083\n",
      "Train Epoch: 79 [20/107 (19%)]\tTrain Loss: 0.000166\n",
      "Train Epoch: 79 [24/107 (22%)]\tTrain Loss: 0.000364\n",
      "Train Epoch: 79 [28/107 (26%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 79 [32/107 (30%)]\tTrain Loss: 0.008773\n",
      "Train Epoch: 79 [36/107 (34%)]\tTrain Loss: 0.000152\n",
      "Train Epoch: 79 [40/107 (37%)]\tTrain Loss: 0.000492\n",
      "Train Epoch: 79 [44/107 (41%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 79 [48/107 (45%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 79 [52/107 (49%)]\tTrain Loss: 0.000123\n",
      "Train Epoch: 79 [56/107 (52%)]\tTrain Loss: 0.001016\n",
      "Train Epoch: 79 [60/107 (56%)]\tTrain Loss: 0.000068\n",
      "Train Epoch: 79 [64/107 (60%)]\tTrain Loss: 0.000417\n",
      "Train Epoch: 79 [68/107 (64%)]\tTrain Loss: 0.000261\n",
      "Train Epoch: 79 [72/107 (67%)]\tTrain Loss: 0.000227\n",
      "Train Epoch: 79 [76/107 (71%)]\tTrain Loss: 0.025660\n",
      "Train Epoch: 79 [80/107 (75%)]\tTrain Loss: 0.000554\n",
      "Train Epoch: 79 [84/107 (79%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 79 [88/107 (82%)]\tTrain Loss: 0.000502\n",
      "Train Epoch: 79 [92/107 (86%)]\tTrain Loss: 0.000105\n",
      "Train Epoch: 79 [96/107 (90%)]\tTrain Loss: 0.025011\n",
      "Train Epoch: 79 [100/107 (93%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 79 [104/107 (97%)]\tTrain Loss: 0.000417\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.90120393e-02 9.97725070e-01 6.81212544e-01 3.52775425e-01\n",
      " 4.47311662e-02 2.93089566e-03 9.89849925e-01 1.79823697e-01\n",
      " 5.04593598e-03 1.11298375e-01 7.96039581e-01 1.12508889e-04\n",
      " 6.74531996e-01 6.51689991e-03 8.97853523e-02 1.13682026e-05\n",
      " 7.93473009e-06 8.02264750e-01 3.08815300e-01 6.78950846e-01\n",
      " 8.46620262e-01 9.93214250e-01 9.99985099e-01 9.99961853e-01\n",
      " 9.69274879e-01 9.99786794e-01 9.99587595e-01 7.90600181e-01\n",
      " 9.23466921e-01 1.76086966e-02 9.11455691e-01 2.93826222e-01\n",
      " 9.73513722e-01 1.89744551e-05 4.11552992e-06 1.20703736e-03\n",
      " 1.38203788e-04 9.97712612e-01 9.80918825e-01 2.05417418e-05\n",
      " 8.91451873e-06 5.71483630e-04 9.15098965e-01 4.22872901e-01\n",
      " 9.72543657e-01 2.94975154e-02 9.63553488e-01 9.34802592e-01\n",
      " 9.83104527e-01 3.23360682e-01 9.81571496e-01 1.42193679e-03\n",
      " 2.02380288e-02 2.82421662e-03 3.46403956e-01 9.07001738e-03\n",
      " 9.91275191e-01 1.38290517e-07 2.15289678e-04 1.28463497e-02\n",
      " 9.99768198e-01 9.99823749e-01 9.99982595e-01 9.99982238e-01\n",
      " 9.99992728e-01 9.98910308e-01 9.97563481e-01 9.99999523e-01\n",
      " 9.99960065e-01 9.99214172e-01 9.78369892e-01 9.64507043e-01\n",
      " 9.82898116e-01 9.98606145e-01 9.99645948e-01 9.94339168e-01\n",
      " 9.99980927e-01 9.99887466e-01 9.99994397e-01 9.99873281e-01\n",
      " 9.99988794e-01 9.99951720e-01 9.99973655e-01 9.99059975e-01\n",
      " 9.94846344e-01 9.99994040e-01 9.99338686e-01 9.99020934e-01\n",
      " 8.09240818e-01 9.94839013e-01 9.99870062e-01 9.78724301e-01\n",
      " 9.46577847e-01 9.99999642e-01 9.99782979e-01 9.99993324e-01\n",
      " 2.70265281e-01 9.97331023e-01 9.99956131e-01 9.99722302e-01\n",
      " 7.35543966e-01 9.98094618e-01 8.64785492e-01 9.98100579e-01\n",
      " 9.89592075e-01 9.99029994e-01 9.98463273e-01 8.47332537e-01\n",
      " 3.46846953e-02 9.79931235e-01 9.94634509e-01 9.54026043e-01\n",
      " 9.99527693e-01 9.56176579e-01 4.51316945e-02 1.08331561e-01\n",
      " 9.99953747e-01 9.99857426e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 80 [0/107 (0%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 80 [4/107 (4%)]\tTrain Loss: 0.000495\n",
      "Train Epoch: 80 [8/107 (7%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 80 [12/107 (11%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 80 [16/107 (15%)]\tTrain Loss: 0.000060\n",
      "Train Epoch: 80 [20/107 (19%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 80 [24/107 (22%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 80 [28/107 (26%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 80 [32/107 (30%)]\tTrain Loss: 0.000196\n",
      "Train Epoch: 80 [36/107 (34%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 80 [40/107 (37%)]\tTrain Loss: 0.000134\n",
      "Train Epoch: 80 [44/107 (41%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 80 [48/107 (45%)]\tTrain Loss: 0.000424\n",
      "Train Epoch: 80 [52/107 (49%)]\tTrain Loss: 0.000224\n",
      "Train Epoch: 80 [56/107 (52%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 80 [60/107 (56%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 80 [64/107 (60%)]\tTrain Loss: 0.000260\n",
      "Train Epoch: 80 [68/107 (64%)]\tTrain Loss: 0.000370\n",
      "Train Epoch: 80 [72/107 (67%)]\tTrain Loss: 0.000317\n",
      "Train Epoch: 80 [76/107 (71%)]\tTrain Loss: 0.000911\n",
      "Train Epoch: 80 [80/107 (75%)]\tTrain Loss: 0.001938\n",
      "Train Epoch: 80 [84/107 (79%)]\tTrain Loss: 0.000347\n",
      "Train Epoch: 80 [88/107 (82%)]\tTrain Loss: 0.002782\n",
      "Train Epoch: 80 [92/107 (86%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 80 [96/107 (90%)]\tTrain Loss: 0.000207\n",
      "Train Epoch: 80 [100/107 (93%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 80 [104/107 (97%)]\tTrain Loss: 0.000083\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.12258974e-04 9.71365571e-01 5.11043472e-03 1.25856455e-02\n",
      " 2.82509514e-04 1.46483770e-04 9.00024891e-01 4.84681409e-03\n",
      " 1.76320507e-04 4.60775290e-03 3.25728387e-01 3.71344890e-06\n",
      " 1.32535487e-01 3.50665687e-05 1.17609417e-03 1.86701698e-07\n",
      " 1.11518077e-07 1.44000188e-01 1.30413165e-02 2.40275249e-01\n",
      " 5.38964808e-01 8.64581764e-01 9.99960303e-01 9.99938130e-01\n",
      " 7.74081707e-01 9.99522567e-01 9.99542236e-01 4.26231213e-02\n",
      " 2.70900339e-01 1.01654627e-03 7.54454583e-02 3.54130706e-03\n",
      " 7.65530050e-01 1.25637854e-07 6.68583837e-08 1.71641714e-05\n",
      " 8.70342683e-06 9.61165667e-01 3.00887555e-01 3.84084160e-07\n",
      " 1.86043351e-07 7.29763087e-06 1.21048696e-01 3.09037361e-02\n",
      " 5.72780013e-01 1.97027135e-03 4.51330245e-01 4.06210661e-01\n",
      " 6.43916309e-01 6.46457076e-02 6.33774221e-01 2.25585391e-05\n",
      " 2.37550077e-04 3.35124096e-05 1.74628962e-02 6.72708731e-04\n",
      " 9.37129915e-01 1.47740975e-09 1.75961832e-05 1.42974453e-03\n",
      " 9.91870165e-01 9.95227456e-01 9.99662280e-01 9.99755681e-01\n",
      " 9.99977708e-01 9.88332331e-01 9.81706202e-01 9.99999046e-01\n",
      " 9.99853373e-01 9.95047569e-01 5.11978805e-01 1.86443731e-01\n",
      " 6.78119302e-01 9.81953084e-01 9.95504200e-01 9.01505232e-01\n",
      " 9.99857306e-01 9.98366296e-01 9.99985099e-01 9.98531342e-01\n",
      " 9.99969363e-01 9.99690056e-01 9.99904156e-01 9.91873205e-01\n",
      " 8.10747623e-01 9.99856234e-01 9.97240901e-01 9.93683815e-01\n",
      " 6.41863421e-02 9.20138896e-01 9.99652267e-01 7.92305410e-01\n",
      " 6.61380410e-01 9.99998927e-01 9.99042213e-01 9.99973893e-01\n",
      " 1.23096786e-01 7.06049740e-01 9.99470174e-01 9.98680413e-01\n",
      " 6.60826936e-02 8.62859428e-01 5.51732033e-02 9.72935855e-01\n",
      " 6.33478284e-01 9.94269967e-01 9.77014482e-01 1.39432296e-01\n",
      " 3.88347660e-04 7.88739383e-01 9.06469584e-01 5.24541140e-01\n",
      " 9.98725235e-01 5.74567080e-01 6.92223897e-03 1.42998500e-02\n",
      " 9.98841465e-01 9.98536468e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 50 TN= 42 FN= 8 FP= 18\n",
      "TP+FP 68\n",
      "precision 0.7352941176470589\n",
      "recall 0.8620689655172413\n",
      "F1 0.7936507936507937\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7810344827586206\n",
      "AUC 0.863793103448276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 80, average recall: 0.8621, average precision: 0.7353,average F1: 0.7937, average accuracy: 0.7797, average AUC: 0.8638\n",
      "Train Epoch: 81 [0/107 (0%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 81 [4/107 (4%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 81 [8/107 (7%)]\tTrain Loss: 0.000092\n",
      "Train Epoch: 81 [12/107 (11%)]\tTrain Loss: 0.000322\n",
      "Train Epoch: 81 [16/107 (15%)]\tTrain Loss: 0.000225\n",
      "Train Epoch: 81 [20/107 (19%)]\tTrain Loss: 0.000688\n",
      "Train Epoch: 81 [24/107 (22%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 81 [28/107 (26%)]\tTrain Loss: 0.000123\n",
      "Train Epoch: 81 [32/107 (30%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 81 [36/107 (34%)]\tTrain Loss: 0.000377\n",
      "Train Epoch: 81 [40/107 (37%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 81 [44/107 (41%)]\tTrain Loss: 0.000608\n",
      "Train Epoch: 81 [48/107 (45%)]\tTrain Loss: 0.000097\n",
      "Train Epoch: 81 [52/107 (49%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 81 [56/107 (52%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 81 [60/107 (56%)]\tTrain Loss: 0.000268\n",
      "Train Epoch: 81 [64/107 (60%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 81 [68/107 (64%)]\tTrain Loss: 0.002919\n",
      "Train Epoch: 81 [72/107 (67%)]\tTrain Loss: 0.000870\n",
      "Train Epoch: 81 [76/107 (71%)]\tTrain Loss: 0.000122\n",
      "Train Epoch: 81 [80/107 (75%)]\tTrain Loss: 0.000174\n",
      "Train Epoch: 81 [84/107 (79%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 81 [88/107 (82%)]\tTrain Loss: 0.000212\n",
      "Train Epoch: 81 [92/107 (86%)]\tTrain Loss: 0.009384\n",
      "Train Epoch: 81 [96/107 (90%)]\tTrain Loss: 0.000952\n",
      "Train Epoch: 81 [100/107 (93%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 81 [104/107 (97%)]\tTrain Loss: 0.000113\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.39176846e-02 9.91604507e-01 2.25152094e-02 2.02145055e-02\n",
      " 1.78770907e-02 1.32448215e-03 9.05294955e-01 3.28088589e-02\n",
      " 8.18059430e-04 1.66170429e-02 2.20279276e-01 3.05989488e-05\n",
      " 2.82246649e-01 3.04587011e-04 7.62942387e-03 6.82381942e-05\n",
      " 3.07830378e-05 1.92955226e-01 1.61970388e-02 9.81795341e-02\n",
      " 2.23945543e-01 9.84230220e-01 9.99842763e-01 9.99971032e-01\n",
      " 9.44378257e-01 9.99629378e-01 9.99916911e-01 3.73301059e-02\n",
      " 3.21391821e-01 1.10914093e-03 6.41325474e-01 1.45681500e-02\n",
      " 8.95156741e-01 3.74540032e-05 1.35691116e-05 8.50806362e-04\n",
      " 2.73466081e-04 9.77141440e-01 9.13285732e-01 2.23096831e-05\n",
      " 9.44048406e-06 2.22227754e-04 7.64495373e-01 2.84353852e-01\n",
      " 6.10966563e-01 4.06291755e-03 9.05699432e-01 9.46373165e-01\n",
      " 9.70895946e-01 2.11590379e-01 9.56681728e-01 8.26519245e-05\n",
      " 1.99826038e-03 1.86127581e-04 6.19221106e-02 2.13517807e-03\n",
      " 9.71143901e-01 1.45390416e-07 7.44459976e-05 5.10571711e-03\n",
      " 9.98665452e-01 9.98427510e-01 9.99885201e-01 9.99813616e-01\n",
      " 9.99985576e-01 9.97056961e-01 9.94829237e-01 9.99998808e-01\n",
      " 9.99961138e-01 9.99561369e-01 7.25925446e-01 3.58133823e-01\n",
      " 9.43708599e-01 9.97221470e-01 9.98595655e-01 8.23639691e-01\n",
      " 9.99807417e-01 9.99541283e-01 9.99992728e-01 9.99029279e-01\n",
      " 9.99989629e-01 9.99817312e-01 9.99961376e-01 9.94673848e-01\n",
      " 9.59829807e-01 9.99966025e-01 9.98492241e-01 9.97554958e-01\n",
      " 9.63820443e-02 9.99383569e-01 9.99837518e-01 9.55914557e-01\n",
      " 8.17456901e-01 9.99999762e-01 9.99869585e-01 9.99991059e-01\n",
      " 1.04135513e-01 9.26166117e-01 9.99806225e-01 9.99871373e-01\n",
      " 3.11439276e-01 9.87977743e-01 4.24028516e-01 9.96379793e-01\n",
      " 9.52908397e-01 9.95195568e-01 9.92140770e-01 7.01680958e-01\n",
      " 2.27789897e-02 8.87201011e-01 9.97543097e-01 9.76909757e-01\n",
      " 9.99914646e-01 8.57621074e-01 4.71062474e-02 7.32623041e-02\n",
      " 9.99844790e-01 9.99734461e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 82 [0/107 (0%)]\tTrain Loss: 0.001824\n",
      "Train Epoch: 82 [4/107 (4%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 82 [8/107 (7%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 82 [12/107 (11%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 82 [16/107 (15%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 82 [20/107 (19%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 82 [24/107 (22%)]\tTrain Loss: 0.000792\n",
      "Train Epoch: 82 [28/107 (26%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 82 [32/107 (30%)]\tTrain Loss: 0.001225\n",
      "Train Epoch: 82 [36/107 (34%)]\tTrain Loss: 0.011177\n",
      "Train Epoch: 82 [40/107 (37%)]\tTrain Loss: 0.000276\n",
      "Train Epoch: 82 [44/107 (41%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 82 [48/107 (45%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 82 [52/107 (49%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 82 [56/107 (52%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 82 [60/107 (56%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 82 [64/107 (60%)]\tTrain Loss: 0.004219\n",
      "Train Epoch: 82 [68/107 (64%)]\tTrain Loss: 0.001257\n",
      "Train Epoch: 82 [72/107 (67%)]\tTrain Loss: 0.002349\n",
      "Train Epoch: 82 [76/107 (71%)]\tTrain Loss: 0.000297\n",
      "Train Epoch: 82 [80/107 (75%)]\tTrain Loss: 0.000149\n",
      "Train Epoch: 82 [84/107 (79%)]\tTrain Loss: 0.002549\n",
      "Train Epoch: 82 [88/107 (82%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 82 [92/107 (86%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 82 [96/107 (90%)]\tTrain Loss: 0.000204\n",
      "Train Epoch: 82 [100/107 (93%)]\tTrain Loss: 0.000130\n",
      "Train Epoch: 82 [104/107 (97%)]\tTrain Loss: 0.000103\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.99280216e-03 9.44212139e-01 6.82331109e-03 1.04777133e-02\n",
      " 3.81876086e-03 3.91875423e-04 5.83601117e-01 1.59344170e-02\n",
      " 3.45146866e-04 2.09698360e-03 1.20560624e-01 3.67527173e-06\n",
      " 9.28209051e-02 2.36278011e-05 2.30707740e-03 4.25352619e-06\n",
      " 4.45282893e-07 4.58351569e-03 1.95762957e-03 4.36162017e-02\n",
      " 3.89106609e-02 9.13233638e-01 9.97775018e-01 9.99760568e-01\n",
      " 6.93800569e-01 9.95998979e-01 9.98598397e-01 2.97433604e-03\n",
      " 1.07665407e-02 4.48198087e-04 5.52471802e-02 4.84946836e-03\n",
      " 7.70782769e-01 2.28884869e-06 4.25483080e-07 9.57495286e-05\n",
      " 9.17117432e-05 8.35281193e-01 4.70166951e-01 1.89243769e-06\n",
      " 9.56589133e-07 1.56199603e-05 1.22347273e-01 9.59156230e-02\n",
      " 1.76618919e-01 1.11411698e-03 6.27062917e-01 8.34535599e-01\n",
      " 9.06059802e-01 3.85361463e-02 8.42052519e-01 6.82971731e-05\n",
      " 2.35228406e-04 3.69994013e-05 1.14091975e-03 3.29787901e-04\n",
      " 9.21029031e-01 1.16219470e-08 5.50497243e-05 6.13933371e-04\n",
      " 9.94391501e-01 9.94148254e-01 9.99577224e-01 9.99419332e-01\n",
      " 9.99937057e-01 9.77931023e-01 9.55556095e-01 9.99982119e-01\n",
      " 9.99674439e-01 9.97350216e-01 5.30043900e-01 1.34275660e-01\n",
      " 7.38342822e-01 9.86290753e-01 9.84921396e-01 1.75750494e-01\n",
      " 9.99324083e-01 9.97291625e-01 9.99933124e-01 9.90429282e-01\n",
      " 9.99875903e-01 9.95624244e-01 9.99642372e-01 9.75968003e-01\n",
      " 6.90465391e-01 9.99650359e-01 9.92281854e-01 9.85637248e-01\n",
      " 1.23302117e-02 9.77682412e-01 9.95325565e-01 7.37863600e-01\n",
      " 3.48463535e-01 9.99995828e-01 9.98035491e-01 9.99705017e-01\n",
      " 3.22614089e-02 3.61919284e-01 9.99038696e-01 9.98549521e-01\n",
      " 4.78204563e-02 9.31945562e-01 5.19100726e-02 8.39448392e-01\n",
      " 6.87155783e-01 9.10547078e-01 9.77149665e-01 3.53730261e-01\n",
      " 3.82896466e-03 6.06983423e-01 9.86245751e-01 8.33708584e-01\n",
      " 9.98831570e-01 1.13831662e-01 7.18598114e-03 5.91606600e-03\n",
      " 9.97728884e-01 9.98339891e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 83 [0/107 (0%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 83 [4/107 (4%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 83 [8/107 (7%)]\tTrain Loss: 0.000351\n",
      "Train Epoch: 83 [12/107 (11%)]\tTrain Loss: 0.000035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [16/107 (15%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 83 [20/107 (19%)]\tTrain Loss: 0.001595\n",
      "Train Epoch: 83 [24/107 (22%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 83 [28/107 (26%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 83 [32/107 (30%)]\tTrain Loss: 0.005706\n",
      "Train Epoch: 83 [36/107 (34%)]\tTrain Loss: 0.000461\n",
      "Train Epoch: 83 [40/107 (37%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 83 [44/107 (41%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 83 [48/107 (45%)]\tTrain Loss: 0.001141\n",
      "Train Epoch: 83 [52/107 (49%)]\tTrain Loss: 0.000519\n",
      "Train Epoch: 83 [56/107 (52%)]\tTrain Loss: 0.001277\n",
      "Train Epoch: 83 [60/107 (56%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 83 [64/107 (60%)]\tTrain Loss: 0.000092\n",
      "Train Epoch: 83 [68/107 (64%)]\tTrain Loss: 0.007838\n",
      "Train Epoch: 83 [72/107 (67%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 83 [76/107 (71%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 83 [80/107 (75%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 83 [84/107 (79%)]\tTrain Loss: 0.000624\n",
      "Train Epoch: 83 [88/107 (82%)]\tTrain Loss: 0.000801\n",
      "Train Epoch: 83 [92/107 (86%)]\tTrain Loss: 0.000185\n",
      "Train Epoch: 83 [96/107 (90%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 83 [100/107 (93%)]\tTrain Loss: 0.000092\n",
      "Train Epoch: 83 [104/107 (97%)]\tTrain Loss: 0.012134\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.04100297e-03 9.25920248e-01 9.62489401e-04 9.24596563e-03\n",
      " 1.31643109e-03 1.51085871e-04 1.51803941e-01 1.58377755e-02\n",
      " 2.44895404e-04 6.56102225e-03 1.17056489e-01 3.89585966e-06\n",
      " 7.19145089e-02 2.73474780e-05 9.94333299e-04 3.67060943e-06\n",
      " 2.16900321e-06 5.46957776e-02 8.71030788e-04 2.45772321e-02\n",
      " 3.89524065e-02 9.37092781e-01 9.99193966e-01 9.99947071e-01\n",
      " 8.80646586e-01 9.97356772e-01 9.99506354e-01 3.41629772e-03\n",
      " 3.08239888e-02 1.05649633e-04 2.53940430e-02 1.48699176e-03\n",
      " 3.43653053e-01 1.53617054e-06 6.58354566e-07 4.17224328e-05\n",
      " 3.62314422e-05 9.23766375e-01 4.78857517e-01 9.80427103e-07\n",
      " 4.15495208e-07 9.30676379e-06 2.21702129e-01 5.12231700e-02\n",
      " 1.13984436e-01 8.61698471e-04 6.92464471e-01 7.25327730e-01\n",
      " 8.59289825e-01 4.57497910e-02 8.21652710e-01 3.90060995e-05\n",
      " 5.08964120e-04 8.70954173e-05 3.11476481e-03 4.97840461e-04\n",
      " 8.92945647e-01 1.19805348e-08 5.60383196e-05 2.23373459e-03\n",
      " 9.95865226e-01 9.95249629e-01 9.99728501e-01 9.99467790e-01\n",
      " 9.99963403e-01 9.88235712e-01 9.86485481e-01 9.99996066e-01\n",
      " 9.99933362e-01 9.97129142e-01 4.47050363e-01 1.02259174e-01\n",
      " 7.86565304e-01 9.88002896e-01 9.90050614e-01 4.87989873e-01\n",
      " 9.99191225e-01 9.94741440e-01 9.99986172e-01 9.93126750e-01\n",
      " 9.99964714e-01 9.99135315e-01 9.99897838e-01 9.81784225e-01\n",
      " 7.71643043e-01 9.99597251e-01 9.96215522e-01 9.78999376e-01\n",
      " 7.51082972e-03 9.96192217e-01 9.98422742e-01 6.14637434e-01\n",
      " 5.06145179e-01 9.99999881e-01 9.99822199e-01 9.99983668e-01\n",
      " 1.32029459e-01 6.23670876e-01 9.99239564e-01 9.99283373e-01\n",
      " 4.48093824e-02 8.80135655e-01 3.47060002e-02 9.90868449e-01\n",
      " 8.19043636e-01 9.89092112e-01 9.58643138e-01 3.90050709e-01\n",
      " 4.62311367e-03 5.54702640e-01 9.85590279e-01 8.78164470e-01\n",
      " 9.99814332e-01 3.98389041e-01 1.35247433e-03 1.52479671e-03\n",
      " 9.99736488e-01 9.99406338e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 84 [0/107 (0%)]\tTrain Loss: 0.001091\n",
      "Train Epoch: 84 [4/107 (4%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 84 [8/107 (7%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 84 [12/107 (11%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 84 [16/107 (15%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 84 [20/107 (19%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 84 [24/107 (22%)]\tTrain Loss: 0.000938\n",
      "Train Epoch: 84 [28/107 (26%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 84 [32/107 (30%)]\tTrain Loss: 0.000182\n",
      "Train Epoch: 84 [36/107 (34%)]\tTrain Loss: 0.000180\n",
      "Train Epoch: 84 [40/107 (37%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 84 [44/107 (41%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 84 [48/107 (45%)]\tTrain Loss: 0.000722\n",
      "Train Epoch: 84 [52/107 (49%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 84 [56/107 (52%)]\tTrain Loss: 0.011270\n",
      "Train Epoch: 84 [60/107 (56%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 84 [64/107 (60%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 84 [68/107 (64%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 84 [72/107 (67%)]\tTrain Loss: 0.000107\n",
      "Train Epoch: 84 [76/107 (71%)]\tTrain Loss: 0.000342\n",
      "Train Epoch: 84 [80/107 (75%)]\tTrain Loss: 0.006099\n",
      "Train Epoch: 84 [84/107 (79%)]\tTrain Loss: 0.000586\n",
      "Train Epoch: 84 [88/107 (82%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 84 [92/107 (86%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 84 [96/107 (90%)]\tTrain Loss: 0.006422\n",
      "Train Epoch: 84 [100/107 (93%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 84 [104/107 (97%)]\tTrain Loss: 0.000333\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.22879390e-03 9.96182024e-01 9.26752295e-03 3.00212186e-02\n",
      " 5.78224752e-03 4.87415557e-04 8.95422757e-01 3.50002758e-02\n",
      " 7.80516129e-04 2.22143494e-02 1.59640193e-01 1.00893631e-05\n",
      " 7.97960982e-02 1.02707636e-04 2.70098471e-03 1.45556605e-05\n",
      " 3.78676168e-06 2.66670644e-01 7.40591949e-03 6.10057004e-02\n",
      " 1.87874615e-01 9.92339253e-01 9.99933243e-01 9.99991298e-01\n",
      " 9.39270318e-01 9.99825656e-01 9.99983668e-01 1.95495337e-02\n",
      " 1.90487012e-01 1.36147006e-04 2.53893107e-01 7.96889048e-03\n",
      " 8.52311552e-01 1.38430676e-06 5.95723577e-07 8.72854216e-05\n",
      " 3.24022731e-05 9.90133047e-01 7.95795858e-01 1.69124189e-06\n",
      " 7.18452213e-07 1.61608186e-05 5.07402420e-01 2.60305852e-01\n",
      " 5.60530066e-01 1.56854501e-03 9.52638507e-01 9.26422358e-01\n",
      " 9.89362419e-01 1.71447411e-01 9.85509455e-01 9.42183688e-05\n",
      " 7.37239665e-04 3.74469499e-04 7.81636685e-03 1.39042700e-03\n",
      " 9.95710611e-01 1.80650854e-08 1.56128415e-04 4.08907467e-03\n",
      " 9.99801338e-01 9.99736130e-01 9.99992013e-01 9.99976754e-01\n",
      " 9.99997616e-01 9.99661565e-01 9.99546230e-01 1.00000000e+00\n",
      " 9.99996901e-01 9.99734581e-01 8.96760225e-01 2.63758630e-01\n",
      " 9.59309518e-01 9.98736918e-01 9.99600947e-01 8.88189971e-01\n",
      " 9.99958992e-01 9.99870539e-01 9.99998808e-01 9.99700427e-01\n",
      " 9.99998927e-01 9.99967456e-01 9.99996066e-01 9.98633683e-01\n",
      " 9.24799860e-01 9.99993205e-01 9.99550641e-01 9.99012351e-01\n",
      " 1.84218958e-02 9.99596059e-01 9.99923825e-01 9.50974524e-01\n",
      " 8.67493033e-01 1.00000000e+00 9.99985456e-01 9.99999285e-01\n",
      " 2.17990041e-01 8.50039303e-01 9.99932408e-01 9.99923110e-01\n",
      " 6.01319484e-02 9.85835433e-01 6.24408610e-02 9.98674631e-01\n",
      " 9.66381609e-01 9.98626351e-01 9.97879624e-01 5.34278989e-01\n",
      " 4.72551445e-03 9.15059566e-01 9.96110260e-01 9.58052933e-01\n",
      " 9.99974370e-01 7.02525556e-01 6.45624381e-03 8.80745985e-03\n",
      " 9.99986649e-01 9.99883294e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 85 [0/107 (0%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 85 [4/107 (4%)]\tTrain Loss: 0.000089\n",
      "Train Epoch: 85 [8/107 (7%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 85 [12/107 (11%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 85 [16/107 (15%)]\tTrain Loss: 0.000266\n",
      "Train Epoch: 85 [20/107 (19%)]\tTrain Loss: 0.000299\n",
      "Train Epoch: 85 [24/107 (22%)]\tTrain Loss: 0.000140\n",
      "Train Epoch: 85 [28/107 (26%)]\tTrain Loss: 0.000570\n",
      "Train Epoch: 85 [32/107 (30%)]\tTrain Loss: 0.003023\n",
      "Train Epoch: 85 [36/107 (34%)]\tTrain Loss: 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 85 [40/107 (37%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 85 [44/107 (41%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 85 [48/107 (45%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 85 [52/107 (49%)]\tTrain Loss: 0.000496\n",
      "Train Epoch: 85 [56/107 (52%)]\tTrain Loss: 0.000135\n",
      "Train Epoch: 85 [60/107 (56%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 85 [64/107 (60%)]\tTrain Loss: 0.000760\n",
      "Train Epoch: 85 [68/107 (64%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 85 [72/107 (67%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 85 [76/107 (71%)]\tTrain Loss: 0.000555\n",
      "Train Epoch: 85 [80/107 (75%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 85 [84/107 (79%)]\tTrain Loss: 0.001083\n",
      "Train Epoch: 85 [88/107 (82%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 85 [92/107 (86%)]\tTrain Loss: 0.000157\n",
      "Train Epoch: 85 [96/107 (90%)]\tTrain Loss: 0.001294\n",
      "Train Epoch: 85 [100/107 (93%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 85 [104/107 (97%)]\tTrain Loss: 0.000004\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.38402800e-02 9.96870816e-01 2.08091103e-02 4.74977717e-02\n",
      " 7.95470923e-03 1.56275765e-03 9.63952422e-01 2.52483506e-02\n",
      " 8.56243074e-04 1.08753238e-02 1.61469191e-01 1.36231301e-05\n",
      " 5.43874614e-02 5.66049188e-04 4.00797604e-03 6.65605767e-05\n",
      " 6.73151908e-06 1.63887039e-01 6.63801236e-03 9.82051566e-02\n",
      " 1.85130626e-01 9.76974308e-01 9.99682426e-01 9.99963880e-01\n",
      " 9.18888748e-01 9.99552786e-01 9.99959469e-01 2.32145917e-02\n",
      " 9.70602259e-02 2.20742091e-04 3.36956024e-01 1.23758717e-02\n",
      " 7.06583083e-01 5.23927383e-06 2.92738559e-06 3.46381450e-04\n",
      " 1.04623752e-04 9.44796503e-01 7.58623064e-01 1.17570389e-05\n",
      " 6.20583069e-06 1.32516507e-04 3.52983922e-01 1.65583327e-01\n",
      " 3.62747163e-01 3.29129212e-03 8.96645367e-01 9.01127279e-01\n",
      " 9.63743865e-01 9.84203294e-02 9.57607031e-01 1.65920996e-04\n",
      " 3.98837123e-03 2.04532465e-04 2.57135611e-02 1.65116985e-03\n",
      " 9.84487832e-01 7.01893725e-08 1.12833237e-04 4.37182421e-03\n",
      " 9.99573052e-01 9.99606550e-01 9.99984503e-01 9.99956727e-01\n",
      " 9.99994755e-01 9.98464823e-01 9.97669280e-01 9.99999762e-01\n",
      " 9.99984264e-01 9.99397755e-01 8.63569319e-01 3.81461501e-01\n",
      " 9.40321803e-01 9.98325288e-01 9.98938262e-01 8.78226519e-01\n",
      " 9.99970198e-01 9.99723256e-01 9.99997973e-01 9.99243021e-01\n",
      " 9.99995708e-01 9.99895811e-01 9.99980569e-01 9.96486306e-01\n",
      " 8.73161674e-01 9.99969006e-01 9.99043524e-01 9.98384237e-01\n",
      " 2.60775257e-02 9.99417424e-01 9.99768317e-01 9.05146301e-01\n",
      " 7.34261572e-01 9.99999881e-01 9.99850631e-01 9.99994159e-01\n",
      " 9.55161825e-02 5.56912541e-01 9.99934196e-01 9.99831200e-01\n",
      " 2.98158258e-01 9.85132813e-01 1.79318160e-01 9.86058891e-01\n",
      " 9.30358768e-01 9.87586737e-01 9.94836569e-01 8.02413166e-01\n",
      " 1.02922162e-02 9.27065015e-01 9.97528374e-01 9.33614135e-01\n",
      " 9.99915719e-01 6.08247519e-01 2.26435289e-02 9.50736087e-03\n",
      " 9.99958754e-01 9.99918938e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 86 [0/107 (0%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 86 [4/107 (4%)]\tTrain Loss: 0.001096\n",
      "Train Epoch: 86 [8/107 (7%)]\tTrain Loss: 0.000715\n",
      "Train Epoch: 86 [12/107 (11%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 86 [16/107 (15%)]\tTrain Loss: 0.018713\n",
      "Train Epoch: 86 [20/107 (19%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 86 [24/107 (22%)]\tTrain Loss: 0.000772\n",
      "Train Epoch: 86 [28/107 (26%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 86 [32/107 (30%)]\tTrain Loss: 0.000237\n",
      "Train Epoch: 86 [36/107 (34%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 86 [40/107 (37%)]\tTrain Loss: 0.002378\n",
      "Train Epoch: 86 [44/107 (41%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 86 [48/107 (45%)]\tTrain Loss: 0.000442\n",
      "Train Epoch: 86 [52/107 (49%)]\tTrain Loss: 0.000156\n",
      "Train Epoch: 86 [56/107 (52%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 86 [60/107 (56%)]\tTrain Loss: 0.000115\n",
      "Train Epoch: 86 [64/107 (60%)]\tTrain Loss: 0.000205\n",
      "Train Epoch: 86 [68/107 (64%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 86 [72/107 (67%)]\tTrain Loss: 0.008477\n",
      "Train Epoch: 86 [76/107 (71%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 86 [80/107 (75%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 86 [84/107 (79%)]\tTrain Loss: 0.000348\n",
      "Train Epoch: 86 [88/107 (82%)]\tTrain Loss: 0.000163\n",
      "Train Epoch: 86 [92/107 (86%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 86 [96/107 (90%)]\tTrain Loss: 0.000265\n",
      "Train Epoch: 86 [100/107 (93%)]\tTrain Loss: 0.000540\n",
      "Train Epoch: 86 [104/107 (97%)]\tTrain Loss: 0.000949\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.29180446e-02 9.99478400e-01 7.39647597e-02 1.13943011e-01\n",
      " 9.32176784e-03 5.52383438e-03 9.93443370e-01 4.94502522e-02\n",
      " 1.84278435e-03 1.57861188e-02 5.42884946e-01 4.97405836e-06\n",
      " 2.50347257e-01 3.24298092e-03 2.05755606e-02 9.46065702e-05\n",
      " 9.17972375e-06 5.74117899e-01 2.59782579e-02 3.00197124e-01\n",
      " 4.34211075e-01 9.93915498e-01 9.99984622e-01 9.99994040e-01\n",
      " 9.71036553e-01 9.99971032e-01 9.99989629e-01 2.03708634e-02\n",
      " 5.45869648e-01 6.84171158e-04 3.65143836e-01 5.84086664e-02\n",
      " 9.30587828e-01 4.72694546e-06 9.93661888e-06 4.36090573e-04\n",
      " 1.20918143e-04 9.90041435e-01 8.88173819e-01 2.77431764e-06\n",
      " 1.19924550e-06 4.19331955e-05 7.19536483e-01 4.01909381e-01\n",
      " 7.59922802e-01 4.16622823e-03 9.55051184e-01 9.40976918e-01\n",
      " 9.74534273e-01 1.82413161e-01 9.77893293e-01 1.25931890e-03\n",
      " 1.24289480e-03 1.92680722e-03 1.01326881e-02 6.03632070e-03\n",
      " 9.95062768e-01 1.66335461e-08 1.77833252e-04 3.86974262e-03\n",
      " 9.99900103e-01 9.99935865e-01 9.99997616e-01 9.99993682e-01\n",
      " 9.99999523e-01 9.99846339e-01 9.99694228e-01 1.00000000e+00\n",
      " 9.99996543e-01 9.99888182e-01 9.08623755e-01 5.19104898e-01\n",
      " 9.70395029e-01 9.99609411e-01 9.99779999e-01 9.09134805e-01\n",
      " 9.99991179e-01 9.99906301e-01 9.99999523e-01 9.99859333e-01\n",
      " 9.99998689e-01 9.99939799e-01 9.99992371e-01 9.99120653e-01\n",
      " 9.09640849e-01 9.99991059e-01 9.99785483e-01 9.99602854e-01\n",
      " 7.18006119e-02 9.99802291e-01 9.99847054e-01 9.68214452e-01\n",
      " 8.72201562e-01 1.00000000e+00 9.99963522e-01 9.99998331e-01\n",
      " 2.09012300e-01 7.21490145e-01 9.99912381e-01 9.99915481e-01\n",
      " 3.43914270e-01 9.97788668e-01 7.18797982e-01 9.97227967e-01\n",
      " 9.56226647e-01 9.92692828e-01 9.98441994e-01 8.77595603e-01\n",
      " 4.73687164e-02 9.71873343e-01 9.99260962e-01 9.59265947e-01\n",
      " 9.99982953e-01 8.69426727e-01 5.03986031e-02 9.76730883e-03\n",
      " 9.99993682e-01 9.99975801e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 87 [0/107 (0%)]\tTrain Loss: 0.007573\n",
      "Train Epoch: 87 [4/107 (4%)]\tTrain Loss: 0.000101\n",
      "Train Epoch: 87 [8/107 (7%)]\tTrain Loss: 0.000098\n",
      "Train Epoch: 87 [12/107 (11%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 87 [16/107 (15%)]\tTrain Loss: 0.004060\n",
      "Train Epoch: 87 [20/107 (19%)]\tTrain Loss: 0.000502\n",
      "Train Epoch: 87 [24/107 (22%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 87 [28/107 (26%)]\tTrain Loss: 0.002566\n",
      "Train Epoch: 87 [32/107 (30%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 87 [36/107 (34%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 87 [40/107 (37%)]\tTrain Loss: 0.000328\n",
      "Train Epoch: 87 [44/107 (41%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 87 [48/107 (45%)]\tTrain Loss: 0.001799\n",
      "Train Epoch: 87 [52/107 (49%)]\tTrain Loss: 0.000544\n",
      "Train Epoch: 87 [56/107 (52%)]\tTrain Loss: 0.010101\n",
      "Train Epoch: 87 [60/107 (56%)]\tTrain Loss: 0.000233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [64/107 (60%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 87 [68/107 (64%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 87 [72/107 (67%)]\tTrain Loss: 0.000954\n",
      "Train Epoch: 87 [76/107 (71%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 87 [80/107 (75%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 87 [84/107 (79%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 87 [88/107 (82%)]\tTrain Loss: 0.004308\n",
      "Train Epoch: 87 [92/107 (86%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 87 [96/107 (90%)]\tTrain Loss: 0.000073\n",
      "Train Epoch: 87 [100/107 (93%)]\tTrain Loss: 0.002201\n",
      "Train Epoch: 87 [104/107 (97%)]\tTrain Loss: 0.000110\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.25385407e-02 9.98051763e-01 2.65862141e-02 1.06793866e-01\n",
      " 7.48020364e-03 1.87928788e-03 9.30677950e-01 7.76929557e-02\n",
      " 2.33927998e-03 2.96348725e-02 4.92646784e-01 7.14256794e-06\n",
      " 4.03524518e-01 1.45268219e-03 2.15693731e-02 2.03131403e-05\n",
      " 4.30016235e-06 1.90077469e-01 6.31185174e-02 2.35458076e-01\n",
      " 4.89204526e-01 9.83676255e-01 9.99926567e-01 9.99986529e-01\n",
      " 8.84248853e-01 9.99844074e-01 9.99969363e-01 4.17397656e-02\n",
      " 3.92431766e-01 6.31778094e-04 2.30801716e-01 2.61014905e-02\n",
      " 8.35852504e-01 5.13816349e-06 1.77970117e-06 1.98817346e-04\n",
      " 1.38548814e-04 9.85483825e-01 5.74147522e-01 1.03955142e-06\n",
      " 2.30197600e-07 1.26672503e-05 3.60293418e-01 4.25683588e-01\n",
      " 7.69588888e-01 3.47842299e-03 9.11305487e-01 8.82876694e-01\n",
      " 9.81895268e-01 1.45155847e-01 9.77782369e-01 1.32191414e-03\n",
      " 3.57909547e-03 2.68613058e-03 6.92329556e-03 1.27889048e-02\n",
      " 9.95395005e-01 3.29741177e-08 2.21860333e-04 7.83705246e-03\n",
      " 9.99899626e-01 9.99899507e-01 9.99995351e-01 9.99990463e-01\n",
      " 9.99998450e-01 9.99745786e-01 9.99252260e-01 1.00000000e+00\n",
      " 9.99993682e-01 9.99472320e-01 9.18436646e-01 4.63665634e-01\n",
      " 9.75711882e-01 9.99108493e-01 9.99774039e-01 9.22955513e-01\n",
      " 9.99969363e-01 9.99926567e-01 9.99998689e-01 9.99540567e-01\n",
      " 9.99995947e-01 9.99938250e-01 9.99988198e-01 9.98857737e-01\n",
      " 9.60982800e-01 9.99988198e-01 9.99275744e-01 9.98438299e-01\n",
      " 8.34797770e-02 9.99235630e-01 9.99838829e-01 9.67516959e-01\n",
      " 8.52126896e-01 1.00000000e+00 9.99966264e-01 9.99998093e-01\n",
      " 2.75864989e-01 7.12944329e-01 9.99903202e-01 9.99844551e-01\n",
      " 4.17163223e-01 9.94890690e-01 7.14170337e-02 9.97101128e-01\n",
      " 9.20077443e-01 9.95790541e-01 9.96666491e-01 6.22459888e-01\n",
      " 3.25471978e-03 9.45844948e-01 9.97821927e-01 8.41583729e-01\n",
      " 9.99970675e-01 7.30616570e-01 2.43743788e-02 8.15013237e-03\n",
      " 9.99982595e-01 9.99876618e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 88 [0/107 (0%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 88 [4/107 (4%)]\tTrain Loss: 0.001763\n",
      "Train Epoch: 88 [8/107 (7%)]\tTrain Loss: 0.000395\n",
      "Train Epoch: 88 [12/107 (11%)]\tTrain Loss: 0.001381\n",
      "Train Epoch: 88 [16/107 (15%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 88 [20/107 (19%)]\tTrain Loss: 0.000403\n",
      "Train Epoch: 88 [24/107 (22%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 88 [28/107 (26%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 88 [32/107 (30%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 88 [36/107 (34%)]\tTrain Loss: 0.000448\n",
      "Train Epoch: 88 [40/107 (37%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 88 [44/107 (41%)]\tTrain Loss: 0.000316\n",
      "Train Epoch: 88 [48/107 (45%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 88 [52/107 (49%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 88 [56/107 (52%)]\tTrain Loss: 0.001279\n",
      "Train Epoch: 88 [60/107 (56%)]\tTrain Loss: 0.001239\n",
      "Train Epoch: 88 [64/107 (60%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 88 [68/107 (64%)]\tTrain Loss: 0.000376\n",
      "Train Epoch: 88 [72/107 (67%)]\tTrain Loss: 0.001922\n",
      "Train Epoch: 88 [76/107 (71%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 88 [80/107 (75%)]\tTrain Loss: 0.000060\n",
      "Train Epoch: 88 [84/107 (79%)]\tTrain Loss: 0.000264\n",
      "Train Epoch: 88 [88/107 (82%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 88 [92/107 (86%)]\tTrain Loss: 0.000677\n",
      "Train Epoch: 88 [96/107 (90%)]\tTrain Loss: 0.035234\n",
      "Train Epoch: 88 [100/107 (93%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 88 [104/107 (97%)]\tTrain Loss: 0.000073\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.25613858e-03 9.93038714e-01 6.28477708e-03 2.55640447e-02\n",
      " 2.09103874e-03 3.67305765e-04 5.90925574e-01 1.01825390e-02\n",
      " 4.61305142e-04 4.06776601e-03 1.11995988e-01 9.47499757e-07\n",
      " 5.78258224e-02 2.00674360e-04 2.38145539e-03 2.15554792e-06\n",
      " 2.41784448e-07 8.68546516e-02 1.76521670e-03 1.88597944e-02\n",
      " 4.38869037e-02 8.08965564e-01 9.98980224e-01 9.99968410e-01\n",
      " 2.88272053e-01 9.99059379e-01 9.99930143e-01 2.83072516e-03\n",
      " 5.47714084e-02 2.03867221e-05 2.00498290e-02 2.14057835e-03\n",
      " 6.08185470e-01 2.41161956e-07 2.24244900e-07 2.00847589e-05\n",
      " 1.49844709e-05 9.13382113e-01 1.47519678e-01 4.78799720e-08\n",
      " 1.57820335e-08 4.20581017e-07 6.90046400e-02 3.65434177e-02\n",
      " 3.46553862e-01 2.21821902e-04 5.41134655e-01 5.53543329e-01\n",
      " 8.39438260e-01 3.96101773e-02 8.32336426e-01 1.27849111e-04\n",
      " 3.97196913e-04 1.29716514e-04 1.96625027e-04 1.10359245e-03\n",
      " 9.86726403e-01 1.98844763e-09 4.36220507e-05 1.00078434e-03\n",
      " 9.99672294e-01 9.99760807e-01 9.99986768e-01 9.99968290e-01\n",
      " 9.99995947e-01 9.98302460e-01 9.95788157e-01 9.99999881e-01\n",
      " 9.99981642e-01 9.99101281e-01 7.17367351e-01 1.80907860e-01\n",
      " 8.18306804e-01 9.91607070e-01 9.98688519e-01 2.67099619e-01\n",
      " 9.99951005e-01 9.99603331e-01 9.99996543e-01 9.97350812e-01\n",
      " 9.99984622e-01 9.99318719e-01 9.99951720e-01 9.96031225e-01\n",
      " 6.66235447e-01 9.99895692e-01 9.98543143e-01 9.95180249e-01\n",
      " 8.02817196e-03 9.94905472e-01 9.99232411e-01 8.30543578e-01\n",
      " 5.40667295e-01 9.99999881e-01 9.99897957e-01 9.99986649e-01\n",
      " 9.92385298e-02 1.24954343e-01 9.98091877e-01 9.98955011e-01\n",
      " 3.88943925e-02 9.78102386e-01 1.89482942e-02 9.83618438e-01\n",
      " 5.01681924e-01 9.83205497e-01 9.90742147e-01 8.88267085e-02\n",
      " 2.25694996e-04 5.27732968e-01 9.65898931e-01 4.34051335e-01\n",
      " 9.99725640e-01 8.61763582e-02 2.67899456e-03 3.57101875e-04\n",
      " 9.99939322e-01 9.99779999e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 89 [0/107 (0%)]\tTrain Loss: 0.000399\n",
      "Train Epoch: 89 [4/107 (4%)]\tTrain Loss: 0.000941\n",
      "Train Epoch: 89 [8/107 (7%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 89 [12/107 (11%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 89 [16/107 (15%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 89 [20/107 (19%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 89 [24/107 (22%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 89 [28/107 (26%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 89 [32/107 (30%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 89 [36/107 (34%)]\tTrain Loss: 0.000639\n",
      "Train Epoch: 89 [40/107 (37%)]\tTrain Loss: 0.000437\n",
      "Train Epoch: 89 [44/107 (41%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 89 [48/107 (45%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 89 [52/107 (49%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 89 [56/107 (52%)]\tTrain Loss: 0.000097\n",
      "Train Epoch: 89 [60/107 (56%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 89 [64/107 (60%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 89 [68/107 (64%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 89 [72/107 (67%)]\tTrain Loss: 0.001367\n",
      "Train Epoch: 89 [76/107 (71%)]\tTrain Loss: 0.000735\n",
      "Train Epoch: 89 [80/107 (75%)]\tTrain Loss: 0.001709\n",
      "Train Epoch: 89 [84/107 (79%)]\tTrain Loss: 0.000112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89 [88/107 (82%)]\tTrain Loss: 0.005213\n",
      "Train Epoch: 89 [92/107 (86%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 89 [96/107 (90%)]\tTrain Loss: 0.004072\n",
      "Train Epoch: 89 [100/107 (93%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 89 [104/107 (97%)]\tTrain Loss: 0.001415\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.05865146e-03 9.29643035e-01 1.44846272e-03 7.32092187e-03\n",
      " 1.85958145e-03 3.48168891e-04 1.85898393e-01 3.37337842e-03\n",
      " 1.63240053e-04 3.60242208e-03 3.64690155e-01 3.17391164e-06\n",
      " 2.61499554e-01 2.24108426e-05 9.41798266e-04 7.17809826e-07\n",
      " 1.19948069e-07 1.28307408e-02 6.57465891e-04 1.73959956e-02\n",
      " 4.66491841e-02 5.28897047e-01 9.98544931e-01 9.99875903e-01\n",
      " 4.58219081e-01 9.98428762e-01 9.98769104e-01 6.34198601e-04\n",
      " 2.03273091e-02 2.78043426e-05 1.61467900e-03 1.61441811e-03\n",
      " 2.54622936e-01 2.75528066e-07 8.88684326e-08 1.22766414e-05\n",
      " 1.99875249e-05 5.71922600e-01 4.38016579e-02 6.01084480e-08\n",
      " 3.41701423e-08 5.04021898e-07 1.59163494e-02 8.90963897e-03\n",
      " 3.92481476e-01 3.65169049e-04 3.05495799e-01 4.49841887e-01\n",
      " 6.97875321e-01 2.22817343e-02 7.20071137e-01 4.30803120e-05\n",
      " 8.09264020e-05 3.62957362e-05 1.61375981e-04 9.58626624e-04\n",
      " 9.29342628e-01 5.96837579e-10 4.13056914e-05 2.46723968e-04\n",
      " 9.97449219e-01 9.98270154e-01 9.99770343e-01 9.99733865e-01\n",
      " 9.99966264e-01 9.89396155e-01 9.50808525e-01 9.99994993e-01\n",
      " 9.99699235e-01 9.96938229e-01 5.82585335e-01 1.13411792e-01\n",
      " 6.31303012e-01 9.86553967e-01 9.89950299e-01 6.22398369e-02\n",
      " 9.99699593e-01 9.95954275e-01 9.99962807e-01 9.90917861e-01\n",
      " 9.99902487e-01 9.97252166e-01 9.99558866e-01 9.87558365e-01\n",
      " 7.86492705e-01 9.98376608e-01 9.97933030e-01 9.90510523e-01\n",
      " 2.32219486e-03 9.84759033e-01 9.93881106e-01 6.98545933e-01\n",
      " 3.26586157e-01 9.99997973e-01 9.99472916e-01 9.99899149e-01\n",
      " 1.16306677e-01 2.41173074e-01 9.99101758e-01 9.98872459e-01\n",
      " 2.89636374e-01 9.31565464e-01 1.40254889e-02 9.79655385e-01\n",
      " 4.43873316e-01 9.83434319e-01 9.80002642e-01 3.33960839e-02\n",
      " 8.86034104e-05 2.68726945e-01 9.17103589e-01 5.90600550e-01\n",
      " 9.97697175e-01 1.53699711e-01 1.24248099e-02 4.19683405e-04\n",
      " 9.98433173e-01 9.98553813e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 90 [0/107 (0%)]\tTrain Loss: 0.000428\n",
      "Train Epoch: 90 [4/107 (4%)]\tTrain Loss: 0.002238\n",
      "Train Epoch: 90 [8/107 (7%)]\tTrain Loss: 0.000175\n",
      "Train Epoch: 90 [12/107 (11%)]\tTrain Loss: 0.000519\n",
      "Train Epoch: 90 [16/107 (15%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 90 [20/107 (19%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 90 [24/107 (22%)]\tTrain Loss: 0.000695\n",
      "Train Epoch: 90 [28/107 (26%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 90 [32/107 (30%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 90 [36/107 (34%)]\tTrain Loss: 0.001722\n",
      "Train Epoch: 90 [40/107 (37%)]\tTrain Loss: 0.000353\n",
      "Train Epoch: 90 [44/107 (41%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 90 [48/107 (45%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 90 [52/107 (49%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 90 [56/107 (52%)]\tTrain Loss: 0.000956\n",
      "Train Epoch: 90 [60/107 (56%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 90 [64/107 (60%)]\tTrain Loss: 0.000468\n",
      "Train Epoch: 90 [68/107 (64%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 90 [72/107 (67%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 90 [76/107 (71%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 90 [80/107 (75%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 90 [84/107 (79%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 90 [88/107 (82%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 90 [92/107 (86%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 90 [96/107 (90%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 90 [100/107 (93%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 90 [104/107 (97%)]\tTrain Loss: 0.000124\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.66927686e-03 9.73405063e-01 2.18029576e-03 4.25638892e-02\n",
      " 6.62518106e-03 8.95604433e-04 1.66634962e-01 1.82442702e-02\n",
      " 1.12613291e-03 1.87808946e-02 3.72491091e-01 6.28473981e-06\n",
      " 2.80584514e-01 2.96584330e-04 4.06058086e-03 2.77957429e-06\n",
      " 7.63040646e-07 7.44643584e-02 3.11305071e-03 4.61171195e-02\n",
      " 8.29992145e-02 5.93559921e-01 9.97358501e-01 9.99906778e-01\n",
      " 4.37962770e-01 9.98406589e-01 9.99746621e-01 2.23139906e-03\n",
      " 7.09146932e-02 5.51593293e-05 1.31769739e-02 4.57359245e-03\n",
      " 4.13473397e-01 1.24843393e-06 7.67554013e-07 4.91212013e-05\n",
      " 5.57644125e-05 8.30449939e-01 1.88845381e-01 1.91879266e-07\n",
      " 9.84323805e-08 1.85217471e-06 6.50915056e-02 3.64837386e-02\n",
      " 4.57034528e-01 1.45260280e-03 6.12214983e-01 6.21155858e-01\n",
      " 8.70322049e-01 4.87216339e-02 8.79738092e-01 3.78505851e-04\n",
      " 2.26319209e-03 2.08295137e-03 1.89196784e-03 8.64633266e-03\n",
      " 9.73930538e-01 3.59587951e-08 1.39531112e-04 2.70648440e-03\n",
      " 9.99266088e-01 9.99299169e-01 9.99920130e-01 9.99923468e-01\n",
      " 9.99984980e-01 9.95970666e-01 9.85627770e-01 9.99996543e-01\n",
      " 9.99851108e-01 9.97756302e-01 7.26480961e-01 3.72544110e-01\n",
      " 8.96994293e-01 9.90220189e-01 9.96801138e-01 3.57810616e-01\n",
      " 9.99835134e-01 9.98202085e-01 9.99980927e-01 9.96307373e-01\n",
      " 9.99954343e-01 9.99603450e-01 9.99890327e-01 9.95729864e-01\n",
      " 8.62353981e-01 9.99337137e-01 9.97925878e-01 9.91213143e-01\n",
      " 6.89940527e-03 9.86886263e-01 9.98607934e-01 8.52922618e-01\n",
      " 5.66816807e-01 9.99998689e-01 9.99799192e-01 9.99934793e-01\n",
      " 3.30140591e-01 5.02119243e-01 9.99179423e-01 9.98201251e-01\n",
      " 2.23573461e-01 9.51525509e-01 1.12527860e-02 9.91637886e-01\n",
      " 8.09400856e-01 9.93903458e-01 9.87993598e-01 9.15472060e-02\n",
      " 2.66504940e-04 7.38362134e-01 9.72912252e-01 5.60553730e-01\n",
      " 9.99285400e-01 9.98838320e-02 6.91173272e-03 6.16863195e-04\n",
      " 9.99778926e-01 9.99159932e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 45 FN= 11 FP= 15\n",
      "TP+FP 62\n",
      "precision 0.7580645161290323\n",
      "recall 0.8103448275862069\n",
      "F1 0.7833333333333333\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7801724137931034\n",
      "AUC 0.8658045977011495\n",
      "\n",
      " The epoch is 90, average recall: 0.8103, average precision: 0.7581,average F1: 0.7833, average accuracy: 0.7797, average AUC: 0.8658\n",
      "Train Epoch: 91 [0/107 (0%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 91 [4/107 (4%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 91 [8/107 (7%)]\tTrain Loss: 0.000261\n",
      "Train Epoch: 91 [12/107 (11%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 91 [16/107 (15%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 91 [20/107 (19%)]\tTrain Loss: 0.002913\n",
      "Train Epoch: 91 [24/107 (22%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 91 [28/107 (26%)]\tTrain Loss: 0.000082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 91 [32/107 (30%)]\tTrain Loss: 0.000706\n",
      "Train Epoch: 91 [36/107 (34%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 91 [40/107 (37%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 91 [44/107 (41%)]\tTrain Loss: 0.000196\n",
      "Train Epoch: 91 [48/107 (45%)]\tTrain Loss: 0.000310\n",
      "Train Epoch: 91 [52/107 (49%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 91 [56/107 (52%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 91 [60/107 (56%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 91 [64/107 (60%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 91 [68/107 (64%)]\tTrain Loss: 0.002952\n",
      "Train Epoch: 91 [72/107 (67%)]\tTrain Loss: 0.000158\n",
      "Train Epoch: 91 [76/107 (71%)]\tTrain Loss: 0.000140\n",
      "Train Epoch: 91 [80/107 (75%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 91 [84/107 (79%)]\tTrain Loss: 0.000098\n",
      "Train Epoch: 91 [88/107 (82%)]\tTrain Loss: 0.000236\n",
      "Train Epoch: 91 [92/107 (86%)]\tTrain Loss: 0.000261\n",
      "Train Epoch: 91 [96/107 (90%)]\tTrain Loss: 0.000092\n",
      "Train Epoch: 91 [100/107 (93%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 91 [104/107 (97%)]\tTrain Loss: 0.000037\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.82722695e-02 9.93709207e-01 1.08671328e-02 8.26967657e-02\n",
      " 1.88791696e-02 4.83257929e-03 6.54599845e-01 5.99274486e-02\n",
      " 2.42637563e-03 3.69832739e-02 6.09005988e-01 1.44147734e-05\n",
      " 5.43172359e-01 9.83363832e-04 9.40839667e-03 3.79174744e-05\n",
      " 6.80141102e-06 1.41952157e-01 1.45406015e-02 8.66880268e-02\n",
      " 2.11796284e-01 9.33131635e-01 9.99363005e-01 9.99959111e-01\n",
      " 6.91471040e-01 9.99486685e-01 9.99895930e-01 5.97896194e-03\n",
      " 2.06867754e-01 1.18613927e-04 9.44241583e-02 7.85330590e-03\n",
      " 7.15281010e-01 8.55357212e-06 3.76513776e-06 2.19620561e-04\n",
      " 2.81646586e-04 9.69920635e-01 6.41080260e-01 7.84535416e-07\n",
      " 2.85567381e-07 1.52046068e-05 4.08305317e-01 8.93133134e-02\n",
      " 6.99795961e-01 2.63727503e-03 6.78849518e-01 6.79034948e-01\n",
      " 9.43451643e-01 1.06843479e-01 9.40619349e-01 1.39166764e-03\n",
      " 1.13308253e-02 2.34989077e-03 2.78338487e-03 1.63083244e-02\n",
      " 9.91592288e-01 1.24786567e-07 2.67026218e-04 9.97684523e-03\n",
      " 9.99720633e-01 9.99829531e-01 9.99986291e-01 9.99983668e-01\n",
      " 9.99995828e-01 9.99402761e-01 9.97062624e-01 9.99999642e-01\n",
      " 9.99966860e-01 9.99036670e-01 8.13981950e-01 3.59855145e-01\n",
      " 9.54870284e-01 9.97098804e-01 9.99501705e-01 7.24217892e-01\n",
      " 9.99964833e-01 9.99766290e-01 9.99995589e-01 9.99116957e-01\n",
      " 9.99989986e-01 9.99817073e-01 9.99969840e-01 9.98418450e-01\n",
      " 9.36977029e-01 9.99913692e-01 9.99178588e-01 9.97752249e-01\n",
      " 2.05734447e-02 9.98256385e-01 9.99655962e-01 9.65749562e-01\n",
      " 7.88509250e-01 9.99999881e-01 9.99929428e-01 9.99988794e-01\n",
      " 5.42226493e-01 6.43667400e-01 9.99744713e-01 9.99616981e-01\n",
      " 3.08589935e-01 9.91205394e-01 4.73894887e-02 9.94547248e-01\n",
      " 6.51296020e-01 9.96439159e-01 9.96154368e-01 3.04609865e-01\n",
      " 8.39402026e-04 7.51924336e-01 9.92889762e-01 7.76315451e-01\n",
      " 9.99726474e-01 4.05418962e-01 2.79330406e-02 6.06266735e-03\n",
      " 9.99975562e-01 9.99909639e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 92 [0/107 (0%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 92 [4/107 (4%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 92 [8/107 (7%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 92 [12/107 (11%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 92 [16/107 (15%)]\tTrain Loss: 0.000137\n",
      "Train Epoch: 92 [20/107 (19%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 92 [24/107 (22%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 92 [28/107 (26%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 92 [32/107 (30%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 92 [36/107 (34%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 92 [40/107 (37%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 92 [44/107 (41%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 92 [48/107 (45%)]\tTrain Loss: 0.000352\n",
      "Train Epoch: 92 [52/107 (49%)]\tTrain Loss: 0.000167\n",
      "Train Epoch: 92 [56/107 (52%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 92 [60/107 (56%)]\tTrain Loss: 0.002265\n",
      "Train Epoch: 92 [64/107 (60%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 92 [68/107 (64%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 92 [72/107 (67%)]\tTrain Loss: 0.000149\n",
      "Train Epoch: 92 [76/107 (71%)]\tTrain Loss: 0.000387\n",
      "Train Epoch: 92 [80/107 (75%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 92 [84/107 (79%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 92 [88/107 (82%)]\tTrain Loss: 0.000313\n",
      "Train Epoch: 92 [92/107 (86%)]\tTrain Loss: 0.000095\n",
      "Train Epoch: 92 [96/107 (90%)]\tTrain Loss: 0.005298\n",
      "Train Epoch: 92 [100/107 (93%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 92 [104/107 (97%)]\tTrain Loss: 0.000248\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.35733997e-02 9.89806831e-01 5.80575736e-03 8.20210055e-02\n",
      " 1.16235139e-02 1.98782235e-03 6.65954053e-01 5.71219698e-02\n",
      " 1.48954161e-03 1.83431786e-02 6.89926207e-01 1.15776902e-05\n",
      " 4.87163275e-01 5.49562741e-04 7.75463507e-03 1.72571436e-05\n",
      " 4.49564868e-06 2.23236784e-01 1.21346740e-02 8.66413787e-02\n",
      " 2.49031156e-01 9.44601893e-01 9.99417186e-01 9.99955893e-01\n",
      " 8.73934746e-01 9.99213457e-01 9.99858141e-01 9.08527523e-03\n",
      " 1.10886887e-01 1.00368605e-04 4.11190130e-02 9.45596397e-03\n",
      " 7.04352856e-01 3.66701215e-06 1.84024964e-06 1.33923881e-04\n",
      " 2.57009175e-04 9.67201054e-01 7.09451556e-01 6.09687959e-07\n",
      " 2.89230769e-07 9.10263407e-06 3.90356690e-01 9.29543227e-02\n",
      " 7.28865206e-01 1.77465717e-03 6.29699707e-01 6.60475791e-01\n",
      " 8.80120575e-01 7.13622347e-02 8.42997074e-01 5.11357212e-04\n",
      " 1.73135591e-03 1.70319830e-03 2.68280180e-03 9.57327057e-03\n",
      " 9.81084824e-01 1.27543318e-08 2.61506386e-04 3.72495898e-03\n",
      " 9.99730289e-01 9.99770820e-01 9.99987721e-01 9.99983788e-01\n",
      " 9.99991655e-01 9.98656750e-01 9.95719135e-01 9.99999166e-01\n",
      " 9.99958038e-01 9.98923481e-01 8.36326540e-01 2.23166704e-01\n",
      " 9.38470662e-01 9.97867465e-01 9.99556720e-01 6.73969686e-01\n",
      " 9.99930739e-01 9.99459445e-01 9.99988675e-01 9.98730719e-01\n",
      " 9.99988556e-01 9.99673963e-01 9.99957561e-01 9.98471081e-01\n",
      " 9.10813987e-01 9.99903440e-01 9.98881519e-01 9.96243477e-01\n",
      " 2.11247634e-02 9.99084234e-01 9.99252975e-01 9.32435334e-01\n",
      " 7.51839936e-01 9.99999642e-01 9.99950767e-01 9.99991894e-01\n",
      " 4.60732698e-01 8.43422294e-01 9.99903321e-01 9.99765456e-01\n",
      " 4.24818337e-01 9.86930132e-01 3.87094438e-01 9.96231735e-01\n",
      " 7.41956115e-01 9.96704519e-01 9.96491611e-01 3.73013616e-01\n",
      " 3.12367803e-03 8.34654152e-01 9.96302128e-01 8.88371527e-01\n",
      " 9.99702156e-01 5.29789448e-01 4.00624163e-02 1.93944816e-02\n",
      " 9.99959469e-01 9.99933362e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 93 [0/107 (0%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 93 [4/107 (4%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 93 [8/107 (7%)]\tTrain Loss: 0.000625\n",
      "Train Epoch: 93 [12/107 (11%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 93 [16/107 (15%)]\tTrain Loss: 0.000626\n",
      "Train Epoch: 93 [20/107 (19%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 93 [24/107 (22%)]\tTrain Loss: 0.002408\n",
      "Train Epoch: 93 [28/107 (26%)]\tTrain Loss: 0.000133\n",
      "Train Epoch: 93 [32/107 (30%)]\tTrain Loss: 0.000703\n",
      "Train Epoch: 93 [36/107 (34%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 93 [40/107 (37%)]\tTrain Loss: 0.000653\n",
      "Train Epoch: 93 [44/107 (41%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 93 [48/107 (45%)]\tTrain Loss: 0.001495\n",
      "Train Epoch: 93 [52/107 (49%)]\tTrain Loss: 0.000058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 93 [56/107 (52%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 93 [60/107 (56%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 93 [64/107 (60%)]\tTrain Loss: 0.008623\n",
      "Train Epoch: 93 [68/107 (64%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 93 [72/107 (67%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 93 [76/107 (71%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 93 [80/107 (75%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 93 [84/107 (79%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 93 [88/107 (82%)]\tTrain Loss: 0.000885\n",
      "Train Epoch: 93 [92/107 (86%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 93 [96/107 (90%)]\tTrain Loss: 0.001125\n",
      "Train Epoch: 93 [100/107 (93%)]\tTrain Loss: 0.000777\n",
      "Train Epoch: 93 [104/107 (97%)]\tTrain Loss: 0.000056\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.62950214e-03 9.77715552e-01 1.65889645e-03 3.94133180e-02\n",
      " 2.68398668e-03 5.35752100e-04 3.65020663e-01 1.90333184e-02\n",
      " 7.20133830e-04 6.98748557e-03 3.74323606e-01 2.70937062e-06\n",
      " 1.57937452e-01 1.28203144e-04 1.64992851e-03 3.19942751e-06\n",
      " 7.85150746e-07 3.07601243e-01 1.54378533e-03 3.77730317e-02\n",
      " 7.22864047e-02 9.17019486e-01 9.98937070e-01 9.99923825e-01\n",
      " 8.21172833e-01 9.98962164e-01 9.99786198e-01 2.41692038e-03\n",
      " 2.37289052e-02 2.67504838e-05 3.12976092e-02 3.10275215e-03\n",
      " 4.76765394e-01 1.10530891e-06 8.28654379e-07 2.69900047e-05\n",
      " 3.98590928e-05 9.76170421e-01 7.11422503e-01 1.68475779e-07\n",
      " 5.01662036e-08 1.60916841e-06 3.09729606e-01 3.97218242e-02\n",
      " 5.08842170e-01 1.08356774e-03 6.00865483e-01 6.10335231e-01\n",
      " 8.34527493e-01 5.27340882e-02 8.50372791e-01 1.39763724e-04\n",
      " 1.76693802e-03 6.40027400e-04 1.95880653e-03 3.91311012e-03\n",
      " 9.83742774e-01 7.91816657e-09 1.02024278e-04 2.15670676e-03\n",
      " 9.99600708e-01 9.99671340e-01 9.99976039e-01 9.99965906e-01\n",
      " 9.99991894e-01 9.98411179e-01 9.92635429e-01 9.99997616e-01\n",
      " 9.99911427e-01 9.98998582e-01 7.44228899e-01 2.06778720e-01\n",
      " 9.14109349e-01 9.95829880e-01 9.99130070e-01 3.29713792e-01\n",
      " 9.99889731e-01 9.99315023e-01 9.99987006e-01 9.98480141e-01\n",
      " 9.99977708e-01 9.99593437e-01 9.99920368e-01 9.98518050e-01\n",
      " 8.50851834e-01 9.99803603e-01 9.98919487e-01 9.96962249e-01\n",
      " 4.99611115e-03 9.95306551e-01 9.99077439e-01 8.39733720e-01\n",
      " 6.45752609e-01 9.99999285e-01 9.99855280e-01 9.99953032e-01\n",
      " 2.71527648e-01 7.37486243e-01 9.99634027e-01 9.98941839e-01\n",
      " 3.81801784e-01 9.87743914e-01 2.23366588e-01 9.93018568e-01\n",
      " 6.42393172e-01 9.93960261e-01 9.91226852e-01 1.66220888e-01\n",
      " 1.15110027e-03 6.91228867e-01 9.85311508e-01 8.36020172e-01\n",
      " 9.99295950e-01 2.25414082e-01 7.65413558e-03 5.06269094e-03\n",
      " 9.99920368e-01 9.99553025e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 94 [0/107 (0%)]\tTrain Loss: 0.000123\n",
      "Train Epoch: 94 [4/107 (4%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 94 [8/107 (7%)]\tTrain Loss: 0.001208\n",
      "Train Epoch: 94 [12/107 (11%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 94 [16/107 (15%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 94 [20/107 (19%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 94 [24/107 (22%)]\tTrain Loss: 0.002267\n",
      "Train Epoch: 94 [28/107 (26%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 94 [32/107 (30%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 94 [36/107 (34%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 94 [40/107 (37%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 94 [44/107 (41%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 94 [48/107 (45%)]\tTrain Loss: 0.000262\n",
      "Train Epoch: 94 [52/107 (49%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 94 [56/107 (52%)]\tTrain Loss: 0.000279\n",
      "Train Epoch: 94 [60/107 (56%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 94 [64/107 (60%)]\tTrain Loss: 0.000239\n",
      "Train Epoch: 94 [68/107 (64%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 94 [72/107 (67%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 94 [76/107 (71%)]\tTrain Loss: 0.001448\n",
      "Train Epoch: 94 [80/107 (75%)]\tTrain Loss: 0.001461\n",
      "Train Epoch: 94 [84/107 (79%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 94 [88/107 (82%)]\tTrain Loss: 0.000821\n",
      "Train Epoch: 94 [92/107 (86%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 94 [96/107 (90%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 94 [100/107 (93%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 94 [104/107 (97%)]\tTrain Loss: 0.000024\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.67568699e-03 9.82976198e-01 3.39707220e-03 5.57184927e-02\n",
      " 6.29337179e-03 9.78365541e-04 3.28041524e-01 2.12899093e-02\n",
      " 1.38466468e-03 9.07854736e-03 3.73655617e-01 3.96848418e-06\n",
      " 8.57215747e-02 4.28104278e-04 2.07153405e-03 6.28303769e-06\n",
      " 4.67579923e-07 4.21058178e-01 2.23080092e-03 8.93480703e-02\n",
      " 5.67950942e-02 9.14479196e-01 9.99291301e-01 9.99948144e-01\n",
      " 8.29545438e-01 9.99161959e-01 9.99915600e-01 5.62943192e-03\n",
      " 5.98222390e-02 3.15035759e-05 4.94831316e-02 3.74222407e-03\n",
      " 7.16241002e-01 9.83462996e-07 7.91034097e-07 3.73970506e-05\n",
      " 2.52817863e-05 9.71216559e-01 8.53353798e-01 2.05352691e-07\n",
      " 6.60637056e-08 2.38990424e-06 3.55773479e-01 3.67513560e-02\n",
      " 6.17936671e-01 1.24609610e-03 6.17405772e-01 5.58765829e-01\n",
      " 7.90852427e-01 4.10245433e-02 8.30411434e-01 1.53047775e-04\n",
      " 4.13459027e-03 4.79800248e-04 3.54088331e-03 9.43602156e-03\n",
      " 9.87128854e-01 6.24629504e-09 3.92299989e-05 3.03111714e-03\n",
      " 9.99731004e-01 9.99852061e-01 9.99987006e-01 9.99987364e-01\n",
      " 9.99995589e-01 9.98925745e-01 9.95362520e-01 9.99999046e-01\n",
      " 9.99898911e-01 9.99524951e-01 7.14095116e-01 3.02820206e-01\n",
      " 9.42164183e-01 9.97260332e-01 9.99476731e-01 6.87003136e-01\n",
      " 9.99941349e-01 9.99538183e-01 9.99992490e-01 9.99027967e-01\n",
      " 9.99984622e-01 9.99731123e-01 9.99969006e-01 9.99046981e-01\n",
      " 8.92898977e-01 9.99923468e-01 9.99467909e-01 9.98516142e-01\n",
      " 4.44483617e-03 9.95898426e-01 9.97650683e-01 9.08902168e-01\n",
      " 7.12966084e-01 9.99998331e-01 9.99733984e-01 9.99890566e-01\n",
      " 2.40925521e-01 7.71418810e-01 9.99699950e-01 9.99349415e-01\n",
      " 2.28713244e-01 9.92264032e-01 4.68788892e-01 9.93312538e-01\n",
      " 7.39194989e-01 9.96106327e-01 9.94438410e-01 1.60320342e-01\n",
      " 3.33919795e-03 7.67812431e-01 9.72792327e-01 7.72103965e-01\n",
      " 9.99228358e-01 1.91691458e-01 1.97203383e-02 9.36879031e-03\n",
      " 9.99980450e-01 9.99851704e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 95 [0/107 (0%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 95 [4/107 (4%)]\tTrain Loss: 0.000201\n",
      "Train Epoch: 95 [8/107 (7%)]\tTrain Loss: 0.000249\n",
      "Train Epoch: 95 [12/107 (11%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 95 [16/107 (15%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 95 [20/107 (19%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 95 [24/107 (22%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 95 [28/107 (26%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 95 [32/107 (30%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 95 [36/107 (34%)]\tTrain Loss: 0.000231\n",
      "Train Epoch: 95 [40/107 (37%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 95 [44/107 (41%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 95 [48/107 (45%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 95 [52/107 (49%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 95 [56/107 (52%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 95 [60/107 (56%)]\tTrain Loss: 0.000263\n",
      "Train Epoch: 95 [64/107 (60%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 95 [68/107 (64%)]\tTrain Loss: 0.000252\n",
      "Train Epoch: 95 [72/107 (67%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 95 [76/107 (71%)]\tTrain Loss: 0.000061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [80/107 (75%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 95 [84/107 (79%)]\tTrain Loss: 0.065826\n",
      "Train Epoch: 95 [88/107 (82%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 95 [92/107 (86%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 95 [96/107 (90%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 95 [100/107 (93%)]\tTrain Loss: 0.003306\n",
      "Train Epoch: 95 [104/107 (97%)]\tTrain Loss: 0.000072\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.61683338e-03 9.97085869e-01 6.51568174e-03 1.67317353e-02\n",
      " 4.26796731e-03 3.27632995e-04 9.37005579e-01 6.39699819e-03\n",
      " 1.50732812e-04 2.86294706e-03 3.58728647e-01 7.95138760e-07\n",
      " 2.39945367e-01 1.53718080e-04 1.29176292e-03 5.16843670e-07\n",
      " 6.33581081e-08 9.40817520e-02 1.35445315e-03 4.34249565e-02\n",
      " 1.24366812e-01 9.32043314e-01 9.99345720e-01 9.99960661e-01\n",
      " 7.92138100e-01 9.99551117e-01 9.99788702e-01 2.55985418e-03\n",
      " 3.28313038e-02 2.37974491e-05 1.00889839e-02 1.21710578e-03\n",
      " 6.46764815e-01 2.42523669e-07 1.52208386e-07 7.83684809e-05\n",
      " 4.75581292e-05 9.49671507e-01 6.70844853e-01 1.64946059e-07\n",
      " 4.13107166e-08 4.31165972e-06 7.42499381e-02 1.03463950e-02\n",
      " 6.36735380e-01 2.98382365e-04 3.69466513e-01 4.97025341e-01\n",
      " 7.84607708e-01 1.15001369e-02 6.54829144e-01 1.46012651e-04\n",
      " 3.49388021e-04 5.22713999e-05 6.41155129e-05 4.27878741e-03\n",
      " 9.37101662e-01 2.12960960e-09 1.56286333e-05 4.19655931e-04\n",
      " 9.99631643e-01 9.99802411e-01 9.99994874e-01 9.99992013e-01\n",
      " 9.99995708e-01 9.98791397e-01 9.95561481e-01 9.99999881e-01\n",
      " 9.99976516e-01 9.98840749e-01 5.90690136e-01 1.62412718e-01\n",
      " 7.19099343e-01 9.96061027e-01 9.98988450e-01 5.28030246e-02\n",
      " 9.99993086e-01 9.99868870e-01 9.99994040e-01 9.99285042e-01\n",
      " 9.99986053e-01 9.98098314e-01 9.99921799e-01 9.97823358e-01\n",
      " 8.95092666e-01 9.99874592e-01 9.98245835e-01 9.96944964e-01\n",
      " 9.47352871e-03 9.98945177e-01 9.99610841e-01 9.59945202e-01\n",
      " 5.46275735e-01 9.99999285e-01 9.99727905e-01 9.99989867e-01\n",
      " 1.26552388e-01 1.63758740e-01 9.99680519e-01 9.99796569e-01\n",
      " 2.00975493e-01 9.90760803e-01 2.94527769e-01 8.57088149e-01\n",
      " 3.35347019e-02 9.43278432e-01 9.93372321e-01 3.14906627e-01\n",
      " 4.48076462e-04 6.81437016e-01 9.97521102e-01 8.19184184e-01\n",
      " 9.99569237e-01 4.22038645e-01 1.30787631e-02 8.61285953e-04\n",
      " 9.99983907e-01 9.99991298e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 96 [0/107 (0%)]\tTrain Loss: 0.000111\n",
      "Train Epoch: 96 [4/107 (4%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 96 [8/107 (7%)]\tTrain Loss: 0.005394\n",
      "Train Epoch: 96 [12/107 (11%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 96 [16/107 (15%)]\tTrain Loss: 0.000758\n",
      "Train Epoch: 96 [20/107 (19%)]\tTrain Loss: 0.002148\n",
      "Train Epoch: 96 [24/107 (22%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 96 [28/107 (26%)]\tTrain Loss: 0.000206\n",
      "Train Epoch: 96 [32/107 (30%)]\tTrain Loss: 0.000206\n",
      "Train Epoch: 96 [36/107 (34%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 96 [40/107 (37%)]\tTrain Loss: 0.000224\n",
      "Train Epoch: 96 [44/107 (41%)]\tTrain Loss: 0.000401\n",
      "Train Epoch: 96 [48/107 (45%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 96 [52/107 (49%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 96 [56/107 (52%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 96 [60/107 (56%)]\tTrain Loss: 0.001022\n",
      "Train Epoch: 96 [64/107 (60%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 96 [68/107 (64%)]\tTrain Loss: 0.001213\n",
      "Train Epoch: 96 [72/107 (67%)]\tTrain Loss: 0.000195\n",
      "Train Epoch: 96 [76/107 (71%)]\tTrain Loss: 0.002703\n",
      "Train Epoch: 96 [80/107 (75%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 96 [84/107 (79%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 96 [88/107 (82%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 96 [92/107 (86%)]\tTrain Loss: 0.000724\n",
      "Train Epoch: 96 [96/107 (90%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 96 [100/107 (93%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 96 [104/107 (97%)]\tTrain Loss: 0.000008\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.12517574e-03 9.98762369e-01 5.96818700e-03 1.65026896e-02\n",
      " 2.03122990e-03 3.38960235e-04 9.14950848e-01 1.09907007e-02\n",
      " 3.51537252e-04 2.97654956e-03 1.62121445e-01 6.83178882e-07\n",
      " 8.85970369e-02 3.20808933e-04 1.43162825e-03 3.23380277e-06\n",
      " 2.92216242e-07 4.11415130e-01 2.97581730e-03 8.82881433e-02\n",
      " 1.86909020e-01 9.74085689e-01 9.99680400e-01 9.99984503e-01\n",
      " 8.61565828e-01 9.99722064e-01 9.99964952e-01 5.62082883e-03\n",
      " 1.07237101e-01 1.29254759e-05 5.70828915e-02 1.10715965e-03\n",
      " 5.98046005e-01 4.19538225e-07 4.18236340e-07 3.24062603e-05\n",
      " 1.28035017e-05 9.90464211e-01 7.02701390e-01 1.15865710e-07\n",
      " 2.82627397e-08 3.39678354e-06 2.76192188e-01 2.60207355e-02\n",
      " 6.81100130e-01 5.15926920e-04 4.18890715e-01 4.79022801e-01\n",
      " 7.76185095e-01 7.96350278e-03 7.59420216e-01 8.37270127e-05\n",
      " 1.04518305e-03 3.23301734e-04 5.10500686e-04 8.61554407e-03\n",
      " 9.87265229e-01 6.94470748e-09 1.91640574e-05 1.66734285e-03\n",
      " 9.99894023e-01 9.99955773e-01 9.99998808e-01 9.99998569e-01\n",
      " 9.99998808e-01 9.99780118e-01 9.98816013e-01 1.00000000e+00\n",
      " 9.99991298e-01 9.99359310e-01 5.95832944e-01 1.43928602e-01\n",
      " 9.49570596e-01 9.98655677e-01 9.99865532e-01 3.22256684e-01\n",
      " 9.99995708e-01 9.99982834e-01 9.99996662e-01 9.99327779e-01\n",
      " 9.99992609e-01 9.99741018e-01 9.99972224e-01 9.99548495e-01\n",
      " 9.30080771e-01 9.99974370e-01 9.99070704e-01 9.98727262e-01\n",
      " 1.03931883e-02 9.99616981e-01 9.99829292e-01 9.65571463e-01\n",
      " 7.70239532e-01 9.99999285e-01 9.99880075e-01 9.99993563e-01\n",
      " 3.33682209e-01 5.87406039e-01 9.99871731e-01 9.99837995e-01\n",
      " 5.49249500e-02 9.92238581e-01 1.81184992e-01 9.59208548e-01\n",
      " 9.59470347e-02 9.80792701e-01 9.85570014e-01 3.33126396e-01\n",
      " 2.31268257e-03 7.32252538e-01 9.92385864e-01 7.24975169e-01\n",
      " 9.99866843e-01 4.22044069e-01 3.21001466e-03 1.86249265e-03\n",
      " 9.99998689e-01 9.99997258e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 97 [0/107 (0%)]\tTrain Loss: 0.002710\n",
      "Train Epoch: 97 [4/107 (4%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 97 [8/107 (7%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 97 [12/107 (11%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 97 [16/107 (15%)]\tTrain Loss: 0.003246\n",
      "Train Epoch: 97 [20/107 (19%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 97 [24/107 (22%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 97 [28/107 (26%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 97 [32/107 (30%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 97 [36/107 (34%)]\tTrain Loss: 0.000194\n",
      "Train Epoch: 97 [40/107 (37%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 97 [44/107 (41%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 97 [48/107 (45%)]\tTrain Loss: 0.000503\n",
      "Train Epoch: 97 [52/107 (49%)]\tTrain Loss: 0.012842\n",
      "Train Epoch: 97 [56/107 (52%)]\tTrain Loss: 0.000095\n",
      "Train Epoch: 97 [60/107 (56%)]\tTrain Loss: 0.003979\n",
      "Train Epoch: 97 [64/107 (60%)]\tTrain Loss: 0.002509\n",
      "Train Epoch: 97 [68/107 (64%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 97 [72/107 (67%)]\tTrain Loss: 0.000192\n",
      "Train Epoch: 97 [76/107 (71%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 97 [80/107 (75%)]\tTrain Loss: 0.000159\n",
      "Train Epoch: 97 [84/107 (79%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 97 [88/107 (82%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 97 [92/107 (86%)]\tTrain Loss: 0.000354\n",
      "Train Epoch: 97 [96/107 (90%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 97 [100/107 (93%)]\tTrain Loss: 0.000182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [104/107 (97%)]\tTrain Loss: 0.000118\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.97161178e-03 9.97756183e-01 1.78109873e-02 2.74902433e-02\n",
      " 1.01509122e-02 1.35272951e-03 9.36712503e-01 9.49740037e-03\n",
      " 3.69802292e-04 9.84297507e-03 7.30135381e-01 1.29187865e-05\n",
      " 3.83800030e-01 1.97272212e-03 1.06764007e-02 8.38946562e-06\n",
      " 4.77250205e-06 4.43671823e-01 6.95977593e-03 2.80463874e-01\n",
      " 3.65087181e-01 9.85698044e-01 9.99948621e-01 9.99979377e-01\n",
      " 9.63180423e-01 9.99852777e-01 9.99908924e-01 8.32152925e-03\n",
      " 2.61983603e-01 2.43564849e-04 8.31756741e-02 4.44963202e-03\n",
      " 6.79811120e-01 7.88859688e-06 4.17658566e-06 5.63866051e-04\n",
      " 2.74430582e-04 9.91517186e-01 9.03036654e-01 1.42187253e-06\n",
      " 8.40252881e-07 3.34694159e-05 3.43710274e-01 8.30435380e-02\n",
      " 7.56765008e-01 3.16459080e-03 6.93028510e-01 6.87227786e-01\n",
      " 8.51522863e-01 5.26293628e-02 8.73658061e-01 2.13310108e-04\n",
      " 3.43635608e-03 5.48610464e-04 3.90563579e-03 1.55889643e-02\n",
      " 9.83672678e-01 2.87322468e-08 5.48945281e-05 2.93370499e-03\n",
      " 9.99890804e-01 9.99945283e-01 9.99997497e-01 9.99996781e-01\n",
      " 9.99996305e-01 9.99575675e-01 9.97804821e-01 9.99999642e-01\n",
      " 9.99971271e-01 9.99770224e-01 6.87838376e-01 2.57199615e-01\n",
      " 9.72498536e-01 9.99103844e-01 9.99484420e-01 3.10015917e-01\n",
      " 9.99991655e-01 9.99862671e-01 9.99997020e-01 9.99522090e-01\n",
      " 9.99992847e-01 9.99593318e-01 9.99970317e-01 9.99552667e-01\n",
      " 9.84832466e-01 9.99967694e-01 9.99631643e-01 9.98575091e-01\n",
      " 5.27448915e-02 9.99128997e-01 9.99113977e-01 9.33737099e-01\n",
      " 8.66424739e-01 9.99999523e-01 9.99898195e-01 9.99994040e-01\n",
      " 4.44890022e-01 9.17037427e-01 9.99949932e-01 9.99869585e-01\n",
      " 7.02166617e-01 9.94297564e-01 8.21518004e-01 9.85907853e-01\n",
      " 2.51941592e-01 9.94072855e-01 9.96728420e-01 6.52928054e-01\n",
      " 7.19620194e-03 7.40256190e-01 9.96406019e-01 9.49343503e-01\n",
      " 9.99403119e-01 8.10841501e-01 2.38973796e-02 3.37330215e-02\n",
      " 9.99996662e-01 9.99996901e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 98 [0/107 (0%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 98 [4/107 (4%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 98 [8/107 (7%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 98 [12/107 (11%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 98 [16/107 (15%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 98 [20/107 (19%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 98 [24/107 (22%)]\tTrain Loss: 0.001134\n",
      "Train Epoch: 98 [28/107 (26%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 98 [32/107 (30%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 98 [36/107 (34%)]\tTrain Loss: 0.000001\n",
      "Train Epoch: 98 [40/107 (37%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 98 [44/107 (41%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 98 [48/107 (45%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 98 [52/107 (49%)]\tTrain Loss: 0.001107\n",
      "Train Epoch: 98 [56/107 (52%)]\tTrain Loss: 0.000412\n",
      "Train Epoch: 98 [60/107 (56%)]\tTrain Loss: 0.000248\n",
      "Train Epoch: 98 [64/107 (60%)]\tTrain Loss: 0.000192\n",
      "Train Epoch: 98 [68/107 (64%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 98 [72/107 (67%)]\tTrain Loss: 0.000097\n",
      "Train Epoch: 98 [76/107 (71%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 98 [80/107 (75%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 98 [84/107 (79%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 98 [88/107 (82%)]\tTrain Loss: 0.000212\n",
      "Train Epoch: 98 [92/107 (86%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 98 [96/107 (90%)]\tTrain Loss: 0.000179\n",
      "Train Epoch: 98 [100/107 (93%)]\tTrain Loss: 0.000060\n",
      "Train Epoch: 98 [104/107 (97%)]\tTrain Loss: 0.000461\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.22130306e-03 9.93158281e-01 3.49381426e-03 2.49239821e-02\n",
      " 2.81628477e-03 5.91388845e-04 7.07976699e-01 7.40980403e-03\n",
      " 2.44383467e-04 8.55712220e-03 4.42160249e-01 4.52801441e-06\n",
      " 2.79545397e-01 1.15562778e-03 6.46781782e-03 4.77154208e-06\n",
      " 3.60704644e-06 2.69729435e-01 1.08033058e-03 4.87485491e-02\n",
      " 1.21472284e-01 9.74922657e-01 9.99752462e-01 9.99981523e-01\n",
      " 9.17446494e-01 9.99725163e-01 9.99931335e-01 2.18292070e-03\n",
      " 6.83441609e-02 1.15596209e-04 3.55275795e-02 1.12969347e-03\n",
      " 3.70222360e-01 1.36946358e-06 1.12900898e-06 7.11807224e-05\n",
      " 5.71433302e-05 9.84937489e-01 6.67935908e-01 5.21641539e-07\n",
      " 2.66995698e-07 1.21095663e-05 1.38142094e-01 5.13300002e-02\n",
      " 5.21465659e-01 1.42549048e-03 5.21816909e-01 5.89797795e-01\n",
      " 8.38057935e-01 1.62746757e-02 8.75172377e-01 2.62888148e-04\n",
      " 9.96345188e-04 4.85085446e-04 3.85373423e-04 8.40464979e-03\n",
      " 9.76370275e-01 1.62106826e-08 3.57397184e-05 1.48564251e-03\n",
      " 9.99830604e-01 9.99859571e-01 9.99997735e-01 9.99995708e-01\n",
      " 9.99997377e-01 9.99613702e-01 9.97951090e-01 9.99999881e-01\n",
      " 9.99980092e-01 9.99650836e-01 5.91030300e-01 1.42477751e-01\n",
      " 9.54635799e-01 9.95951056e-01 9.98504758e-01 1.13434561e-01\n",
      " 9.99990582e-01 9.99869108e-01 9.99997735e-01 9.99105036e-01\n",
      " 9.99987721e-01 9.99713004e-01 9.99979138e-01 9.99563992e-01\n",
      " 9.56586123e-01 9.99943137e-01 9.99413013e-01 9.97346640e-01\n",
      " 1.97719485e-02 9.99451697e-01 9.99753892e-01 9.07718718e-01\n",
      " 7.86576509e-01 9.99999642e-01 9.99917030e-01 9.99996781e-01\n",
      " 2.88013160e-01 6.54053032e-01 9.99861360e-01 9.99815285e-01\n",
      " 5.46542764e-01 9.95366573e-01 1.91036448e-01 9.89908338e-01\n",
      " 1.89095527e-01 9.88013387e-01 9.93570566e-01 4.80924666e-01\n",
      " 8.46538052e-04 4.02528256e-01 9.92936313e-01 8.63845468e-01\n",
      " 9.99884486e-01 4.06191140e-01 1.04518319e-02 1.22706220e-03\n",
      " 9.99997258e-01 9.99997139e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 99 [0/107 (0%)]\tTrain Loss: 0.021022\n",
      "Train Epoch: 99 [4/107 (4%)]\tTrain Loss: 0.000055\n",
      "Train Epoch: 99 [8/107 (7%)]\tTrain Loss: 0.001319\n",
      "Train Epoch: 99 [12/107 (11%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 99 [16/107 (15%)]\tTrain Loss: 0.000818\n",
      "Train Epoch: 99 [20/107 (19%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 99 [24/107 (22%)]\tTrain Loss: 0.000448\n",
      "Train Epoch: 99 [28/107 (26%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 99 [32/107 (30%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 99 [36/107 (34%)]\tTrain Loss: 0.000191\n",
      "Train Epoch: 99 [40/107 (37%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 99 [44/107 (41%)]\tTrain Loss: 0.000106\n",
      "Train Epoch: 99 [48/107 (45%)]\tTrain Loss: 0.000278\n",
      "Train Epoch: 99 [52/107 (49%)]\tTrain Loss: 0.000193\n",
      "Train Epoch: 99 [56/107 (52%)]\tTrain Loss: 0.000205\n",
      "Train Epoch: 99 [60/107 (56%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 99 [64/107 (60%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 99 [68/107 (64%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 99 [72/107 (67%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 99 [76/107 (71%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 99 [80/107 (75%)]\tTrain Loss: 0.001218\n",
      "Train Epoch: 99 [84/107 (79%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 99 [88/107 (82%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 99 [92/107 (86%)]\tTrain Loss: 0.000638\n",
      "Train Epoch: 99 [96/107 (90%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 99 [100/107 (93%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 99 [104/107 (97%)]\tTrain Loss: 0.000521\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.20293279e-03 9.89307702e-01 3.21635720e-03 3.16121131e-02\n",
      " 2.31176103e-03 6.72273163e-04 6.98991835e-01 6.56016916e-03\n",
      " 4.49007232e-04 1.07651697e-02 4.59839433e-01 6.05610467e-06\n",
      " 3.07325006e-01 9.07822687e-04 3.61914095e-03 3.19479909e-06\n",
      " 1.33401613e-06 3.63191456e-01 9.35426098e-04 5.31194061e-02\n",
      " 1.89278319e-01 9.76681709e-01 9.99823630e-01 9.99981761e-01\n",
      " 9.16032434e-01 9.99666095e-01 9.99856710e-01 3.26936599e-03\n",
      " 7.24221095e-02 9.52042319e-05 4.51145470e-02 7.35795242e-04\n",
      " 2.08953753e-01 8.05730110e-07 1.36251492e-06 8.19848792e-05\n",
      " 3.98390148e-05 9.79186356e-01 4.93564039e-01 8.64888989e-07\n",
      " 3.29579308e-07 2.46125273e-05 7.87512064e-02 7.43649825e-02\n",
      " 5.60363293e-01 7.85460346e-04 2.98575968e-01 4.61962253e-01\n",
      " 8.03582549e-01 1.53402723e-02 8.46488774e-01 3.11589538e-04\n",
      " 3.61602497e-03 7.82745716e-04 5.75340993e-04 1.14705190e-02\n",
      " 9.72201347e-01 8.96291681e-08 2.22156232e-05 3.30942613e-03\n",
      " 9.99628186e-01 9.99764621e-01 9.99990344e-01 9.99981403e-01\n",
      " 9.99996781e-01 9.99474108e-01 9.97997463e-01 9.99999881e-01\n",
      " 9.99971509e-01 9.99223113e-01 4.20684338e-01 1.33453965e-01\n",
      " 9.27031100e-01 9.96404171e-01 9.97714162e-01 1.72644630e-01\n",
      " 9.99990821e-01 9.99659300e-01 9.99996662e-01 9.98390913e-01\n",
      " 9.99969959e-01 9.99139071e-01 9.99922037e-01 9.99281824e-01\n",
      " 9.71312463e-01 9.99759018e-01 9.98980105e-01 9.96600986e-01\n",
      " 2.85508633e-02 9.98249412e-01 9.99675989e-01 9.00547087e-01\n",
      " 8.26685846e-01 9.99999523e-01 9.99466479e-01 9.99992013e-01\n",
      " 3.42360467e-01 3.36816728e-01 9.99620318e-01 9.99636412e-01\n",
      " 4.03930366e-01 9.77720022e-01 4.74864841e-02 9.43921089e-01\n",
      " 4.95846048e-02 8.61531496e-01 9.76748228e-01 5.29461682e-01\n",
      " 4.80259128e-04 4.46773142e-01 9.86912847e-01 7.34884739e-01\n",
      " 9.99582112e-01 6.36314809e-01 3.13727721e-03 3.26472596e-04\n",
      " 9.99997616e-01 9.99991536e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/107 (0%)]\tTrain Loss: 0.001096\n",
      "Train Epoch: 100 [4/107 (4%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 100 [8/107 (7%)]\tTrain Loss: 0.000190\n",
      "Train Epoch: 100 [12/107 (11%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 100 [16/107 (15%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 100 [20/107 (19%)]\tTrain Loss: 0.000110\n",
      "Train Epoch: 100 [24/107 (22%)]\tTrain Loss: 0.000188\n",
      "Train Epoch: 100 [28/107 (26%)]\tTrain Loss: 0.001460\n",
      "Train Epoch: 100 [32/107 (30%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 100 [36/107 (34%)]\tTrain Loss: 0.000367\n",
      "Train Epoch: 100 [40/107 (37%)]\tTrain Loss: 0.000069\n",
      "Train Epoch: 100 [44/107 (41%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 100 [48/107 (45%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 100 [52/107 (49%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 100 [56/107 (52%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 100 [60/107 (56%)]\tTrain Loss: 0.001766\n",
      "Train Epoch: 100 [64/107 (60%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 100 [68/107 (64%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 100 [72/107 (67%)]\tTrain Loss: 0.000215\n",
      "Train Epoch: 100 [76/107 (71%)]\tTrain Loss: 0.000623\n",
      "Train Epoch: 100 [80/107 (75%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 100 [84/107 (79%)]\tTrain Loss: 0.001611\n",
      "Train Epoch: 100 [88/107 (82%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 100 [92/107 (86%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 100 [96/107 (90%)]\tTrain Loss: 0.000685\n",
      "Train Epoch: 100 [100/107 (93%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 100 [104/107 (97%)]\tTrain Loss: 0.000380\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.97701052e-03 9.97152805e-01 9.02099535e-03 1.42956063e-01\n",
      " 1.15941633e-02 3.68032581e-03 8.79082322e-01 4.27927226e-02\n",
      " 1.77591003e-03 3.98170725e-02 7.18067765e-01 1.08180957e-05\n",
      " 4.49609071e-01 3.91784823e-03 1.17024863e-02 2.42022743e-05\n",
      " 9.52096161e-06 6.27232611e-01 1.52350161e-02 1.63364261e-01\n",
      " 6.29077911e-01 9.94820714e-01 9.99979973e-01 9.99992132e-01\n",
      " 9.46973145e-01 9.99955297e-01 9.99976039e-01 1.62071697e-02\n",
      " 3.19389820e-01 2.74026504e-04 2.87544072e-01 6.59870496e-03\n",
      " 5.68445086e-01 3.35650793e-06 6.29556189e-06 2.60210305e-04\n",
      " 9.13743424e-05 9.91010666e-01 7.95456827e-01 2.28018644e-06\n",
      " 8.61320757e-07 5.22653099e-05 5.14450431e-01 3.34643930e-01\n",
      " 9.03196990e-01 5.53203700e-03 7.82841206e-01 7.44727850e-01\n",
      " 9.13451493e-01 5.00678010e-02 9.29951012e-01 2.08339235e-03\n",
      " 1.03417598e-02 2.95395614e-03 2.15586368e-03 2.34070458e-02\n",
      " 9.89812076e-01 1.89916932e-07 6.71815942e-05 1.07261669e-02\n",
      " 9.99955058e-01 9.99960899e-01 9.99999642e-01 9.99999046e-01\n",
      " 9.99999404e-01 9.99897361e-01 9.99747694e-01 1.00000000e+00\n",
      " 9.99998450e-01 9.99847651e-01 7.69427180e-01 4.89271849e-01\n",
      " 9.87062156e-01 9.99446213e-01 9.99459684e-01 7.63554871e-01\n",
      " 9.99998450e-01 9.99972701e-01 9.99999762e-01 9.99851346e-01\n",
      " 9.99998808e-01 9.99820054e-01 9.99984264e-01 9.99792397e-01\n",
      " 9.84101474e-01 9.99985814e-01 9.99661446e-01 9.99244094e-01\n",
      " 9.80946869e-02 9.99885559e-01 9.99900579e-01 9.79235470e-01\n",
      " 9.52977896e-01 1.00000000e+00 9.99962568e-01 9.99999523e-01\n",
      " 4.09552574e-01 5.73567033e-01 9.99972105e-01 9.99965549e-01\n",
      " 5.38608134e-01 9.97920811e-01 3.28473002e-01 9.96106327e-01\n",
      " 3.62211704e-01 9.65042830e-01 9.97580290e-01 5.50753117e-01\n",
      " 1.77198299e-03 8.16824377e-01 9.96064961e-01 7.78280795e-01\n",
      " 9.99951005e-01 8.89148653e-01 2.98324674e-02 1.25298621e-02\n",
      " 9.99999881e-01 9.99999523e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 43 FN= 12 FP= 17\n",
      "TP+FP 63\n",
      "precision 0.7301587301587301\n",
      "recall 0.7931034482758621\n",
      "F1 0.7603305785123967\n",
      "acc 0.7542372881355932\n",
      "AUCp 0.7548850574712644\n",
      "AUC 0.8689655172413793\n",
      "\n",
      " The epoch is 100, average recall: 0.7931, average precision: 0.7302,average F1: 0.7603, average accuracy: 0.7542, average AUC: 0.8690\n",
      "Train Epoch: 101 [0/107 (0%)]\tTrain Loss: 0.000337\n",
      "Train Epoch: 101 [4/107 (4%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 101 [8/107 (7%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 101 [12/107 (11%)]\tTrain Loss: 0.000241\n",
      "Train Epoch: 101 [16/107 (15%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 101 [20/107 (19%)]\tTrain Loss: 0.006615\n",
      "Train Epoch: 101 [24/107 (22%)]\tTrain Loss: 0.000614\n",
      "Train Epoch: 101 [28/107 (26%)]\tTrain Loss: 0.002453\n",
      "Train Epoch: 101 [32/107 (30%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 101 [36/107 (34%)]\tTrain Loss: 0.000234\n",
      "Train Epoch: 101 [40/107 (37%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 101 [44/107 (41%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 101 [48/107 (45%)]\tTrain Loss: 0.000435\n",
      "Train Epoch: 101 [52/107 (49%)]\tTrain Loss: 0.000141\n",
      "Train Epoch: 101 [56/107 (52%)]\tTrain Loss: 0.001182\n",
      "Train Epoch: 101 [60/107 (56%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 101 [64/107 (60%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 101 [68/107 (64%)]\tTrain Loss: 0.000154\n",
      "Train Epoch: 101 [72/107 (67%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 101 [76/107 (71%)]\tTrain Loss: 0.000877\n",
      "Train Epoch: 101 [80/107 (75%)]\tTrain Loss: 0.000170\n",
      "Train Epoch: 101 [84/107 (79%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 101 [88/107 (82%)]\tTrain Loss: 0.000373\n",
      "Train Epoch: 101 [92/107 (86%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 101 [96/107 (90%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 101 [100/107 (93%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 101 [104/107 (97%)]\tTrain Loss: 0.000285\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.98403825e-03 9.95262027e-01 6.89621316e-03 6.90028965e-02\n",
      " 5.93949249e-03 1.21438352e-03 8.08139205e-01 3.43097225e-02\n",
      " 7.54117558e-04 2.83544399e-02 6.63554013e-01 1.10669180e-05\n",
      " 3.66568029e-01 2.40102224e-03 7.69123714e-03 1.44363557e-05\n",
      " 9.18468049e-06 4.01097536e-01 4.46640374e-03 6.83277324e-02\n",
      " 4.13977444e-01 9.85881090e-01 9.99947548e-01 9.99971151e-01\n",
      " 9.05469894e-01 9.99869823e-01 9.99904037e-01 2.94803604e-02\n",
      " 2.53054082e-01 1.16110379e-04 2.09118307e-01 3.57649568e-03\n",
      " 5.64657629e-01 2.95568339e-06 4.74847593e-06 3.33095755e-04\n",
      " 1.13062350e-04 9.83070791e-01 6.80272698e-01 1.54842587e-06\n",
      " 7.47372837e-07 3.43389765e-05 4.45952266e-01 2.82520562e-01\n",
      " 7.66922235e-01 1.57359825e-03 5.73307276e-01 5.18310547e-01\n",
      " 8.05755079e-01 3.18942443e-02 8.43232691e-01 1.06826378e-03\n",
      " 5.18837711e-03 1.27479935e-03 8.63005698e-04 1.66603085e-02\n",
      " 9.78162169e-01 1.44015118e-07 1.03552578e-04 5.59682585e-03\n",
      " 9.99792397e-01 9.99866605e-01 9.99997497e-01 9.99989152e-01\n",
      " 9.99996662e-01 9.99728262e-01 9.99039829e-01 9.99999881e-01\n",
      " 9.99986529e-01 9.99607384e-01 5.84170163e-01 2.33691305e-01\n",
      " 9.61590648e-01 9.98373985e-01 9.99239326e-01 5.47970116e-01\n",
      " 9.99995470e-01 9.99890208e-01 9.99998331e-01 9.99666810e-01\n",
      " 9.99992967e-01 9.99521017e-01 9.99954581e-01 9.99253213e-01\n",
      " 9.72504616e-01 9.99930620e-01 9.99348819e-01 9.97748673e-01\n",
      " 9.96219888e-02 9.99541283e-01 9.99692202e-01 9.43194866e-01\n",
      " 9.00345981e-01 9.99999762e-01 9.99842286e-01 9.99997377e-01\n",
      " 3.50127071e-01 4.14703935e-01 9.99899387e-01 9.99887705e-01\n",
      " 5.06533027e-01 9.96544182e-01 1.75542668e-01 9.84808326e-01\n",
      " 1.21030651e-01 9.40132439e-01 9.93750870e-01 6.43795550e-01\n",
      " 1.35402812e-03 7.21936703e-01 9.94531751e-01 7.62414396e-01\n",
      " 9.99773920e-01 8.57531607e-01 3.57574783e-02 1.22564603e-02\n",
      " 9.99998569e-01 9.99997497e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 102 [0/107 (0%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 102 [4/107 (4%)]\tTrain Loss: 0.000055\n",
      "Train Epoch: 102 [8/107 (7%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 102 [12/107 (11%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 102 [16/107 (15%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 102 [20/107 (19%)]\tTrain Loss: 0.000689\n",
      "Train Epoch: 102 [24/107 (22%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 102 [28/107 (26%)]\tTrain Loss: 0.000284\n",
      "Train Epoch: 102 [32/107 (30%)]\tTrain Loss: 0.000215\n",
      "Train Epoch: 102 [36/107 (34%)]\tTrain Loss: 0.001200\n",
      "Train Epoch: 102 [40/107 (37%)]\tTrain Loss: 0.000196\n",
      "Train Epoch: 102 [44/107 (41%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 102 [48/107 (45%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 102 [52/107 (49%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 102 [56/107 (52%)]\tTrain Loss: 0.000213\n",
      "Train Epoch: 102 [60/107 (56%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 102 [64/107 (60%)]\tTrain Loss: 0.000097\n",
      "Train Epoch: 102 [68/107 (64%)]\tTrain Loss: 0.000295\n",
      "Train Epoch: 102 [72/107 (67%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 102 [76/107 (71%)]\tTrain Loss: 0.000133\n",
      "Train Epoch: 102 [80/107 (75%)]\tTrain Loss: 0.000485\n",
      "Train Epoch: 102 [84/107 (79%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 102 [88/107 (82%)]\tTrain Loss: 0.000686\n",
      "Train Epoch: 102 [92/107 (86%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 102 [96/107 (90%)]\tTrain Loss: 0.001068\n",
      "Train Epoch: 102 [100/107 (93%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 102 [104/107 (97%)]\tTrain Loss: 0.000184\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.15218163e-02 9.92291391e-01 1.35445530e-02 2.04365030e-01\n",
      " 3.88957560e-02 2.80906470e-03 8.27190399e-01 5.85590564e-02\n",
      " 2.57389573e-03 1.48673713e-01 9.52570021e-01 1.26759624e-04\n",
      " 8.11081171e-01 9.25445743e-03 4.24453542e-02 1.22227895e-04\n",
      " 8.92026641e-04 5.45042872e-01 1.77338365e-02 1.70989349e-01\n",
      " 6.29119158e-01 9.94329929e-01 9.99989271e-01 9.99985099e-01\n",
      " 9.84209239e-01 9.99944210e-01 9.99863982e-01 3.58149968e-02\n",
      " 8.62452507e-01 1.76838436e-03 6.46923721e-01 2.79495399e-02\n",
      " 7.36580968e-01 1.41088516e-04 1.25494116e-04 2.54609273e-03\n",
      " 3.12985829e-03 9.94658291e-01 9.49011743e-01 6.58173230e-05\n",
      " 2.08993079e-05 1.12237956e-03 5.07643282e-01 7.03836024e-01\n",
      " 9.65357602e-01 1.38641139e-02 8.97956014e-01 8.17563593e-01\n",
      " 9.06514704e-01 6.71297982e-02 9.07799840e-01 6.09211437e-03\n",
      " 5.52729554e-02 5.73661625e-02 7.66481161e-02 9.88588631e-02\n",
      " 9.83338714e-01 1.28440970e-05 2.37717963e-04 7.58055821e-02\n",
      " 9.99681473e-01 9.99759853e-01 9.99994040e-01 9.99983311e-01\n",
      " 9.99997616e-01 9.99892354e-01 9.99415159e-01 9.99999762e-01\n",
      " 9.99982715e-01 9.99504924e-01 5.54944873e-01 2.53123075e-01\n",
      " 9.83541846e-01 9.98511612e-01 9.99366701e-01 7.68065274e-01\n",
      " 9.99988914e-01 9.99793708e-01 9.99998689e-01 9.99456227e-01\n",
      " 9.99984264e-01 9.99785960e-01 9.99946594e-01 9.99428689e-01\n",
      " 9.90764856e-01 9.99932766e-01 9.99637604e-01 9.98064697e-01\n",
      " 1.53204158e-01 9.99739110e-01 9.99696732e-01 9.61111605e-01\n",
      " 9.45603669e-01 9.99999881e-01 9.99946713e-01 9.99998569e-01\n",
      " 7.14418888e-01 8.93844664e-01 9.99949694e-01 9.99846578e-01\n",
      " 9.03624833e-01 9.97397423e-01 4.47852373e-01 9.97946560e-01\n",
      " 7.60508895e-01 9.83756423e-01 9.90928590e-01 7.77709961e-01\n",
      " 1.07785594e-02 8.02551985e-01 9.98335183e-01 9.48754370e-01\n",
      " 9.99817550e-01 9.73572135e-01 7.37852976e-02 1.26547873e-01\n",
      " 9.99994040e-01 9.99996305e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 103 [0/107 (0%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 103 [4/107 (4%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 103 [8/107 (7%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 103 [12/107 (11%)]\tTrain Loss: 0.006455\n",
      "Train Epoch: 103 [16/107 (15%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 103 [20/107 (19%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 103 [24/107 (22%)]\tTrain Loss: 0.010055\n",
      "Train Epoch: 103 [28/107 (26%)]\tTrain Loss: 0.000165\n",
      "Train Epoch: 103 [32/107 (30%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 103 [36/107 (34%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 103 [40/107 (37%)]\tTrain Loss: 0.000208\n",
      "Train Epoch: 103 [44/107 (41%)]\tTrain Loss: 0.000114\n",
      "Train Epoch: 103 [48/107 (45%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 103 [52/107 (49%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 103 [56/107 (52%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 103 [60/107 (56%)]\tTrain Loss: 0.000156\n",
      "Train Epoch: 103 [64/107 (60%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 103 [68/107 (64%)]\tTrain Loss: 0.000130\n",
      "Train Epoch: 103 [72/107 (67%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 103 [76/107 (71%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 103 [80/107 (75%)]\tTrain Loss: 0.000204\n",
      "Train Epoch: 103 [84/107 (79%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 103 [88/107 (82%)]\tTrain Loss: 0.000760\n",
      "Train Epoch: 103 [92/107 (86%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 103 [96/107 (90%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 103 [100/107 (93%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 103 [104/107 (97%)]\tTrain Loss: 0.000157\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.05415213e-03 9.97001946e-01 2.30929796e-02 5.17524555e-02\n",
      " 1.28696598e-02 4.34383051e-03 9.68820989e-01 1.67900473e-02\n",
      " 1.60952506e-03 5.57236075e-02 8.71118307e-01 1.46313278e-05\n",
      " 6.15981340e-01 7.28933420e-03 2.60651018e-02 4.12782356e-05\n",
      " 4.94125343e-05 4.88528848e-01 4.32149023e-02 1.10362746e-01\n",
      " 6.49954855e-01 9.98029053e-01 9.99961972e-01 9.99994636e-01\n",
      " 9.88996983e-01 9.99950767e-01 9.99910593e-01 2.52617504e-02\n",
      " 4.94837880e-01 6.28880865e-04 7.08117127e-01 9.07603931e-03\n",
      " 7.18323767e-01 2.64374776e-05 2.69026605e-05 8.89047224e-04\n",
      " 8.66957766e-04 9.98017311e-01 9.53523099e-01 1.52192588e-05\n",
      " 2.73994101e-06 1.14619976e-03 5.40267825e-01 6.73574805e-01\n",
      " 9.26289558e-01 6.05643680e-03 8.70338321e-01 8.50929081e-01\n",
      " 9.71811652e-01 3.48049439e-02 9.54990864e-01 4.38693119e-03\n",
      " 1.30429380e-02 1.33694774e-02 5.80030307e-03 4.00027260e-02\n",
      " 9.81622934e-01 1.37926884e-06 6.31824805e-05 7.57498434e-03\n",
      " 9.99841571e-01 9.99869108e-01 9.99998331e-01 9.99996066e-01\n",
      " 9.99998927e-01 9.99912262e-01 9.99714196e-01 1.00000000e+00\n",
      " 9.99992967e-01 9.99719203e-01 5.89338124e-01 1.89194515e-01\n",
      " 9.75084841e-01 9.99514103e-01 9.99614596e-01 5.16128719e-01\n",
      " 9.99995708e-01 9.99893785e-01 9.99999046e-01 9.99371231e-01\n",
      " 9.99991059e-01 9.99636292e-01 9.99957442e-01 9.99671698e-01\n",
      " 9.86246347e-01 9.99983668e-01 9.99468029e-01 9.98657942e-01\n",
      " 2.24321231e-01 9.99946475e-01 9.99935508e-01 9.80930865e-01\n",
      " 9.14134860e-01 1.00000000e+00 9.99881506e-01 9.99999285e-01\n",
      " 3.52807015e-01 8.31180871e-01 9.99964952e-01 9.99915242e-01\n",
      " 6.77682757e-01 9.97850418e-01 7.03792095e-01 9.80433226e-01\n",
      " 1.62936643e-01 8.10318768e-01 9.92348790e-01 9.33802485e-01\n",
      " 3.32832746e-02 8.26746821e-01 9.99272645e-01 9.46448863e-01\n",
      " 9.99989390e-01 9.85395610e-01 2.22883709e-02 8.33053961e-02\n",
      " 9.99998927e-01 9.99999523e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 104 [0/107 (0%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 104 [4/107 (4%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 104 [8/107 (7%)]\tTrain Loss: 0.004447\n",
      "Train Epoch: 104 [12/107 (11%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 104 [16/107 (15%)]\tTrain Loss: 0.000177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 104 [20/107 (19%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 104 [24/107 (22%)]\tTrain Loss: 0.004724\n",
      "Train Epoch: 104 [28/107 (26%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 104 [32/107 (30%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 104 [36/107 (34%)]\tTrain Loss: 0.000418\n",
      "Train Epoch: 104 [40/107 (37%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 104 [44/107 (41%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 104 [48/107 (45%)]\tTrain Loss: 0.001207\n",
      "Train Epoch: 104 [52/107 (49%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 104 [56/107 (52%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 104 [60/107 (56%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 104 [64/107 (60%)]\tTrain Loss: 0.001260\n",
      "Train Epoch: 104 [68/107 (64%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 104 [72/107 (67%)]\tTrain Loss: 0.021045\n",
      "Train Epoch: 104 [76/107 (71%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 104 [80/107 (75%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 104 [84/107 (79%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 104 [88/107 (82%)]\tTrain Loss: 0.000163\n",
      "Train Epoch: 104 [92/107 (86%)]\tTrain Loss: 0.000446\n",
      "Train Epoch: 104 [96/107 (90%)]\tTrain Loss: 0.000307\n",
      "Train Epoch: 104 [100/107 (93%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 104 [104/107 (97%)]\tTrain Loss: 0.000186\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.59203063e-03 9.85297859e-01 3.38671892e-03 6.21889569e-02\n",
      " 6.11137925e-03 4.78405273e-04 6.58614397e-01 2.62082145e-02\n",
      " 4.27135470e-04 2.41102260e-02 8.39468181e-01 8.24364542e-06\n",
      " 3.36340159e-01 2.11168686e-03 8.33191816e-03 8.08881305e-06\n",
      " 2.73997593e-05 5.73918760e-01 5.35591040e-03 5.81638925e-02\n",
      " 2.98360646e-01 9.93341386e-01 9.99960303e-01 9.99972343e-01\n",
      " 9.63586807e-01 9.99906659e-01 9.99879479e-01 4.98364773e-03\n",
      " 4.85970736e-01 1.43351790e-04 4.46532756e-01 4.28511575e-03\n",
      " 7.01379120e-01 5.62825153e-06 8.18901481e-06 3.57353681e-04\n",
      " 3.41710838e-04 9.89885688e-01 8.90023828e-01 3.75928244e-06\n",
      " 1.38081919e-06 8.53826568e-05 2.10731760e-01 2.77092606e-01\n",
      " 7.75026798e-01 2.72738887e-03 8.44542146e-01 7.54436433e-01\n",
      " 8.55465055e-01 1.93030238e-02 8.39008212e-01 8.10904894e-04\n",
      " 3.78230540e-03 6.39168220e-03 1.06055923e-02 2.28543673e-02\n",
      " 9.76684451e-01 6.89330761e-07 3.35135082e-05 5.45893610e-03\n",
      " 9.99719322e-01 9.99803841e-01 9.99996424e-01 9.99993563e-01\n",
      " 9.99995708e-01 9.99845386e-01 9.99070227e-01 9.99999642e-01\n",
      " 9.99973536e-01 9.99469817e-01 4.68346387e-01 1.47140428e-01\n",
      " 9.72030103e-01 9.98086214e-01 9.99174178e-01 3.78304809e-01\n",
      " 9.99987721e-01 9.99653101e-01 9.99995708e-01 9.99339521e-01\n",
      " 9.99983072e-01 9.99164104e-01 9.99936461e-01 9.99318600e-01\n",
      " 9.84303772e-01 9.99959588e-01 9.99402642e-01 9.97039974e-01\n",
      " 4.08293046e-02 9.99491930e-01 9.99662280e-01 9.52577293e-01\n",
      " 8.62960637e-01 9.99999762e-01 9.99863982e-01 9.99994397e-01\n",
      " 3.09494257e-01 8.61228824e-01 9.99930024e-01 9.99702632e-01\n",
      " 5.06517828e-01 9.96792734e-01 3.93491715e-01 9.80666220e-01\n",
      " 2.15132624e-01 9.69609678e-01 9.87154961e-01 5.86630404e-01\n",
      " 2.48924037e-03 5.83005965e-01 9.94536638e-01 8.92458856e-01\n",
      " 9.99761999e-01 8.82991672e-01 1.66705009e-02 4.65741232e-02\n",
      " 9.99995232e-01 9.99994636e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 105 [0/107 (0%)]\tTrain Loss: 0.000095\n",
      "Train Epoch: 105 [4/107 (4%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 105 [8/107 (7%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 105 [12/107 (11%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 105 [16/107 (15%)]\tTrain Loss: 0.000107\n",
      "Train Epoch: 105 [20/107 (19%)]\tTrain Loss: 0.000148\n",
      "Train Epoch: 105 [24/107 (22%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 105 [28/107 (26%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 105 [32/107 (30%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 105 [36/107 (34%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 105 [40/107 (37%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 105 [44/107 (41%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 105 [48/107 (45%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 105 [52/107 (49%)]\tTrain Loss: 0.000383\n",
      "Train Epoch: 105 [56/107 (52%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 105 [60/107 (56%)]\tTrain Loss: 0.001481\n",
      "Train Epoch: 105 [64/107 (60%)]\tTrain Loss: 0.003455\n",
      "Train Epoch: 105 [68/107 (64%)]\tTrain Loss: 0.005788\n",
      "Train Epoch: 105 [72/107 (67%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 105 [76/107 (71%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 105 [80/107 (75%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 105 [84/107 (79%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 105 [88/107 (82%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 105 [92/107 (86%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 105 [96/107 (90%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 105 [100/107 (93%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 105 [104/107 (97%)]\tTrain Loss: 0.000040\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.15328757e-03 9.93297994e-01 3.41085228e-03 8.40468034e-02\n",
      " 1.11170979e-02 9.31828108e-04 4.42318976e-01 3.72961164e-02\n",
      " 1.60940143e-03 4.37305570e-02 7.32565522e-01 9.08611310e-06\n",
      " 4.53793138e-01 2.34262855e-03 1.42202368e-02 2.14945776e-05\n",
      " 4.94714004e-05 5.77808142e-01 1.54310530e-02 5.54702468e-02\n",
      " 4.44536418e-01 9.90413845e-01 9.99965191e-01 9.99985814e-01\n",
      " 9.34283793e-01 9.99941587e-01 9.99972105e-01 2.03347486e-02\n",
      " 4.99614090e-01 1.95139117e-04 4.23127294e-01 1.17805339e-02\n",
      " 5.23012102e-01 4.59171360e-06 1.29900800e-05 2.35967251e-04\n",
      " 2.97325954e-04 9.92066741e-01 8.35003257e-01 5.19158311e-06\n",
      " 1.53611506e-06 6.63950559e-05 4.36438769e-01 4.93829668e-01\n",
      " 8.64754498e-01 7.10454816e-03 8.07938933e-01 7.58063972e-01\n",
      " 8.91042948e-01 4.10189666e-02 8.96501184e-01 1.90562219e-03\n",
      " 2.18487419e-02 2.51830928e-02 3.18321921e-02 2.28917375e-02\n",
      " 9.92293835e-01 2.59964554e-06 9.57851225e-05 3.69059741e-02\n",
      " 9.99936819e-01 9.99936104e-01 9.99999166e-01 9.99996305e-01\n",
      " 9.99998093e-01 9.99896526e-01 9.99555767e-01 1.00000000e+00\n",
      " 9.99985576e-01 9.99717772e-01 6.64561033e-01 3.19108337e-01\n",
      " 9.80886042e-01 9.99057710e-01 9.99449909e-01 8.33290517e-01\n",
      " 9.99991536e-01 9.99889851e-01 9.99998689e-01 9.99593437e-01\n",
      " 9.99994993e-01 9.99730408e-01 9.99973059e-01 9.99739587e-01\n",
      " 9.76187766e-01 9.99980569e-01 9.99473989e-01 9.98150408e-01\n",
      " 6.61673322e-02 9.99864340e-01 9.99799430e-01 9.57956314e-01\n",
      " 8.88502955e-01 9.99999881e-01 9.99951005e-01 9.99998450e-01\n",
      " 3.49552363e-01 6.34275854e-01 9.99949694e-01 9.99847293e-01\n",
      " 5.90280712e-01 9.96050179e-01 1.39833897e-01 9.92768764e-01\n",
      " 4.71574485e-01 9.70253527e-01 9.93403137e-01 7.42823303e-01\n",
      " 2.53364351e-03 8.62552345e-01 9.97474015e-01 8.59966278e-01\n",
      " 9.99944210e-01 8.87401700e-01 2.42570657e-02 3.03732343e-02\n",
      " 9.99998331e-01 9.99994636e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 106 [0/107 (0%)]\tTrain Loss: 0.006870\n",
      "Train Epoch: 106 [4/107 (4%)]\tTrain Loss: 0.000678\n",
      "Train Epoch: 106 [8/107 (7%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 106 [12/107 (11%)]\tTrain Loss: 0.000222\n",
      "Train Epoch: 106 [16/107 (15%)]\tTrain Loss: 0.000832\n",
      "Train Epoch: 106 [20/107 (19%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 106 [24/107 (22%)]\tTrain Loss: 0.000215\n",
      "Train Epoch: 106 [28/107 (26%)]\tTrain Loss: 0.000874\n",
      "Train Epoch: 106 [32/107 (30%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 106 [36/107 (34%)]\tTrain Loss: 0.000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106 [40/107 (37%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 106 [44/107 (41%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 106 [48/107 (45%)]\tTrain Loss: 0.000360\n",
      "Train Epoch: 106 [52/107 (49%)]\tTrain Loss: 0.000107\n",
      "Train Epoch: 106 [56/107 (52%)]\tTrain Loss: 0.000754\n",
      "Train Epoch: 106 [60/107 (56%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 106 [64/107 (60%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 106 [68/107 (64%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 106 [72/107 (67%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 106 [76/107 (71%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 106 [80/107 (75%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 106 [84/107 (79%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 106 [88/107 (82%)]\tTrain Loss: 0.000138\n",
      "Train Epoch: 106 [92/107 (86%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 106 [96/107 (90%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 106 [100/107 (93%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 106 [104/107 (97%)]\tTrain Loss: 0.000055\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.78763829e-03 9.84708667e-01 2.06041569e-03 3.71349193e-02\n",
      " 3.27619794e-03 5.43469097e-04 5.74267030e-01 7.30827684e-03\n",
      " 1.46561151e-03 2.42344122e-02 7.30434239e-01 9.52642858e-06\n",
      " 2.97835857e-01 1.26528763e-03 6.40910678e-03 1.43151119e-05\n",
      " 2.32659913e-05 2.77821958e-01 8.09064042e-03 9.37835351e-02\n",
      " 5.11167526e-01 9.82419729e-01 9.99971390e-01 9.99989986e-01\n",
      " 9.45890605e-01 9.99950171e-01 9.99957085e-01 1.71889607e-02\n",
      " 4.91041243e-01 1.51986300e-04 4.73631531e-01 7.07017351e-03\n",
      " 4.17629123e-01 4.84580187e-06 9.39015626e-06 1.32626403e-04\n",
      " 1.11285015e-04 9.73681629e-01 6.43487573e-01 7.48802177e-06\n",
      " 2.24843302e-06 1.13978531e-04 2.06871256e-01 2.28379875e-01\n",
      " 8.56870949e-01 8.97283014e-03 7.90191650e-01 6.99681282e-01\n",
      " 8.91034365e-01 4.21404205e-02 9.18682933e-01 4.62429336e-04\n",
      " 1.88738499e-02 1.22595858e-02 5.19232824e-02 2.74654664e-02\n",
      " 9.90054965e-01 1.10473138e-06 3.19142746e-05 3.46772186e-02\n",
      " 9.99923229e-01 9.99930143e-01 9.99998808e-01 9.99998093e-01\n",
      " 9.99999166e-01 9.99861479e-01 9.99217629e-01 1.00000000e+00\n",
      " 9.99992013e-01 9.99449432e-01 6.42494738e-01 4.13527429e-01\n",
      " 9.80762839e-01 9.98891890e-01 9.99309540e-01 8.44226122e-01\n",
      " 9.99990940e-01 9.99776900e-01 9.99999046e-01 9.99526978e-01\n",
      " 9.99997258e-01 9.99907494e-01 9.99986410e-01 9.99689341e-01\n",
      " 9.66166139e-01 9.99973655e-01 9.99655366e-01 9.98359740e-01\n",
      " 3.63572575e-02 9.99782264e-01 9.99848843e-01 9.05186236e-01\n",
      " 8.38345289e-01 1.00000000e+00 9.99975443e-01 9.99999046e-01\n",
      " 5.43954492e-01 7.76702762e-01 9.99959111e-01 9.99873757e-01\n",
      " 4.70953673e-01 9.85131681e-01 1.23901598e-01 9.94973779e-01\n",
      " 3.09322417e-01 9.87221658e-01 9.92939591e-01 5.69721997e-01\n",
      " 1.47435244e-03 8.21669877e-01 9.91643190e-01 7.06753731e-01\n",
      " 9.99957800e-01 9.22502637e-01 2.94039529e-02 3.09806988e-02\n",
      " 9.99995470e-01 9.99996066e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 107 [0/107 (0%)]\tTrain Loss: 0.000456\n",
      "Train Epoch: 107 [4/107 (4%)]\tTrain Loss: 0.001922\n",
      "Train Epoch: 107 [8/107 (7%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 107 [12/107 (11%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 107 [16/107 (15%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 107 [20/107 (19%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 107 [24/107 (22%)]\tTrain Loss: 0.000370\n",
      "Train Epoch: 107 [28/107 (26%)]\tTrain Loss: 0.000503\n",
      "Train Epoch: 107 [32/107 (30%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 107 [36/107 (34%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 107 [40/107 (37%)]\tTrain Loss: 0.001233\n",
      "Train Epoch: 107 [44/107 (41%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 107 [48/107 (45%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 107 [52/107 (49%)]\tTrain Loss: 0.000556\n",
      "Train Epoch: 107 [56/107 (52%)]\tTrain Loss: 0.000184\n",
      "Train Epoch: 107 [60/107 (56%)]\tTrain Loss: 0.000405\n",
      "Train Epoch: 107 [64/107 (60%)]\tTrain Loss: 0.000297\n",
      "Train Epoch: 107 [68/107 (64%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 107 [72/107 (67%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 107 [76/107 (71%)]\tTrain Loss: 0.000160\n",
      "Train Epoch: 107 [80/107 (75%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 107 [84/107 (79%)]\tTrain Loss: 0.000286\n",
      "Train Epoch: 107 [88/107 (82%)]\tTrain Loss: 0.000482\n",
      "Train Epoch: 107 [92/107 (86%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 107 [96/107 (90%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 107 [100/107 (93%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 107 [104/107 (97%)]\tTrain Loss: 0.000048\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.27028344e-04 9.64980602e-01 1.08410651e-03 6.48718793e-03\n",
      " 1.05529057e-03 1.79026669e-04 3.70805055e-01 2.45323125e-03\n",
      " 2.58867367e-04 8.08544178e-03 3.91035438e-01 1.72245518e-06\n",
      " 1.20788641e-01 5.10082580e-04 2.48941733e-03 1.94032577e-06\n",
      " 1.34790798e-06 1.21760145e-01 2.89651472e-03 2.71916501e-02\n",
      " 2.55267441e-01 9.74497139e-01 9.99902964e-01 9.99980450e-01\n",
      " 8.53693902e-01 9.99853969e-01 9.99884009e-01 1.78509410e-02\n",
      " 1.55707881e-01 7.16108407e-05 2.48674661e-01 2.16488517e-03\n",
      " 3.41650486e-01 2.26530437e-06 1.38454698e-06 4.16618932e-05\n",
      " 6.77146600e-05 9.65002418e-01 6.20993912e-01 5.08344272e-07\n",
      " 9.75658239e-08 9.78323897e-06 2.47430101e-01 1.71753943e-01\n",
      " 5.44303000e-01 9.25735803e-04 3.18922222e-01 3.76018435e-01\n",
      " 7.66736865e-01 1.05671929e-02 7.61284888e-01 1.82298696e-04\n",
      " 2.09207763e-03 9.23898479e-04 1.99825270e-03 9.56340320e-03\n",
      " 9.63734567e-01 1.11547436e-07 1.40928851e-05 2.96337646e-03\n",
      " 9.99601066e-01 9.99684334e-01 9.99995232e-01 9.99988556e-01\n",
      " 9.99995112e-01 9.99533057e-01 9.97401237e-01 9.99999762e-01\n",
      " 9.99955177e-01 9.99368966e-01 2.80709714e-01 8.03094655e-02\n",
      " 9.10327911e-01 9.95996356e-01 9.97884810e-01 4.77083415e-01\n",
      " 9.99976754e-01 9.99569952e-01 9.99996662e-01 9.97658372e-01\n",
      " 9.99975324e-01 9.99132454e-01 9.99951839e-01 9.99031425e-01\n",
      " 9.24103141e-01 9.99959946e-01 9.99044478e-01 9.96407092e-01\n",
      " 1.00682341e-02 9.97825265e-01 9.99380827e-01 7.84664214e-01\n",
      " 6.59292936e-01 9.99999762e-01 9.99559581e-01 9.99992013e-01\n",
      " 1.54237077e-01 5.05378008e-01 9.99675989e-01 9.99621511e-01\n",
      " 2.07748666e-01 9.86228049e-01 3.78097333e-02 8.80065739e-01\n",
      " 4.45907973e-02 9.39152539e-01 9.79785502e-01 5.31254053e-01\n",
      " 7.85710581e-04 3.84249359e-01 9.69690382e-01 5.34119904e-01\n",
      " 9.99784887e-01 7.26468146e-01 7.77398888e-03 1.46812024e-02\n",
      " 9.99991655e-01 9.99981523e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 108 [0/107 (0%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 108 [4/107 (4%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 108 [8/107 (7%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 108 [12/107 (11%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 108 [16/107 (15%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 108 [20/107 (19%)]\tTrain Loss: 0.000128\n",
      "Train Epoch: 108 [24/107 (22%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 108 [28/107 (26%)]\tTrain Loss: 0.023018\n",
      "Train Epoch: 108 [32/107 (30%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 108 [36/107 (34%)]\tTrain Loss: 0.009242\n",
      "Train Epoch: 108 [40/107 (37%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 108 [44/107 (41%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 108 [48/107 (45%)]\tTrain Loss: 0.001040\n",
      "Train Epoch: 108 [52/107 (49%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 108 [56/107 (52%)]\tTrain Loss: 0.005266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108 [60/107 (56%)]\tTrain Loss: 0.005290\n",
      "Train Epoch: 108 [64/107 (60%)]\tTrain Loss: 0.000851\n",
      "Train Epoch: 108 [68/107 (64%)]\tTrain Loss: 0.000208\n",
      "Train Epoch: 108 [72/107 (67%)]\tTrain Loss: 0.000434\n",
      "Train Epoch: 108 [76/107 (71%)]\tTrain Loss: 0.000055\n",
      "Train Epoch: 108 [80/107 (75%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 108 [84/107 (79%)]\tTrain Loss: 0.000247\n",
      "Train Epoch: 108 [88/107 (82%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 108 [92/107 (86%)]\tTrain Loss: 0.007715\n",
      "Train Epoch: 108 [96/107 (90%)]\tTrain Loss: 0.000114\n",
      "Train Epoch: 108 [100/107 (93%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 108 [104/107 (97%)]\tTrain Loss: 0.001980\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.62169899e-04 9.52045143e-01 1.93942583e-03 7.20764697e-03\n",
      " 2.34433333e-03 3.64948879e-04 5.97479641e-01 3.15548270e-03\n",
      " 3.58944235e-04 6.25208905e-03 4.41003501e-01 4.28097565e-06\n",
      " 2.57975787e-01 5.89232950e-04 2.10676156e-03 9.10902600e-06\n",
      " 1.08264030e-05 1.11403503e-01 2.39537912e-03 3.73114794e-02\n",
      " 2.51908273e-01 9.69385803e-01 9.99932647e-01 9.99944448e-01\n",
      " 8.75873744e-01 9.99746859e-01 9.99406099e-01 1.15200216e-02\n",
      " 2.52027184e-01 1.25209481e-04 2.81580299e-01 2.27789627e-03\n",
      " 4.35619473e-01 4.83966915e-06 4.30606678e-06 2.25683165e-04\n",
      " 1.66691214e-04 9.73823488e-01 7.47110546e-01 1.85874842e-06\n",
      " 6.27283214e-07 2.85279693e-05 4.54875439e-01 1.92839146e-01\n",
      " 7.56691933e-01 2.63461214e-03 4.33885932e-01 4.54080880e-01\n",
      " 7.50519931e-01 1.28000071e-02 7.99962342e-01 1.92292850e-04\n",
      " 1.96183450e-03 3.91010777e-04 2.63980054e-03 9.61180497e-03\n",
      " 9.60616767e-01 1.81104923e-07 2.39212477e-05 2.43683299e-03\n",
      " 9.99337137e-01 9.99339879e-01 9.99972820e-01 9.99958396e-01\n",
      " 9.99994278e-01 9.99228001e-01 9.94048953e-01 9.99998927e-01\n",
      " 9.99933600e-01 9.98601973e-01 1.89581126e-01 5.61333373e-02\n",
      " 8.86951089e-01 9.96559799e-01 9.98009503e-01 5.28530180e-01\n",
      " 9.99963999e-01 9.99119461e-01 9.99995470e-01 9.97693241e-01\n",
      " 9.99970436e-01 9.99038815e-01 9.99863267e-01 9.98410821e-01\n",
      " 9.02986109e-01 9.99827743e-01 9.99109805e-01 9.97235715e-01\n",
      " 1.53605836e-02 9.96607542e-01 9.98245955e-01 7.49390900e-01\n",
      " 7.15942442e-01 9.99999404e-01 9.99532461e-01 9.99971151e-01\n",
      " 1.94151849e-01 3.96659166e-01 9.99737561e-01 9.99400258e-01\n",
      " 2.00260833e-01 9.71878290e-01 9.99773964e-02 9.53127027e-01\n",
      " 4.96485978e-02 9.27589357e-01 9.68092740e-01 2.87959933e-01\n",
      " 5.69142750e-04 3.08081329e-01 9.54357207e-01 6.16344154e-01\n",
      " 9.98697221e-01 7.23250628e-01 1.86341126e-02 5.88588864e-02\n",
      " 9.99964118e-01 9.99916434e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 109 [0/107 (0%)]\tTrain Loss: 0.000105\n",
      "Train Epoch: 109 [4/107 (4%)]\tTrain Loss: 0.004038\n",
      "Train Epoch: 109 [8/107 (7%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 109 [12/107 (11%)]\tTrain Loss: 0.000382\n",
      "Train Epoch: 109 [16/107 (15%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 109 [20/107 (19%)]\tTrain Loss: 0.000377\n",
      "Train Epoch: 109 [24/107 (22%)]\tTrain Loss: 0.000294\n",
      "Train Epoch: 109 [28/107 (26%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 109 [32/107 (30%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 109 [36/107 (34%)]\tTrain Loss: 0.000137\n",
      "Train Epoch: 109 [40/107 (37%)]\tTrain Loss: 0.000790\n",
      "Train Epoch: 109 [44/107 (41%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 109 [48/107 (45%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 109 [52/107 (49%)]\tTrain Loss: 0.000073\n",
      "Train Epoch: 109 [56/107 (52%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 109 [60/107 (56%)]\tTrain Loss: 0.002681\n",
      "Train Epoch: 109 [64/107 (60%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 109 [68/107 (64%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 109 [72/107 (67%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 109 [76/107 (71%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 109 [80/107 (75%)]\tTrain Loss: 0.001265\n",
      "Train Epoch: 109 [84/107 (79%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 109 [88/107 (82%)]\tTrain Loss: 0.002008\n",
      "Train Epoch: 109 [92/107 (86%)]\tTrain Loss: 0.001094\n",
      "Train Epoch: 109 [96/107 (90%)]\tTrain Loss: 0.009276\n",
      "Train Epoch: 109 [100/107 (93%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 109 [104/107 (97%)]\tTrain Loss: 0.000083\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.35505950e-04 9.88203347e-01 2.59014289e-03 1.43296150e-02\n",
      " 2.43642391e-03 3.08055256e-04 5.60208321e-01 7.00316345e-03\n",
      " 3.88879445e-04 1.37345502e-02 5.53089499e-01 4.87561556e-06\n",
      " 3.35567445e-01 1.42068148e-03 4.34141606e-03 1.27649819e-05\n",
      " 1.14705053e-05 4.25520509e-01 4.05295333e-03 4.03858572e-02\n",
      " 5.93873680e-01 9.88759756e-01 9.99954939e-01 9.99979138e-01\n",
      " 9.36584294e-01 9.99901891e-01 9.99882698e-01 3.52245532e-02\n",
      " 2.93643534e-01 1.58045848e-04 5.00262320e-01 2.13224860e-03\n",
      " 4.68705535e-01 7.79982838e-06 1.05216095e-05 2.67725060e-04\n",
      " 2.99114385e-04 9.89050150e-01 8.38353157e-01 2.47035996e-06\n",
      " 9.44080398e-07 3.90598070e-05 6.73750520e-01 1.88657224e-01\n",
      " 6.97648525e-01 1.81134243e-03 4.63453948e-01 4.64608788e-01\n",
      " 7.88047373e-01 1.75282750e-02 7.70741343e-01 3.22380278e-04\n",
      " 3.39280698e-03 1.05245749e-03 5.79080172e-03 1.38819134e-02\n",
      " 9.71297622e-01 4.39264966e-07 4.37828676e-05 8.47113039e-03\n",
      " 9.99671698e-01 9.99800503e-01 9.99996424e-01 9.99989748e-01\n",
      " 9.99996901e-01 9.99746263e-01 9.97476280e-01 9.99999881e-01\n",
      " 9.99980807e-01 9.99104440e-01 3.63678485e-01 9.83634368e-02\n",
      " 9.50739861e-01 9.97115731e-01 9.99337971e-01 7.45490909e-01\n",
      " 9.99988079e-01 9.99846339e-01 9.99997735e-01 9.98675048e-01\n",
      " 9.99990940e-01 9.99662161e-01 9.99971151e-01 9.99197543e-01\n",
      " 9.73085403e-01 9.99918938e-01 9.99526024e-01 9.98248219e-01\n",
      " 4.57253903e-02 9.99473512e-01 9.99651551e-01 8.83653164e-01\n",
      " 8.53782415e-01 9.99999762e-01 9.99749959e-01 9.99996543e-01\n",
      " 3.81588519e-01 5.61030209e-01 9.99944925e-01 9.99880791e-01\n",
      " 4.06585693e-01 9.85663116e-01 1.00151978e-01 9.59788680e-01\n",
      " 4.84760478e-02 9.61497724e-01 9.79357481e-01 6.79556966e-01\n",
      " 1.38749147e-03 5.69653988e-01 9.86933053e-01 8.08555245e-01\n",
      " 9.99693155e-01 9.34911788e-01 2.42977887e-02 3.62082869e-02\n",
      " 9.99995828e-01 9.99987364e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 110 [0/107 (0%)]\tTrain Loss: 0.001835\n",
      "Train Epoch: 110 [4/107 (4%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 110 [8/107 (7%)]\tTrain Loss: 0.000178\n",
      "Train Epoch: 110 [12/107 (11%)]\tTrain Loss: 0.000166\n",
      "Train Epoch: 110 [16/107 (15%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 110 [20/107 (19%)]\tTrain Loss: 0.000282\n",
      "Train Epoch: 110 [24/107 (22%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 110 [28/107 (26%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 110 [32/107 (30%)]\tTrain Loss: 0.000300\n",
      "Train Epoch: 110 [36/107 (34%)]\tTrain Loss: 0.000090\n",
      "Train Epoch: 110 [40/107 (37%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 110 [44/107 (41%)]\tTrain Loss: 0.000063\n",
      "Train Epoch: 110 [48/107 (45%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 110 [52/107 (49%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 110 [56/107 (52%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 110 [60/107 (56%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 110 [64/107 (60%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 110 [68/107 (64%)]\tTrain Loss: 0.000345\n",
      "Train Epoch: 110 [72/107 (67%)]\tTrain Loss: 0.001229\n",
      "Train Epoch: 110 [76/107 (71%)]\tTrain Loss: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 110 [80/107 (75%)]\tTrain Loss: 0.000177\n",
      "Train Epoch: 110 [84/107 (79%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 110 [88/107 (82%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 110 [92/107 (86%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 110 [96/107 (90%)]\tTrain Loss: 0.000387\n",
      "Train Epoch: 110 [100/107 (93%)]\tTrain Loss: 0.000486\n",
      "Train Epoch: 110 [104/107 (97%)]\tTrain Loss: 0.000067\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.15081377e-03 9.82147813e-01 2.10852921e-03 1.61890630e-02\n",
      " 3.80924321e-03 3.85408406e-04 4.82010305e-01 9.84562375e-03\n",
      " 5.89795352e-04 1.65527165e-02 5.50666630e-01 5.37647884e-06\n",
      " 3.71180475e-01 7.10847438e-04 4.46304958e-03 7.58381975e-06\n",
      " 7.67314123e-06 2.29505509e-01 3.85431317e-03 4.72204499e-02\n",
      " 3.83197039e-01 9.87118006e-01 9.99932528e-01 9.99988198e-01\n",
      " 9.10198987e-01 9.99841809e-01 9.99842525e-01 2.66501401e-02\n",
      " 2.93417394e-01 1.86995516e-04 4.09972608e-01 2.79180706e-03\n",
      " 4.43658948e-01 4.68584176e-06 4.79658911e-06 2.04173193e-04\n",
      " 2.82394059e-04 9.88324404e-01 7.70819128e-01 2.14194142e-06\n",
      " 5.53832649e-07 4.01338875e-05 4.74647850e-01 2.49186769e-01\n",
      " 7.38640904e-01 2.59120134e-03 5.32241583e-01 5.13535857e-01\n",
      " 8.95053983e-01 2.83599067e-02 8.48475993e-01 4.66125697e-04\n",
      " 5.00999577e-03 1.76509109e-03 3.25705716e-03 1.66003946e-02\n",
      " 9.84065592e-01 6.78061440e-07 4.93450825e-05 6.46519987e-03\n",
      " 9.99802530e-01 9.99870300e-01 9.99996901e-01 9.99991059e-01\n",
      " 9.99997139e-01 9.99688625e-01 9.97182012e-01 9.99999881e-01\n",
      " 9.99969006e-01 9.99119699e-01 3.97493809e-01 1.65409997e-01\n",
      " 9.55322027e-01 9.96263683e-01 9.99168634e-01 7.18683660e-01\n",
      " 9.99981284e-01 9.99816716e-01 9.99997258e-01 9.98006523e-01\n",
      " 9.99976158e-01 9.99396205e-01 9.99959469e-01 9.99437273e-01\n",
      " 9.74939525e-01 9.99958396e-01 9.99365032e-01 9.97780144e-01\n",
      " 2.13081576e-02 9.98704672e-01 9.99580562e-01 8.98052633e-01\n",
      " 8.06715429e-01 9.99999881e-01 9.99770701e-01 9.99994993e-01\n",
      " 3.79734099e-01 5.81973732e-01 9.99927044e-01 9.99827623e-01\n",
      " 4.09378111e-01 9.82796550e-01 2.35732365e-02 9.56836224e-01\n",
      " 4.49048392e-02 9.50820684e-01 9.82002974e-01 4.58815336e-01\n",
      " 4.89936850e-04 4.25990194e-01 9.81340349e-01 5.68142653e-01\n",
      " 9.99473035e-01 9.27583218e-01 1.66993234e-02 2.60306746e-02\n",
      " 9.99996185e-01 9.99977350e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 48 TN= 43 FN= 10 FP= 17\n",
      "TP+FP 65\n",
      "precision 0.7384615384615385\n",
      "recall 0.8275862068965517\n",
      "F1 0.7804878048780489\n",
      "acc 0.7711864406779662\n",
      "AUCp 0.7721264367816092\n",
      "AUC 0.860632183908046\n",
      "\n",
      " The epoch is 110, average recall: 0.8276, average precision: 0.7385,average F1: 0.7805, average accuracy: 0.7712, average AUC: 0.8606\n",
      "Train Epoch: 111 [0/107 (0%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 111 [4/107 (4%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 111 [8/107 (7%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 111 [12/107 (11%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 111 [16/107 (15%)]\tTrain Loss: 0.062393\n",
      "Train Epoch: 111 [20/107 (19%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 111 [24/107 (22%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 111 [28/107 (26%)]\tTrain Loss: 0.003227\n",
      "Train Epoch: 111 [32/107 (30%)]\tTrain Loss: 0.000293\n",
      "Train Epoch: 111 [36/107 (34%)]\tTrain Loss: 0.000213\n",
      "Train Epoch: 111 [40/107 (37%)]\tTrain Loss: 0.000077\n",
      "Train Epoch: 111 [44/107 (41%)]\tTrain Loss: 0.003718\n",
      "Train Epoch: 111 [48/107 (45%)]\tTrain Loss: 0.001378\n",
      "Train Epoch: 111 [52/107 (49%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 111 [56/107 (52%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 111 [60/107 (56%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 111 [64/107 (60%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 111 [68/107 (64%)]\tTrain Loss: 0.000777\n",
      "Train Epoch: 111 [72/107 (67%)]\tTrain Loss: 0.000122\n",
      "Train Epoch: 111 [76/107 (71%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 111 [80/107 (75%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 111 [84/107 (79%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 111 [88/107 (82%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 111 [92/107 (86%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 111 [96/107 (90%)]\tTrain Loss: 0.001573\n",
      "Train Epoch: 111 [100/107 (93%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 111 [104/107 (97%)]\tTrain Loss: 0.000312\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.11504365e-04 9.67674673e-01 1.66421128e-03 5.01384726e-03\n",
      " 1.55485899e-03 2.58641667e-04 5.58394551e-01 1.81287457e-03\n",
      " 2.19488255e-04 5.71911270e-03 5.10025382e-01 6.28388898e-06\n",
      " 1.99224100e-01 1.55224768e-03 1.68721110e-03 1.66921709e-05\n",
      " 1.38454734e-05 3.56065810e-01 2.08535325e-03 6.28981814e-02\n",
      " 2.99198240e-01 9.73537862e-01 9.99904990e-01 9.99969125e-01\n",
      " 9.21267211e-01 9.99737203e-01 9.99810040e-01 4.69970796e-03\n",
      " 2.51893461e-01 1.72464148e-04 1.08852483e-01 8.52097815e-04\n",
      " 1.40164971e-01 9.09906157e-06 1.12703574e-05 4.69701918e-04\n",
      " 2.83598754e-04 9.23985779e-01 7.35679388e-01 4.76836703e-06\n",
      " 2.35787479e-06 6.58576973e-05 1.22995242e-01 6.23896234e-02\n",
      " 4.16324258e-01 2.33517843e-03 2.60875732e-01 2.39563495e-01\n",
      " 5.71175814e-01 1.56925954e-02 6.58436656e-01 1.53940040e-04\n",
      " 1.79656956e-03 4.51891014e-04 9.35720559e-03 1.45751024e-02\n",
      " 9.24565613e-01 7.37048538e-07 1.92191364e-05 1.14185736e-03\n",
      " 9.99360383e-01 9.99627113e-01 9.99988794e-01 9.99950290e-01\n",
      " 9.99980450e-01 9.97878075e-01 9.86049235e-01 9.99999642e-01\n",
      " 9.99849677e-01 9.98332083e-01 1.94783211e-01 1.03989586e-01\n",
      " 8.45345259e-01 9.92556572e-01 9.96100426e-01 2.67378628e-01\n",
      " 9.99967933e-01 9.98490810e-01 9.99989748e-01 9.95582879e-01\n",
      " 9.99970913e-01 9.98430789e-01 9.99843478e-01 9.98632729e-01\n",
      " 9.26132083e-01 9.99715865e-01 9.98585463e-01 9.94059801e-01\n",
      " 7.49462890e-03 9.98513639e-01 9.99210238e-01 7.50861645e-01\n",
      " 6.44045949e-01 9.99999642e-01 9.99791324e-01 9.99990582e-01\n",
      " 2.84312308e-01 5.36941469e-01 9.99899387e-01 9.99746144e-01\n",
      " 3.92290622e-01 8.99660170e-01 1.11941613e-01 9.46406484e-01\n",
      " 6.58996999e-02 9.38867450e-01 9.60913122e-01 6.10700190e-01\n",
      " 7.43172131e-04 4.30521399e-01 9.81311500e-01 8.35385501e-01\n",
      " 9.99146342e-01 8.38536382e-01 1.29906721e-02 1.28458701e-02\n",
      " 9.99985695e-01 9.99987125e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 112 [0/107 (0%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 112 [4/107 (4%)]\tTrain Loss: 0.000107\n",
      "Train Epoch: 112 [8/107 (7%)]\tTrain Loss: 0.001676\n",
      "Train Epoch: 112 [12/107 (11%)]\tTrain Loss: 0.000781\n",
      "Train Epoch: 112 [16/107 (15%)]\tTrain Loss: 0.000033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 112 [20/107 (19%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 112 [24/107 (22%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 112 [28/107 (26%)]\tTrain Loss: 0.000241\n",
      "Train Epoch: 112 [32/107 (30%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 112 [36/107 (34%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 112 [40/107 (37%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 112 [44/107 (41%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 112 [48/107 (45%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 112 [52/107 (49%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 112 [56/107 (52%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 112 [60/107 (56%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 112 [64/107 (60%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 112 [68/107 (64%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 112 [72/107 (67%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 112 [76/107 (71%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 112 [80/107 (75%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 112 [84/107 (79%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 112 [88/107 (82%)]\tTrain Loss: 0.008664\n",
      "Train Epoch: 112 [92/107 (86%)]\tTrain Loss: 0.004107\n",
      "Train Epoch: 112 [96/107 (90%)]\tTrain Loss: 0.002202\n",
      "Train Epoch: 112 [100/107 (93%)]\tTrain Loss: 0.000447\n",
      "Train Epoch: 112 [104/107 (97%)]\tTrain Loss: 0.000036\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.93755234e-04 9.94105697e-01 2.96454970e-03 2.81247199e-02\n",
      " 4.59362892e-03 3.51325580e-04 8.73044670e-01 1.33532081e-02\n",
      " 6.48013724e-04 2.17401925e-02 7.35971928e-01 1.22447491e-05\n",
      " 3.25563431e-01 3.85877513e-03 4.77011967e-03 2.45595147e-05\n",
      " 3.29686918e-05 7.14585662e-01 2.07129270e-02 2.09023848e-01\n",
      " 6.43177569e-01 9.95958388e-01 9.99984384e-01 9.99996781e-01\n",
      " 9.94440496e-01 9.99966025e-01 9.99991894e-01 2.87110992e-02\n",
      " 6.29106104e-01 2.54241051e-04 5.01389623e-01 2.83566746e-03\n",
      " 4.64137644e-01 6.95036942e-06 1.62575525e-05 6.05238078e-04\n",
      " 7.51701416e-04 9.90788400e-01 9.31397557e-01 1.24879089e-05\n",
      " 5.16532964e-06 2.39595611e-04 4.59332138e-01 2.38513574e-01\n",
      " 7.46945679e-01 2.70238402e-03 6.09787285e-01 5.23407161e-01\n",
      " 8.33545864e-01 2.40960028e-02 7.83714592e-01 4.68036480e-04\n",
      " 7.40391063e-03 3.98567924e-03 5.21238334e-02 3.07473820e-02\n",
      " 9.88925993e-01 2.31626791e-06 5.59691034e-05 8.89670197e-03\n",
      " 9.99953628e-01 9.99958396e-01 9.99999523e-01 9.99999046e-01\n",
      " 9.99997973e-01 9.99794662e-01 9.99060690e-01 1.00000000e+00\n",
      " 9.99992013e-01 9.99634385e-01 5.58739364e-01 2.74386168e-01\n",
      " 9.54942048e-01 9.98493195e-01 9.99743521e-01 6.76594555e-01\n",
      " 9.99996781e-01 9.99863029e-01 9.99998331e-01 9.99231458e-01\n",
      " 9.99995708e-01 9.99731839e-01 9.99989510e-01 9.99840140e-01\n",
      " 9.84797299e-01 9.99985218e-01 9.99475896e-01 9.98351097e-01\n",
      " 7.81779513e-02 9.99968290e-01 9.99958038e-01 9.47366059e-01\n",
      " 8.24133039e-01 1.00000000e+00 9.99983430e-01 9.99999642e-01\n",
      " 4.71435428e-01 7.79479265e-01 9.99992967e-01 9.99977708e-01\n",
      " 6.58013463e-01 9.92598653e-01 4.51030761e-01 9.89612162e-01\n",
      " 1.37398392e-01 9.86161470e-01 9.90620255e-01 8.80758405e-01\n",
      " 5.75980218e-03 7.90422201e-01 9.98782218e-01 9.04056191e-01\n",
      " 9.99961734e-01 9.80745673e-01 7.71419555e-02 6.97247908e-02\n",
      " 9.99999881e-01 9.99999642e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 113 [0/107 (0%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 113 [4/107 (4%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 113 [8/107 (7%)]\tTrain Loss: 0.000129\n",
      "Train Epoch: 113 [12/107 (11%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 113 [16/107 (15%)]\tTrain Loss: 0.000243\n",
      "Train Epoch: 113 [20/107 (19%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 113 [24/107 (22%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 113 [28/107 (26%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 113 [32/107 (30%)]\tTrain Loss: 0.000666\n",
      "Train Epoch: 113 [36/107 (34%)]\tTrain Loss: 0.005512\n",
      "Train Epoch: 113 [40/107 (37%)]\tTrain Loss: 0.001654\n",
      "Train Epoch: 113 [44/107 (41%)]\tTrain Loss: 0.001267\n",
      "Train Epoch: 113 [48/107 (45%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 113 [52/107 (49%)]\tTrain Loss: 0.000158\n",
      "Train Epoch: 113 [56/107 (52%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 113 [60/107 (56%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 113 [64/107 (60%)]\tTrain Loss: 0.000167\n",
      "Train Epoch: 113 [68/107 (64%)]\tTrain Loss: 0.000519\n",
      "Train Epoch: 113 [72/107 (67%)]\tTrain Loss: 0.000202\n",
      "Train Epoch: 113 [76/107 (71%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 113 [80/107 (75%)]\tTrain Loss: 0.000105\n",
      "Train Epoch: 113 [84/107 (79%)]\tTrain Loss: 0.000171\n",
      "Train Epoch: 113 [88/107 (82%)]\tTrain Loss: 0.000391\n",
      "Train Epoch: 113 [92/107 (86%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 113 [96/107 (90%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 113 [100/107 (93%)]\tTrain Loss: 0.000801\n",
      "Train Epoch: 113 [104/107 (97%)]\tTrain Loss: 0.000028\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.88303548e-04 8.48718047e-01 1.11330871e-03 4.03418113e-03\n",
      " 1.58818753e-03 2.06017110e-04 3.93690430e-02 1.03815668e-03\n",
      " 1.74740067e-04 5.61635662e-03 5.29987335e-01 4.72785814e-06\n",
      " 2.22282529e-01 3.21486819e-04 1.63439289e-03 3.54002032e-06\n",
      " 2.71396107e-06 3.67367193e-02 4.53174143e-04 2.22183671e-02\n",
      " 8.88557211e-02 8.78745854e-01 9.99208987e-01 9.99941349e-01\n",
      " 7.26289570e-01 9.98913407e-01 9.99548614e-01 2.42126593e-03\n",
      " 2.34618019e-02 9.14914999e-05 1.72493998e-02 4.19321848e-04\n",
      " 8.02418739e-02 3.34858873e-06 1.48013021e-06 1.42388759e-04\n",
      " 2.14686239e-04 6.21706188e-01 2.97138810e-01 1.58686692e-06\n",
      " 5.51902360e-07 3.26008776e-05 1.48000233e-02 2.61085499e-02\n",
      " 1.69991180e-01 5.11038932e-04 9.73546356e-02 1.54194176e-01\n",
      " 7.00401306e-01 8.37287493e-03 6.57907486e-01 9.11563839e-05\n",
      " 6.47240086e-04 1.02188402e-04 3.89855308e-03 1.43324276e-02\n",
      " 9.27580655e-01 8.58496776e-08 9.35449680e-06 5.40529145e-04\n",
      " 9.98649538e-01 9.99217272e-01 9.99939442e-01 9.99887705e-01\n",
      " 9.99940038e-01 9.97126520e-01 9.52753961e-01 9.99998808e-01\n",
      " 9.99769747e-01 9.95040119e-01 1.69316769e-01 4.23639193e-02\n",
      " 7.50723779e-01 9.82972443e-01 9.88669872e-01 1.14176795e-01\n",
      " 9.99876499e-01 9.91532624e-01 9.99961734e-01 9.92087662e-01\n",
      " 9.99918938e-01 9.95337605e-01 9.99776661e-01 9.93078291e-01\n",
      " 8.95346820e-01 9.98726308e-01 9.97117043e-01 9.85356629e-01\n",
      " 2.84470315e-03 9.98302102e-01 9.98877227e-01 7.23854244e-01\n",
      " 5.72026253e-01 9.99999642e-01 9.99327660e-01 9.99984860e-01\n",
      " 1.48851171e-01 1.53134167e-01 9.99268711e-01 9.99559939e-01\n",
      " 3.93638015e-01 9.34393466e-01 5.50953206e-03 9.53601658e-01\n",
      " 3.02964672e-02 9.39167261e-01 9.72341418e-01 3.53999972e-01\n",
      " 2.96508748e-04 2.07485884e-01 9.47611570e-01 5.16957104e-01\n",
      " 9.99434888e-01 5.62210560e-01 8.06031842e-03 1.31495623e-03\n",
      " 9.99692440e-01 9.99829054e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 114 [0/107 (0%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 114 [4/107 (4%)]\tTrain Loss: 0.000409\n",
      "Train Epoch: 114 [8/107 (7%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 114 [12/107 (11%)]\tTrain Loss: 0.000599\n",
      "Train Epoch: 114 [16/107 (15%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 114 [20/107 (19%)]\tTrain Loss: 0.000299\n",
      "Train Epoch: 114 [24/107 (22%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 114 [28/107 (26%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 114 [32/107 (30%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 114 [36/107 (34%)]\tTrain Loss: 0.000051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 114 [40/107 (37%)]\tTrain Loss: 0.001448\n",
      "Train Epoch: 114 [44/107 (41%)]\tTrain Loss: 0.000314\n",
      "Train Epoch: 114 [48/107 (45%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 114 [52/107 (49%)]\tTrain Loss: 0.000349\n",
      "Train Epoch: 114 [56/107 (52%)]\tTrain Loss: 0.002789\n",
      "Train Epoch: 114 [60/107 (56%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 114 [64/107 (60%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 114 [68/107 (64%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 114 [72/107 (67%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 114 [76/107 (71%)]\tTrain Loss: 0.001771\n",
      "Train Epoch: 114 [80/107 (75%)]\tTrain Loss: 0.001847\n",
      "Train Epoch: 114 [84/107 (79%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 114 [88/107 (82%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 114 [92/107 (86%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 114 [96/107 (90%)]\tTrain Loss: 0.012410\n",
      "Train Epoch: 114 [100/107 (93%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 114 [104/107 (97%)]\tTrain Loss: 0.002940\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.43930898e-03 8.87473285e-01 3.00832279e-03 1.36159137e-02\n",
      " 5.98930847e-03 4.74600703e-04 1.31783471e-01 6.12671953e-03\n",
      " 3.15080280e-04 1.29405512e-02 6.23074591e-01 1.12168209e-05\n",
      " 4.09268498e-01 9.64303385e-04 7.62589835e-03 1.31950728e-05\n",
      " 1.18159942e-05 1.64877921e-01 6.73128525e-03 6.72231764e-02\n",
      " 3.72053534e-01 9.48314488e-01 9.99754727e-01 9.99976516e-01\n",
      " 7.82203019e-01 9.99624491e-01 9.99825418e-01 2.20054258e-02\n",
      " 2.23996729e-01 4.45174053e-04 1.41233727e-01 2.42486713e-03\n",
      " 2.56185979e-01 1.12117032e-05 6.50607672e-06 5.59235457e-04\n",
      " 8.07496021e-04 9.08970714e-01 6.48556471e-01 4.44445550e-06\n",
      " 2.10614280e-06 8.24925737e-05 8.94788578e-02 1.05749287e-01\n",
      " 6.59512460e-01 4.42851242e-03 3.60017449e-01 3.37500095e-01\n",
      " 7.85102606e-01 2.17167400e-02 8.13186944e-01 4.19202464e-04\n",
      " 2.74397433e-03 6.26861991e-04 6.17674133e-03 3.48265395e-02\n",
      " 9.80132043e-01 2.61294957e-07 2.77340259e-05 1.58216455e-03\n",
      " 9.99775708e-01 9.99790847e-01 9.99992371e-01 9.99974251e-01\n",
      " 9.99985456e-01 9.98953342e-01 9.92986500e-01 9.99999762e-01\n",
      " 9.99950051e-01 9.98334229e-01 3.22272748e-01 8.66878703e-02\n",
      " 9.09969151e-01 9.96375382e-01 9.98704910e-01 3.71123344e-01\n",
      " 9.99969244e-01 9.98322189e-01 9.99984860e-01 9.97407615e-01\n",
      " 9.99982357e-01 9.98083591e-01 9.99871612e-01 9.97119904e-01\n",
      " 9.25225616e-01 9.99613822e-01 9.98685062e-01 9.93758202e-01\n",
      " 1.16550522e-02 9.99192655e-01 9.99517798e-01 8.85048091e-01\n",
      " 7.42544889e-01 9.99999881e-01 9.99898195e-01 9.99997735e-01\n",
      " 4.15676564e-01 4.68331724e-01 9.99820292e-01 9.99736726e-01\n",
      " 3.21742624e-01 9.72510278e-01 2.52339467e-02 9.75738108e-01\n",
      " 7.03525096e-02 9.76865172e-01 9.89358068e-01 1.69714302e-01\n",
      " 6.98275398e-04 4.56317484e-01 9.67654228e-01 6.60090804e-01\n",
      " 9.99543846e-01 6.76797688e-01 2.40166578e-02 9.77177639e-03\n",
      " 9.99917388e-01 9.99900937e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 115 [0/107 (0%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 115 [4/107 (4%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 115 [8/107 (7%)]\tTrain Loss: 0.000073\n",
      "Train Epoch: 115 [12/107 (11%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 115 [16/107 (15%)]\tTrain Loss: 0.000875\n",
      "Train Epoch: 115 [20/107 (19%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 115 [24/107 (22%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 115 [28/107 (26%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 115 [32/107 (30%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 115 [36/107 (34%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 115 [40/107 (37%)]\tTrain Loss: 0.000751\n",
      "Train Epoch: 115 [44/107 (41%)]\tTrain Loss: 0.003087\n",
      "Train Epoch: 115 [48/107 (45%)]\tTrain Loss: 0.000245\n",
      "Train Epoch: 115 [52/107 (49%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 115 [56/107 (52%)]\tTrain Loss: 0.000422\n",
      "Train Epoch: 115 [60/107 (56%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 115 [64/107 (60%)]\tTrain Loss: 0.000291\n",
      "Train Epoch: 115 [68/107 (64%)]\tTrain Loss: 0.000658\n",
      "Train Epoch: 115 [72/107 (67%)]\tTrain Loss: 0.000188\n",
      "Train Epoch: 115 [76/107 (71%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 115 [80/107 (75%)]\tTrain Loss: 0.000071\n",
      "Train Epoch: 115 [84/107 (79%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 115 [88/107 (82%)]\tTrain Loss: 0.003195\n",
      "Train Epoch: 115 [92/107 (86%)]\tTrain Loss: 0.000069\n",
      "Train Epoch: 115 [96/107 (90%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 115 [100/107 (93%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 115 [104/107 (97%)]\tTrain Loss: 0.000060\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.06989825e-03 9.82447088e-01 4.65053413e-03 9.70434770e-03\n",
      " 2.61860527e-03 5.84428373e-04 6.72600627e-01 1.81364815e-03\n",
      " 4.20536526e-04 8.79271980e-03 6.50779545e-01 5.07838240e-06\n",
      " 3.06824654e-01 1.69255980e-03 4.27127024e-03 1.85231438e-05\n",
      " 1.29632272e-05 1.41095459e-01 1.46942167e-02 2.16834411e-01\n",
      " 7.14811265e-01 9.77799237e-01 9.99955058e-01 9.99973297e-01\n",
      " 8.62953603e-01 9.99894619e-01 9.99869943e-01 3.01657245e-02\n",
      " 2.75297403e-01 1.78355214e-04 2.60063857e-01 2.39517121e-03\n",
      " 3.70448530e-01 4.88528531e-06 4.82167661e-06 3.62033985e-04\n",
      " 2.76549690e-04 8.07007492e-01 5.45072138e-01 8.10459642e-06\n",
      " 2.85209421e-06 1.45307902e-04 9.13385823e-02 1.12841956e-01\n",
      " 8.04808080e-01 5.55522135e-03 3.72283041e-01 2.86795229e-01\n",
      " 8.32911909e-01 3.43796872e-02 8.40657115e-01 1.81569761e-04\n",
      " 3.66718345e-03 7.63360527e-04 4.86711860e-02 5.08515500e-02\n",
      " 9.78043735e-01 1.77517379e-07 1.52325583e-05 1.72238296e-03\n",
      " 9.99673843e-01 9.99736845e-01 9.99989033e-01 9.99982238e-01\n",
      " 9.99990582e-01 9.99403834e-01 9.90720868e-01 9.99999881e-01\n",
      " 9.99949813e-01 9.97643530e-01 3.56708616e-01 1.30748734e-01\n",
      " 9.11200762e-01 9.96751308e-01 9.98733819e-01 5.48569679e-01\n",
      " 9.99973416e-01 9.99292374e-01 9.99993086e-01 9.99362409e-01\n",
      " 9.99991536e-01 9.99218106e-01 9.99939561e-01 9.97200608e-01\n",
      " 9.43716466e-01 9.99603808e-01 9.99243736e-01 9.98216927e-01\n",
      " 3.02760694e-02 9.99772727e-01 9.99748766e-01 9.08087611e-01\n",
      " 8.07832003e-01 9.99999762e-01 9.99851227e-01 9.99997139e-01\n",
      " 4.37624246e-01 3.58252555e-01 9.99947429e-01 9.99932051e-01\n",
      " 3.47482562e-01 9.84115124e-01 2.00246707e-01 9.91400778e-01\n",
      " 9.89401042e-02 9.77587759e-01 9.95402217e-01 5.26801586e-01\n",
      " 2.02715327e-03 8.40907931e-01 9.86750662e-01 7.66779840e-01\n",
      " 9.99741256e-01 8.87829304e-01 9.36577916e-02 2.88228337e-02\n",
      " 9.99908924e-01 9.99947071e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 116 [0/107 (0%)]\tTrain Loss: 0.001266\n",
      "Train Epoch: 116 [4/107 (4%)]\tTrain Loss: 0.003479\n",
      "Train Epoch: 116 [8/107 (7%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 116 [12/107 (11%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 116 [16/107 (15%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 116 [20/107 (19%)]\tTrain Loss: 0.001203\n",
      "Train Epoch: 116 [24/107 (22%)]\tTrain Loss: 0.000121\n",
      "Train Epoch: 116 [28/107 (26%)]\tTrain Loss: 0.002507\n",
      "Train Epoch: 116 [32/107 (30%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 116 [36/107 (34%)]\tTrain Loss: 0.000262\n",
      "Train Epoch: 116 [40/107 (37%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 116 [44/107 (41%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 116 [48/107 (45%)]\tTrain Loss: 0.030112\n",
      "Train Epoch: 116 [52/107 (49%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 116 [56/107 (52%)]\tTrain Loss: 0.000078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 116 [60/107 (56%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 116 [64/107 (60%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 116 [68/107 (64%)]\tTrain Loss: 0.000055\n",
      "Train Epoch: 116 [72/107 (67%)]\tTrain Loss: 0.000165\n",
      "Train Epoch: 116 [76/107 (71%)]\tTrain Loss: 0.006564\n",
      "Train Epoch: 116 [80/107 (75%)]\tTrain Loss: 0.000185\n",
      "Train Epoch: 116 [84/107 (79%)]\tTrain Loss: 0.000263\n",
      "Train Epoch: 116 [88/107 (82%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 116 [92/107 (86%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 116 [96/107 (90%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 116 [100/107 (93%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 116 [104/107 (97%)]\tTrain Loss: 0.000014\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.31964986e-03 9.84259903e-01 2.44112941e-03 2.91780848e-02\n",
      " 4.80345357e-03 6.06612710e-04 5.58390141e-01 1.09584387e-02\n",
      " 8.85732879e-04 1.17182741e-02 7.20974863e-01 6.91775949e-06\n",
      " 3.22661132e-01 1.76355138e-03 5.40967332e-03 1.41521014e-05\n",
      " 1.74726665e-05 2.61049420e-01 2.02176441e-02 1.65529281e-01\n",
      " 7.00172901e-01 9.86111760e-01 9.99859214e-01 9.99981761e-01\n",
      " 9.29571331e-01 9.99762714e-01 9.99942899e-01 1.41396359e-01\n",
      " 2.26698816e-01 3.31156101e-04 5.38796425e-01 2.89913313e-03\n",
      " 4.23885912e-01 9.16419231e-06 7.58544502e-06 5.41402085e-04\n",
      " 4.93636762e-04 9.35295999e-01 6.49192810e-01 6.17659271e-06\n",
      " 2.49012919e-06 1.34877002e-04 1.09919690e-01 1.28586724e-01\n",
      " 7.00432003e-01 5.54300891e-03 4.65525478e-01 3.22708577e-01\n",
      " 8.26094568e-01 4.49221022e-02 8.75550389e-01 4.37093782e-04\n",
      " 7.89045729e-03 3.12662078e-03 3.85771915e-02 4.68548685e-02\n",
      " 9.89132345e-01 5.62598814e-07 6.14579985e-05 1.00363027e-02\n",
      " 9.99899387e-01 9.99900937e-01 9.99995470e-01 9.99990106e-01\n",
      " 9.99993682e-01 9.99332726e-01 9.95892048e-01 9.99999881e-01\n",
      " 9.99955893e-01 9.97874498e-01 5.59001029e-01 2.47457057e-01\n",
      " 9.60209727e-01 9.98058379e-01 9.99079585e-01 8.02125871e-01\n",
      " 9.99982119e-01 9.99599278e-01 9.99992013e-01 9.98167276e-01\n",
      " 9.99987721e-01 9.99687910e-01 9.99946117e-01 9.99213815e-01\n",
      " 9.61190760e-01 9.99880791e-01 9.99214172e-01 9.96868670e-01\n",
      " 2.16274530e-01 9.99854684e-01 9.99875784e-01 8.96696448e-01\n",
      " 7.82346129e-01 1.00000000e+00 9.99933720e-01 9.99999166e-01\n",
      " 5.57553947e-01 6.84537113e-01 9.99950767e-01 9.99837399e-01\n",
      " 5.51342666e-01 9.81974185e-01 1.21562876e-01 9.89661694e-01\n",
      " 1.26806810e-01 9.78142738e-01 9.93450403e-01 4.48053032e-01\n",
      " 2.29088007e-03 7.99660683e-01 9.94929969e-01 7.03911185e-01\n",
      " 9.99851227e-01 8.98376942e-01 1.23210885e-02 1.77599639e-02\n",
      " 9.99992251e-01 9.99972820e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 117 [0/107 (0%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 117 [4/107 (4%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 117 [8/107 (7%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 117 [12/107 (11%)]\tTrain Loss: 0.000176\n",
      "Train Epoch: 117 [16/107 (15%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 117 [20/107 (19%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 117 [24/107 (22%)]\tTrain Loss: 0.002662\n",
      "Train Epoch: 117 [28/107 (26%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 117 [32/107 (30%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 117 [36/107 (34%)]\tTrain Loss: 0.000283\n",
      "Train Epoch: 117 [40/107 (37%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 117 [44/107 (41%)]\tTrain Loss: 0.003861\n",
      "Train Epoch: 117 [48/107 (45%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 117 [52/107 (49%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 117 [56/107 (52%)]\tTrain Loss: 0.001158\n",
      "Train Epoch: 117 [60/107 (56%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 117 [64/107 (60%)]\tTrain Loss: 0.000290\n",
      "Train Epoch: 117 [68/107 (64%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 117 [72/107 (67%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 117 [76/107 (71%)]\tTrain Loss: 0.000213\n",
      "Train Epoch: 117 [80/107 (75%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 117 [84/107 (79%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 117 [88/107 (82%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 117 [92/107 (86%)]\tTrain Loss: 0.000153\n",
      "Train Epoch: 117 [96/107 (90%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 117 [100/107 (93%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 117 [104/107 (97%)]\tTrain Loss: 0.000008\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.75617363e-04 9.19261336e-01 7.74621265e-04 1.48565061e-02\n",
      " 3.49571882e-03 1.17913740e-04 2.76172280e-01 4.37348243e-03\n",
      " 1.86090445e-04 8.36300384e-03 6.76743567e-01 3.05771732e-06\n",
      " 3.92734468e-01 4.80138580e-04 3.26729217e-03 4.12816007e-06\n",
      " 1.34186030e-05 1.24523066e-01 2.13722046e-03 6.33448139e-02\n",
      " 4.29600716e-01 9.56181943e-01 9.99763072e-01 9.99930024e-01\n",
      " 9.17930722e-01 9.99503493e-01 9.99441206e-01 5.87960612e-03\n",
      " 1.37851477e-01 1.45607337e-04 1.21458374e-01 1.80873694e-03\n",
      " 1.45131573e-01 2.52052973e-06 2.33235710e-06 1.97980218e-04\n",
      " 3.14526376e-04 8.98864031e-01 6.20461524e-01 1.84784165e-06\n",
      " 7.30778879e-07 2.61882651e-05 2.31013540e-02 7.12876320e-02\n",
      " 5.93455136e-01 2.90639931e-03 4.13772047e-01 3.35867494e-01\n",
      " 6.82256997e-01 2.04587616e-02 7.74472475e-01 1.58427312e-04\n",
      " 1.12820428e-03 4.91491868e-04 6.46280078e-03 1.83299743e-02\n",
      " 9.66044605e-01 2.26166875e-07 2.18859113e-05 2.52256356e-03\n",
      " 9.99249041e-01 9.99411225e-01 9.99949574e-01 9.99892831e-01\n",
      " 9.99979377e-01 9.98594105e-01 9.91935730e-01 9.99998331e-01\n",
      " 9.99821246e-01 9.97306228e-01 3.34038794e-01 9.10276249e-02\n",
      " 8.89366031e-01 9.92757142e-01 9.95512903e-01 3.25298667e-01\n",
      " 9.99906182e-01 9.97104108e-01 9.99966025e-01 9.96913075e-01\n",
      " 9.99930739e-01 9.98090208e-01 9.99599516e-01 9.97800529e-01\n",
      " 9.53345597e-01 9.99145746e-01 9.98521984e-01 9.92223322e-01\n",
      " 2.61377897e-02 9.98428345e-01 9.99512792e-01 7.70002782e-01\n",
      " 7.06517339e-01 9.99999642e-01 9.99840975e-01 9.99995470e-01\n",
      " 4.99389499e-01 5.45821071e-01 9.99828577e-01 9.99407291e-01\n",
      " 3.91950727e-01 9.77251530e-01 1.89179573e-02 9.88647759e-01\n",
      " 1.11433640e-01 9.76626337e-01 9.82100666e-01 2.30741858e-01\n",
      " 3.21530533e-04 3.57107460e-01 9.90090609e-01 6.63948596e-01\n",
      " 9.99125421e-01 8.49676013e-01 1.48492241e-02 8.17442033e-03\n",
      " 9.99914765e-01 9.99881268e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 118 [0/107 (0%)]\tTrain Loss: 0.001503\n",
      "Train Epoch: 118 [4/107 (4%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 118 [8/107 (7%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 118 [12/107 (11%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 118 [16/107 (15%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 118 [20/107 (19%)]\tTrain Loss: 0.000283\n",
      "Train Epoch: 118 [24/107 (22%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 118 [28/107 (26%)]\tTrain Loss: 0.000350\n",
      "Train Epoch: 118 [32/107 (30%)]\tTrain Loss: 0.000308\n",
      "Train Epoch: 118 [36/107 (34%)]\tTrain Loss: 0.000851\n",
      "Train Epoch: 118 [40/107 (37%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 118 [44/107 (41%)]\tTrain Loss: 0.000165\n",
      "Train Epoch: 118 [48/107 (45%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 118 [52/107 (49%)]\tTrain Loss: 0.000595\n",
      "Train Epoch: 118 [56/107 (52%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 118 [60/107 (56%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 118 [64/107 (60%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 118 [68/107 (64%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 118 [72/107 (67%)]\tTrain Loss: 0.000290\n",
      "Train Epoch: 118 [76/107 (71%)]\tTrain Loss: 0.000490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 118 [80/107 (75%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 118 [84/107 (79%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 118 [88/107 (82%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 118 [92/107 (86%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 118 [96/107 (90%)]\tTrain Loss: 0.002063\n",
      "Train Epoch: 118 [100/107 (93%)]\tTrain Loss: 0.000477\n",
      "Train Epoch: 118 [104/107 (97%)]\tTrain Loss: 0.000041\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.05279056e-04 9.68368471e-01 2.66402774e-03 1.10401791e-02\n",
      " 5.02342684e-03 1.91477026e-04 5.34883261e-01 4.46905568e-03\n",
      " 2.30628633e-04 1.28792636e-02 7.31741846e-01 5.56002078e-06\n",
      " 4.08969760e-01 8.67271214e-04 2.60718842e-03 8.91019408e-06\n",
      " 1.21963949e-05 2.46186212e-01 5.24821412e-03 1.01118401e-01\n",
      " 5.93711436e-01 9.72374439e-01 9.99837756e-01 9.99979973e-01\n",
      " 8.79802763e-01 9.99808013e-01 9.99896049e-01 3.85613702e-02\n",
      " 3.01175684e-01 1.91444342e-04 3.72430295e-01 2.20284611e-03\n",
      " 3.50150198e-01 4.71542444e-06 4.24087330e-06 3.62422899e-04\n",
      " 1.85726778e-04 9.34037149e-01 6.81971908e-01 2.82801329e-06\n",
      " 8.94711548e-07 6.84022816e-05 6.49807230e-02 7.34203756e-02\n",
      " 6.58729613e-01 3.08413384e-03 5.91366291e-01 3.33005935e-01\n",
      " 8.64303768e-01 3.59892920e-02 8.31908882e-01 2.52454571e-04\n",
      " 2.73053674e-03 5.73058904e-04 1.38913980e-02 2.97973361e-02\n",
      " 9.75298047e-01 3.67607754e-07 3.29091417e-05 2.90899654e-03\n",
      " 9.99708593e-01 9.99742687e-01 9.99990940e-01 9.99976635e-01\n",
      " 9.99985456e-01 9.99114096e-01 9.95043397e-01 9.99999762e-01\n",
      " 9.99952197e-01 9.98474419e-01 4.30756599e-01 1.56387299e-01\n",
      " 9.46601272e-01 9.96313632e-01 9.98587370e-01 6.33619785e-01\n",
      " 9.99968529e-01 9.99237657e-01 9.99993086e-01 9.98866916e-01\n",
      " 9.99986768e-01 9.99135196e-01 9.99899983e-01 9.98712778e-01\n",
      " 9.60525811e-01 9.99858379e-01 9.99078512e-01 9.96295750e-01\n",
      " 5.22934571e-02 9.99627590e-01 9.99883771e-01 9.06519532e-01\n",
      " 7.62289226e-01 9.99999881e-01 9.99941230e-01 9.99999166e-01\n",
      " 5.23987412e-01 6.25534832e-01 9.99917269e-01 9.99900222e-01\n",
      " 4.20204669e-01 9.87436175e-01 1.85685307e-02 9.92669702e-01\n",
      " 9.94307324e-02 9.82694328e-01 9.95053887e-01 2.68545866e-01\n",
      " 8.17635679e-04 6.91751778e-01 9.87267077e-01 7.62127519e-01\n",
      " 9.99769986e-01 8.63671482e-01 2.72127613e-02 1.11847976e-02\n",
      " 9.99980092e-01 9.99972939e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 119 [0/107 (0%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 119 [4/107 (4%)]\tTrain Loss: 0.000142\n",
      "Train Epoch: 119 [8/107 (7%)]\tTrain Loss: 0.000645\n",
      "Train Epoch: 119 [12/107 (11%)]\tTrain Loss: 0.007943\n",
      "Train Epoch: 119 [16/107 (15%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 119 [20/107 (19%)]\tTrain Loss: 0.000134\n",
      "Train Epoch: 119 [24/107 (22%)]\tTrain Loss: 0.000161\n",
      "Train Epoch: 119 [28/107 (26%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 119 [32/107 (30%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 119 [36/107 (34%)]\tTrain Loss: 0.000743\n",
      "Train Epoch: 119 [40/107 (37%)]\tTrain Loss: 0.000296\n",
      "Train Epoch: 119 [44/107 (41%)]\tTrain Loss: 0.000216\n",
      "Train Epoch: 119 [48/107 (45%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 119 [52/107 (49%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 119 [56/107 (52%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 119 [60/107 (56%)]\tTrain Loss: 0.001733\n",
      "Train Epoch: 119 [64/107 (60%)]\tTrain Loss: 0.013025\n",
      "Train Epoch: 119 [68/107 (64%)]\tTrain Loss: 0.000192\n",
      "Train Epoch: 119 [72/107 (67%)]\tTrain Loss: 0.001796\n",
      "Train Epoch: 119 [76/107 (71%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 119 [80/107 (75%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 119 [84/107 (79%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 119 [88/107 (82%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 119 [92/107 (86%)]\tTrain Loss: 0.000151\n",
      "Train Epoch: 119 [96/107 (90%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 119 [100/107 (93%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 119 [104/107 (97%)]\tTrain Loss: 0.000010\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.31989352e-03 9.77269650e-01 3.19033465e-03 2.46223696e-02\n",
      " 8.62636045e-03 3.41671373e-04 3.69204849e-01 1.05119022e-02\n",
      " 6.03647088e-04 1.57187264e-02 7.20724881e-01 1.08053609e-05\n",
      " 3.59724522e-01 1.79018010e-03 8.44929833e-03 2.64673090e-05\n",
      " 2.92255245e-05 3.12265635e-01 6.79930393e-03 1.82727590e-01\n",
      " 6.94851816e-01 9.78234351e-01 9.99779642e-01 9.99979854e-01\n",
      " 9.00283039e-01 9.99723494e-01 9.99922633e-01 6.92794770e-02\n",
      " 3.83491218e-01 3.36557918e-04 5.50458670e-01 3.42766452e-03\n",
      " 4.45841193e-01 7.29256999e-06 6.66193273e-06 2.72941106e-04\n",
      " 3.56552278e-04 9.62967932e-01 7.46707141e-01 5.65105802e-06\n",
      " 2.02810816e-06 1.24336089e-04 1.14866562e-01 1.74912602e-01\n",
      " 7.00667143e-01 5.04518254e-03 6.02529407e-01 3.58682156e-01\n",
      " 8.21681678e-01 3.13849784e-02 8.59008253e-01 4.08618216e-04\n",
      " 1.19979652e-02 3.85113433e-03 3.83129194e-02 5.62676042e-02\n",
      " 9.85875309e-01 7.43995543e-07 4.33535934e-05 2.13900488e-02\n",
      " 9.99767363e-01 9.99833226e-01 9.99989867e-01 9.99985933e-01\n",
      " 9.99992609e-01 9.99454439e-01 9.94805753e-01 9.99999523e-01\n",
      " 9.99920607e-01 9.98516738e-01 5.06117463e-01 2.13482395e-01\n",
      " 9.79567409e-01 9.98198807e-01 9.99219537e-01 8.23457479e-01\n",
      " 9.99962330e-01 9.99152184e-01 9.99989629e-01 9.97896671e-01\n",
      " 9.99970078e-01 9.99572933e-01 9.99933243e-01 9.99076843e-01\n",
      " 9.68212903e-01 9.99819100e-01 9.99386311e-01 9.96982157e-01\n",
      " 1.19228922e-01 9.99493480e-01 9.99727070e-01 9.33338583e-01\n",
      " 8.64163578e-01 9.99999762e-01 9.99859571e-01 9.99998093e-01\n",
      " 6.73053503e-01 7.60030568e-01 9.99885321e-01 9.99774277e-01\n",
      " 4.76362616e-01 9.90970373e-01 4.85850610e-02 9.91334617e-01\n",
      " 1.94159791e-01 9.90200460e-01 9.92097974e-01 2.63088346e-01\n",
      " 2.09760596e-03 7.40591884e-01 9.85936821e-01 6.17489278e-01\n",
      " 9.99749839e-01 8.35207283e-01 2.46788152e-02 2.11233441e-02\n",
      " 9.99989271e-01 9.99965191e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 120 [0/107 (0%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 120 [4/107 (4%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 120 [8/107 (7%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 120 [12/107 (11%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 120 [16/107 (15%)]\tTrain Loss: 0.000133\n",
      "Train Epoch: 120 [20/107 (19%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 120 [24/107 (22%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 120 [28/107 (26%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 120 [32/107 (30%)]\tTrain Loss: 0.000301\n",
      "Train Epoch: 120 [36/107 (34%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 120 [40/107 (37%)]\tTrain Loss: 0.000524\n",
      "Train Epoch: 120 [44/107 (41%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 120 [48/107 (45%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 120 [52/107 (49%)]\tTrain Loss: 0.000324\n",
      "Train Epoch: 120 [56/107 (52%)]\tTrain Loss: 0.000197\n",
      "Train Epoch: 120 [60/107 (56%)]\tTrain Loss: 0.000683\n",
      "Train Epoch: 120 [64/107 (60%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 120 [68/107 (64%)]\tTrain Loss: 0.002272\n",
      "Train Epoch: 120 [72/107 (67%)]\tTrain Loss: 0.000175\n",
      "Train Epoch: 120 [76/107 (71%)]\tTrain Loss: 0.000090\n",
      "Train Epoch: 120 [80/107 (75%)]\tTrain Loss: 0.000657\n",
      "Train Epoch: 120 [84/107 (79%)]\tTrain Loss: 0.000883\n",
      "Train Epoch: 120 [88/107 (82%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 120 [92/107 (86%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 120 [96/107 (90%)]\tTrain Loss: 0.000022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 120 [100/107 (93%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 120 [104/107 (97%)]\tTrain Loss: 0.000065\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.54328910e-04 9.60697174e-01 1.52906345e-03 2.17150915e-02\n",
      " 4.18583862e-03 2.08233265e-04 4.94707137e-01 6.84047630e-03\n",
      " 2.18117886e-04 1.24436691e-02 7.13548064e-01 4.26100132e-06\n",
      " 4.46489960e-01 1.14973297e-03 4.86023724e-03 9.62288050e-06\n",
      " 4.41999146e-05 3.04234117e-01 3.47922463e-03 7.29307085e-02\n",
      " 7.20765173e-01 9.80449677e-01 9.99898434e-01 9.99981046e-01\n",
      " 9.34570551e-01 9.99851346e-01 9.99870539e-01 2.61909105e-02\n",
      " 2.94434369e-01 1.23812526e-04 4.47365940e-01 2.02754047e-03\n",
      " 2.71811366e-01 4.70903842e-06 4.85751934e-06 2.34724619e-04\n",
      " 4.30687098e-04 9.74719226e-01 8.10163677e-01 5.34113451e-06\n",
      " 1.42520412e-06 8.15242602e-05 1.12002864e-01 1.23004749e-01\n",
      " 5.89851379e-01 3.69775179e-03 4.82312381e-01 3.51708144e-01\n",
      " 8.02095294e-01 3.69559452e-02 7.68955350e-01 3.28902155e-04\n",
      " 4.19155415e-03 2.63810903e-03 3.48554999e-02 2.61820182e-02\n",
      " 9.81782973e-01 4.68270713e-07 4.96070388e-05 8.58533382e-03\n",
      " 9.99714673e-01 9.99773800e-01 9.99989152e-01 9.99976635e-01\n",
      " 9.99995351e-01 9.99467075e-01 9.97843504e-01 9.99999762e-01\n",
      " 9.99980450e-01 9.97248352e-01 4.16450113e-01 1.67708516e-01\n",
      " 9.51998472e-01 9.95244801e-01 9.99292254e-01 6.54094756e-01\n",
      " 9.99958873e-01 9.99062836e-01 9.99994516e-01 9.98327196e-01\n",
      " 9.99983191e-01 9.99596179e-01 9.99927878e-01 9.98946011e-01\n",
      " 9.56391573e-01 9.99757469e-01 9.99272525e-01 9.96424973e-01\n",
      " 5.97265512e-02 9.99709904e-01 9.99927640e-01 8.66662979e-01\n",
      " 8.39158535e-01 1.00000000e+00 9.99979258e-01 9.99999642e-01\n",
      " 6.71780765e-01 7.78729618e-01 9.99923348e-01 9.99867201e-01\n",
      " 5.43766201e-01 9.90995347e-01 4.57803085e-02 9.96635616e-01\n",
      " 1.89796194e-01 9.92454648e-01 9.92268264e-01 2.50698715e-01\n",
      " 1.30354532e-03 5.95312178e-01 9.90937471e-01 7.82286167e-01\n",
      " 9.99906301e-01 9.27751422e-01 1.12674255e-02 1.87535211e-02\n",
      " 9.99971032e-01 9.99919295e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 45 FN= 11 FP= 15\n",
      "TP+FP 62\n",
      "precision 0.7580645161290323\n",
      "recall 0.8103448275862069\n",
      "F1 0.7833333333333333\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7801724137931034\n",
      "AUC 0.867816091954023\n",
      "\n",
      " The epoch is 120, average recall: 0.8103, average precision: 0.7581,average F1: 0.7833, average accuracy: 0.7797, average AUC: 0.8678\n",
      "Train Epoch: 121 [0/107 (0%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 121 [4/107 (4%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 121 [8/107 (7%)]\tTrain Loss: 0.001665\n",
      "Train Epoch: 121 [12/107 (11%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 121 [16/107 (15%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 121 [20/107 (19%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 121 [24/107 (22%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 121 [28/107 (26%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 121 [32/107 (30%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 121 [36/107 (34%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 121 [40/107 (37%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 121 [44/107 (41%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 121 [48/107 (45%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 121 [52/107 (49%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 121 [56/107 (52%)]\tTrain Loss: 0.000190\n",
      "Train Epoch: 121 [60/107 (56%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 121 [64/107 (60%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 121 [68/107 (64%)]\tTrain Loss: 0.000147\n",
      "Train Epoch: 121 [72/107 (67%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 121 [76/107 (71%)]\tTrain Loss: 0.000391\n",
      "Train Epoch: 121 [80/107 (75%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 121 [84/107 (79%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 121 [88/107 (82%)]\tTrain Loss: 0.000799\n",
      "Train Epoch: 121 [92/107 (86%)]\tTrain Loss: 0.000946\n",
      "Train Epoch: 121 [96/107 (90%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 121 [100/107 (93%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 121 [104/107 (97%)]\tTrain Loss: 0.000007\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.97841786e-03 9.66869473e-01 3.45259462e-03 2.76700519e-02\n",
      " 8.05779081e-03 1.07446965e-03 3.71457547e-01 7.47068273e-03\n",
      " 9.14545264e-04 1.18672317e-02 5.51663399e-01 9.76622687e-06\n",
      " 2.15042621e-01 1.40237203e-03 5.78370411e-03 4.05014980e-05\n",
      " 3.65931483e-05 2.31557250e-01 1.15492027e-02 2.67237484e-01\n",
      " 6.59182966e-01 9.71325517e-01 9.99921679e-01 9.99973416e-01\n",
      " 8.95133197e-01 9.99814451e-01 9.99930382e-01 7.16717541e-02\n",
      " 3.77957910e-01 2.60250323e-04 3.70886981e-01 4.01883060e-03\n",
      " 4.92765605e-01 9.65922027e-06 5.76468574e-06 2.45515781e-04\n",
      " 2.24450545e-04 9.30207431e-01 7.48425364e-01 3.76230241e-06\n",
      " 1.28857710e-06 6.31302537e-05 1.45555928e-01 1.14533454e-01\n",
      " 6.81323111e-01 7.46049406e-03 5.03757179e-01 3.53453904e-01\n",
      " 7.81284094e-01 2.11945083e-02 8.58200550e-01 4.88896389e-04\n",
      " 7.04061566e-03 2.61290674e-03 1.97866075e-02 5.75570278e-02\n",
      " 9.89074290e-01 4.32866557e-07 7.12907640e-05 1.49385333e-02\n",
      " 9.99733865e-01 9.99818981e-01 9.99991894e-01 9.99991179e-01\n",
      " 9.99994516e-01 9.99452770e-01 9.96924579e-01 9.99999642e-01\n",
      " 9.99941349e-01 9.98931706e-01 4.16944236e-01 1.74892098e-01\n",
      " 9.65002239e-01 9.97604072e-01 9.98775303e-01 7.91619360e-01\n",
      " 9.99975204e-01 9.99305606e-01 9.99993443e-01 9.99114573e-01\n",
      " 9.99990463e-01 9.99461114e-01 9.99930978e-01 9.98922467e-01\n",
      " 9.44465339e-01 9.99783933e-01 9.99282777e-01 9.97680426e-01\n",
      " 6.11332208e-02 9.99359071e-01 9.99663115e-01 9.16381538e-01\n",
      " 7.96118796e-01 9.99999762e-01 9.99811709e-01 9.99997258e-01\n",
      " 4.65705454e-01 6.20530844e-01 9.99890924e-01 9.99744475e-01\n",
      " 3.34165633e-01 9.90224421e-01 1.25160247e-01 9.93197560e-01\n",
      " 1.17426403e-01 9.81441259e-01 9.92474973e-01 1.87683299e-01\n",
      " 1.80747733e-03 7.72698760e-01 9.86662567e-01 6.88662887e-01\n",
      " 9.99781549e-01 7.41567731e-01 3.67596075e-02 2.67972276e-02\n",
      " 9.99987125e-01 9.99956489e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 122 [0/107 (0%)]\tTrain Loss: 0.003063\n",
      "Train Epoch: 122 [4/107 (4%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 122 [8/107 (7%)]\tTrain Loss: 0.000131\n",
      "Train Epoch: 122 [12/107 (11%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 122 [16/107 (15%)]\tTrain Loss: 0.000089\n",
      "Train Epoch: 122 [20/107 (19%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 122 [24/107 (22%)]\tTrain Loss: 0.001823\n",
      "Train Epoch: 122 [28/107 (26%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 122 [32/107 (30%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 122 [36/107 (34%)]\tTrain Loss: 0.000089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [40/107 (37%)]\tTrain Loss: 0.001550\n",
      "Train Epoch: 122 [44/107 (41%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 122 [48/107 (45%)]\tTrain Loss: 0.000558\n",
      "Train Epoch: 122 [52/107 (49%)]\tTrain Loss: 0.004465\n",
      "Train Epoch: 122 [56/107 (52%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 122 [60/107 (56%)]\tTrain Loss: 0.000252\n",
      "Train Epoch: 122 [64/107 (60%)]\tTrain Loss: 0.000547\n",
      "Train Epoch: 122 [68/107 (64%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 122 [72/107 (67%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 122 [76/107 (71%)]\tTrain Loss: 0.000358\n",
      "Train Epoch: 122 [80/107 (75%)]\tTrain Loss: 0.001091\n",
      "Train Epoch: 122 [84/107 (79%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 122 [88/107 (82%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 122 [92/107 (86%)]\tTrain Loss: 0.000776\n",
      "Train Epoch: 122 [96/107 (90%)]\tTrain Loss: 0.000224\n",
      "Train Epoch: 122 [100/107 (93%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 122 [104/107 (97%)]\tTrain Loss: 0.000021\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.08899083e-03 9.43678677e-01 2.40429910e-03 1.24519616e-02\n",
      " 8.53943918e-03 3.25368310e-04 5.93336165e-01 2.75432062e-03\n",
      " 1.80885923e-04 1.08391335e-02 6.64501429e-01 6.65001926e-06\n",
      " 3.19192171e-01 1.24705012e-03 4.69013862e-03 1.29600394e-05\n",
      " 3.17470913e-05 1.41047388e-01 1.61915703e-03 7.33951777e-02\n",
      " 5.99827766e-01 9.34042096e-01 9.99857426e-01 9.99947667e-01\n",
      " 8.68307531e-01 9.99719918e-01 9.99739349e-01 1.23372450e-02\n",
      " 2.78102905e-01 2.86159484e-04 3.22171450e-01 1.35334826e-03\n",
      " 1.84402496e-01 1.15856392e-05 5.81590257e-06 3.64463107e-04\n",
      " 5.22546412e-04 9.21396554e-01 7.94671416e-01 5.21086895e-06\n",
      " 2.00565978e-06 1.25889885e-04 4.12629321e-02 9.23466831e-02\n",
      " 5.60811877e-01 3.98440845e-03 4.44467127e-01 2.77793288e-01\n",
      " 7.81564176e-01 1.79149862e-02 7.31105208e-01 4.16788331e-04\n",
      " 4.20449628e-03 1.02263538e-03 9.10351612e-03 3.29910815e-02\n",
      " 9.47115302e-01 3.90948259e-07 2.42751994e-05 3.71635845e-03\n",
      " 9.99016762e-01 9.99450505e-01 9.99978304e-01 9.99953151e-01\n",
      " 9.99990106e-01 9.98914480e-01 9.94068027e-01 9.99999166e-01\n",
      " 9.99883652e-01 9.97242928e-01 2.61238128e-01 1.18622944e-01\n",
      " 9.09988821e-01 9.93850112e-01 9.97221828e-01 4.41702455e-01\n",
      " 9.99955654e-01 9.98048186e-01 9.99991059e-01 9.97769833e-01\n",
      " 9.99958873e-01 9.99199450e-01 9.99801815e-01 9.97708321e-01\n",
      " 9.49207306e-01 9.99607861e-01 9.98953462e-01 9.93465245e-01\n",
      " 2.97183357e-02 9.98688519e-01 9.99702871e-01 8.93310130e-01\n",
      " 6.74344242e-01 9.99999642e-01 9.99803364e-01 9.99997020e-01\n",
      " 4.23743188e-01 5.97282350e-01 9.99843001e-01 9.99676943e-01\n",
      " 6.20152473e-01 9.87947762e-01 4.12229858e-02 9.90337253e-01\n",
      " 1.64654836e-01 9.75158632e-01 9.85201120e-01 2.95641720e-01\n",
      " 5.30477206e-04 4.89232600e-01 9.86932218e-01 7.99202144e-01\n",
      " 9.99648690e-01 7.81583190e-01 1.80048253e-02 1.06481193e-02\n",
      " 9.99926567e-01 9.99963641e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 123 [0/107 (0%)]\tTrain Loss: 0.000219\n",
      "Train Epoch: 123 [4/107 (4%)]\tTrain Loss: 0.000665\n",
      "Train Epoch: 123 [8/107 (7%)]\tTrain Loss: 0.000138\n",
      "Train Epoch: 123 [12/107 (11%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 123 [16/107 (15%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 123 [20/107 (19%)]\tTrain Loss: 0.000129\n",
      "Train Epoch: 123 [24/107 (22%)]\tTrain Loss: 0.000082\n",
      "Train Epoch: 123 [28/107 (26%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 123 [32/107 (30%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 123 [36/107 (34%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 123 [40/107 (37%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 123 [44/107 (41%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 123 [48/107 (45%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 123 [52/107 (49%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 123 [56/107 (52%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 123 [60/107 (56%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 123 [64/107 (60%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 123 [68/107 (64%)]\tTrain Loss: 0.000479\n",
      "Train Epoch: 123 [72/107 (67%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 123 [76/107 (71%)]\tTrain Loss: 0.000309\n",
      "Train Epoch: 123 [80/107 (75%)]\tTrain Loss: 0.000195\n",
      "Train Epoch: 123 [84/107 (79%)]\tTrain Loss: 0.000157\n",
      "Train Epoch: 123 [88/107 (82%)]\tTrain Loss: 0.005527\n",
      "Train Epoch: 123 [92/107 (86%)]\tTrain Loss: 0.000389\n",
      "Train Epoch: 123 [96/107 (90%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 123 [100/107 (93%)]\tTrain Loss: 0.000943\n",
      "Train Epoch: 123 [104/107 (97%)]\tTrain Loss: 0.000010\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.14592181e-03 9.63600218e-01 3.97929596e-03 3.77739780e-02\n",
      " 1.48349619e-02 8.47941206e-04 4.69265282e-01 1.41774425e-02\n",
      " 1.48760853e-03 3.45617533e-02 8.21385741e-01 1.18712269e-05\n",
      " 4.73968089e-01 2.45873886e-03 8.66890606e-03 4.20693505e-05\n",
      " 6.74907496e-05 3.83867174e-01 8.19746498e-03 4.01746094e-01\n",
      " 8.43654335e-01 9.84503090e-01 9.99890804e-01 9.99992847e-01\n",
      " 9.63010132e-01 9.99891520e-01 9.99970198e-01 2.97144167e-02\n",
      " 4.82263893e-01 7.29675870e-04 3.28229398e-01 4.04437957e-03\n",
      " 3.19393218e-01 2.17806519e-05 2.76196588e-05 7.19352509e-04\n",
      " 5.67210256e-04 9.66480851e-01 8.34220290e-01 1.59594183e-05\n",
      " 5.41260397e-06 5.74882200e-04 7.88660944e-02 2.00116798e-01\n",
      " 7.03078628e-01 2.00413968e-02 7.47292161e-01 4.76425141e-01\n",
      " 9.29506063e-01 7.16267005e-02 9.47039425e-01 9.53615468e-04\n",
      " 2.44247280e-02 1.83685590e-02 1.36802360e-01 8.94698203e-02\n",
      " 9.93169308e-01 2.77301547e-06 4.65946287e-05 2.02902239e-02\n",
      " 9.99895096e-01 9.99935150e-01 9.99997377e-01 9.99993682e-01\n",
      " 9.99995947e-01 9.99747217e-01 9.97826636e-01 1.00000000e+00\n",
      " 9.99977469e-01 9.98739779e-01 4.59395647e-01 2.88047522e-01\n",
      " 9.82341528e-01 9.98441398e-01 9.99354661e-01 8.73185754e-01\n",
      " 9.99986649e-01 9.99392033e-01 9.99995470e-01 9.99438226e-01\n",
      " 9.99990582e-01 9.99842763e-01 9.99961615e-01 9.99688148e-01\n",
      " 9.86924648e-01 9.99865890e-01 9.99440134e-01 9.97236371e-01\n",
      " 1.08690217e-01 9.99932885e-01 9.99938369e-01 9.65977669e-01\n",
      " 8.75683188e-01 1.00000000e+00 9.99962330e-01 9.99999762e-01\n",
      " 7.12894976e-01 8.99910748e-01 9.99964952e-01 9.99905825e-01\n",
      " 7.17545629e-01 9.90009367e-01 6.27540275e-02 9.96162176e-01\n",
      " 2.97858387e-01 9.89354491e-01 9.91478026e-01 3.24181288e-01\n",
      " 3.97315808e-03 8.66821766e-01 9.87546265e-01 7.36338794e-01\n",
      " 9.99926567e-01 9.12903965e-01 2.26840470e-02 8.13905243e-03\n",
      " 9.99998569e-01 9.99986529e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 124 [0/107 (0%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 124 [4/107 (4%)]\tTrain Loss: 0.000457\n",
      "Train Epoch: 124 [8/107 (7%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 124 [12/107 (11%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 124 [16/107 (15%)]\tTrain Loss: 0.000115\n",
      "Train Epoch: 124 [20/107 (19%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 124 [24/107 (22%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 124 [28/107 (26%)]\tTrain Loss: 0.002254\n",
      "Train Epoch: 124 [32/107 (30%)]\tTrain Loss: 0.001501\n",
      "Train Epoch: 124 [36/107 (34%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 124 [40/107 (37%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 124 [44/107 (41%)]\tTrain Loss: 0.000316\n",
      "Train Epoch: 124 [48/107 (45%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 124 [52/107 (49%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 124 [56/107 (52%)]\tTrain Loss: 0.000451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 124 [60/107 (56%)]\tTrain Loss: 0.000785\n",
      "Train Epoch: 124 [64/107 (60%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 124 [68/107 (64%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 124 [72/107 (67%)]\tTrain Loss: 0.001338\n",
      "Train Epoch: 124 [76/107 (71%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 124 [80/107 (75%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 124 [84/107 (79%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 124 [88/107 (82%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 124 [92/107 (86%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 124 [96/107 (90%)]\tTrain Loss: 0.000558\n",
      "Train Epoch: 124 [100/107 (93%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 124 [104/107 (97%)]\tTrain Loss: 0.000006\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.55663272e-04 9.23865378e-01 1.56693789e-03 2.11947896e-02\n",
      " 6.26253616e-03 1.67316059e-04 1.00790888e-01 7.60680437e-03\n",
      " 3.35028162e-04 1.05513744e-02 6.66851103e-01 4.70207942e-06\n",
      " 2.51476705e-01 6.13161654e-04 3.86590161e-03 9.90295939e-06\n",
      " 1.32234381e-05 2.43134499e-01 4.57481295e-03 1.28074914e-01\n",
      " 4.66170341e-01 9.43508863e-01 9.99909759e-01 9.99969840e-01\n",
      " 7.54096985e-01 9.99803364e-01 9.99838233e-01 2.04416774e-02\n",
      " 2.98111111e-01 2.02506853e-04 1.88686103e-01 3.07487254e-03\n",
      " 4.50743377e-01 2.30094042e-06 1.84277860e-06 2.05231496e-04\n",
      " 2.42786176e-04 9.32702839e-01 5.43676496e-01 2.63360926e-06\n",
      " 8.40385951e-07 3.03478919e-05 6.51182309e-02 1.91176817e-01\n",
      " 7.72482932e-01 4.02090466e-03 5.60300350e-01 2.94980466e-01\n",
      " 7.75991738e-01 1.65989492e-02 7.39802063e-01 2.53565697e-04\n",
      " 2.93955929e-03 5.33518323e-04 2.38640029e-02 2.06019599e-02\n",
      " 9.82466698e-01 1.89664974e-07 2.41357538e-05 4.68051014e-03\n",
      " 9.99749362e-01 9.99786198e-01 9.99987006e-01 9.99969840e-01\n",
      " 9.99989510e-01 9.99325156e-01 9.95126367e-01 9.99999523e-01\n",
      " 9.99910355e-01 9.98201489e-01 3.14850450e-01 1.60563484e-01\n",
      " 9.46326077e-01 9.95399296e-01 9.98084188e-01 6.01383328e-01\n",
      " 9.99947906e-01 9.98568177e-01 9.99989033e-01 9.98545408e-01\n",
      " 9.99977708e-01 9.98960137e-01 9.99866247e-01 9.98587608e-01\n",
      " 9.66524780e-01 9.99756038e-01 9.99016643e-01 9.95873630e-01\n",
      " 2.69730520e-02 9.99142885e-01 9.99380112e-01 8.77263248e-01\n",
      " 8.55693758e-01 9.99999642e-01 9.99844313e-01 9.99995232e-01\n",
      " 4.55818295e-01 6.15653098e-01 9.99864936e-01 9.99752820e-01\n",
      " 2.27464959e-01 9.91375268e-01 3.80326733e-02 9.94053781e-01\n",
      " 3.36592585e-01 9.92227614e-01 9.92219985e-01 1.40775487e-01\n",
      " 6.19305822e-04 6.92633152e-01 9.58231986e-01 5.03679991e-01\n",
      " 9.99573648e-01 8.31608415e-01 1.82968937e-02 1.48472190e-02\n",
      " 9.99977946e-01 9.99880672e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 125 [0/107 (0%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 125 [4/107 (4%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 125 [8/107 (7%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 125 [12/107 (11%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 125 [16/107 (15%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 125 [20/107 (19%)]\tTrain Loss: 0.000887\n",
      "Train Epoch: 125 [24/107 (22%)]\tTrain Loss: 0.005552\n",
      "Train Epoch: 125 [28/107 (26%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 125 [32/107 (30%)]\tTrain Loss: 0.000732\n",
      "Train Epoch: 125 [36/107 (34%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 125 [40/107 (37%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 125 [44/107 (41%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 125 [48/107 (45%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 125 [52/107 (49%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 125 [56/107 (52%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 125 [60/107 (56%)]\tTrain Loss: 0.000166\n",
      "Train Epoch: 125 [64/107 (60%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 125 [68/107 (64%)]\tTrain Loss: 0.000854\n",
      "Train Epoch: 125 [72/107 (67%)]\tTrain Loss: 0.000174\n",
      "Train Epoch: 125 [76/107 (71%)]\tTrain Loss: 0.000292\n",
      "Train Epoch: 125 [80/107 (75%)]\tTrain Loss: 0.000177\n",
      "Train Epoch: 125 [84/107 (79%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 125 [88/107 (82%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 125 [92/107 (86%)]\tTrain Loss: 0.004106\n",
      "Train Epoch: 125 [96/107 (90%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 125 [100/107 (93%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 125 [104/107 (97%)]\tTrain Loss: 0.000239\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.07507201e-04 8.87748122e-01 1.46177376e-03 1.48916421e-02\n",
      " 4.57708258e-03 2.65633687e-04 1.02023050e-01 6.07734034e-03\n",
      " 4.02913924e-04 5.74493129e-03 6.46016002e-01 2.32165371e-06\n",
      " 2.12462440e-01 6.73934352e-04 7.66503066e-03 5.16685304e-06\n",
      " 6.36895675e-06 1.51342154e-01 6.15640590e-03 1.50126681e-01\n",
      " 4.07140136e-01 9.51506197e-01 9.99720871e-01 9.99949217e-01\n",
      " 8.23287189e-01 9.99576628e-01 9.99808252e-01 1.23412982e-02\n",
      " 2.21394688e-01 3.68075911e-04 1.56239554e-01 3.43213417e-03\n",
      " 3.61658394e-01 2.93435369e-06 1.79230881e-06 7.98708570e-05\n",
      " 1.32039684e-04 9.25840020e-01 6.83631003e-01 1.21575056e-06\n",
      " 3.50025971e-07 1.85531262e-05 4.29632030e-02 1.28434762e-01\n",
      " 7.00948536e-01 4.99164965e-03 5.58154225e-01 2.80002862e-01\n",
      " 8.03996325e-01 1.22751622e-02 8.43755245e-01 2.85762973e-04\n",
      " 3.52272880e-03 1.48158404e-03 9.52871796e-03 3.81836630e-02\n",
      " 9.81392324e-01 1.28815515e-07 1.69967243e-05 4.93932003e-03\n",
      " 9.99766409e-01 9.99787629e-01 9.99988198e-01 9.99979973e-01\n",
      " 9.99982238e-01 9.99005973e-01 9.92353261e-01 9.99998927e-01\n",
      " 9.99884844e-01 9.98196423e-01 3.41939241e-01 1.57035932e-01\n",
      " 9.67827141e-01 9.96646464e-01 9.98076677e-01 5.94521403e-01\n",
      " 9.99932051e-01 9.98484313e-01 9.99985695e-01 9.98137832e-01\n",
      " 9.99972463e-01 9.99175847e-01 9.99873638e-01 9.98689592e-01\n",
      " 9.63059664e-01 9.99789178e-01 9.98625636e-01 9.93802309e-01\n",
      " 2.15498731e-02 9.97610927e-01 9.99081254e-01 8.83421719e-01\n",
      " 7.75268614e-01 9.99999642e-01 9.99686599e-01 9.99989033e-01\n",
      " 3.98854584e-01 6.77861631e-01 9.99845386e-01 9.99583066e-01\n",
      " 3.29985559e-01 9.88328040e-01 2.69298293e-02 9.86959279e-01\n",
      " 1.97090358e-01 9.80813682e-01 9.90065157e-01 1.14632800e-01\n",
      " 6.96753967e-04 5.42194426e-01 9.32497144e-01 3.59110802e-01\n",
      " 9.99529481e-01 6.79011047e-01 1.33602032e-02 7.15492899e-03\n",
      " 9.99960423e-01 9.99848247e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 126 [0/107 (0%)]\tTrain Loss: 0.004945\n",
      "Train Epoch: 126 [4/107 (4%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 126 [8/107 (7%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 126 [12/107 (11%)]\tTrain Loss: 0.001030\n",
      "Train Epoch: 126 [16/107 (15%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 126 [20/107 (19%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 126 [24/107 (22%)]\tTrain Loss: 0.000236\n",
      "Train Epoch: 126 [28/107 (26%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 126 [32/107 (30%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 126 [36/107 (34%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 126 [40/107 (37%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 126 [44/107 (41%)]\tTrain Loss: 0.000342\n",
      "Train Epoch: 126 [48/107 (45%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 126 [52/107 (49%)]\tTrain Loss: 0.000247\n",
      "Train Epoch: 126 [56/107 (52%)]\tTrain Loss: 0.000267\n",
      "Train Epoch: 126 [60/107 (56%)]\tTrain Loss: 0.001069\n",
      "Train Epoch: 126 [64/107 (60%)]\tTrain Loss: 0.000072\n",
      "Train Epoch: 126 [68/107 (64%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 126 [72/107 (67%)]\tTrain Loss: 0.000114\n",
      "Train Epoch: 126 [76/107 (71%)]\tTrain Loss: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 126 [80/107 (75%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 126 [84/107 (79%)]\tTrain Loss: 0.000451\n",
      "Train Epoch: 126 [88/107 (82%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 126 [92/107 (86%)]\tTrain Loss: 0.000313\n",
      "Train Epoch: 126 [96/107 (90%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 126 [100/107 (93%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 126 [104/107 (97%)]\tTrain Loss: 0.001246\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.10575022e-04 8.58541429e-01 9.04414570e-04 1.35020651e-02\n",
      " 2.36251322e-03 2.21720853e-04 8.25575665e-02 2.83687026e-03\n",
      " 2.02066265e-04 7.87579827e-03 6.82125568e-01 3.89676643e-06\n",
      " 3.68627489e-01 4.45495796e-04 2.67310045e-03 8.10019992e-06\n",
      " 1.66883001e-05 6.70110434e-02 3.57011403e-03 4.41409834e-02\n",
      " 5.39775074e-01 9.59585905e-01 9.99933124e-01 9.99958873e-01\n",
      " 8.63455296e-01 9.99769628e-01 9.99615431e-01 1.21454708e-02\n",
      " 2.03408301e-01 1.02700535e-04 1.54993773e-01 2.80293473e-03\n",
      " 2.40465745e-01 2.44690727e-06 1.90458832e-06 1.22065976e-04\n",
      " 2.57575855e-04 8.63236904e-01 4.55490470e-01 2.44722037e-06\n",
      " 1.35523965e-06 3.44766922e-05 4.87908162e-02 8.27061236e-02\n",
      " 6.71674013e-01 3.77367809e-03 3.61095786e-01 2.67641455e-01\n",
      " 7.26479352e-01 2.92624664e-02 7.37469196e-01 1.04526516e-04\n",
      " 1.80017995e-03 6.71288057e-04 1.54267522e-02 2.23587397e-02\n",
      " 9.65982020e-01 1.07165931e-07 2.20923757e-05 4.64988733e-03\n",
      " 9.99306321e-01 9.99581277e-01 9.99967217e-01 9.99934673e-01\n",
      " 9.99989986e-01 9.99113500e-01 9.95172560e-01 9.99999046e-01\n",
      " 9.99922037e-01 9.96604323e-01 4.47874904e-01 1.57588929e-01\n",
      " 9.03535604e-01 9.94629443e-01 9.98287976e-01 6.63621783e-01\n",
      " 9.99863029e-01 9.96766090e-01 9.99991059e-01 9.98712420e-01\n",
      " 9.99983311e-01 9.99257267e-01 9.99856472e-01 9.97493505e-01\n",
      " 9.35778320e-01 9.99378443e-01 9.99091864e-01 9.95074451e-01\n",
      " 1.88095383e-02 9.98830378e-01 9.99529839e-01 8.11905801e-01\n",
      " 8.21816385e-01 9.99999881e-01 9.99934316e-01 9.99997616e-01\n",
      " 5.61052263e-01 4.49675679e-01 9.99735296e-01 9.99715865e-01\n",
      " 2.92680025e-01 9.84400928e-01 1.66635104e-02 9.95333135e-01\n",
      " 1.70342326e-01 9.89705682e-01 9.90422845e-01 2.09385678e-01\n",
      " 4.45790036e-04 5.14222443e-01 9.46404636e-01 5.15929341e-01\n",
      " 9.99295115e-01 8.61948073e-01 2.19703913e-02 2.10689865e-02\n",
      " 9.99776542e-01 9.99698520e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 127 [0/107 (0%)]\tTrain Loss: 0.000529\n",
      "Train Epoch: 127 [4/107 (4%)]\tTrain Loss: 0.000814\n",
      "Train Epoch: 127 [8/107 (7%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 127 [12/107 (11%)]\tTrain Loss: 0.000095\n",
      "Train Epoch: 127 [16/107 (15%)]\tTrain Loss: 0.000071\n",
      "Train Epoch: 127 [20/107 (19%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 127 [24/107 (22%)]\tTrain Loss: 0.000270\n",
      "Train Epoch: 127 [28/107 (26%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 127 [32/107 (30%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 127 [36/107 (34%)]\tTrain Loss: 0.000695\n",
      "Train Epoch: 127 [40/107 (37%)]\tTrain Loss: 0.000310\n",
      "Train Epoch: 127 [44/107 (41%)]\tTrain Loss: 0.001248\n",
      "Train Epoch: 127 [48/107 (45%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 127 [52/107 (49%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 127 [56/107 (52%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 127 [60/107 (56%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 127 [64/107 (60%)]\tTrain Loss: 0.000148\n",
      "Train Epoch: 127 [68/107 (64%)]\tTrain Loss: 0.000316\n",
      "Train Epoch: 127 [72/107 (67%)]\tTrain Loss: 0.000095\n",
      "Train Epoch: 127 [76/107 (71%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 127 [80/107 (75%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 127 [84/107 (79%)]\tTrain Loss: 0.000270\n",
      "Train Epoch: 127 [88/107 (82%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 127 [92/107 (86%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 127 [96/107 (90%)]\tTrain Loss: 0.000058\n",
      "Train Epoch: 127 [100/107 (93%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 127 [104/107 (97%)]\tTrain Loss: 0.000667\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.75557064e-03 9.81678426e-01 5.04955836e-03 3.46955769e-02\n",
      " 7.20085017e-03 4.96438181e-04 5.37510395e-01 1.02241402e-02\n",
      " 4.22727870e-04 1.48946270e-02 7.70695686e-01 4.88673140e-06\n",
      " 3.72351259e-01 3.13715055e-03 1.46130826e-02 2.35387852e-05\n",
      " 3.03104043e-05 2.79537886e-01 1.74205210e-02 1.93985075e-01\n",
      " 7.37887442e-01 9.93606567e-01 9.99940991e-01 9.99992609e-01\n",
      " 9.67041254e-01 9.99946237e-01 9.99980927e-01 5.72968982e-02\n",
      " 3.92168909e-01 4.49231331e-04 6.13757610e-01 4.92049986e-03\n",
      " 4.43882853e-01 6.52814515e-06 7.69025337e-06 3.81768419e-04\n",
      " 5.22852410e-04 9.74356592e-01 8.40561986e-01 9.72411726e-06\n",
      " 2.93221387e-06 2.04180818e-04 1.27629012e-01 2.84596443e-01\n",
      " 7.81509995e-01 1.12361694e-02 6.52733028e-01 5.44327259e-01\n",
      " 9.12115037e-01 4.01094481e-02 9.16391850e-01 6.86370535e-04\n",
      " 1.69812217e-02 5.20385709e-03 1.40317872e-01 5.76348230e-02\n",
      " 9.93301034e-01 1.04192463e-06 2.73537516e-05 1.96706243e-02\n",
      " 9.99945402e-01 9.99957919e-01 9.99999046e-01 9.99997854e-01\n",
      " 9.99997735e-01 9.99823987e-01 9.99051630e-01 1.00000000e+00\n",
      " 9.99984264e-01 9.99031067e-01 6.73145056e-01 3.38620484e-01\n",
      " 9.76458788e-01 9.98443425e-01 9.99645114e-01 8.62193584e-01\n",
      " 9.99993086e-01 9.99787748e-01 9.99997497e-01 9.99367535e-01\n",
      " 9.99992132e-01 9.99782979e-01 9.99976039e-01 9.99823391e-01\n",
      " 9.83478665e-01 9.99930620e-01 9.99519110e-01 9.98090923e-01\n",
      " 8.59024972e-02 9.99957204e-01 9.99958158e-01 9.52700317e-01\n",
      " 8.84055316e-01 1.00000000e+00 9.99979138e-01 9.99999642e-01\n",
      " 5.97146511e-01 8.29684079e-01 9.99971032e-01 9.99941111e-01\n",
      " 5.68543851e-01 9.95862007e-01 6.85539767e-02 9.94197369e-01\n",
      " 2.88641781e-01 9.94890094e-01 9.96197462e-01 5.33785522e-01\n",
      " 2.60435860e-03 8.62688959e-01 9.93240237e-01 6.99306250e-01\n",
      " 9.99974251e-01 8.96833777e-01 3.95729393e-02 1.19566657e-02\n",
      " 9.99998212e-01 9.99993443e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 128 [0/107 (0%)]\tTrain Loss: 0.000432\n",
      "Train Epoch: 128 [4/107 (4%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 128 [8/107 (7%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 128 [12/107 (11%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 128 [16/107 (15%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 128 [20/107 (19%)]\tTrain Loss: 0.000264\n",
      "Train Epoch: 128 [24/107 (22%)]\tTrain Loss: 0.000069\n",
      "Train Epoch: 128 [28/107 (26%)]\tTrain Loss: 0.000363\n",
      "Train Epoch: 128 [32/107 (30%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 128 [36/107 (34%)]\tTrain Loss: 0.001187\n",
      "Train Epoch: 128 [40/107 (37%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 128 [44/107 (41%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 128 [48/107 (45%)]\tTrain Loss: 0.000701\n",
      "Train Epoch: 128 [52/107 (49%)]\tTrain Loss: 0.000951\n",
      "Train Epoch: 128 [56/107 (52%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 128 [60/107 (56%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 128 [64/107 (60%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 128 [68/107 (64%)]\tTrain Loss: 0.000265\n",
      "Train Epoch: 128 [72/107 (67%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 128 [76/107 (71%)]\tTrain Loss: 0.000156\n",
      "Train Epoch: 128 [80/107 (75%)]\tTrain Loss: 0.000353\n",
      "Train Epoch: 128 [84/107 (79%)]\tTrain Loss: 0.000001\n",
      "Train Epoch: 128 [88/107 (82%)]\tTrain Loss: 0.000071\n",
      "Train Epoch: 128 [92/107 (86%)]\tTrain Loss: 0.000867\n",
      "Train Epoch: 128 [96/107 (90%)]\tTrain Loss: 0.000022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 128 [100/107 (93%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 128 [104/107 (97%)]\tTrain Loss: 0.000040\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.19202922e-03 9.90315259e-01 3.84003599e-03 1.67922955e-02\n",
      " 4.45258897e-03 5.03707153e-04 6.51193738e-01 7.87258148e-03\n",
      " 4.99197922e-04 1.66434161e-02 5.90320945e-01 4.76549394e-06\n",
      " 2.57460803e-01 2.48333532e-03 6.15368877e-03 1.97670142e-05\n",
      " 2.57735010e-05 3.86297762e-01 1.35772601e-02 1.36697561e-01\n",
      " 7.32715249e-01 9.94212687e-01 9.99904275e-01 9.99991894e-01\n",
      " 9.20893967e-01 9.99889731e-01 9.99972105e-01 1.06382251e-01\n",
      " 2.02967092e-01 3.52236297e-04 4.84180331e-01 2.56481953e-03\n",
      " 4.35460180e-01 8.06614571e-06 1.00841971e-05 3.23519460e-04\n",
      " 3.71305534e-04 9.58526373e-01 7.30703354e-01 4.79771916e-06\n",
      " 1.12353757e-06 1.16438488e-04 1.27213761e-01 1.58799186e-01\n",
      " 7.33576238e-01 5.56349522e-03 5.30791700e-01 2.81721592e-01\n",
      " 8.94675314e-01 5.53778447e-02 8.72308314e-01 4.79576498e-04\n",
      " 5.37591940e-03 2.30870838e-03 7.65185431e-02 3.31386514e-02\n",
      " 9.90980089e-01 8.77065702e-07 4.77857648e-05 4.25081747e-03\n",
      " 9.99917507e-01 9.99936938e-01 9.99998093e-01 9.99991775e-01\n",
      " 9.99992967e-01 9.99548733e-01 9.95999336e-01 1.00000000e+00\n",
      " 9.99979854e-01 9.98659015e-01 5.05116224e-01 1.75754935e-01\n",
      " 9.57727194e-01 9.96274948e-01 9.99283373e-01 7.56761968e-01\n",
      " 9.99986053e-01 9.99815285e-01 9.99995112e-01 9.98919606e-01\n",
      " 9.99983549e-01 9.99552906e-01 9.99963164e-01 9.99410272e-01\n",
      " 9.62854087e-01 9.99968171e-01 9.99321580e-01 9.98273969e-01\n",
      " 1.31540626e-01 9.99938607e-01 9.99951124e-01 9.23003733e-01\n",
      " 8.43646407e-01 1.00000000e+00 9.99935031e-01 9.99999404e-01\n",
      " 4.69871998e-01 6.82563365e-01 9.99935031e-01 9.99946356e-01\n",
      " 4.21268314e-01 9.89438236e-01 4.86996435e-02 9.88602102e-01\n",
      " 1.90531150e-01 9.81863737e-01 9.94601727e-01 5.66217899e-01\n",
      " 5.36159473e-03 8.14260304e-01 9.88060415e-01 7.49902368e-01\n",
      " 9.99929905e-01 8.87426078e-01 1.87034626e-02 1.03926398e-02\n",
      " 9.99997497e-01 9.99985695e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 129 [0/107 (0%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 129 [4/107 (4%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 129 [8/107 (7%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 129 [12/107 (11%)]\tTrain Loss: 0.000820\n",
      "Train Epoch: 129 [16/107 (15%)]\tTrain Loss: 0.000248\n",
      "Train Epoch: 129 [20/107 (19%)]\tTrain Loss: 0.000080\n",
      "Train Epoch: 129 [24/107 (22%)]\tTrain Loss: 0.002270\n",
      "Train Epoch: 129 [28/107 (26%)]\tTrain Loss: 0.000403\n",
      "Train Epoch: 129 [32/107 (30%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 129 [36/107 (34%)]\tTrain Loss: 0.005998\n",
      "Train Epoch: 129 [40/107 (37%)]\tTrain Loss: 0.000826\n",
      "Train Epoch: 129 [44/107 (41%)]\tTrain Loss: 0.000896\n",
      "Train Epoch: 129 [48/107 (45%)]\tTrain Loss: 0.000178\n",
      "Train Epoch: 129 [52/107 (49%)]\tTrain Loss: 0.000163\n",
      "Train Epoch: 129 [56/107 (52%)]\tTrain Loss: 0.000328\n",
      "Train Epoch: 129 [60/107 (56%)]\tTrain Loss: 0.000972\n",
      "Train Epoch: 129 [64/107 (60%)]\tTrain Loss: 0.000226\n",
      "Train Epoch: 129 [68/107 (64%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 129 [72/107 (67%)]\tTrain Loss: 0.000205\n",
      "Train Epoch: 129 [76/107 (71%)]\tTrain Loss: 0.000800\n",
      "Train Epoch: 129 [80/107 (75%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 129 [84/107 (79%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 129 [88/107 (82%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 129 [92/107 (86%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 129 [96/107 (90%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 129 [100/107 (93%)]\tTrain Loss: 0.000150\n",
      "Train Epoch: 129 [104/107 (97%)]\tTrain Loss: 0.000174\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.58596633e-04 9.65719104e-01 2.23180396e-03 2.29861178e-02\n",
      " 3.22744320e-03 2.54121143e-04 2.93353468e-01 7.22288759e-03\n",
      " 5.44814218e-04 1.70921925e-02 5.97690284e-01 9.06758760e-06\n",
      " 2.61269629e-01 1.40743388e-03 8.29760171e-03 1.45202785e-05\n",
      " 2.57813681e-05 3.17605734e-01 6.71116542e-03 1.14779070e-01\n",
      " 5.86700380e-01 9.79263842e-01 9.99884844e-01 9.99984384e-01\n",
      " 8.93266082e-01 9.99870658e-01 9.99950528e-01 6.84017390e-02\n",
      " 3.17108899e-01 2.85617338e-04 5.21064103e-01 3.22394422e-03\n",
      " 4.38397110e-01 5.89579622e-06 8.21520462e-06 2.50353594e-04\n",
      " 3.00380430e-04 9.61241245e-01 6.94037497e-01 4.36952951e-06\n",
      " 1.13832198e-06 5.93041877e-05 1.11625396e-01 2.17261001e-01\n",
      " 6.36936724e-01 4.51455917e-03 5.01505136e-01 2.18587577e-01\n",
      " 8.23077440e-01 3.21555138e-02 8.32221687e-01 4.56368405e-04\n",
      " 4.38471884e-03 2.36993865e-03 1.26983032e-01 3.19245942e-02\n",
      " 9.91786182e-01 8.75162414e-07 5.67297284e-05 9.12385434e-03\n",
      " 9.99860644e-01 9.99912977e-01 9.99996066e-01 9.99985576e-01\n",
      " 9.99993563e-01 9.99582946e-01 9.97331142e-01 9.99999881e-01\n",
      " 9.99969482e-01 9.98343349e-01 4.14599687e-01 1.27031162e-01\n",
      " 9.55159187e-01 9.95683551e-01 9.99229193e-01 8.26884925e-01\n",
      " 9.99972463e-01 9.99565423e-01 9.99992728e-01 9.98002589e-01\n",
      " 9.99988317e-01 9.99759495e-01 9.99953151e-01 9.99521852e-01\n",
      " 9.46374714e-01 9.99872684e-01 9.99360383e-01 9.96645749e-01\n",
      " 6.19316399e-02 9.99775469e-01 9.99886274e-01 9.02594149e-01\n",
      " 8.32467198e-01 1.00000000e+00 9.99959230e-01 9.99999404e-01\n",
      " 5.54041803e-01 7.60493338e-01 9.99915004e-01 9.99824226e-01\n",
      " 3.94687474e-01 9.85952377e-01 1.46685280e-02 9.94428873e-01\n",
      " 1.93583846e-01 9.90351737e-01 9.90814269e-01 3.27905893e-01\n",
      " 2.01680884e-03 7.76471734e-01 9.82782841e-01 6.67593777e-01\n",
      " 9.99890208e-01 8.24334085e-01 1.48727987e-02 1.31562622e-02\n",
      " 9.99995828e-01 9.99957919e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 130 [0/107 (0%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 130 [4/107 (4%)]\tTrain Loss: 0.000917\n",
      "Train Epoch: 130 [8/107 (7%)]\tTrain Loss: 0.000375\n",
      "Train Epoch: 130 [12/107 (11%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 130 [16/107 (15%)]\tTrain Loss: 0.000163\n",
      "Train Epoch: 130 [20/107 (19%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 130 [24/107 (22%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 130 [28/107 (26%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 130 [32/107 (30%)]\tTrain Loss: 0.000317\n",
      "Train Epoch: 130 [36/107 (34%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 130 [40/107 (37%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 130 [44/107 (41%)]\tTrain Loss: 0.000282\n",
      "Train Epoch: 130 [48/107 (45%)]\tTrain Loss: 0.000135\n",
      "Train Epoch: 130 [52/107 (49%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 130 [56/107 (52%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 130 [60/107 (56%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 130 [64/107 (60%)]\tTrain Loss: 0.000137\n",
      "Train Epoch: 130 [68/107 (64%)]\tTrain Loss: 0.000141\n",
      "Train Epoch: 130 [72/107 (67%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 130 [76/107 (71%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 130 [80/107 (75%)]\tTrain Loss: 0.000513\n",
      "Train Epoch: 130 [84/107 (79%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 130 [88/107 (82%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 130 [92/107 (86%)]\tTrain Loss: 0.000229\n",
      "Train Epoch: 130 [96/107 (90%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 130 [100/107 (93%)]\tTrain Loss: 0.003393\n",
      "Train Epoch: 130 [104/107 (97%)]\tTrain Loss: 0.000050\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.43504313e-04 9.36332941e-01 1.44366338e-03 4.30344511e-03\n",
      " 2.27528205e-03 2.23877636e-04 2.47357517e-01 1.82630017e-03\n",
      " 2.39033965e-04 4.99698054e-03 4.29944336e-01 2.11635711e-06\n",
      " 2.24222764e-01 2.19550842e-04 3.35820368e-03 2.77912363e-06\n",
      " 3.54410440e-06 7.95245022e-02 1.41340494e-03 4.33898047e-02\n",
      " 3.55998218e-01 9.36757922e-01 9.99509811e-01 9.99958396e-01\n",
      " 8.20081413e-01 9.99399304e-01 9.99707639e-01 9.27344896e-03\n",
      " 5.48991002e-02 1.00068602e-04 1.17486045e-01 6.43085514e-04\n",
      " 1.50328770e-01 1.78856578e-06 6.68741279e-07 6.94899427e-05\n",
      " 1.57792834e-04 8.86166096e-01 5.45525432e-01 1.09625273e-06\n",
      " 2.77782846e-07 1.86113939e-05 1.77547894e-02 4.50204387e-02\n",
      " 5.23533762e-01 1.56192551e-03 3.20477307e-01 3.05839121e-01\n",
      " 7.90532410e-01 1.41513450e-02 8.69978964e-01 1.07293148e-04\n",
      " 9.79877776e-04 2.22033821e-04 2.34567421e-03 1.74473282e-02\n",
      " 9.73737597e-01 1.35177487e-07 2.08001438e-05 8.98213242e-04\n",
      " 9.99462783e-01 9.99609649e-01 9.99970198e-01 9.99941707e-01\n",
      " 9.99982953e-01 9.98374939e-01 9.79021549e-01 9.99998808e-01\n",
      " 9.99819577e-01 9.97765541e-01 2.23802552e-01 3.40703279e-02\n",
      " 8.56376588e-01 9.92513597e-01 9.96106207e-01 2.11207002e-01\n",
      " 9.99891520e-01 9.98025179e-01 9.99967098e-01 9.94530976e-01\n",
      " 9.99919295e-01 9.98352766e-01 9.99654412e-01 9.96833861e-01\n",
      " 9.29484308e-01 9.99596417e-01 9.97823358e-01 9.92829978e-01\n",
      " 1.28338160e-02 9.97377753e-01 9.99504566e-01 8.35475385e-01\n",
      " 5.27284145e-01 9.99999046e-01 9.99189079e-01 9.99989748e-01\n",
      " 2.63714582e-01 3.36932153e-01 9.99603212e-01 9.99287784e-01\n",
      " 2.49629900e-01 9.65024889e-01 3.79507989e-03 9.49153364e-01\n",
      " 2.03594752e-02 9.28249896e-01 9.66660559e-01 2.01047719e-01\n",
      " 2.29029552e-04 2.90672660e-01 9.72788692e-01 6.02371097e-01\n",
      " 9.99473035e-01 5.26174486e-01 6.19150791e-03 2.43480061e-03\n",
      " 9.99876738e-01 9.99905467e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 44 FN= 11 FP= 16\n",
      "TP+FP 63\n",
      "precision 0.746031746031746\n",
      "recall 0.8103448275862069\n",
      "F1 0.7768595041322314\n",
      "acc 0.7711864406779662\n",
      "AUCp 0.7718390804597701\n",
      "AUC 0.8649425287356322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 130, average recall: 0.8103, average precision: 0.7460,average F1: 0.7769, average accuracy: 0.7712, average AUC: 0.8649\n",
      "Train Epoch: 131 [0/107 (0%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 131 [4/107 (4%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 131 [8/107 (7%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 131 [12/107 (11%)]\tTrain Loss: 0.003930\n",
      "Train Epoch: 131 [16/107 (15%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 131 [20/107 (19%)]\tTrain Loss: 0.010024\n",
      "Train Epoch: 131 [24/107 (22%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 131 [28/107 (26%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 131 [32/107 (30%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 131 [36/107 (34%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 131 [40/107 (37%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 131 [44/107 (41%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 131 [48/107 (45%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 131 [52/107 (49%)]\tTrain Loss: 0.000538\n",
      "Train Epoch: 131 [56/107 (52%)]\tTrain Loss: 0.000284\n",
      "Train Epoch: 131 [60/107 (56%)]\tTrain Loss: 0.000166\n",
      "Train Epoch: 131 [64/107 (60%)]\tTrain Loss: 0.000322\n",
      "Train Epoch: 131 [68/107 (64%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 131 [72/107 (67%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 131 [76/107 (71%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 131 [80/107 (75%)]\tTrain Loss: 0.000098\n",
      "Train Epoch: 131 [84/107 (79%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 131 [88/107 (82%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 131 [92/107 (86%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 131 [96/107 (90%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 131 [100/107 (93%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 131 [104/107 (97%)]\tTrain Loss: 0.000196\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.31339044e-03 8.74933600e-01 1.83446554e-03 1.77373029e-02\n",
      " 4.64433571e-03 5.15939901e-04 2.35310972e-01 5.63996984e-03\n",
      " 5.80557913e-04 1.60066970e-02 7.49964356e-01 1.00171492e-05\n",
      " 3.61199290e-01 7.44020217e-04 4.82983328e-03 9.11679581e-06\n",
      " 2.37015902e-05 1.61760107e-01 5.41220978e-03 1.07191004e-01\n",
      " 5.93491256e-01 9.68996346e-01 9.99900699e-01 9.99972939e-01\n",
      " 8.79066646e-01 9.99722660e-01 9.99730051e-01 1.50968004e-02\n",
      " 3.29439551e-01 2.44670606e-04 2.18370780e-01 3.01269838e-03\n",
      " 2.31284499e-01 5.08926496e-06 5.05573280e-06 1.87035796e-04\n",
      " 2.54676270e-04 9.20690179e-01 5.50128996e-01 4.03312424e-06\n",
      " 1.17189643e-06 5.67842981e-05 4.88024801e-02 1.31502971e-01\n",
      " 7.14416564e-01 6.49468601e-03 5.09762108e-01 3.95807326e-01\n",
      " 8.19189131e-01 3.79005596e-02 8.68715048e-01 3.04055953e-04\n",
      " 4.88236407e-03 1.23823399e-03 2.40992941e-02 4.03089598e-02\n",
      " 9.79068160e-01 4.42863012e-07 5.28707424e-05 4.96895704e-03\n",
      " 9.99545157e-01 9.99659300e-01 9.99980688e-01 9.99968052e-01\n",
      " 9.99987245e-01 9.99073505e-01 9.95339155e-01 9.99999166e-01\n",
      " 9.99939561e-01 9.97892082e-01 3.67430776e-01 1.36558875e-01\n",
      " 9.10390735e-01 9.94407535e-01 9.97759581e-01 7.10633755e-01\n",
      " 9.99926686e-01 9.97332931e-01 9.99988317e-01 9.98087227e-01\n",
      " 9.99975681e-01 9.99094844e-01 9.99860048e-01 9.98598874e-01\n",
      " 9.45116460e-01 9.99377310e-01 9.99130070e-01 9.95769143e-01\n",
      " 1.80123970e-02 9.98586416e-01 9.99618649e-01 8.54399264e-01\n",
      " 7.49895990e-01 9.99999881e-01 9.99911785e-01 9.99997377e-01\n",
      " 5.84503174e-01 6.63971841e-01 9.99791324e-01 9.99662519e-01\n",
      " 4.13111269e-01 9.83377695e-01 2.93355584e-02 9.94559109e-01\n",
      " 1.44709766e-01 9.88026500e-01 9.87362266e-01 1.38884380e-01\n",
      " 7.63811579e-04 5.52508831e-01 9.64937091e-01 5.90066552e-01\n",
      " 9.99646068e-01 7.96127319e-01 2.33954582e-02 1.27925286e-02\n",
      " 9.99919891e-01 9.99876976e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 132 [0/107 (0%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 132 [4/107 (4%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 132 [8/107 (7%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 132 [12/107 (11%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 132 [16/107 (15%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 132 [20/107 (19%)]\tTrain Loss: 0.000397\n",
      "Train Epoch: 132 [24/107 (22%)]\tTrain Loss: 0.000206\n",
      "Train Epoch: 132 [28/107 (26%)]\tTrain Loss: 0.000124\n",
      "Train Epoch: 132 [32/107 (30%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 132 [36/107 (34%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 132 [40/107 (37%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 132 [44/107 (41%)]\tTrain Loss: 0.002503\n",
      "Train Epoch: 132 [48/107 (45%)]\tTrain Loss: 0.003771\n",
      "Train Epoch: 132 [52/107 (49%)]\tTrain Loss: 0.000603\n",
      "Train Epoch: 132 [56/107 (52%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 132 [60/107 (56%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 132 [64/107 (60%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 132 [68/107 (64%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 132 [72/107 (67%)]\tTrain Loss: 0.001383\n",
      "Train Epoch: 132 [76/107 (71%)]\tTrain Loss: 0.000234\n",
      "Train Epoch: 132 [80/107 (75%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 132 [84/107 (79%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 132 [88/107 (82%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 132 [92/107 (86%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 132 [96/107 (90%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 132 [100/107 (93%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 132 [104/107 (97%)]\tTrain Loss: 0.000159\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.49994055e-04 9.82117116e-01 2.42372393e-03 6.43293746e-03\n",
      " 1.72466249e-03 1.88872131e-04 6.49082720e-01 2.00828863e-03\n",
      " 1.63344550e-04 3.15257860e-03 4.41380322e-01 2.04554181e-06\n",
      " 1.29160509e-01 1.24071259e-03 2.19604024e-03 6.67832637e-06\n",
      " 6.10782445e-06 1.97341144e-01 4.37857443e-03 1.35625035e-01\n",
      " 7.00812340e-01 9.84778047e-01 9.99894261e-01 9.99974847e-01\n",
      " 8.04854274e-01 9.99797165e-01 9.99903321e-01 7.39780962e-02\n",
      " 2.16643199e-01 9.73952920e-05 3.55052173e-01 1.72707171e-03\n",
      " 3.79682034e-01 1.86239276e-06 1.79430970e-06 1.51004962e-04\n",
      " 1.32959685e-04 9.29708362e-01 6.50161386e-01 2.66806546e-06\n",
      " 9.74890668e-07 5.60755943e-05 1.09242707e-01 6.22447021e-02\n",
      " 5.84601462e-01 2.11313972e-03 3.05228651e-01 1.76050633e-01\n",
      " 6.86014056e-01 8.56540445e-03 6.98122025e-01 7.87981771e-05\n",
      " 2.51048431e-03 2.41146088e-04 1.73776466e-02 2.35735290e-02\n",
      " 9.65332508e-01 7.24424254e-08 8.56815132e-06 2.49282713e-03\n",
      " 9.99596536e-01 9.99767959e-01 9.99988794e-01 9.99981523e-01\n",
      " 9.99993682e-01 9.99396324e-01 9.95901525e-01 9.99999881e-01\n",
      " 9.99942780e-01 9.97767329e-01 2.66817212e-01 6.17529079e-02\n",
      " 9.17008936e-01 9.97471988e-01 9.99012589e-01 6.31530643e-01\n",
      " 9.99975324e-01 9.99308825e-01 9.99991417e-01 9.98414874e-01\n",
      " 9.99983907e-01 9.99218464e-01 9.99903917e-01 9.98527050e-01\n",
      " 8.83294940e-01 9.99876022e-01 9.98889387e-01 9.97457564e-01\n",
      " 1.24955505e-01 9.99745786e-01 9.99832988e-01 8.44948053e-01\n",
      " 7.06412137e-01 9.99999881e-01 9.99817193e-01 9.99999166e-01\n",
      " 3.49965990e-01 4.21856880e-01 9.99862194e-01 9.99845028e-01\n",
      " 1.18649647e-01 9.74847198e-01 1.23162113e-01 9.78908420e-01\n",
      " 2.34610327e-02 9.59861279e-01 9.81511295e-01 4.62961197e-01\n",
      " 1.98831479e-03 6.86388612e-01 9.85363364e-01 7.33080626e-01\n",
      " 9.99761164e-01 7.89547384e-01 1.09765856e-02 2.16040276e-02\n",
      " 9.99990106e-01 9.99983191e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 133 [0/107 (0%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 133 [4/107 (4%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 133 [8/107 (7%)]\tTrain Loss: 0.001126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133 [12/107 (11%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 133 [16/107 (15%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 133 [20/107 (19%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 133 [24/107 (22%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 133 [28/107 (26%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 133 [32/107 (30%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 133 [36/107 (34%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 133 [40/107 (37%)]\tTrain Loss: 0.000070\n",
      "Train Epoch: 133 [44/107 (41%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 133 [48/107 (45%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 133 [52/107 (49%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 133 [56/107 (52%)]\tTrain Loss: 0.000207\n",
      "Train Epoch: 133 [60/107 (56%)]\tTrain Loss: 0.004360\n",
      "Train Epoch: 133 [64/107 (60%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 133 [68/107 (64%)]\tTrain Loss: 0.000195\n",
      "Train Epoch: 133 [72/107 (67%)]\tTrain Loss: 0.000170\n",
      "Train Epoch: 133 [76/107 (71%)]\tTrain Loss: 0.000202\n",
      "Train Epoch: 133 [80/107 (75%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 133 [84/107 (79%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 133 [88/107 (82%)]\tTrain Loss: 0.000242\n",
      "Train Epoch: 133 [92/107 (86%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 133 [96/107 (90%)]\tTrain Loss: 0.000209\n",
      "Train Epoch: 133 [100/107 (93%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 133 [104/107 (97%)]\tTrain Loss: 0.000239\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.14767265e-03 9.10241365e-01 1.85865839e-03 2.65659224e-02\n",
      " 4.77664685e-03 2.23627576e-04 3.98178220e-01 7.62921525e-03\n",
      " 2.07192803e-04 1.10644437e-02 8.80177557e-01 4.78912580e-06\n",
      " 6.49912715e-01 7.92242470e-04 6.34757522e-03 4.89307831e-06\n",
      " 1.96863821e-05 6.85883984e-02 1.00253066e-02 7.55151585e-02\n",
      " 6.31627142e-01 9.75389600e-01 9.99949574e-01 9.99976039e-01\n",
      " 9.07587588e-01 9.99821961e-01 9.99701321e-01 1.71969626e-02\n",
      " 3.11570317e-01 2.14673957e-04 2.40336537e-01 3.96020059e-03\n",
      " 4.83093590e-01 3.21288394e-06 1.84819760e-06 3.09450435e-04\n",
      " 5.52869053e-04 9.32426333e-01 5.88837802e-01 3.46523962e-06\n",
      " 1.36603830e-06 5.26591393e-05 4.32109945e-02 1.69603840e-01\n",
      " 7.91552842e-01 4.69829235e-03 7.00168312e-01 4.50655341e-01\n",
      " 8.75326455e-01 2.27961894e-02 8.12486887e-01 2.82991939e-04\n",
      " 1.42250722e-03 6.22876571e-04 8.51169787e-03 3.64822969e-02\n",
      " 9.71711457e-01 1.19695869e-07 3.50474074e-05 2.88084685e-03\n",
      " 9.99751389e-01 9.99717653e-01 9.99988198e-01 9.99981403e-01\n",
      " 9.99991417e-01 9.99299169e-01 9.97502387e-01 9.99999523e-01\n",
      " 9.99960303e-01 9.97491002e-01 5.68079650e-01 2.13595361e-01\n",
      " 9.35549796e-01 9.96618867e-01 9.98817086e-01 4.83211309e-01\n",
      " 9.99952555e-01 9.98756886e-01 9.99992251e-01 9.99176323e-01\n",
      " 9.99986053e-01 9.99437153e-01 9.99907136e-01 9.98300254e-01\n",
      " 9.69117582e-01 9.99844193e-01 9.99046624e-01 9.94604290e-01\n",
      " 5.59774749e-02 9.99600708e-01 9.99820054e-01 8.97538960e-01\n",
      " 8.44679892e-01 1.00000000e+00 9.99957919e-01 9.99999285e-01\n",
      " 5.49891710e-01 6.57654703e-01 9.99937773e-01 9.99907732e-01\n",
      " 6.40153646e-01 9.93178964e-01 3.29853259e-02 9.96268630e-01\n",
      " 2.08046868e-01 9.92019832e-01 9.94792044e-01 2.61535913e-01\n",
      " 3.12053802e-04 6.25161469e-01 9.90130901e-01 6.31695509e-01\n",
      " 9.99799430e-01 9.06813085e-01 4.04989608e-02 2.53329165e-02\n",
      " 9.99933124e-01 9.99966025e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 134 [0/107 (0%)]\tTrain Loss: 0.000802\n",
      "Train Epoch: 134 [4/107 (4%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 134 [8/107 (7%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 134 [12/107 (11%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 134 [16/107 (15%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 134 [20/107 (19%)]\tTrain Loss: 0.001377\n",
      "Train Epoch: 134 [24/107 (22%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 134 [28/107 (26%)]\tTrain Loss: 0.000154\n",
      "Train Epoch: 134 [32/107 (30%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 134 [36/107 (34%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 134 [40/107 (37%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 134 [44/107 (41%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 134 [48/107 (45%)]\tTrain Loss: 0.001441\n",
      "Train Epoch: 134 [52/107 (49%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 134 [56/107 (52%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 134 [60/107 (56%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 134 [64/107 (60%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 134 [68/107 (64%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 134 [72/107 (67%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 134 [76/107 (71%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 134 [80/107 (75%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 134 [84/107 (79%)]\tTrain Loss: 0.000249\n",
      "Train Epoch: 134 [88/107 (82%)]\tTrain Loss: 0.003332\n",
      "Train Epoch: 134 [92/107 (86%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 134 [96/107 (90%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 134 [100/107 (93%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 134 [104/107 (97%)]\tTrain Loss: 0.000008\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.44515373e-03 9.59676683e-01 1.90287689e-03 2.59323232e-02\n",
      " 3.53879901e-03 6.27749774e-04 5.01567960e-01 7.56441243e-03\n",
      " 6.00893807e-04 5.22502698e-03 6.83954716e-01 2.87962189e-06\n",
      " 2.52498448e-01 1.14285829e-03 5.58944279e-03 1.88995728e-05\n",
      " 2.53941253e-05 3.98122013e-01 1.33970790e-02 1.54356271e-01\n",
      " 7.22005785e-01 9.92112637e-01 9.99964118e-01 9.99986172e-01\n",
      " 9.50727403e-01 9.99906301e-01 9.99925375e-01 4.90790233e-02\n",
      " 3.51154953e-01 2.44044757e-04 3.30634832e-01 5.66424755e-03\n",
      " 4.86055344e-01 3.17021136e-06 5.28876990e-06 2.40641632e-04\n",
      " 2.68695061e-04 9.51122761e-01 7.52536297e-01 3.32842956e-06\n",
      " 1.53407871e-06 3.84995437e-05 2.55059659e-01 1.89157084e-01\n",
      " 7.67281115e-01 6.69796718e-03 5.53754330e-01 3.64619851e-01\n",
      " 7.02442467e-01 2.19449122e-02 7.67278850e-01 2.84140580e-04\n",
      " 4.59799077e-03 1.62183237e-03 2.26456393e-02 2.88589150e-02\n",
      " 9.86090660e-01 1.94755444e-07 2.93995254e-05 7.94113241e-03\n",
      " 9.99852657e-01 9.99916553e-01 9.99996424e-01 9.99993563e-01\n",
      " 9.99995708e-01 9.99483466e-01 9.96922910e-01 9.99999881e-01\n",
      " 9.99976516e-01 9.98757839e-01 4.18799698e-01 1.82610542e-01\n",
      " 9.50999737e-01 9.98323977e-01 9.99330282e-01 7.93999195e-01\n",
      " 9.99984026e-01 9.99249399e-01 9.99993801e-01 9.99270499e-01\n",
      " 9.99992609e-01 9.99461830e-01 9.99945283e-01 9.99236345e-01\n",
      " 9.48113024e-01 9.99907494e-01 9.99360621e-01 9.98268127e-01\n",
      " 6.38804957e-02 9.99875426e-01 9.99626160e-01 8.97136748e-01\n",
      " 8.64877105e-01 9.99999881e-01 9.99956727e-01 9.99999166e-01\n",
      " 4.57944483e-01 6.61333501e-01 9.99952435e-01 9.99894261e-01\n",
      " 2.87762403e-01 9.89721835e-01 3.97566646e-01 9.92941380e-01\n",
      " 2.11709231e-01 9.87045884e-01 9.95269954e-01 4.63042051e-01\n",
      " 4.17432468e-03 7.87239671e-01 9.80547547e-01 6.33131623e-01\n",
      " 9.99839783e-01 9.12530601e-01 2.99415160e-02 2.41600871e-02\n",
      " 9.99995470e-01 9.99983668e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 135 [0/107 (0%)]\tTrain Loss: 0.000034\n",
      "Train Epoch: 135 [4/107 (4%)]\tTrain Loss: 0.000514\n",
      "Train Epoch: 135 [8/107 (7%)]\tTrain Loss: 0.000348\n",
      "Train Epoch: 135 [12/107 (11%)]\tTrain Loss: 0.000197\n",
      "Train Epoch: 135 [16/107 (15%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 135 [20/107 (19%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 135 [24/107 (22%)]\tTrain Loss: 0.000908\n",
      "Train Epoch: 135 [28/107 (26%)]\tTrain Loss: 0.002197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 135 [32/107 (30%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 135 [36/107 (34%)]\tTrain Loss: 0.000451\n",
      "Train Epoch: 135 [40/107 (37%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 135 [44/107 (41%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 135 [48/107 (45%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 135 [52/107 (49%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 135 [56/107 (52%)]\tTrain Loss: 0.001912\n",
      "Train Epoch: 135 [60/107 (56%)]\tTrain Loss: 0.000097\n",
      "Train Epoch: 135 [64/107 (60%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 135 [68/107 (64%)]\tTrain Loss: 0.000282\n",
      "Train Epoch: 135 [72/107 (67%)]\tTrain Loss: 0.000150\n",
      "Train Epoch: 135 [76/107 (71%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 135 [80/107 (75%)]\tTrain Loss: 0.000433\n",
      "Train Epoch: 135 [84/107 (79%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 135 [88/107 (82%)]\tTrain Loss: 0.001493\n",
      "Train Epoch: 135 [92/107 (86%)]\tTrain Loss: 0.000694\n",
      "Train Epoch: 135 [96/107 (90%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 135 [100/107 (93%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 135 [104/107 (97%)]\tTrain Loss: 0.000047\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.08136935e-03 8.63545179e-01 1.20067154e-03 2.38879472e-02\n",
      " 2.11124099e-03 2.79257249e-04 5.06945327e-02 5.84940193e-03\n",
      " 6.50610717e-04 4.46024863e-03 6.19132221e-01 1.69123700e-06\n",
      " 2.10732102e-01 5.13408391e-04 7.76111381e-03 1.38277292e-05\n",
      " 1.23644986e-05 3.48142713e-01 3.66768427e-03 1.83743834e-01\n",
      " 4.84102100e-01 9.67700779e-01 9.99947429e-01 9.99971151e-01\n",
      " 8.83148193e-01 9.99871492e-01 9.99830127e-01 2.15348527e-02\n",
      " 3.18023115e-01 1.99132948e-04 1.98768154e-01 3.66319646e-03\n",
      " 4.31164324e-01 9.97451934e-07 1.62386777e-06 5.56513405e-05\n",
      " 8.77140046e-05 9.69414353e-01 6.21934414e-01 2.21537357e-06\n",
      " 8.62249465e-07 1.59980755e-05 1.93958998e-01 2.10428983e-01\n",
      " 7.20670283e-01 6.64486736e-03 5.65472484e-01 2.87803084e-01\n",
      " 6.72054112e-01 1.54827302e-02 8.24637532e-01 2.56233441e-04\n",
      " 3.32427397e-03 3.35006043e-03 2.72165146e-02 4.22489457e-02\n",
      " 9.89604831e-01 1.67152109e-07 1.43888192e-05 1.58834625e-02\n",
      " 9.99663591e-01 9.99854565e-01 9.99987364e-01 9.99977350e-01\n",
      " 9.99995470e-01 9.99641180e-01 9.97789741e-01 9.99998927e-01\n",
      " 9.99905825e-01 9.98678148e-01 4.09836918e-01 1.83611259e-01\n",
      " 9.79566753e-01 9.97706771e-01 9.98947918e-01 8.21039557e-01\n",
      " 9.99918699e-01 9.98100102e-01 9.99990344e-01 9.98632252e-01\n",
      " 9.99985099e-01 9.99516487e-01 9.99933481e-01 9.99426007e-01\n",
      " 9.42810118e-01 9.99573529e-01 9.99582231e-01 9.97965336e-01\n",
      " 2.37658955e-02 9.98146176e-01 9.99178588e-01 8.62236381e-01\n",
      " 8.94068718e-01 9.99999523e-01 9.99869943e-01 9.99995112e-01\n",
      " 5.88989615e-01 6.33477390e-01 9.99831080e-01 9.99572814e-01\n",
      " 1.96395725e-01 9.90083694e-01 7.62015134e-02 9.96405482e-01\n",
      " 4.38085735e-01 9.94990766e-01 9.87813711e-01 1.50725991e-01\n",
      " 1.98340626e-03 7.20190406e-01 8.91441584e-01 4.45748866e-01\n",
      " 9.99569952e-01 8.05741906e-01 1.09900078e-02 9.56654456e-03\n",
      " 9.99980092e-01 9.99817193e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 136 [0/107 (0%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 136 [4/107 (4%)]\tTrain Loss: 0.000397\n",
      "Train Epoch: 136 [8/107 (7%)]\tTrain Loss: 0.000251\n",
      "Train Epoch: 136 [12/107 (11%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 136 [16/107 (15%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 136 [20/107 (19%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 136 [24/107 (22%)]\tTrain Loss: 0.000260\n",
      "Train Epoch: 136 [28/107 (26%)]\tTrain Loss: 0.000071\n",
      "Train Epoch: 136 [32/107 (30%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 136 [36/107 (34%)]\tTrain Loss: 0.000149\n",
      "Train Epoch: 136 [40/107 (37%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 136 [44/107 (41%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 136 [48/107 (45%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 136 [52/107 (49%)]\tTrain Loss: 0.000332\n",
      "Train Epoch: 136 [56/107 (52%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 136 [60/107 (56%)]\tTrain Loss: 0.000798\n",
      "Train Epoch: 136 [64/107 (60%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 136 [68/107 (64%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 136 [72/107 (67%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 136 [76/107 (71%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 136 [80/107 (75%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 136 [84/107 (79%)]\tTrain Loss: 0.000057\n",
      "Train Epoch: 136 [88/107 (82%)]\tTrain Loss: 0.000035\n",
      "Train Epoch: 136 [92/107 (86%)]\tTrain Loss: 0.000093\n",
      "Train Epoch: 136 [96/107 (90%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 136 [100/107 (93%)]\tTrain Loss: 0.000369\n",
      "Train Epoch: 136 [104/107 (97%)]\tTrain Loss: 0.000943\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.28384051e-03 9.02307928e-01 2.09324737e-03 2.00233348e-02\n",
      " 5.65870060e-03 5.40638750e-04 2.97612160e-01 6.15534605e-03\n",
      " 3.67306580e-04 1.03715658e-02 7.83618689e-01 6.34810249e-06\n",
      " 4.58744913e-01 6.92904869e-04 6.14390476e-03 1.13982205e-05\n",
      " 1.99134138e-05 5.83854169e-02 4.16461378e-03 5.51045425e-02\n",
      " 5.11290610e-01 9.78050292e-01 9.99839425e-01 9.99965191e-01\n",
      " 9.06877518e-01 9.99586046e-01 9.99593198e-01 1.28358072e-02\n",
      " 1.93811029e-01 2.78686377e-04 1.31104246e-01 3.14802886e-03\n",
      " 2.94801384e-01 5.09618667e-06 2.72823377e-06 2.32151026e-04\n",
      " 4.33991634e-04 9.05078113e-01 6.29527152e-01 3.19766150e-06\n",
      " 1.12948067e-06 6.29113201e-05 7.38917664e-02 1.04088694e-01\n",
      " 7.21428990e-01 3.66238877e-03 4.44895148e-01 3.36514115e-01\n",
      " 7.14685440e-01 1.74228624e-02 7.65701056e-01 3.06133821e-04\n",
      " 2.59914738e-03 4.42056102e-04 4.78787860e-03 3.78930904e-02\n",
      " 9.59089994e-01 1.23333592e-07 4.29097781e-05 3.85434460e-03\n",
      " 9.99522448e-01 9.99666810e-01 9.99977469e-01 9.99967813e-01\n",
      " 9.99987006e-01 9.98933375e-01 9.93155658e-01 9.99999166e-01\n",
      " 9.99893188e-01 9.97319520e-01 3.52216184e-01 9.73370373e-02\n",
      " 8.92985821e-01 9.94842231e-01 9.98143673e-01 6.13276064e-01\n",
      " 9.99905705e-01 9.96828020e-01 9.99983191e-01 9.97306943e-01\n",
      " 9.99953389e-01 9.98877108e-01 9.99857664e-01 9.97995734e-01\n",
      " 9.63481426e-01 9.99354303e-01 9.98907685e-01 9.94009256e-01\n",
      " 2.85757389e-02 9.98877466e-01 9.99275744e-01 8.19341719e-01\n",
      " 8.00873220e-01 9.99999762e-01 9.99816835e-01 9.99996424e-01\n",
      " 5.15170097e-01 4.61166739e-01 9.99768078e-01 9.99594748e-01\n",
      " 5.21895409e-01 9.87380981e-01 5.37278578e-02 9.88549292e-01\n",
      " 8.30257162e-02 9.80373979e-01 9.82956290e-01 2.24281818e-01\n",
      " 9.95029812e-04 3.74609798e-01 9.72092688e-01 5.14967024e-01\n",
      " 9.99512672e-01 8.15251708e-01 3.24133188e-02 2.26164814e-02\n",
      " 9.99883533e-01 9.99921560e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 137 [0/107 (0%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 137 [4/107 (4%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 137 [8/107 (7%)]\tTrain Loss: 0.000138\n",
      "Train Epoch: 137 [12/107 (11%)]\tTrain Loss: 0.000804\n",
      "Train Epoch: 137 [16/107 (15%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 137 [20/107 (19%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 137 [24/107 (22%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 137 [28/107 (26%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 137 [32/107 (30%)]\tTrain Loss: 0.000090\n",
      "Train Epoch: 137 [36/107 (34%)]\tTrain Loss: 0.000115\n",
      "Train Epoch: 137 [40/107 (37%)]\tTrain Loss: 0.000151\n",
      "Train Epoch: 137 [44/107 (41%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 137 [48/107 (45%)]\tTrain Loss: 0.000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 137 [52/107 (49%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 137 [56/107 (52%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 137 [60/107 (56%)]\tTrain Loss: 0.000180\n",
      "Train Epoch: 137 [64/107 (60%)]\tTrain Loss: 0.000047\n",
      "Train Epoch: 137 [68/107 (64%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 137 [72/107 (67%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 137 [76/107 (71%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 137 [80/107 (75%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 137 [84/107 (79%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 137 [88/107 (82%)]\tTrain Loss: 0.000236\n",
      "Train Epoch: 137 [92/107 (86%)]\tTrain Loss: 0.000276\n",
      "Train Epoch: 137 [96/107 (90%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 137 [100/107 (93%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 137 [104/107 (97%)]\tTrain Loss: 0.000017\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.59594846e-04 9.63742912e-01 1.61414512e-03 1.72674488e-02\n",
      " 4.00947500e-03 2.75065511e-04 4.29160058e-01 7.08476268e-03\n",
      " 3.20495164e-04 7.17489608e-03 8.00341249e-01 3.19712467e-06\n",
      " 6.10495746e-01 9.07384616e-04 7.15864217e-03 6.19962566e-06\n",
      " 1.17056306e-05 2.46223047e-01 3.79365706e-03 1.16245195e-01\n",
      " 5.73671520e-01 9.76004541e-01 9.99873638e-01 9.99968171e-01\n",
      " 9.36002612e-01 9.99722660e-01 9.99781191e-01 1.95198860e-02\n",
      " 1.90867588e-01 1.95322311e-04 1.29357964e-01 2.12102989e-03\n",
      " 3.70274782e-01 2.42643296e-06 2.13488715e-06 1.82504940e-04\n",
      " 3.34797660e-04 9.62949097e-01 7.55689561e-01 2.11930183e-06\n",
      " 7.14046450e-07 3.52573879e-05 5.40946871e-02 1.51154831e-01\n",
      " 7.67345428e-01 3.26539460e-03 6.12699687e-01 4.06488270e-01\n",
      " 8.48312199e-01 2.66425349e-02 8.62303317e-01 2.54622370e-04\n",
      " 9.31286660e-04 8.33858678e-04 4.03760606e-03 3.51124145e-02\n",
      " 9.80699897e-01 2.04980140e-07 3.73082148e-05 2.32141162e-03\n",
      " 9.99782741e-01 9.99842286e-01 9.99989033e-01 9.99979854e-01\n",
      " 9.99988914e-01 9.99215484e-01 9.93524313e-01 9.99999046e-01\n",
      " 9.99926925e-01 9.98721898e-01 4.31923121e-01 1.02944687e-01\n",
      " 9.41907108e-01 9.97078419e-01 9.99010205e-01 4.89215523e-01\n",
      " 9.99935031e-01 9.98366654e-01 9.99984980e-01 9.98150110e-01\n",
      " 9.99957085e-01 9.99228477e-01 9.99804556e-01 9.98859763e-01\n",
      " 9.68427598e-01 9.99755085e-01 9.99243379e-01 9.96351480e-01\n",
      " 5.56834973e-02 9.99487877e-01 9.99689817e-01 9.04235780e-01\n",
      " 8.05853605e-01 9.99999762e-01 9.99922752e-01 9.99996543e-01\n",
      " 5.33194065e-01 6.95165277e-01 9.99875665e-01 9.99701083e-01\n",
      " 4.76981580e-01 9.91504133e-01 5.44750020e-02 9.94527042e-01\n",
      " 1.06853336e-01 9.87813950e-01 9.89872038e-01 3.61700147e-01\n",
      " 1.17996580e-03 5.84707022e-01 9.94448066e-01 7.70999312e-01\n",
      " 9.99674559e-01 8.82246494e-01 1.45035386e-02 1.52818840e-02\n",
      " 9.99977350e-01 9.99975085e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 138 [0/107 (0%)]\tTrain Loss: 0.000159\n",
      "Train Epoch: 138 [4/107 (4%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 138 [8/107 (7%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 138 [12/107 (11%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 138 [16/107 (15%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 138 [20/107 (19%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 138 [24/107 (22%)]\tTrain Loss: 0.001339\n",
      "Train Epoch: 138 [28/107 (26%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 138 [32/107 (30%)]\tTrain Loss: 0.001150\n",
      "Train Epoch: 138 [36/107 (34%)]\tTrain Loss: 0.000121\n",
      "Train Epoch: 138 [40/107 (37%)]\tTrain Loss: 0.000072\n",
      "Train Epoch: 138 [44/107 (41%)]\tTrain Loss: 0.000294\n",
      "Train Epoch: 138 [48/107 (45%)]\tTrain Loss: 0.000221\n",
      "Train Epoch: 138 [52/107 (49%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 138 [56/107 (52%)]\tTrain Loss: 0.000055\n",
      "Train Epoch: 138 [60/107 (56%)]\tTrain Loss: 0.000197\n",
      "Train Epoch: 138 [64/107 (60%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 138 [68/107 (64%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 138 [72/107 (67%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 138 [76/107 (71%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 138 [80/107 (75%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 138 [84/107 (79%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 138 [88/107 (82%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 138 [92/107 (86%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 138 [96/107 (90%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 138 [100/107 (93%)]\tTrain Loss: 0.000051\n",
      "Train Epoch: 138 [104/107 (97%)]\tTrain Loss: 0.000005\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.52174543e-04 9.69592512e-01 1.17311825e-03 2.05916595e-02\n",
      " 3.08343093e-03 1.25564256e-04 5.03619611e-01 3.68233491e-03\n",
      " 2.28853067e-04 8.90211854e-03 6.83986187e-01 6.44829743e-06\n",
      " 4.70710129e-01 1.06110447e-03 4.57799388e-03 8.48086529e-06\n",
      " 1.88960166e-05 1.78968832e-01 2.44908710e-03 6.88166618e-02\n",
      " 7.71615803e-01 9.71059263e-01 9.99949574e-01 9.99961734e-01\n",
      " 9.42933500e-01 9.99882460e-01 9.99773920e-01 1.30061377e-02\n",
      " 2.32157677e-01 9.64320934e-05 2.55689591e-01 2.77925096e-03\n",
      " 3.30235481e-01 1.54156680e-06 2.75747220e-06 1.59198506e-04\n",
      " 2.49716279e-04 9.22481537e-01 5.04303694e-01 5.12003362e-06\n",
      " 1.88713204e-06 6.40709040e-05 6.64205030e-02 1.03183508e-01\n",
      " 7.30497658e-01 5.59446216e-03 5.20057678e-01 3.86042088e-01\n",
      " 7.45071411e-01 3.52173373e-02 7.93100834e-01 1.27383290e-04\n",
      " 2.60779168e-03 6.40610349e-04 5.33608608e-02 2.57799122e-02\n",
      " 9.74978864e-01 2.83221027e-07 3.26030422e-05 5.09592472e-03\n",
      " 9.99463379e-01 9.99635816e-01 9.99974728e-01 9.99947667e-01\n",
      " 9.99993205e-01 9.99026179e-01 9.95329499e-01 9.99999404e-01\n",
      " 9.99944448e-01 9.96984422e-01 3.76331896e-01 1.22094877e-01\n",
      " 8.81253421e-01 9.95548010e-01 9.98325646e-01 6.53957188e-01\n",
      " 9.99923110e-01 9.98152792e-01 9.99991655e-01 9.98191178e-01\n",
      " 9.99985456e-01 9.99499917e-01 9.99755919e-01 9.97569740e-01\n",
      " 8.92082751e-01 9.99432623e-01 9.99376595e-01 9.96875763e-01\n",
      " 5.57014383e-02 9.99651194e-01 9.99777377e-01 8.81980658e-01\n",
      " 8.11421394e-01 9.99999881e-01 9.99927640e-01 9.99998331e-01\n",
      " 5.30610025e-01 4.26961064e-01 9.99826849e-01 9.99732435e-01\n",
      " 4.23589349e-01 9.74632800e-01 9.24291760e-02 9.97229874e-01\n",
      " 2.43011892e-01 9.84263957e-01 9.86700058e-01 3.42695653e-01\n",
      " 9.29714413e-04 6.50817573e-01 9.92053747e-01 7.94212282e-01\n",
      " 9.99649405e-01 8.98334801e-01 2.16892809e-02 2.41316352e-02\n",
      " 9.99927402e-01 9.99902010e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 139 [0/107 (0%)]\tTrain Loss: 0.002104\n",
      "Train Epoch: 139 [4/107 (4%)]\tTrain Loss: 0.000192\n",
      "Train Epoch: 139 [8/107 (7%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 139 [12/107 (11%)]\tTrain Loss: 0.000908\n",
      "Train Epoch: 139 [16/107 (15%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 139 [20/107 (19%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 139 [24/107 (22%)]\tTrain Loss: 0.000210\n",
      "Train Epoch: 139 [28/107 (26%)]\tTrain Loss: 0.001778\n",
      "Train Epoch: 139 [32/107 (30%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 139 [36/107 (34%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 139 [40/107 (37%)]\tTrain Loss: 0.001363\n",
      "Train Epoch: 139 [44/107 (41%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 139 [48/107 (45%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 139 [52/107 (49%)]\tTrain Loss: 0.000196\n",
      "Train Epoch: 139 [56/107 (52%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 139 [60/107 (56%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 139 [64/107 (60%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 139 [68/107 (64%)]\tTrain Loss: 0.000283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139 [72/107 (67%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 139 [76/107 (71%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 139 [80/107 (75%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 139 [84/107 (79%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 139 [88/107 (82%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 139 [92/107 (86%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 139 [96/107 (90%)]\tTrain Loss: 0.001120\n",
      "Train Epoch: 139 [100/107 (93%)]\tTrain Loss: 0.000613\n",
      "Train Epoch: 139 [104/107 (97%)]\tTrain Loss: 0.000012\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.58415840e-03 9.74468291e-01 2.18085176e-03 4.29799296e-02\n",
      " 4.68493579e-03 5.30112535e-04 5.25173128e-01 1.36785470e-02\n",
      " 5.66312228e-04 1.29659353e-02 6.47242069e-01 7.01753697e-06\n",
      " 3.76064420e-01 2.52487371e-03 8.20116978e-03 2.46911877e-05\n",
      " 4.38877214e-05 4.00090128e-01 1.08524412e-02 1.04683012e-01\n",
      " 6.91689909e-01 9.83942509e-01 9.99931693e-01 9.99966264e-01\n",
      " 9.45520341e-01 9.99888897e-01 9.99933004e-01 4.94270734e-02\n",
      " 3.07462811e-01 2.77715328e-04 4.74082828e-01 6.44474057e-03\n",
      " 4.37889636e-01 3.79741505e-06 7.25827704e-06 4.01513651e-04\n",
      " 5.74187958e-04 9.63048279e-01 8.05510461e-01 8.62854267e-06\n",
      " 3.34932724e-06 7.70680708e-05 3.45912367e-01 1.41988412e-01\n",
      " 8.09526145e-01 8.35756771e-03 6.18050158e-01 5.04299581e-01\n",
      " 8.19000065e-01 2.31476706e-02 8.81130576e-01 4.04323684e-04\n",
      " 4.39138571e-03 1.10793777e-03 3.86666991e-02 4.41234298e-02\n",
      " 9.88693058e-01 5.49548929e-07 5.86201277e-05 8.57763924e-03\n",
      " 9.99852896e-01 9.99842286e-01 9.99995828e-01 9.99989867e-01\n",
      " 9.99994874e-01 9.99679804e-01 9.98589218e-01 9.99999881e-01\n",
      " 9.99966264e-01 9.98318672e-01 6.11812890e-01 1.78681567e-01\n",
      " 9.45420861e-01 9.96488094e-01 9.99246716e-01 8.50032806e-01\n",
      " 9.99982357e-01 9.99497414e-01 9.99994636e-01 9.99441206e-01\n",
      " 9.99995589e-01 9.99724209e-01 9.99949336e-01 9.98954177e-01\n",
      " 9.59256053e-01 9.99784052e-01 9.99247313e-01 9.98274922e-01\n",
      " 8.00730065e-02 9.99870420e-01 9.99915123e-01 9.19679284e-01\n",
      " 8.40375006e-01 9.99999881e-01 9.99942899e-01 9.99999523e-01\n",
      " 5.17696917e-01 5.31803250e-01 9.99959707e-01 9.99908328e-01\n",
      " 3.71022671e-01 9.83895898e-01 1.36320040e-01 9.94995356e-01\n",
      " 1.37382805e-01 9.80375588e-01 9.91646349e-01 4.48975921e-01\n",
      " 2.00651563e-03 7.25986600e-01 9.89310026e-01 8.14779818e-01\n",
      " 9.99883652e-01 9.24462497e-01 6.27803430e-02 5.34076467e-02\n",
      " 9.99989986e-01 9.99976516e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 140 [0/107 (0%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 140 [4/107 (4%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 140 [8/107 (7%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 140 [12/107 (11%)]\tTrain Loss: 0.000382\n",
      "Train Epoch: 140 [16/107 (15%)]\tTrain Loss: 0.000341\n",
      "Train Epoch: 140 [20/107 (19%)]\tTrain Loss: 0.000532\n",
      "Train Epoch: 140 [24/107 (22%)]\tTrain Loss: 0.000178\n",
      "Train Epoch: 140 [28/107 (26%)]\tTrain Loss: 0.000131\n",
      "Train Epoch: 140 [32/107 (30%)]\tTrain Loss: 0.000304\n",
      "Train Epoch: 140 [36/107 (34%)]\tTrain Loss: 0.000649\n",
      "Train Epoch: 140 [40/107 (37%)]\tTrain Loss: 0.003167\n",
      "Train Epoch: 140 [44/107 (41%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 140 [48/107 (45%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 140 [52/107 (49%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 140 [56/107 (52%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 140 [60/107 (56%)]\tTrain Loss: 0.000433\n",
      "Train Epoch: 140 [64/107 (60%)]\tTrain Loss: 0.000253\n",
      "Train Epoch: 140 [68/107 (64%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 140 [72/107 (67%)]\tTrain Loss: 0.000215\n",
      "Train Epoch: 140 [76/107 (71%)]\tTrain Loss: 0.000130\n",
      "Train Epoch: 140 [80/107 (75%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 140 [84/107 (79%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 140 [88/107 (82%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 140 [92/107 (86%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 140 [96/107 (90%)]\tTrain Loss: 0.000106\n",
      "Train Epoch: 140 [100/107 (93%)]\tTrain Loss: 0.000336\n",
      "Train Epoch: 140 [104/107 (97%)]\tTrain Loss: 0.000021\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.46487767e-03 9.84446704e-01 3.05141718e-03 1.59731358e-02\n",
      " 3.15346359e-03 1.34307274e-03 7.78590143e-01 6.72702119e-03\n",
      " 8.05176562e-04 1.70082487e-02 8.50875080e-01 1.29509090e-05\n",
      " 4.94066179e-01 4.85730171e-03 5.06316638e-03 5.91490571e-05\n",
      " 7.88084944e-05 4.32012290e-01 2.75970194e-02 2.72496730e-01\n",
      " 9.36317384e-01 9.94804919e-01 9.99978662e-01 9.99993563e-01\n",
      " 9.80355024e-01 9.99973297e-01 9.99982953e-01 1.28459290e-01\n",
      " 5.17388940e-01 4.15969815e-04 6.01377606e-01 6.60300860e-03\n",
      " 4.96347755e-01 1.37542866e-05 2.54914194e-05 1.16676046e-03\n",
      " 5.94303536e-04 9.65147555e-01 7.17143834e-01 4.38300594e-05\n",
      " 1.40646443e-05 8.73963931e-04 3.00185025e-01 2.20500916e-01\n",
      " 8.96612227e-01 2.36536432e-02 6.77404046e-01 4.59297389e-01\n",
      " 8.96435440e-01 5.59827536e-02 8.98064733e-01 5.41297020e-04\n",
      " 1.01749096e-02 2.41330173e-03 6.05499819e-02 6.41224682e-02\n",
      " 9.87224579e-01 1.06208074e-06 5.82264656e-05 6.03080774e-03\n",
      " 9.99930620e-01 9.99921918e-01 9.99998927e-01 9.99995947e-01\n",
      " 9.99998331e-01 9.99879479e-01 9.98686016e-01 1.00000000e+00\n",
      " 9.99990344e-01 9.99024153e-01 5.40918827e-01 3.08434367e-01\n",
      " 9.59631383e-01 9.99181807e-01 9.99785602e-01 8.61602545e-01\n",
      " 9.99995470e-01 9.99784768e-01 9.99998808e-01 9.99747932e-01\n",
      " 9.99998212e-01 9.99858499e-01 9.99979615e-01 9.99590695e-01\n",
      " 9.62300897e-01 9.99917507e-01 9.99654055e-01 9.99268591e-01\n",
      " 2.19469234e-01 9.99991179e-01 9.99961972e-01 9.65121925e-01\n",
      " 8.64349186e-01 1.00000000e+00 9.99975085e-01 9.99999881e-01\n",
      " 5.60328305e-01 8.34533095e-01 9.99981999e-01 9.99992132e-01\n",
      " 3.52730006e-01 9.93280709e-01 3.00231129e-01 9.95219171e-01\n",
      " 1.04782820e-01 9.78844941e-01 9.94523764e-01 6.25376880e-01\n",
      " 2.92840507e-03 8.52840543e-01 9.95275378e-01 8.52619946e-01\n",
      " 9.99934077e-01 9.78648484e-01 5.00966348e-02 5.82850017e-02\n",
      " 9.99998450e-01 9.99997854e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 48 TN= 44 FN= 10 FP= 16\n",
      "TP+FP 64\n",
      "precision 0.75\n",
      "recall 0.8275862068965517\n",
      "F1 0.7868852459016394\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7804597701149425\n",
      "AUC 0.8658045977011495\n",
      "\n",
      " The epoch is 140, average recall: 0.8276, average precision: 0.7500,average F1: 0.7869, average accuracy: 0.7797, average AUC: 0.8658\n",
      "Train Epoch: 141 [0/107 (0%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 141 [4/107 (4%)]\tTrain Loss: 0.000242\n",
      "Train Epoch: 141 [8/107 (7%)]\tTrain Loss: 0.000036\n",
      "Train Epoch: 141 [12/107 (11%)]\tTrain Loss: 0.000401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 141 [16/107 (15%)]\tTrain Loss: 0.000168\n",
      "Train Epoch: 141 [20/107 (19%)]\tTrain Loss: 0.003644\n",
      "Train Epoch: 141 [24/107 (22%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 141 [28/107 (26%)]\tTrain Loss: 0.000037\n",
      "Train Epoch: 141 [32/107 (30%)]\tTrain Loss: 0.000088\n",
      "Train Epoch: 141 [36/107 (34%)]\tTrain Loss: 0.000267\n",
      "Train Epoch: 141 [40/107 (37%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 141 [44/107 (41%)]\tTrain Loss: 0.000125\n",
      "Train Epoch: 141 [48/107 (45%)]\tTrain Loss: 0.000422\n",
      "Train Epoch: 141 [52/107 (49%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 141 [56/107 (52%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 141 [60/107 (56%)]\tTrain Loss: 0.000670\n",
      "Train Epoch: 141 [64/107 (60%)]\tTrain Loss: 0.000139\n",
      "Train Epoch: 141 [68/107 (64%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 141 [72/107 (67%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 141 [76/107 (71%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 141 [80/107 (75%)]\tTrain Loss: 0.000301\n",
      "Train Epoch: 141 [84/107 (79%)]\tTrain Loss: 0.001414\n",
      "Train Epoch: 141 [88/107 (82%)]\tTrain Loss: 0.000103\n",
      "Train Epoch: 141 [92/107 (86%)]\tTrain Loss: 0.000016\n",
      "Train Epoch: 141 [96/107 (90%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 141 [100/107 (93%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 141 [104/107 (97%)]\tTrain Loss: 0.000437\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.42873474e-03 9.75323498e-01 2.22445186e-03 4.03462090e-02\n",
      " 6.92915358e-03 3.81686259e-04 5.47823370e-01 2.26236898e-02\n",
      " 4.56130190e-04 1.61145441e-02 8.22700143e-01 5.12763154e-06\n",
      " 4.92189527e-01 2.43165134e-03 1.23469401e-02 3.53377363e-05\n",
      " 6.98588483e-05 3.40771317e-01 1.02024255e-02 9.96304899e-02\n",
      " 8.27022851e-01 9.82265353e-01 9.99935508e-01 9.99981403e-01\n",
      " 9.42604423e-01 9.99908805e-01 9.99940038e-01 6.00501113e-02\n",
      " 5.32781005e-01 3.62681923e-04 5.10801852e-01 8.98182206e-03\n",
      " 4.22088921e-01 8.82837139e-06 1.90911833e-05 4.97454836e-04\n",
      " 8.95082194e-04 9.67943311e-01 7.09718049e-01 8.81696815e-06\n",
      " 3.65193978e-06 1.45511818e-04 2.17143983e-01 2.47019306e-01\n",
      " 8.26699793e-01 1.66108254e-02 7.21654832e-01 5.16712666e-01\n",
      " 8.41427267e-01 5.28744794e-02 8.80846918e-01 5.82524226e-04\n",
      " 1.27241835e-02 6.51578559e-03 5.51529378e-02 5.80225214e-02\n",
      " 9.84527469e-01 1.52993641e-06 5.40703040e-05 2.79096328e-02\n",
      " 9.99852180e-01 9.99886870e-01 9.99996781e-01 9.99992013e-01\n",
      " 9.99993801e-01 9.99655724e-01 9.97637987e-01 9.99999881e-01\n",
      " 9.99966383e-01 9.97856557e-01 6.90348744e-01 3.62039030e-01\n",
      " 9.64355886e-01 9.97113705e-01 9.99370039e-01 8.98666024e-01\n",
      " 9.99982715e-01 9.99437034e-01 9.99994516e-01 9.99079466e-01\n",
      " 9.99991775e-01 9.99725044e-01 9.99943852e-01 9.99302745e-01\n",
      " 9.78043318e-01 9.99800503e-01 9.99458611e-01 9.97423530e-01\n",
      " 1.49584591e-01 9.99859095e-01 9.99904037e-01 9.18717444e-01\n",
      " 8.55864227e-01 1.00000000e+00 9.99977827e-01 9.99999523e-01\n",
      " 7.10083604e-01 8.03380907e-01 9.99941468e-01 9.99936461e-01\n",
      " 6.78854704e-01 9.93960500e-01 7.44963959e-02 9.96347964e-01\n",
      " 4.40069646e-01 9.93503749e-01 9.94314849e-01 4.25341725e-01\n",
      " 1.25125586e-03 7.60514617e-01 9.92694736e-01 5.80603540e-01\n",
      " 9.99894738e-01 9.38884616e-01 3.29215713e-02 2.45178398e-02\n",
      " 9.99991775e-01 9.99990106e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 142 [0/107 (0%)]\tTrain Loss: 0.000049\n",
      "Train Epoch: 142 [4/107 (4%)]\tTrain Loss: 0.000067\n",
      "Train Epoch: 142 [8/107 (7%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 142 [12/107 (11%)]\tTrain Loss: 0.000624\n",
      "Train Epoch: 142 [16/107 (15%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 142 [20/107 (19%)]\tTrain Loss: 0.000165\n",
      "Train Epoch: 142 [24/107 (22%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 142 [28/107 (26%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 142 [32/107 (30%)]\tTrain Loss: 0.000221\n",
      "Train Epoch: 142 [36/107 (34%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 142 [40/107 (37%)]\tTrain Loss: 0.000276\n",
      "Train Epoch: 142 [44/107 (41%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 142 [48/107 (45%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 142 [52/107 (49%)]\tTrain Loss: 0.000894\n",
      "Train Epoch: 142 [56/107 (52%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 142 [60/107 (56%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 142 [64/107 (60%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 142 [68/107 (64%)]\tTrain Loss: 0.000802\n",
      "Train Epoch: 142 [72/107 (67%)]\tTrain Loss: 0.000004\n",
      "Train Epoch: 142 [76/107 (71%)]\tTrain Loss: 0.004768\n",
      "Train Epoch: 142 [80/107 (75%)]\tTrain Loss: 0.000257\n",
      "Train Epoch: 142 [84/107 (79%)]\tTrain Loss: 0.000177\n",
      "Train Epoch: 142 [88/107 (82%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 142 [92/107 (86%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 142 [96/107 (90%)]\tTrain Loss: 0.000066\n",
      "Train Epoch: 142 [100/107 (93%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 142 [104/107 (97%)]\tTrain Loss: 0.001245\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.69418403e-03 9.91045117e-01 5.07281069e-03 2.87539251e-02\n",
      " 6.73317024e-03 5.31172147e-04 6.30201459e-01 1.21625960e-02\n",
      " 9.50999325e-04 2.73275487e-02 7.58895755e-01 7.73531883e-06\n",
      " 3.42819661e-01 2.36102543e-03 8.96189082e-03 3.18463426e-05\n",
      " 4.84096745e-05 3.26882660e-01 1.31353382e-02 1.35098338e-01\n",
      " 7.52958059e-01 9.88378465e-01 9.99944448e-01 9.99992967e-01\n",
      " 9.23981190e-01 9.99946475e-01 9.99988198e-01 5.87720945e-02\n",
      " 3.43472511e-01 5.23118768e-04 4.71871525e-01 6.68897573e-03\n",
      " 4.17141199e-01 1.01943988e-05 1.33938238e-05 4.27370338e-04\n",
      " 5.55422157e-04 9.35585558e-01 5.88483393e-01 1.67137496e-05\n",
      " 4.46897320e-06 2.47749500e-04 1.25940174e-01 2.19390705e-01\n",
      " 8.03224206e-01 8.37780908e-03 6.62996292e-01 4.77928579e-01\n",
      " 8.76733065e-01 5.35826758e-02 8.98906708e-01 7.45690020e-04\n",
      " 1.34603949e-02 4.23734775e-03 9.68977809e-02 4.01176810e-02\n",
      " 9.90761817e-01 2.21288565e-06 7.47601443e-05 1.36801191e-02\n",
      " 9.99961734e-01 9.99963880e-01 9.99999046e-01 9.99996543e-01\n",
      " 9.99994755e-01 9.99651194e-01 9.95951653e-01 1.00000000e+00\n",
      " 9.99983907e-01 9.98967290e-01 6.79002583e-01 4.41225290e-01\n",
      " 9.58241403e-01 9.97032404e-01 9.99350250e-01 8.69491935e-01\n",
      " 9.99992013e-01 9.99786675e-01 9.99997854e-01 9.99100327e-01\n",
      " 9.99991775e-01 9.99795020e-01 9.99961019e-01 9.99621987e-01\n",
      " 9.73713279e-01 9.99948859e-01 9.99458730e-01 9.98164833e-01\n",
      " 9.15578008e-02 9.99972343e-01 9.99951959e-01 9.38521564e-01\n",
      " 8.53310049e-01 1.00000000e+00 9.99979973e-01 9.99999642e-01\n",
      " 5.58086395e-01 7.14930356e-01 9.99975801e-01 9.99970436e-01\n",
      " 6.67513371e-01 9.92819488e-01 6.36570603e-02 9.95166540e-01\n",
      " 6.56759322e-01 9.91840482e-01 9.96577680e-01 5.06551087e-01\n",
      " 2.90474249e-03 8.76258910e-01 9.91374075e-01 6.32655621e-01\n",
      " 9.99966979e-01 9.40007806e-01 3.86542045e-02 8.93507898e-03\n",
      " 9.99998450e-01 9.99992847e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 143 [0/107 (0%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 143 [4/107 (4%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 143 [8/107 (7%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 143 [12/107 (11%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 143 [16/107 (15%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 143 [20/107 (19%)]\tTrain Loss: 0.000608\n",
      "Train Epoch: 143 [24/107 (22%)]\tTrain Loss: 0.002151\n",
      "Train Epoch: 143 [28/107 (26%)]\tTrain Loss: 0.000005\n",
      "Train Epoch: 143 [32/107 (30%)]\tTrain Loss: 0.000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 143 [36/107 (34%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 143 [40/107 (37%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 143 [44/107 (41%)]\tTrain Loss: 0.000412\n",
      "Train Epoch: 143 [48/107 (45%)]\tTrain Loss: 0.000086\n",
      "Train Epoch: 143 [52/107 (49%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 143 [56/107 (52%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 143 [60/107 (56%)]\tTrain Loss: 0.000683\n",
      "Train Epoch: 143 [64/107 (60%)]\tTrain Loss: 0.000478\n",
      "Train Epoch: 143 [68/107 (64%)]\tTrain Loss: 0.000379\n",
      "Train Epoch: 143 [72/107 (67%)]\tTrain Loss: 0.000220\n",
      "Train Epoch: 143 [76/107 (71%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 143 [80/107 (75%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 143 [84/107 (79%)]\tTrain Loss: 0.000651\n",
      "Train Epoch: 143 [88/107 (82%)]\tTrain Loss: 0.000069\n",
      "Train Epoch: 143 [92/107 (86%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 143 [96/107 (90%)]\tTrain Loss: 0.000361\n",
      "Train Epoch: 143 [100/107 (93%)]\tTrain Loss: 0.000073\n",
      "Train Epoch: 143 [104/107 (97%)]\tTrain Loss: 0.000561\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.43986207e-03 9.70276952e-01 2.70508765e-03 3.61278392e-02\n",
      " 6.78059319e-03 6.76356372e-04 2.63030857e-01 1.16315577e-02\n",
      " 7.79671187e-04 2.04336457e-02 7.08006501e-01 1.15194616e-05\n",
      " 3.69429350e-01 1.50226150e-03 7.82080926e-03 3.99548335e-05\n",
      " 6.62632956e-05 4.55604434e-01 6.36386452e-03 1.27136827e-01\n",
      " 6.57269299e-01 9.91632938e-01 9.99955297e-01 9.99988317e-01\n",
      " 9.59410191e-01 9.99953032e-01 9.99974847e-01 3.09842173e-02\n",
      " 3.46525639e-01 2.09049482e-04 3.37795615e-01 6.27449062e-03\n",
      " 3.67884368e-01 4.60105912e-06 1.50421793e-05 3.55644588e-04\n",
      " 3.95174226e-04 9.74882901e-01 8.41575384e-01 1.00853131e-05\n",
      " 2.74961553e-06 1.03767139e-04 3.55791956e-01 2.02691898e-01\n",
      " 7.32365906e-01 1.46449879e-02 6.78415537e-01 4.24928963e-01\n",
      " 8.41719270e-01 3.54415365e-02 8.82804513e-01 8.34391161e-04\n",
      " 5.44477766e-03 5.03700320e-03 5.95164858e-02 3.98254693e-02\n",
      " 9.89935577e-01 1.01751095e-06 6.61956874e-05 1.12997741e-02\n",
      " 9.99922514e-01 9.99963880e-01 9.99998569e-01 9.99993205e-01\n",
      " 9.99996305e-01 9.99759972e-01 9.98732388e-01 1.00000000e+00\n",
      " 9.99977112e-01 9.98602211e-01 5.26620328e-01 3.06953937e-01\n",
      " 9.79602993e-01 9.98214483e-01 9.99477684e-01 9.17671025e-01\n",
      " 9.99991059e-01 9.99768555e-01 9.99996543e-01 9.99365866e-01\n",
      " 9.99994278e-01 9.99801099e-01 9.99946356e-01 9.99801219e-01\n",
      " 9.75635290e-01 9.99899387e-01 9.99591291e-01 9.98673320e-01\n",
      " 6.13694265e-02 9.99962807e-01 9.99937177e-01 9.43331480e-01\n",
      " 8.94184530e-01 1.00000000e+00 9.99969244e-01 9.99999642e-01\n",
      " 5.89779496e-01 7.75652707e-01 9.99953032e-01 9.99917030e-01\n",
      " 4.07486439e-01 9.94956315e-01 1.00817770e-01 9.97180581e-01\n",
      " 3.46363753e-01 9.90214169e-01 9.93820369e-01 3.38637501e-01\n",
      " 8.87890998e-03 8.26446235e-01 9.86329973e-01 8.20610046e-01\n",
      " 9.99924421e-01 9.30758893e-01 2.59808917e-02 2.21686643e-02\n",
      " 9.99999166e-01 9.99989510e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 144 [0/107 (0%)]\tTrain Loss: 0.000353\n",
      "Train Epoch: 144 [4/107 (4%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 144 [8/107 (7%)]\tTrain Loss: 0.000110\n",
      "Train Epoch: 144 [12/107 (11%)]\tTrain Loss: 0.000041\n",
      "Train Epoch: 144 [16/107 (15%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 144 [20/107 (19%)]\tTrain Loss: 0.000099\n",
      "Train Epoch: 144 [24/107 (22%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 144 [28/107 (26%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 144 [32/107 (30%)]\tTrain Loss: 0.000855\n",
      "Train Epoch: 144 [36/107 (34%)]\tTrain Loss: 0.000131\n",
      "Train Epoch: 144 [40/107 (37%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 144 [44/107 (41%)]\tTrain Loss: 0.003503\n",
      "Train Epoch: 144 [48/107 (45%)]\tTrain Loss: 0.002413\n",
      "Train Epoch: 144 [52/107 (49%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 144 [56/107 (52%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 144 [60/107 (56%)]\tTrain Loss: 0.000394\n",
      "Train Epoch: 144 [64/107 (60%)]\tTrain Loss: 0.000119\n",
      "Train Epoch: 144 [68/107 (64%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 144 [72/107 (67%)]\tTrain Loss: 0.000061\n",
      "Train Epoch: 144 [76/107 (71%)]\tTrain Loss: 0.000079\n",
      "Train Epoch: 144 [80/107 (75%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 144 [84/107 (79%)]\tTrain Loss: 0.000572\n",
      "Train Epoch: 144 [88/107 (82%)]\tTrain Loss: 0.005336\n",
      "Train Epoch: 144 [92/107 (86%)]\tTrain Loss: 0.000157\n",
      "Train Epoch: 144 [96/107 (90%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 144 [100/107 (93%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 144 [104/107 (97%)]\tTrain Loss: 0.000064\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.08128064e-03 9.07640159e-01 1.46966265e-03 1.93406809e-02\n",
      " 4.10135416e-03 4.64388810e-04 4.26882952e-01 7.69902114e-03\n",
      " 3.94022878e-04 1.46369934e-02 7.98732638e-01 1.38995947e-05\n",
      " 4.02262002e-01 1.38050760e-03 4.46569547e-03 9.86392934e-06\n",
      " 3.84977320e-05 3.97634834e-01 1.00578079e-02 1.38447836e-01\n",
      " 7.14081883e-01 9.75268722e-01 9.99880433e-01 9.99970555e-01\n",
      " 9.61330771e-01 9.99801457e-01 9.99876618e-01 2.55247504e-02\n",
      " 4.55756009e-01 3.71127069e-04 3.39490980e-01 2.68754200e-03\n",
      " 2.84685552e-01 1.06150837e-05 9.04856643e-06 3.96535965e-04\n",
      " 6.28011883e-04 9.53395307e-01 7.68958986e-01 9.82239999e-06\n",
      " 3.40041697e-06 1.42777135e-04 9.93356630e-02 1.06122531e-01\n",
      " 6.24659240e-01 7.01726088e-03 5.99441111e-01 3.51860553e-01\n",
      " 7.88037598e-01 3.32443304e-02 7.79103696e-01 3.79578181e-04\n",
      " 3.49848974e-03 1.86293200e-03 5.29888645e-02 5.22376448e-02\n",
      " 9.69993114e-01 6.33068169e-07 5.19269815e-05 4.41359635e-03\n",
      " 9.99597728e-01 9.99683619e-01 9.99988198e-01 9.99982715e-01\n",
      " 9.99986649e-01 9.99189913e-01 9.96384501e-01 9.99999762e-01\n",
      " 9.99947548e-01 9.96518254e-01 4.92903143e-01 2.04908326e-01\n",
      " 9.32518184e-01 9.96136725e-01 9.98610258e-01 6.44561291e-01\n",
      " 9.99956131e-01 9.98935401e-01 9.99990821e-01 9.98526454e-01\n",
      " 9.99985337e-01 9.99520779e-01 9.99925852e-01 9.99042332e-01\n",
      " 9.60114300e-01 9.99670982e-01 9.98662114e-01 9.93051052e-01\n",
      " 5.37016355e-02 9.99738395e-01 9.99866605e-01 8.88267457e-01\n",
      " 7.60526299e-01 9.99999881e-01 9.99926567e-01 9.99999046e-01\n",
      " 5.09276867e-01 8.17337394e-01 9.99945760e-01 9.99814093e-01\n",
      " 7.12978661e-01 9.85146582e-01 9.14197639e-02 9.94872749e-01\n",
      " 2.96725571e-01 9.85586524e-01 9.87421036e-01 3.36273164e-01\n",
      " 1.62007601e-03 6.93668008e-01 9.85747874e-01 8.21734369e-01\n",
      " 9.99835849e-01 9.15826797e-01 2.91524362e-02 3.65866236e-02\n",
      " 9.99984264e-01 9.99967337e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 145 [0/107 (0%)]\tTrain Loss: 0.000436\n",
      "Train Epoch: 145 [4/107 (4%)]\tTrain Loss: 0.000043\n",
      "Train Epoch: 145 [8/107 (7%)]\tTrain Loss: 0.000267\n",
      "Train Epoch: 145 [12/107 (11%)]\tTrain Loss: 0.000248\n",
      "Train Epoch: 145 [16/107 (15%)]\tTrain Loss: 0.000025\n",
      "Train Epoch: 145 [20/107 (19%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 145 [24/107 (22%)]\tTrain Loss: 0.000133\n",
      "Train Epoch: 145 [28/107 (26%)]\tTrain Loss: 0.000147\n",
      "Train Epoch: 145 [32/107 (30%)]\tTrain Loss: 0.000162\n",
      "Train Epoch: 145 [36/107 (34%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 145 [40/107 (37%)]\tTrain Loss: 0.000237\n",
      "Train Epoch: 145 [44/107 (41%)]\tTrain Loss: 0.000114\n",
      "Train Epoch: 145 [48/107 (45%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 145 [52/107 (49%)]\tTrain Loss: 0.003919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [56/107 (52%)]\tTrain Loss: 0.000071\n",
      "Train Epoch: 145 [60/107 (56%)]\tTrain Loss: 0.000107\n",
      "Train Epoch: 145 [64/107 (60%)]\tTrain Loss: 0.000421\n",
      "Train Epoch: 145 [68/107 (64%)]\tTrain Loss: 0.000068\n",
      "Train Epoch: 145 [72/107 (67%)]\tTrain Loss: 0.002484\n",
      "Train Epoch: 145 [76/107 (71%)]\tTrain Loss: 0.000388\n",
      "Train Epoch: 145 [80/107 (75%)]\tTrain Loss: 0.001574\n",
      "Train Epoch: 145 [84/107 (79%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 145 [88/107 (82%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 145 [92/107 (86%)]\tTrain Loss: 0.000033\n",
      "Train Epoch: 145 [96/107 (90%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 145 [100/107 (93%)]\tTrain Loss: 0.000031\n",
      "Train Epoch: 145 [104/107 (97%)]\tTrain Loss: 0.000013\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.82845851e-03 9.56025422e-01 1.86650828e-03 2.05847211e-02\n",
      " 3.67835932e-03 4.98513575e-04 3.96950930e-01 7.55426940e-03\n",
      " 6.11351221e-04 1.53238820e-02 6.47532105e-01 5.92958077e-06\n",
      " 3.11991394e-01 6.11191907e-04 4.70646936e-03 7.79088350e-06\n",
      " 1.77238344e-05 2.13231280e-01 4.24993131e-03 5.10754548e-02\n",
      " 6.44921064e-01 9.83855426e-01 9.99897122e-01 9.99980092e-01\n",
      " 9.18591321e-01 9.99860048e-01 9.99907613e-01 1.19864820e-02\n",
      " 1.89180687e-01 1.61449076e-04 2.68394679e-01 2.11196067e-03\n",
      " 3.24877679e-01 3.24894222e-06 5.11780672e-06 2.93798395e-04\n",
      " 2.31654427e-04 9.40897048e-01 5.25178075e-01 2.49773279e-06\n",
      " 7.68476809e-07 3.79761659e-05 1.45461902e-01 9.78364646e-02\n",
      " 6.65763676e-01 5.21655194e-03 5.34695029e-01 4.15614188e-01\n",
      " 7.95327663e-01 2.83741839e-02 8.23290408e-01 3.30412702e-04\n",
      " 3.54105420e-03 6.64998195e-04 1.47740785e-02 2.34035067e-02\n",
      " 9.79020059e-01 2.91304104e-07 5.38779386e-05 3.37421079e-03\n",
      " 9.99794424e-01 9.99858499e-01 9.99996305e-01 9.99986768e-01\n",
      " 9.99991655e-01 9.99486446e-01 9.95734274e-01 9.99999881e-01\n",
      " 9.99957204e-01 9.98447657e-01 4.21549112e-01 1.59087196e-01\n",
      " 9.20894563e-01 9.95006680e-01 9.98790920e-01 5.53336740e-01\n",
      " 9.99982119e-01 9.99267995e-01 9.99994993e-01 9.99038577e-01\n",
      " 9.99991059e-01 9.99628425e-01 9.99924302e-01 9.98477995e-01\n",
      " 9.52957571e-01 9.99788582e-01 9.99200404e-01 9.97417331e-01\n",
      " 2.02237871e-02 9.99790967e-01 9.99813855e-01 8.88370574e-01\n",
      " 8.19654703e-01 9.99999881e-01 9.99885321e-01 9.99999046e-01\n",
      " 5.17872155e-01 6.35693848e-01 9.99951005e-01 9.99932408e-01\n",
      " 4.35469657e-01 9.91950512e-01 2.29597706e-02 9.92486000e-01\n",
      " 1.49300799e-01 9.78554666e-01 9.89694953e-01 3.55377883e-01\n",
      " 5.41688467e-04 5.99644780e-01 9.74511325e-01 5.37473202e-01\n",
      " 9.99826968e-01 8.73177648e-01 1.71843935e-02 8.04309268e-03\n",
      " 9.99990940e-01 9.99987721e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 146 [0/107 (0%)]\tTrain Loss: 0.000670\n",
      "Train Epoch: 146 [4/107 (4%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 146 [8/107 (7%)]\tTrain Loss: 0.000046\n",
      "Train Epoch: 146 [12/107 (11%)]\tTrain Loss: 0.000029\n",
      "Train Epoch: 146 [16/107 (15%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 146 [20/107 (19%)]\tTrain Loss: 0.000056\n",
      "Train Epoch: 146 [24/107 (22%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 146 [28/107 (26%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 146 [32/107 (30%)]\tTrain Loss: 0.001543\n",
      "Train Epoch: 146 [36/107 (34%)]\tTrain Loss: 0.000039\n",
      "Train Epoch: 146 [40/107 (37%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 146 [44/107 (41%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 146 [48/107 (45%)]\tTrain Loss: 0.000108\n",
      "Train Epoch: 146 [52/107 (49%)]\tTrain Loss: 0.000104\n",
      "Train Epoch: 146 [56/107 (52%)]\tTrain Loss: 0.000315\n",
      "Train Epoch: 146 [60/107 (56%)]\tTrain Loss: 0.000237\n",
      "Train Epoch: 146 [64/107 (60%)]\tTrain Loss: 0.002362\n",
      "Train Epoch: 146 [68/107 (64%)]\tTrain Loss: 0.000189\n",
      "Train Epoch: 146 [72/107 (67%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 146 [76/107 (71%)]\tTrain Loss: 0.000077\n",
      "Train Epoch: 146 [80/107 (75%)]\tTrain Loss: 0.000077\n",
      "Train Epoch: 146 [84/107 (79%)]\tTrain Loss: 0.000023\n",
      "Train Epoch: 146 [88/107 (82%)]\tTrain Loss: 0.000179\n",
      "Train Epoch: 146 [92/107 (86%)]\tTrain Loss: 0.000030\n",
      "Train Epoch: 146 [96/107 (90%)]\tTrain Loss: 0.000096\n",
      "Train Epoch: 146 [100/107 (93%)]\tTrain Loss: 0.002485\n",
      "Train Epoch: 146 [104/107 (97%)]\tTrain Loss: 0.000004\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.79318525e-03 9.70958233e-01 2.13881861e-03 6.34639263e-02\n",
      " 8.46477784e-03 6.38961094e-04 4.70852226e-01 3.22110839e-02\n",
      " 1.05875963e-03 1.89848207e-02 7.61120498e-01 1.64402009e-05\n",
      " 3.59334677e-01 2.84769386e-03 1.23031288e-02 3.87663567e-05\n",
      " 6.76731797e-05 4.63610232e-01 1.58300847e-02 1.86819777e-01\n",
      " 7.94244945e-01 9.85636711e-01 9.99905705e-01 9.99980211e-01\n",
      " 9.53339875e-01 9.99795496e-01 9.99956727e-01 1.77224234e-01\n",
      " 4.02058452e-01 4.13668749e-04 5.51533699e-01 7.07737822e-03\n",
      " 4.68334496e-01 8.80702828e-06 1.44914311e-05 5.24925883e-04\n",
      " 5.67945011e-04 9.77339447e-01 7.84120679e-01 1.09589309e-05\n",
      " 4.28096291e-06 1.58958908e-04 3.04500937e-01 2.57948995e-01\n",
      " 7.60037601e-01 1.09295649e-02 6.56000376e-01 4.19832796e-01\n",
      " 8.44828427e-01 5.58816008e-02 8.80928874e-01 5.13644307e-04\n",
      " 1.16448486e-02 8.51320196e-03 6.65800348e-02 6.35338202e-02\n",
      " 9.90037203e-01 1.26918633e-06 9.16876743e-05 2.96431538e-02\n",
      " 9.99868155e-01 9.99881506e-01 9.99996305e-01 9.99992967e-01\n",
      " 9.99994636e-01 9.99614954e-01 9.98082995e-01 9.99999881e-01\n",
      " 9.99965906e-01 9.98547018e-01 6.49825633e-01 2.55721688e-01\n",
      " 9.77065325e-01 9.98604238e-01 9.99527812e-01 9.33854878e-01\n",
      " 9.99980330e-01 9.99320388e-01 9.99994040e-01 9.99222994e-01\n",
      " 9.99992251e-01 9.99805629e-01 9.99959588e-01 9.99441683e-01\n",
      " 9.62072134e-01 9.99872088e-01 9.99333680e-01 9.97566223e-01\n",
      " 1.59511968e-01 9.99804914e-01 9.99859452e-01 9.26556408e-01\n",
      " 8.75120819e-01 1.00000000e+00 9.99959707e-01 9.99999523e-01\n",
      " 6.80519700e-01 8.37959766e-01 9.99951005e-01 9.99899745e-01\n",
      " 6.82195842e-01 9.88424897e-01 1.58058405e-01 9.96381640e-01\n",
      " 3.19159478e-01 9.92167771e-01 9.92384434e-01 3.88071835e-01\n",
      " 2.10338761e-03 7.48501003e-01 9.90350187e-01 7.21033096e-01\n",
      " 9.99860168e-01 8.90403569e-01 3.26359682e-02 3.58438045e-02\n",
      " 9.99994040e-01 9.99984145e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 147 [0/107 (0%)]\tTrain Loss: 0.000106\n",
      "Train Epoch: 147 [4/107 (4%)]\tTrain Loss: 0.000168\n",
      "Train Epoch: 147 [8/107 (7%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 147 [12/107 (11%)]\tTrain Loss: 0.004510\n",
      "Train Epoch: 147 [16/107 (15%)]\tTrain Loss: 0.000069\n",
      "Train Epoch: 147 [20/107 (19%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 147 [24/107 (22%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 147 [28/107 (26%)]\tTrain Loss: 0.001142\n",
      "Train Epoch: 147 [32/107 (30%)]\tTrain Loss: 0.000100\n",
      "Train Epoch: 147 [36/107 (34%)]\tTrain Loss: 0.000086\n",
      "Train Epoch: 147 [40/107 (37%)]\tTrain Loss: 0.000011\n",
      "Train Epoch: 147 [44/107 (41%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 147 [48/107 (45%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 147 [52/107 (49%)]\tTrain Loss: 0.000001\n",
      "Train Epoch: 147 [56/107 (52%)]\tTrain Loss: 0.000415\n",
      "Train Epoch: 147 [60/107 (56%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 147 [64/107 (60%)]\tTrain Loss: 0.000704\n",
      "Train Epoch: 147 [68/107 (64%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 147 [72/107 (67%)]\tTrain Loss: 0.000030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [76/107 (71%)]\tTrain Loss: 0.001120\n",
      "Train Epoch: 147 [80/107 (75%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 147 [84/107 (79%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 147 [88/107 (82%)]\tTrain Loss: 0.000064\n",
      "Train Epoch: 147 [92/107 (86%)]\tTrain Loss: 0.000149\n",
      "Train Epoch: 147 [96/107 (90%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 147 [100/107 (93%)]\tTrain Loss: 0.000369\n",
      "Train Epoch: 147 [104/107 (97%)]\tTrain Loss: 0.000086\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.82866676e-04 9.25944090e-01 1.82546070e-03 1.32247098e-02\n",
      " 5.09027019e-03 2.41811969e-04 2.91479886e-01 5.82555868e-03\n",
      " 3.49435228e-04 1.00223245e-02 7.99297631e-01 5.50901314e-06\n",
      " 4.37281549e-01 1.01543521e-03 7.30926357e-03 6.04537172e-06\n",
      " 6.39580503e-06 2.06209034e-01 5.45291184e-03 1.12005919e-01\n",
      " 4.89973098e-01 9.68702912e-01 9.99935508e-01 9.99975562e-01\n",
      " 8.76490951e-01 9.99761403e-01 9.99732673e-01 1.69846937e-02\n",
      " 3.29592347e-01 2.99470761e-04 1.64873332e-01 3.74595681e-03\n",
      " 4.36374485e-01 2.87993134e-06 2.83201030e-06 2.11749953e-04\n",
      " 3.00600281e-04 9.38290000e-01 6.37257040e-01 2.65389508e-06\n",
      " 1.08716358e-06 4.24594837e-05 7.88360760e-02 1.32721737e-01\n",
      " 8.10370505e-01 5.91774238e-03 6.00298464e-01 4.06801283e-01\n",
      " 8.42147768e-01 2.76769716e-02 8.33979607e-01 2.34310515e-04\n",
      " 2.34656362e-03 4.61778662e-04 1.52621148e-02 4.59359996e-02\n",
      " 9.82316554e-01 2.62447514e-07 2.77419513e-05 2.37912009e-03\n",
      " 9.99767840e-01 9.99822080e-01 9.99986768e-01 9.99975443e-01\n",
      " 9.99989986e-01 9.99486804e-01 9.94037747e-01 9.99999404e-01\n",
      " 9.99923706e-01 9.98345137e-01 3.51780772e-01 1.35871813e-01\n",
      " 9.48527157e-01 9.96538162e-01 9.99145627e-01 5.57724476e-01\n",
      " 9.99901652e-01 9.97836530e-01 9.99991059e-01 9.98700738e-01\n",
      " 9.99983191e-01 9.99143720e-01 9.99903798e-01 9.98030245e-01\n",
      " 9.54975426e-01 9.99649048e-01 9.99083519e-01 9.96207237e-01\n",
      " 2.72299629e-02 9.98946130e-01 9.99258816e-01 8.84119987e-01\n",
      " 8.26551974e-01 9.99999881e-01 9.99861121e-01 9.99995947e-01\n",
      " 4.72201347e-01 6.56460702e-01 9.99916792e-01 9.99808252e-01\n",
      " 5.41458905e-01 9.88988578e-01 3.28228511e-02 9.90189135e-01\n",
      " 1.20548956e-01 9.87126052e-01 9.84988928e-01 2.76416451e-01\n",
      " 1.27294671e-03 6.03618860e-01 9.61943924e-01 5.71675241e-01\n",
      " 9.99556720e-01 8.63738298e-01 2.55962275e-02 1.69192012e-02\n",
      " 9.99933600e-01 9.99852180e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 148 [0/107 (0%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 148 [4/107 (4%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 148 [8/107 (7%)]\tTrain Loss: 0.000045\n",
      "Train Epoch: 148 [12/107 (11%)]\tTrain Loss: 0.000496\n",
      "Train Epoch: 148 [16/107 (15%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 148 [20/107 (19%)]\tTrain Loss: 0.002697\n",
      "Train Epoch: 148 [24/107 (22%)]\tTrain Loss: 0.000077\n",
      "Train Epoch: 148 [28/107 (26%)]\tTrain Loss: 0.000026\n",
      "Train Epoch: 148 [32/107 (30%)]\tTrain Loss: 0.001193\n",
      "Train Epoch: 148 [36/107 (34%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 148 [40/107 (37%)]\tTrain Loss: 0.000048\n",
      "Train Epoch: 148 [44/107 (41%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 148 [48/107 (45%)]\tTrain Loss: 0.000310\n",
      "Train Epoch: 148 [52/107 (49%)]\tTrain Loss: 0.000140\n",
      "Train Epoch: 148 [56/107 (52%)]\tTrain Loss: 0.000085\n",
      "Train Epoch: 148 [60/107 (56%)]\tTrain Loss: 0.005116\n",
      "Train Epoch: 148 [64/107 (60%)]\tTrain Loss: 0.000197\n",
      "Train Epoch: 148 [68/107 (64%)]\tTrain Loss: 0.000038\n",
      "Train Epoch: 148 [72/107 (67%)]\tTrain Loss: 0.000744\n",
      "Train Epoch: 148 [76/107 (71%)]\tTrain Loss: 0.000758\n",
      "Train Epoch: 148 [80/107 (75%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 148 [84/107 (79%)]\tTrain Loss: 0.000345\n",
      "Train Epoch: 148 [88/107 (82%)]\tTrain Loss: 0.000121\n",
      "Train Epoch: 148 [92/107 (86%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 148 [96/107 (90%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 148 [100/107 (93%)]\tTrain Loss: 0.000027\n",
      "Train Epoch: 148 [104/107 (97%)]\tTrain Loss: 0.000206\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.38198699e-04 9.47799206e-01 1.49060413e-03 2.21095029e-02\n",
      " 3.30680609e-03 2.40954556e-04 1.26549155e-01 1.18797570e-02\n",
      " 4.92776511e-04 9.77337547e-03 5.38435638e-01 4.16440025e-06\n",
      " 2.41157562e-01 9.25793138e-04 5.80399064e-03 1.49475572e-05\n",
      " 1.57750819e-05 4.67530221e-01 4.83529549e-03 9.92666483e-02\n",
      " 6.45934403e-01 9.79797721e-01 9.99887466e-01 9.99980927e-01\n",
      " 8.74795198e-01 9.99858260e-01 9.99928355e-01 8.38674754e-02\n",
      " 2.45679274e-01 2.07274279e-04 4.67849880e-01 2.44239834e-03\n",
      " 4.55377281e-01 2.20253787e-06 3.11702047e-06 1.30802480e-04\n",
      " 1.91121973e-04 9.82495427e-01 7.37032413e-01 3.26900522e-06\n",
      " 8.56863778e-07 4.05566898e-05 2.48851314e-01 1.84704095e-01\n",
      " 7.08165586e-01 5.05036674e-03 5.37549078e-01 3.15378934e-01\n",
      " 7.89396048e-01 2.33393479e-02 8.33741367e-01 2.23312294e-04\n",
      " 3.68478615e-03 1.71396590e-03 1.89205352e-02 3.60566713e-02\n",
      " 9.89690065e-01 4.63626691e-07 3.52200404e-05 1.17652612e-02\n",
      " 9.99824345e-01 9.99893427e-01 9.99995708e-01 9.99987721e-01\n",
      " 9.99995232e-01 9.99723613e-01 9.98056829e-01 9.99999881e-01\n",
      " 9.99968410e-01 9.98319805e-01 5.46168566e-01 1.73527971e-01\n",
      " 9.67036128e-01 9.96381223e-01 9.99296546e-01 8.21612120e-01\n",
      " 9.99966264e-01 9.99363005e-01 9.99992967e-01 9.98776019e-01\n",
      " 9.99988914e-01 9.99636769e-01 9.99949098e-01 9.99582946e-01\n",
      " 9.58107293e-01 9.99846816e-01 9.99411345e-01 9.97166574e-01\n",
      " 7.30175003e-02 9.99551475e-01 9.99899387e-01 8.99837255e-01\n",
      " 8.56444478e-01 9.99999881e-01 9.99926805e-01 9.99999166e-01\n",
      " 5.66609919e-01 6.96916223e-01 9.99871492e-01 9.99878168e-01\n",
      " 3.19873601e-01 9.89239335e-01 2.21107565e-02 9.94415283e-01\n",
      " 2.65297711e-01 9.94227171e-01 9.90835547e-01 1.58249199e-01\n",
      " 1.00534700e-03 6.75170243e-01 9.72891390e-01 7.00682759e-01\n",
      " 9.99865651e-01 8.50333571e-01 1.78169087e-02 1.44442664e-02\n",
      " 9.99996781e-01 9.99929428e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 149 [0/107 (0%)]\tTrain Loss: 0.000009\n",
      "Train Epoch: 149 [4/107 (4%)]\tTrain Loss: 0.000407\n",
      "Train Epoch: 149 [8/107 (7%)]\tTrain Loss: 0.000078\n",
      "Train Epoch: 149 [12/107 (11%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 149 [16/107 (15%)]\tTrain Loss: 0.000609\n",
      "Train Epoch: 149 [20/107 (19%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 149 [24/107 (22%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 149 [28/107 (26%)]\tTrain Loss: 0.001123\n",
      "Train Epoch: 149 [32/107 (30%)]\tTrain Loss: 0.000138\n",
      "Train Epoch: 149 [36/107 (34%)]\tTrain Loss: 0.000232\n",
      "Train Epoch: 149 [40/107 (37%)]\tTrain Loss: 0.000266\n",
      "Train Epoch: 149 [44/107 (41%)]\tTrain Loss: 0.000684\n",
      "Train Epoch: 149 [48/107 (45%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 149 [52/107 (49%)]\tTrain Loss: 0.000471\n",
      "Train Epoch: 149 [56/107 (52%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 149 [60/107 (56%)]\tTrain Loss: 0.000445\n",
      "Train Epoch: 149 [64/107 (60%)]\tTrain Loss: 0.000113\n",
      "Train Epoch: 149 [68/107 (64%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 149 [72/107 (67%)]\tTrain Loss: 0.000015\n",
      "Train Epoch: 149 [76/107 (71%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 149 [80/107 (75%)]\tTrain Loss: 0.000081\n",
      "Train Epoch: 149 [84/107 (79%)]\tTrain Loss: 0.000671\n",
      "Train Epoch: 149 [88/107 (82%)]\tTrain Loss: 0.000781\n",
      "Train Epoch: 149 [92/107 (86%)]\tTrain Loss: 0.000760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149 [96/107 (90%)]\tTrain Loss: 0.000971\n",
      "Train Epoch: 149 [100/107 (93%)]\tTrain Loss: 0.000054\n",
      "Train Epoch: 149 [104/107 (97%)]\tTrain Loss: 0.000076\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.19647651e-03 8.91037643e-01 1.70233659e-03 1.76942218e-02\n",
      " 5.26326569e-03 2.94901460e-04 1.73738852e-01 7.42372312e-03\n",
      " 4.03777929e-04 8.52477830e-03 6.71785593e-01 7.85663178e-06\n",
      " 4.04626906e-01 5.96568163e-04 6.13709632e-03 7.10037875e-06\n",
      " 1.35479586e-05 1.68394595e-01 5.41522307e-03 1.14712372e-01\n",
      " 5.25727093e-01 9.54915941e-01 9.99868274e-01 9.99945760e-01\n",
      " 8.19057763e-01 9.99658823e-01 9.99565303e-01 2.42708754e-02\n",
      " 2.92956173e-01 2.38754248e-04 1.85012370e-01 4.68154857e-03\n",
      " 4.51299906e-01 3.49820016e-06 1.97797044e-06 1.64307319e-04\n",
      " 2.04283511e-04 9.46272790e-01 5.40968180e-01 1.96471251e-06\n",
      " 7.64758511e-07 2.11012684e-05 6.57088682e-02 1.10582992e-01\n",
      " 7.45631397e-01 5.67002641e-03 4.83463198e-01 2.93906212e-01\n",
      " 7.21591949e-01 2.34734658e-02 8.09706092e-01 1.69157036e-04\n",
      " 1.72109762e-03 6.28343201e-04 8.29800405e-03 3.16848084e-02\n",
      " 9.82641160e-01 1.22263444e-07 3.88495318e-05 4.83572343e-03\n",
      " 9.99471962e-01 9.99555528e-01 9.99968529e-01 9.99946117e-01\n",
      " 9.99985933e-01 9.98979509e-01 9.95725989e-01 9.99997854e-01\n",
      " 9.99896407e-01 9.97658014e-01 3.13039988e-01 8.28058496e-02\n",
      " 9.47771907e-01 9.94472444e-01 9.98284757e-01 6.39237225e-01\n",
      " 9.99854684e-01 9.97536659e-01 9.99984503e-01 9.97905374e-01\n",
      " 9.99967456e-01 9.99042332e-01 9.99753058e-01 9.97873425e-01\n",
      " 9.44310308e-01 9.99372303e-01 9.98922527e-01 9.93933976e-01\n",
      " 2.57371198e-02 9.96736348e-01 9.98948872e-01 8.42187524e-01\n",
      " 8.35556865e-01 9.99999523e-01 9.99834180e-01 9.99991655e-01\n",
      " 4.75769341e-01 6.83795512e-01 9.99722064e-01 9.99370158e-01\n",
      " 2.64538705e-01 9.75156009e-01 2.89400741e-02 9.89874005e-01\n",
      " 1.26830056e-01 9.87515092e-01 9.86596406e-01 6.26157895e-02\n",
      " 4.70435130e-04 4.65124577e-01 9.33267117e-01 5.25049984e-01\n",
      " 9.98619080e-01 7.13973880e-01 2.23638806e-02 2.19952855e-02\n",
      " 9.99889135e-01 9.99611914e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 150 [0/107 (0%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 150 [4/107 (4%)]\tTrain Loss: 0.000569\n",
      "Train Epoch: 150 [8/107 (7%)]\tTrain Loss: 0.000391\n",
      "Train Epoch: 150 [12/107 (11%)]\tTrain Loss: 0.000007\n",
      "Train Epoch: 150 [16/107 (15%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 150 [20/107 (19%)]\tTrain Loss: 0.000008\n",
      "Train Epoch: 150 [24/107 (22%)]\tTrain Loss: 0.001872\n",
      "Train Epoch: 150 [28/107 (26%)]\tTrain Loss: 0.001526\n",
      "Train Epoch: 150 [32/107 (30%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 150 [36/107 (34%)]\tTrain Loss: 0.000024\n",
      "Train Epoch: 150 [40/107 (37%)]\tTrain Loss: 0.000006\n",
      "Train Epoch: 150 [44/107 (41%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 150 [48/107 (45%)]\tTrain Loss: 0.000062\n",
      "Train Epoch: 150 [52/107 (49%)]\tTrain Loss: 0.000124\n",
      "Train Epoch: 150 [56/107 (52%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 150 [60/107 (56%)]\tTrain Loss: 0.000472\n",
      "Train Epoch: 150 [64/107 (60%)]\tTrain Loss: 0.000239\n",
      "Train Epoch: 150 [68/107 (64%)]\tTrain Loss: 0.000021\n",
      "Train Epoch: 150 [72/107 (67%)]\tTrain Loss: 0.000020\n",
      "Train Epoch: 150 [76/107 (71%)]\tTrain Loss: 0.000338\n",
      "Train Epoch: 150 [80/107 (75%)]\tTrain Loss: 0.000183\n",
      "Train Epoch: 150 [84/107 (79%)]\tTrain Loss: 0.000032\n",
      "Train Epoch: 150 [88/107 (82%)]\tTrain Loss: 0.000412\n",
      "Train Epoch: 150 [92/107 (86%)]\tTrain Loss: 0.001325\n",
      "Train Epoch: 150 [96/107 (90%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 150 [100/107 (93%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 150 [104/107 (97%)]\tTrain Loss: 0.000012\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.74947407e-04 9.43188488e-01 1.28949224e-03 1.95035953e-02\n",
      " 2.51246919e-03 2.57295527e-04 5.60551882e-01 7.80920079e-03\n",
      " 2.85374990e-04 6.47919532e-03 7.53495336e-01 3.61119373e-06\n",
      " 4.03085291e-01 6.27965259e-04 4.81925579e-03 5.73047191e-06\n",
      " 1.65724123e-05 2.34017074e-01 2.83776363e-03 5.71398549e-02\n",
      " 4.78431433e-01 9.79964316e-01 9.99821842e-01 9.99957323e-01\n",
      " 9.31752801e-01 9.99720752e-01 9.99736845e-01 9.97948740e-03\n",
      " 1.34133518e-01 2.34385589e-04 2.87304014e-01 2.32761493e-03\n",
      " 3.43124747e-01 1.62580784e-06 2.03923287e-06 1.91452782e-04\n",
      " 2.42916591e-04 9.58732784e-01 8.11142921e-01 4.15134264e-06\n",
      " 1.21772314e-06 5.85413654e-05 9.82087553e-02 8.77899379e-02\n",
      " 6.39425755e-01 4.17203736e-03 6.08743727e-01 4.69599724e-01\n",
      " 8.31646919e-01 2.23770794e-02 8.75225365e-01 2.29307116e-04\n",
      " 1.59657397e-03 3.42917105e-04 5.53394947e-03 2.66448129e-02\n",
      " 9.74938512e-01 1.57830044e-07 2.34586714e-05 2.52156472e-03\n",
      " 9.99686956e-01 9.99740422e-01 9.99987960e-01 9.99977469e-01\n",
      " 9.99989748e-01 9.99345362e-01 9.95655298e-01 9.99999166e-01\n",
      " 9.99920249e-01 9.98591363e-01 4.21809167e-01 1.30604237e-01\n",
      " 9.16361451e-01 9.94982600e-01 9.98374462e-01 4.18518215e-01\n",
      " 9.99937415e-01 9.98449564e-01 9.99987364e-01 9.98657227e-01\n",
      " 9.99982476e-01 9.99072433e-01 9.99863386e-01 9.98881638e-01\n",
      " 9.47079420e-01 9.99708712e-01 9.99246240e-01 9.96894598e-01\n",
      " 2.78631262e-02 9.98991191e-01 9.99594152e-01 8.73500884e-01\n",
      " 7.70804822e-01 9.99999762e-01 9.99868274e-01 9.99996543e-01\n",
      " 4.69296277e-01 5.95216513e-01 9.99862671e-01 9.99691725e-01\n",
      " 3.18335056e-01 9.91626382e-01 1.24104150e-01 9.91969168e-01\n",
      " 1.12962022e-01 9.77627277e-01 9.85392153e-01 3.02822471e-01\n",
      " 1.37992774e-03 3.74867290e-01 9.87236321e-01 7.62492061e-01\n",
      " 9.99620199e-01 8.58712077e-01 2.44182050e-02 2.58518066e-02\n",
      " 9.99959350e-01 9.99945283e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 48 TN= 44 FN= 10 FP= 16\n",
      "TP+FP 64\n",
      "precision 0.75\n",
      "recall 0.8275862068965517\n",
      "F1 0.7868852459016394\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7804597701149425\n",
      "AUC 0.8652298850574712\n",
      "\n",
      " The epoch is 150, average recall: 0.8276, average precision: 0.7500,average F1: 0.7869, average accuracy: 0.7797, average AUC: 0.8652\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "bs =batchsize\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "total_epoch = 150\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9, weight_decay=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_epoch)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "                                             \n",
    "# scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), 'save_model_dense/covid_moco.pt')  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "#         f = open('model_result/medical_transfer/{}_{}.txt'.format(modelname,alpha_name), 'a+')\n",
    "#         f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "# average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "#         epoch, r, p, F1, acc, AUC))\n",
    "#         f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.47594779e-04 9.98058617e-01 3.67927761e-03 1.28029594e-02\n",
      " 8.36032050e-05 7.28268921e-03 8.32518781e-05 9.99179065e-01\n",
      " 3.09764268e-03 6.27140999e-01 5.74265718e-01 3.47314805e-01\n",
      " 4.80874302e-03 9.63134289e-01 1.34913191e-01 3.01472038e-01\n",
      " 2.49140069e-01 3.23192978e-07 1.51178538e-04 2.29170560e-04\n",
      " 1.46424090e-05 3.13428580e-04 4.83794508e-07 3.86625089e-07\n",
      " 1.91339932e-05 6.67027780e-05 1.61692776e-06 2.12903798e-01\n",
      " 9.57206066e-04 4.00580376e-01 1.64042652e-01 2.63241143e-03\n",
      " 9.34342295e-03 2.73087947e-03 4.40167962e-03 7.79349566e-01\n",
      " 4.53986973e-03 8.02293699e-03 2.62391362e-02 2.30709044e-03\n",
      " 4.00859118e-03 1.75315198e-02 2.33135093e-03 1.39698343e-04\n",
      " 3.54320020e-03 1.08914777e-04 1.05077542e-01 1.23856943e-02\n",
      " 9.75355089e-01 9.61774647e-01 2.89906356e-02 2.11848572e-04\n",
      " 9.83990908e-01 7.28562415e-01 4.51403263e-04 4.32842644e-03\n",
      " 5.21427132e-02 8.71169493e-02 9.99997020e-01 9.99937415e-01\n",
      " 4.90138555e-05 9.95414734e-01 3.88257467e-04 9.09706280e-02\n",
      " 1.42089193e-04 1.11948140e-07 5.55807333e-07 7.03852056e-05\n",
      " 2.58225769e-01 9.99578178e-01 2.80630705e-03 1.20949873e-03\n",
      " 2.45784817e-04 6.30341237e-04 9.18808859e-03 1.28324114e-04\n",
      " 1.48145659e-02 9.81136262e-01 7.67214298e-02 6.71794057e-01\n",
      " 1.00913802e-02 5.62368287e-03 3.08380816e-02 3.20545398e-03\n",
      " 7.31916225e-05 3.56118828e-02 6.82373941e-01 9.07301605e-02\n",
      " 8.11956823e-02 5.68491332e-02 3.04370821e-02 1.80148885e-01\n",
      " 4.54370409e-01 1.13886665e-03 5.26871812e-03 4.28487696e-02\n",
      " 9.99164701e-01 9.89085138e-01 9.99964833e-01 9.76476848e-01\n",
      " 9.98308897e-01 9.99998212e-01 9.99997377e-01 6.25769556e-01\n",
      " 9.78288651e-01 9.98112082e-01 9.89612401e-01 9.82734263e-01\n",
      " 9.97002304e-01 9.99205768e-01 9.99455273e-01 9.98785555e-01\n",
      " 9.97626126e-01 9.97389138e-01 9.99215007e-01 9.99512792e-01\n",
      " 9.99284565e-01 9.99510050e-01 9.99370754e-01 9.99749959e-01\n",
      " 9.98635471e-01 9.99742210e-01 9.99686003e-01 9.99212503e-01\n",
      " 9.99046862e-01 9.99994040e-01 9.99730051e-01 9.98987377e-01\n",
      " 9.99759972e-01 9.98003542e-01 9.10258770e-01 9.95286584e-01\n",
      " 9.86934185e-01 9.98901010e-01 9.99774039e-01 9.84794557e-01\n",
      " 9.99878407e-01 9.99881983e-01 9.99935150e-01 9.99632359e-01\n",
      " 9.95713592e-01 9.93093371e-01 9.99922395e-01 9.94816720e-01\n",
      " 9.37819839e-01 8.91331971e-01 9.99723971e-01 8.90728176e-01\n",
      " 6.86543584e-02 9.99998331e-01 9.98719573e-01 9.76893842e-01\n",
      " 9.91896570e-01 9.61810708e-01 9.80218053e-01 9.99673605e-01\n",
      " 9.99276340e-01 9.98904109e-01 9.77044046e-01 1.22908634e-04\n",
      " 3.48549858e-02 9.99937296e-01 9.47124541e-01 9.95366812e-01\n",
      " 9.41981912e-01 9.99461353e-01 3.14363182e-01 9.99981046e-01\n",
      " 9.80276585e-01 8.65137279e-01 4.06104252e-02 1.53169721e-01\n",
      " 9.77523506e-01 8.77337217e-01 9.98873413e-01 4.45292920e-01\n",
      " 9.96472538e-01 9.14944172e-01 9.51633692e-01 1.13782547e-01\n",
      " 1.00829534e-01 8.33891754e-05 6.48235087e-04 9.99746025e-01\n",
      " 9.98686969e-01 9.98196661e-01 9.98371899e-01 9.96212482e-01\n",
      " 3.85694876e-02 4.61361080e-01 1.80192571e-02 8.22721124e-01\n",
      " 9.98344421e-01 9.99666452e-01 9.98133242e-01 9.94180739e-01\n",
      " 9.99992251e-01 9.99260128e-01 9.99732316e-01 9.94265020e-01\n",
      " 8.44723135e-02 1.06623142e-04 7.23147511e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "TP= 89 TN= 79 FN= 16 FP= 19\n",
      "TP+FP 108\n",
      "precision 0.8240740740740741\n",
      "recall 0.8476190476190476\n",
      "F1 0.8356807511737089\n",
      "acc 0.8275862068965517\n",
      "AUC 0.8810495626822158\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "bs = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epoch = 1\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "\n",
    "targetlist, scorelist, predlist = test(epoch)\n",
    "print('target',targetlist)\n",
    "print('score',scorelist)\n",
    "print('predict',predlist)\n",
    "vote_pred = vote_pred + predlist \n",
    "vote_score = vote_score + scorelist \n",
    "\n",
    "TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "\n",
    "TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "print('TP+FP',TP+FP)\n",
    "p = TP / (TP + FP)\n",
    "print('precision',p)\n",
    "p = TP / (TP + FP)\n",
    "r = TP / (TP + FN)\n",
    "print('recall',r)\n",
    "F1 = 2 * r * p / (r + p)\n",
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "print('F1',F1)\n",
    "print('acc',acc)\n",
    "AUC = roc_auc_score(targetlist, vote_score)\n",
    "print('AUC', AUC)\n",
    "\n",
    "# f = open(f'model_result/medical_transfer/test_{modelname}_{alpha_name}_LUNA_moco_CT_moco.txt', 'a+')\n",
    "# f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "# average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "# epoch, r, p, F1, acc, AUC))\n",
    "# f.close()\n",
    "# torch.save(model.state_dict(), \"model_backup/medical_transfer/{}_{}_covid_moco_covid.pt\".format(modelname,alpha_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
